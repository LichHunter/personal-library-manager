{
  "benchmark_run_at": "2026-01-27T18:40:19.204042",
  "needle_doc_id": "tasks_administer-cluster_topology-manager",
  "total_documents": 1569,
  "total_chunks": 7269,
  "needle_chunks": 14,
  "index_time_s": 112.4,
  "index_stats": {
    "num_chunks": 7269,
    "embedding_dim": 768,
    "bm25_avg_doc_len": 191.32576695556472,
    "rrf_k": 60,
    "enrichment_time_s": 1.0528104305267334,
    "rewrite_timeout_s": 5.0,
    "enricher_stats": {
      "total_processed": 0,
      "total_time_s": 0.0,
      "avg_time_ms": 0.0
    }
  },
  "summary": {
    "total_questions": 20,
    "needle_found_count": 14,
    "needle_found_rate": 70.0,
    "avg_latency_ms": 1123.0
  },
  "results": [
    {
      "question_id": "adv_v01",
      "question": "What's the minimum kubernetes version requirement for topology manager?",
      "expected_answer": "v1.18",
      "category": "VERSION",
      "latency_ms": 1071.9,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}}\n\n{{< version-check >}} If you are running an older version of Kubernetes, check the documentation\nfor the version of Kubernetes you are running.\n\n### Resource alignment prerequisites\n\nTo align memory resources with other requested resources in a Pod spec:\n\n- the CPU Manager should be enabled and proper CPU Manager policy should be configured on a Node.\n  See [control CPU Management Policies](/docs/tasks/administer-cluster/cpu-management-policies/);\n- the Topology Manager should be enabled and proper Topology Manager policy should be configured on a Node.\n  See [control Topology Management Policies](/docs/tasks/administer-cluster/topology-manager/).",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_9",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policy options\n\nSupport for the Topology Manager policy options requires `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) to be enabled\n(it is enabled by default).\n\nYou can toggle groups of options on and off based upon their maturity level using the following feature gates:\n\n* `TopologyManagerPolicyBetaOptions` default enabled. Enable to show beta-level options.\n* `TopologyManagerPolicyAlphaOptions` default disabled. Enable to show alpha-level options.\n\nYou will still have to enable each option using the `TopologyManagerPolicyOptions` kubelet option.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_extend-kubernetes_compute-storage-net_device-plugins_mdsem_7",
          "doc_id": "concepts_extend-kubernetes_compute-storage-net_device-plugins",
          "content": "## API compatibility\n\nPreviously, the versioning scheme required the Device Plugin's API version to match\nexactly the Kubelet's version. Since the graduation of this feature to Beta in v1.12\nthis is no longer a hard requirement. The API is versioned and has been stable since\nBeta graduation of this feature. Because of this, kubelet upgrades should be seamless\nbut there still may be changes in the API before stabilization making upgrades not\nguaranteed to be non-breaking.\n\n{{< note >}}\nAlthough the Device Manager component of Kubernetes is a generally available feature,\nthe _device plugin API_ is not stable. For information on the device plugin API and\nversion compatibility, read [Device Plugin API versions](/docs/reference/node/device-plugin-api-versions/).\n{{< /note >}}\n\nAs a project, Kubernetes recommends that device plugin developers:\n\n* Watch for Device Plugin API changes in the future releases.\n* Support multiple versions of the device plugin API for backward/forward compatibility.\n\nTo run device plugins on nodes that need to be upgraded to a Kubernetes release with\na newer device plugin API version, upgrade your device plugins to support both versions\nbefore upgrading these nodes. Taking that approach will ensure the continuous functioning\nof the device allocations during the upgrade.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Windows Support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nThe Topology Manager support can be enabled on Windows by using the `WindowsCPUAndMemoryAffinity` feature gate and\nit requires support in the container runtime.\n\n## Topology manager scopes and policies\n\nThe Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_v02",
      "question": "Which Kubernetes release made Topology Manager GA/stable?",
      "expected_answer": "v1.27",
      "category": "VERSION",
      "latency_ms": 1075.8,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}}\n\n{{< version-check >}} If you are running an older version of Kubernetes, check the documentation\nfor the version of Kubernetes you are running.\n\n### Resource alignment prerequisites\n\nTo align memory resources with other requested resources in a Pod spec:\n\n- the CPU Manager should be enabled and proper CPU Manager policy should be configured on a Node.\n  See [control CPU Management Policies](/docs/tasks/administer-cluster/cpu-management-policies/);\n- the Topology Manager should be enabled and proper Topology Manager policy should be configured on a Node.\n  See [control Topology Management Policies](/docs/tasks/administer-cluster/topology-manager/).",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_9",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policy options\n\nSupport for the Topology Manager policy options requires `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) to be enabled\n(it is enabled by default).\n\nYou can toggle groups of options on and off based upon their maturity level using the following feature gates:\n\n* `TopologyManagerPolicyBetaOptions` default enabled. Enable to show beta-level options.\n* `TopologyManagerPolicyAlphaOptions` default disabled. Enable to show alpha-level options.\n\nYou will still have to enable each option using the `TopologyManagerPolicyOptions` kubelet option.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n<!-- steps -->\n\n## How topology manager works\n\nPrior to the introduction of Topology Manager, the CPU and Device Manager in Kubernetes make\nresource allocation decisions independently of each other. This can result in undesirable\nallocations on multiple-socketed systems, and performance/latency sensitive applications will suffer\ndue to these undesirable allocations. Undesirable in this case meaning, for example, CPUs and\ndevices being allocated from different NUMA Nodes, thus incurring additional latency.\n\nThe Topology Manager is a kubelet component, which acts as a source of truth so that other kubelet\ncomponents can make topology aligned resource allocation choices.\n\nThe Topology Manager provides an interface for components, called *Hint Providers*, to send and\nreceive topology information. The Topology Manager has a set of node level policies which are\nexplained below.\n\nThe Topology Manager receives topology information from the *Hint Providers* as a bitmask denoting\nNUMA Nodes available and a preferred allocation indication. The Topology Manager policies perform\na set of operations on the hints provided and converge on the hint determined by the policy to\ngive the optimal result. If an undesirable hint is stored, the preferred field for the hint will be\nset to false. In the current policies preferred is the narrowest preferred mask.\nThe selected hint is stored as part of the Topology Manager. Depending on the policy configured,\nthe pod can be accepted or rejected from the node based on the selected hint.\nThe hint is then stored in the Topology Manager for use by the *Hint Providers* when making the\nresource allocation decisions.\n\nThe flow can be seen in the following diagram.\n\n![topology_manager_flow](/images/docs/topology-manager-flow.png)",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_v03",
      "question": "When did the prefer-closest-numa-nodes option become generally available?",
      "expected_answer": "Kubernetes 1.32",
      "category": "VERSION",
      "latency_ms": 1071.4,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "reference_using-api_deprecation-policy_mdsem_2",
          "doc_id": "reference_using-api_deprecation-policy",
          "content": "## Deprecating parts of the API (continued)\n\n**Rule #3: An API version in a given track may not be deprecated in favor of a less stable API version.**\n\n* GA API versions can replace beta and alpha API versions.\n* Beta API versions can replace earlier beta and alpha API versions, but *may not* replace GA API versions.\n* Alpha API versions can replace earlier alpha API versions, but *may not* replace GA or beta API versions.\n\n**Rule #4a: API lifetime is determined by the API stability level**\n\n* GA API versions may be marked as deprecated, but must not be removed within a major version of Kubernetes\n* Beta API versions are deprecated no more than 9 months or 3 minor releases after introduction (whichever is longer),\n  and are no longer served 9 months or 3 minor releases after deprecation (whichever is longer)\n* Alpha API versions may be removed in any release without prior deprecation notice\n\nThis ensures beta API support covers the [maximum supported version skew of 2 releases](/releases/version-skew-policy/),\nand that APIs don't stagnate on unstable beta versions, accumulating production usage that will be\ndisrupted when support for the beta API ends.\n\n{{< note >}}\nThere are no current plans for a major version revision of Kubernetes that removes GA APIs.\n{{< /note >}}\n\n{{< note >}}\nUntil [#52185](https://github.com/kubernetes/kubernetes/issues/52185) is\nresolved, no API versions that have been persisted to storage may be removed.\nServing REST endpoints for those versions may be disabled (subject to the\ndeprecation timelines in this document), but the API server must remain capable\nof decoding/converting previously persisted data from storage.\n{{< /note >}}\n\n**Rule #4b: The \"preferred\" API version and the \"storage version\" for a given\ngroup may not advance until after a release has been made that supports both the\nnew version and the previous version**\n\nUsers must be able to upgrade to a new release of Kubernetes and then roll back\nto a previous release, without converting anything to the new API version or\nsuffering breakages (unless they explicitly used features only available in the\nnewer version). This is particularly evident in the stored representation of\nobjects.\n\nAll of this is best illustrated by examples. Imagine a Kubernetes release,\nversion X, which introduces a new API group. A new Kubernetes release is made\nevery approximately 4 months (3 per year). The following table describes which\nAPI versions are supported in a series of subsequent releases.",
          "is_needle": false
        },
        {
          "chunk_id": "reference_using-api__index_mdsem_1",
          "doc_id": "reference_using-api__index",
          "content": "## API versioning\n\nThe JSON and Protobuf serialization schemas follow the same guidelines for\nschema changes. The following descriptions cover both formats.\n\nThe API versioning and software versioning are indirectly related.\nThe [API and release versioning proposal](https://git.k8s.io/sig-release/release-engineering/versioning.md)\ndescribes the relationship between API versioning and software versioning.\n\nDifferent API versions indicate different levels of stability and support. You\ncan find more information about the criteria for each level in the\n[API Changes documentation](https://git.k8s.io/community/contributors/devel/sig-architecture/api_changes.md#alpha-beta-and-stable-versions).\n\nHere's a summary of each level:\n\n- Alpha:\n  - The version names contain `alpha` (for example, `v1alpha1`).\n  - Built-in alpha API versions are disabled by default and must be explicitly enabled in the `kube-apiserver` configuration to be used.\n  - The software may contain bugs. Enabling a feature may expose bugs.\n  - Support for an alpha API may be dropped at any time without notice.\n  - The API may change in incompatible ways in a later software release without notice.\n  - The software is recommended for use only in short-lived testing clusters,\n    due to increased risk of bugs and lack of long-term support.\n\n- Beta:\n  - The version names contain `beta` (for example, `v2beta3`).\n  - Built-in beta API versions are disabled by default and must be explicitly enabled in the `kube-apiserver` configuration to be used\n    (**except** for beta versions of APIs introduced prior to Kubernetes 1.22, which were enabled by default).\n  - Built-in beta API versions have a maximum lifetime of 9 months or 3 minor releases (whichever is longer) from introduction\n    to deprecation, and 9 months or 3 minor releases (whichever is longer) from deprecation to removal.\n  - The software is well tested. Enabling a feature is considered safe.\n  - The support for a feature will not be dropped, though the details may change.\n\n  - The schema and/or semantics of objects may change in incompatible ways in\n    a subsequent beta or stable API version. When this happens, migration\n    instructions are provided. Adapting to a subsequent beta or stable API version\n    may require editing or re-creating API objects, and may not be straightforward.\n    The migration may require downtime for applications that rely on the feature.\n  - The software is not recommended for production uses. Subsequent releases\n    may introduce incompatible changes. Use of beta API versions is\n    required to transition to subsequent beta or stable API versions\n    once the beta API version is deprecated and no longer served.\n\n  {{< note >}}\n  Please try beta features and provide feedback. After the features exit beta, it\n  may not be practical to make more changes.\n  {{< /note >}}\n\n- Stable:\n  - The version name is `vX` where `X` is an integer.\n  - Stable API versions remain available for all future releases within a Kubernetes major version,\n    and there are no current plans for a major version revision of Kubernetes that removes stable APIs.",
          "is_needle": false
        },
        {
          "chunk_id": "reference_using-api_deprecation-guide_mdsem_20",
          "doc_id": "reference_using-api_deprecation-guide",
          "content": "### v1.16\n\nThe **v1.16** release stopped serving the following deprecated API versions:\n\n#### NetworkPolicy {#networkpolicy-v116}\n\nThe **extensions/v1beta1** API version of NetworkPolicy is no longer served as of v1.16.\n\n* Migrate manifests and API clients to use the **networking.k8s.io/v1** API version, available since v1.8.\n* All existing persisted objects are accessible via the new API",
          "is_needle": false
        },
        {
          "chunk_id": "reference_using-api_deprecation-guide_mdsem_3",
          "doc_id": "reference_using-api_deprecation-guide",
          "content": "### v1.27\n\nThe **v1.27** release stopped serving the following deprecated API versions:\n\n#### CSIStorageCapacity {#csistoragecapacity-v127}\n\nThe **storage.k8s.io/v1beta1** API version of CSIStorageCapacity is no longer served as of v1.27.\n\n* Migrate manifests and API clients to use the **storage.k8s.io/v1** API version, available since v1.24.\n* All existing persisted objects are accessible via the new API\n* No notable changes",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_cluster-administration_admission-webhooks-good-practices_mdsem_30",
          "doc_id": "concepts_cluster-administration_admission-webhooks-good-practices",
          "content": "### Test minor version upgrades to ensure consistent behavior {#test-minor-version-upgrades}\n\nBefore upgrading your production clusters to a new minor version, test your\nwebhooks and workloads in a staging environment. Compare the results to ensure\nthat your webhooks continue to function as expected after the upgrade. \n\nAdditionally, use the following resources to stay informed about API changes:\n\n* [Kubernetes release notes](/releases/)\n* [Kubernetes blog](/blog/)",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_v04",
      "question": "In what k8s version did max-allowable-numa-nodes become GA?",
      "expected_answer": "Kubernetes 1.35",
      "category": "VERSION",
      "latency_ms": 1237.2,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_cluster-administration_admission-webhooks-good-practices_mdsem_9",
          "doc_id": "concepts_cluster-administration_admission-webhooks-good-practices",
          "content": "### Use a high-availability deployment model {#ha-deployment}\n\nConsider your cluster's availability requirements when designing your webhook. \nFor example, during node downtime or zonal outages, Kubernetes marks Pods as\n`NotReady` to allow load balancers to reroute traffic to available zones and\nnodes. These updates to Pods might trigger your mutating webhooks. Depending on\nthe number of affected Pods, the mutating webhook server has a risk of timing\nout or causing delays in Pod processing. As a result, traffic won't get\nrerouted as quickly as you need.\n\nConsider situations like the preceding example when writing your webhooks.\nExclude operations that are a result of Kubernetes responding to unavoidable\nincidents.",
          "is_needle": false
        },
        {
          "chunk_id": "home_supported-doc-versions_mdsem_0",
          "doc_id": "home_supported-doc-versions",
          "content": "---\ntitle: Available Documentation Versions\ncontent_type: custom\nlayout: supported-versions\nweight: 10\n---\n\nThis website contains documentation for the current version of Kubernetes\nand the four previous versions of Kubernetes.\n\nThe availability of documentation for a Kubernetes version is separate from whether\nthat release is currently supported.\nRead [Support period](/releases/patch-releases/#support-period) to learn about\nwhich versions of Kubernetes are officially supported, and for how long.\n",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_reserve-compute-resources_mdsem_8",
          "doc_id": "tasks_administer-cluster_reserve-compute-resources",
          "content": "## General Guidelines\n\nSystem daemons are expected to be treated similar to\n[Guaranteed pods](/docs/tasks/configure-pod-container/quality-service-pod/#create-a-pod-that-gets-assigned-a-qos-class-of-guaranteed).\nSystem daemons can burst within their bounding control groups and this behavior needs\nto be managed as part of kubernetes deployments. For example, `kubelet` should\nhave its own control group and share `kubeReserved` resources with the\ncontainer runtime. However, Kubelet cannot burst and use up all available Node\nresources if `kubeReserved` is enforced.\n\nBe extra careful while enforcing `systemReserved` reservation since it can lead\nto critical system services being CPU starved, OOM killed, or unable\nto fork on the node. The\nrecommendation is to enforce `systemReserved` only if a user has profiled their\nnodes exhaustively to come up with precise estimates and is confident in their\nability to recover if any process in that group is oom-killed.\n\n* To begin with enforce 'Allocatable' on `pods`.\n* Once adequate monitoring and alerting is in place to track kube system\n  daemons, attempt to enforce `kubeReserved` based on usage heuristics.\n* If absolutely necessary, enforce `systemReserved` over time.\n\nThe resource requirements of kube system daemons may grow over time as more and\nmore features are added. Over time, kubernetes project will attempt to bring\ndown utilization of node system daemons, but that is not a priority as of now.\nSo expect a drop in `Allocatable` capacity in future releases.\n\n<!-- discussion -->",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "setup_production-environment_tools_kubeadm_create-cluster-kubeadm_mdsem_1",
          "doc_id": "setup_production-environment_tools_kubeadm_create-cluster-kubeadm",
          "content": "## {{% heading \"prerequisites\" %}}\n\nTo follow this guide, you need:\n\n- One or more machines running a deb/rpm-compatible Linux OS; for example: Ubuntu or CentOS.\n- 2 GiB or more of RAM per machine--any less leaves little room for your apps.\n- At least 2 CPUs on the machine that you use as a control-plane node.\n- Full network connectivity among all machines in the cluster. You can use either a\n  public or a private network.\n\nYou also need to use a version of `kubeadm` that can deploy the version\nof Kubernetes that you want to use in your new cluster.\n\n[Kubernetes' version and version skew support policy](/docs/setup/release/version-skew-policy/#supported-versions)\napplies to `kubeadm` as well as to Kubernetes overall.\nCheck that policy to learn about what versions of Kubernetes and `kubeadm`\nare supported. This page is written for Kubernetes {{< param \"version\" >}}.\n\nThe `kubeadm` tool's overall feature state is General Availability (GA). Some sub-features are\nstill under active development. The implementation of creating the cluster may change\nslightly as the tool evolves, but the overall implementation should be pretty stable.\n\n{{< note >}}\nAny commands under `kubeadm alpha` are, by definition, supported on an alpha level.\n{{< /note >}}\n\n<!-- steps -->\n\n## Objectives\n\n* Install a single control-plane Kubernetes cluster\n* Install a Pod network on the cluster so that your Pods can\n  talk to each other\n\n## Instructions\n\n",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_v05",
      "question": "What's the default limit on NUMA nodes before kubelet refuses to start with topology manager?",
      "expected_answer": "8",
      "category": "VERSION",
      "latency_ms": 1171.5,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_13",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Known limitations\n\n1. The maximum number of NUMA nodes that Topology Manager allows is 8. With more than 8 NUMA nodes,\n   there will be a state explosion when trying to enumerate the possible NUMA affinities and\n   generating their hints. See [`max-allowable-numa-nodes`](#policy-option-max-allowable-numa-nodes)\n   (beta) for more options.\n\n1. The scheduler is not topology-aware, so it is possible to be scheduled on a node and then fail\n   on the node due to the Topology Manager.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_3",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager scopes\n\nThe Topology Manager can deal with the alignment of resources in a couple of distinct scopes:\n\n* `container` (default)\n* `pod`\n\nEither option can be selected at a time of the kubelet startup, by setting the\n`topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\n### `container` scope\n\nThe `container` scope is used by default. You can also explicitly set the\n`topologyManagerScope` to `container` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\nWithin this scope, the Topology Manager performs a number of sequential resource alignments, i.e.,\nfor each container (in a pod) a separate alignment is computed. In other words, there is no notion\nof grouping the containers to a specific set of NUMA nodes, for this particular scope. In effect,\nthe Topology Manager performs an arbitrary alignment of individual containers to NUMA nodes.\n\nThe notion of grouping the containers was endorsed and implemented on purpose in the following\nscope, for example the `pod` scope.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_c01",
      "question": "How does restricted policy differ from single-numa-node when pod can't get preferred affinity?",
      "expected_answer": "restricted rejects any non-preferred; single-numa-node only rejects if >1 NUMA needed",
      "category": "COMPARISON",
      "latency_ms": 1148.4,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_9",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "#### Scheduling Behavior\n\nWhen scheduling a new Pod, the Kubernetes scheduler evaluates the Pod's affinity/anti-affinity rules in the context of the current cluster state:\n\n1. Hard Constraints (Node Filtering):\n   - `podAffinity.requiredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler ensures the new Pod is assigned to nodes that satisfy these required affinity and anti-affinity rules based on existing Pods.\n\n2. Soft Constraints (Scoring):\n   - `podAffinity.preferredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler scores nodes based on how well they meet these preferred affinity and anti-affinity rules to optimize Pod placement.\n\n3. Ignored Fields:\n   - Existing Pods' `podAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - These preferred affinity rules are not considered during the scheduling decision for new Pods.\n   - Existing Pods' `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - Similarly, preferred anti-affinity rules of existing Pods are ignored during scheduling.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_cluster-administration_node-autoscaling_mdsem_2",
          "doc_id": "concepts_cluster-administration_node-autoscaling",
          "content": "### Pod scheduling constraints {#provisioning-pod-constraints}\n\nPods can express [scheduling constraints](/docs/concepts/scheduling-eviction/assign-pod-node/) to\nimpose limitations on the kind of Nodes they can be scheduled on. Node autoscalers take these\nconstraints into account to ensure that the pending Pods can be scheduled on the provisioned Nodes.\n\nThe most common kind of scheduling constraints are the resource requests specified by Pod\ncontainers. Autoscalers will make sure that the provisioned Nodes have enough resources to satisfy\nthe requests. However, they don't directly take into account the real resource usage of the Pods\nafter they start running. In order to autoscale Nodes based on actual workload resource usage, you\ncan combine [horizontal workload autoscaling](#horizontal-workload-autoscaling) with Node\nautoscaling.\n\nOther common Pod scheduling constraints include\n[Node affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity),\n[inter-Pod affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity),\nor a requirement for a particular [storage volume](/docs/concepts/storage/volumes/).",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_policy_node-resource-managers_mdsem_1",
          "doc_id": "concepts_policy_node-resource-managers",
          "content": "## Hardware topology alignment policies\n\n_Topology Manager_ is a kubelet component that aims to coordinate the set of components that are\nresponsible for these optimizations. The overall resource management process is governed using\nthe policy you specify. To learn more, read\n[Control Topology Management Policies on a Node](/docs/tasks/administer-cluster/topology-manager/).\n\n## Policies for assigning CPUs to Pods\n\n{{< feature-state feature_gate_name=\"CPUManager\" >}}\n\nOnce a Pod is bound to a Node, the kubelet on that node may need to either multiplex the existing\nhardware (for example, sharing CPUs across multiple Pods) or allocate hardware by dedicating some\nresource (for example, assigning one of more CPUs for a Pod's exclusive use).\n\nBy default, the kubelet uses [CFS quota](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler)\nto enforce pod CPU limits. \u00a0When the node runs many CPU-bound pods, the workload can move to\ndifferent CPU cores depending on whether the pod is throttled and which CPU cores are available\nat scheduling time. Many workloads are not sensitive to this migration and thus\nwork fine without any intervention.\n\nHowever, in workloads where CPU cache affinity and scheduling latency significantly affect\nworkload performance, the kubelet allows alternative CPU\nmanagement policies to determine some placement preferences on the node.\nThis is implemented using the _CPU Manager_ and its policy.\nThere are two available policies:\n\n- `none`: the `none` policy explicitly enables the existing default CPU\n  affinity scheme, providing no affinity beyond what the OS scheduler does\n  automatically. \u00a0Limits on CPU usage for\n  [Guaranteed pods](/docs/concepts/workloads/pods/pod-qos/) and\n  [Burstable pods](/docs/concepts/workloads/pods/pod-qos/)\n  are enforced using CFS quota.\n- `static`: the `static` policy allows containers in `Guaranteed` pods with integer CPU\n  `requests` access to exclusive CPUs on the node. This exclusivity is enforced\n  using the [cpuset cgroup controller](https://www.kernel.org/doc/Documentation/cgroup-v2.txt).\n\n{{< note >}}\nSystem services such as the container runtime and the kubelet itself can continue to run on\nthese exclusive CPUs. \u00a0The exclusivity only extends to other pods.\n{{< /note >}}\n\nCPU Manager doesn't support offlining and onlining of CPUs at runtime.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_10",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "#### Scheduling a Group of Pods with Inter-pod Affinity to Themselves\n\nIf the current Pod being scheduled is the first in a series that have affinity to themselves,\nit is allowed to be scheduled if it passes all other affinity checks. This is determined by\nverifying that no other Pod in the cluster matches the namespace and selector of this Pod,\nthat the Pod matches its own terms, and the chosen node matches all requested topologies.\nThis ensures that there will not be a deadlock even if all the Pods have inter-pod affinity\nspecified.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_c02",
      "question": "What's the key difference between container scope and pod scope for topology alignment?",
      "expected_answer": "container=individual alignment per container, no grouping; pod=groups all containers to common NUMA set",
      "category": "COMPARISON",
      "latency_ms": 1393.5,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_3",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager scopes\n\nThe Topology Manager can deal with the alignment of resources in a couple of distinct scopes:\n\n* `container` (default)\n* `pod`\n\nEither option can be selected at a time of the kubelet startup, by setting the\n`topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\n### `container` scope\n\nThe `container` scope is used by default. You can also explicitly set the\n`topologyManagerScope` to `container` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\nWithin this scope, the Topology Manager performs a number of sequential resource alignments, i.e.,\nfor each container (in a pod) a separate alignment is computed. In other words, there is no notion\nof grouping the containers to a specific set of NUMA nodes, for this particular scope. In effect,\nthe Topology Manager performs an arbitrary alignment of individual containers to NUMA nodes.\n\nThe notion of grouping the containers was endorsed and implemented on purpose in the following\nscope, for example the `pod` scope.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_scheduling-eviction_topology-spread-constraints_mdsem_15",
          "doc_id": "concepts_scheduling-eviction_topology-spread-constraints",
          "content": "## Comparison with podAffinity and podAntiAffinity {#comparison-with-podaffinity-podantiaffinity}\n\nIn Kubernetes, [inter-Pod affinity and anti-affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity)\ncontrol how Pods are scheduled in relation to one another - either more packed\nor more scattered.\n\n`podAffinity`\n: attracts Pods; you can try to pack any number of Pods into qualifying\n  topology domain(s).\n\n`podAntiAffinity`\n: repels Pods. If you set this to `requiredDuringSchedulingIgnoredDuringExecution` mode then\n  only a single Pod can be scheduled into a single topology domain; if you choose\n  `preferredDuringSchedulingIgnoredDuringExecution` then you lose the ability to enforce the\n  constraint.\n\nFor finer control, you can specify topology spread constraints to distribute\nPods across different topology domains - to achieve either high availability or\ncost-saving. This can also help on rolling update workloads and scaling out\nreplicas smoothly.\n\nFor more context, see the\n[Motivation](https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/895-pod-topology-spread#motivation)\nsection of the enhancement proposal about Pod topology spread constraints.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Windows Support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nThe Topology Manager support can be enabled on Windows by using the `WindowsCPUAndMemoryAffinity` feature gate and\nit requires support in the container runtime.\n\n## Topology manager scopes and policies\n\nThe Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_c03",
      "question": "Compare what happens with none policy vs best-effort policy when NUMA affinity can't be satisfied",
      "expected_answer": "none=no alignment attempted; best-effort=stores non-preferred hint, admits pod anyway",
      "category": "COMPARISON",
      "latency_ms": 1095.1,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_9",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "#### Scheduling Behavior\n\nWhen scheduling a new Pod, the Kubernetes scheduler evaluates the Pod's affinity/anti-affinity rules in the context of the current cluster state:\n\n1. Hard Constraints (Node Filtering):\n   - `podAffinity.requiredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler ensures the new Pod is assigned to nodes that satisfy these required affinity and anti-affinity rules based on existing Pods.\n\n2. Soft Constraints (Scoring):\n   - `podAffinity.preferredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler scores nodes based on how well they meet these preferred affinity and anti-affinity rules to optimize Pod placement.\n\n3. Ignored Fields:\n   - Existing Pods' `podAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - These preferred affinity rules are not considered during the scheduling decision for new Pods.\n   - Existing Pods' `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - Similarly, preferred anti-affinity rules of existing Pods are ignored during scheduling.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_policy_node-resource-managers_mdsem_4",
          "doc_id": "concepts_policy_node-resource-managers",
          "content": "#### Static policy options {#cpu-policy-static--options} (continued)\n\n`CPUManager`\n\nwill pack CPUs onto one NUMA node until it is\nfilled, with any remaining CPUs simply spilling over to the next NUMA node.\nThis can cause undesired bottlenecks in parallel code relying on barriers (and\nsimilar synchronization primitives), as this type of code tends to run only as\nfast as its slowest worker (which is slowed down by the fact that fewer CPUs\nare available on at least one NUMA node).\nBy distributing CPUs evenly across NUMA nodes, application developers can more\neasily ensure that no single worker suffers from NUMA effects more than any\nother, improving the overall performance of these types of applications.\n\n#####\n\n`align-by-socket`\n\nIf the\n\n`align-by-socket`\n\npolicy option is specified, CPUs will be considered\naligned at the socket boundary when deciding how to allocate CPUs to a\ncontainer. By default, the\n\n`CPUManager`\n\naligns CPU allocations at the NUMA\nboundary, which could result in performance degradation if CPUs need to be\npulled from more than one NUMA node to satisfy the allocation. Although it\ntries to ensure that all CPUs are allocated from the _minimum_ number of NUMA\nnodes, there is no guarantee that those NUMA nodes will be on the same socket.\nBy directing the\n\n`CPUManager`\n\nto explicitly align CPUs at the socket boundary\nrather than the NUMA boundary, we are able to avoid such issues. Note, this\npolicy option is not compatible with\n\n`TopologyManager`\n\n`single-numa-node`\n\npolicy and does not apply to hardware where the number of sockets is greater\nthan number of NUMA nodes.\n\n#####\n\n`distribute-cpus-across-cores`\n\nIf the\n\n`distribute-cpus-across-cores`\n\npolicy option is specified, the static policy\nwill attempt to allocate virtual cores (hardware threads) across different physical cores.\nBy default, the\n\n`CPUManager`\n\ntends to pack CPUs onto as few physical cores as possible,\nwhich can lead to contention among CPUs on the same physical core and result\nin performance bottlenecks. By enabling the\n\n`distribute-cpus-across-cores`\n\npolicy,\nthe static policy ensures that CPUs are distributed across as many physical cores\nas possible, reducing the contention on the same physical core and thereby\nimproving overall performance. However, it is important to note that this strategy\nmight be less effective when the system is heavily loaded. Under such conditions,\nthe benefit of reducing contention diminishes. Conversely, default behavior\ncan help in reducing inter-core communication overhead, potentially providing\nbetter performance under high load conditions.\n\n#####\n\n`strict-cpu-reservation`\n\nThe\n\n`reservedSystemCPUs`\n\nparameter in [KubeletConfiguration](/docs/reference/config-api/kubelet-config.v1beta1/),\nor the deprecated kubelet command line option\n\n`--reserved-cpus`",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_6",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "#### BestEffort policy {#policy-best-effort}\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\n**This policy is only supported on Windows.**\n\nOn Windows, NUMA node assignment works differently than Linux.\nThere is no mechanism to ensure that Memory access only comes from a specific NUMA node.\nInstead the Windows operating system scheduler selects the most optimal NUMA node based on the CPU(s) assignments.\nIt is possible that Windows might use other NUMA nodes if the Windows scheduler deems them optimal.\n\nThe policy does track the amount of memory available and requested through the internal _node map_.\nThe memory manager makes a best effort at ensuring that enough memory is available on a NUMA node before making\na resource assignment.  \nThis means that in most cases memory assignment should function as specified.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_policy_node-resource-managers_mdsem_3",
          "doc_id": "concepts_policy_node-resource-managers",
          "content": "#### Static policy options {#cpu-policy-static--options}\n\nHere are the available policy options for the static CPU management policy,\nlisted in alphabetical order:\n\n`align-by-socket`\n\n(alpha, hidden by default)\n: Align CPUs by physical package / socket boundary, rather than logical NUMA boundaries\n  (available since Kubernetes v1.25)\n\n`distribute-cpus-across-cores`\n\n(alpha, hidden by default)\n: Allocate virtual cores, sometimes called hardware threads, across different physical cores\n  (available since Kubernetes v1.31)\n\n`distribute-cpus-across-numa`\n\n(beta, visible by default)\n: Spread CPUs across different NUMA domains, aiming for an even balance between the selected domains\n  (available since Kubernetes v1.23)\n\n`full-pcpus-only`\n\n(GA, visible by default)\n: Always allocate full physical cores (available since Kubernetes v1.22, GA since Kubernetes v1.33)\n\n`strict-cpu-reservation`\n\n(GA, visible by default)\n: Prevent all the pods regardless of their Quality of Service class to run on reserved CPUs\n  (available since Kubernetes v1.32, GA since Kubernetes v1.35)\n\n`prefer-align-cpus-by-uncorecache`\n\n(beta, visible by default)\n: Align CPUs by uncore (Last-Level) cache boundary on a best-effort way\n  (available since Kubernetes v1.32)\n\nYou can toggle groups of options on and off based upon their maturity level\nusing the following feature gates:\n\n*\n\n`CPUManagerPolicyBetaOptions`\n\n(default enabled). Disable to hide beta-level options.\n*\n\n`CPUManagerPolicyAlphaOptions`\n\n(default disabled). Enable to show alpha-level options.\n\nYou will still have to enable each option using the\n\n`cpuManagerPolicyOptions`\n\nfield in the\nkubelet configuration file.\n\nFor more detail about the individual options you can configure, read on.\n\n#####\n\n`full-pcpus-only`\n\nIf the\n\n`full-pcpus-only`\n\npolicy option is specified, the static policy will always allocate full physical cores.\nBy default, without this option, the static policy allocates CPUs using a topology-aware best-fit allocation.\nOn SMT enabled systems, the policy can allocate individual virtual cores, which correspond to hardware threads.\nThis can lead to different containers sharing the same physical cores; this behaviour in turn contributes\nto the [noisy neighbours problem](https://en.wikipedia.org/wiki/Cloud_computing_issues#Performance_interference_and_noisy_neighbors).\nWith the option enabled, the pod will be admitted by the kubelet only if the CPU request of all its containers\ncan be fulfilled by allocating full physical cores.\nIf the pod does not pass the admission, it will be put in Failed state with the message\n\n`SMTAlignmentError`\n\n.\n\n#####\n\n`distribute-cpus-across-numa`\n\nIf the\n\n`distribute-cpus-across-numa`\n\npolicy option is specified, the static\npolicy will evenly distribute CPUs across NUMA nodes in cases where more than\none NUMA node is required to satisfy the allocation.\nBy default, the\n\n`CPUManager`",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "### Policies\n\nKubernetes' memory manager provides three policies. You can select a policy via the `memoryManagerPolicy` configuration field\nin the kubelet configuration; the values available in Kubernetes {{< skew currentVersion >}} are:\n\n* [`None`](#policy-none) (default)\n* [`Static`](#policy-static) (Linux only)\n* [`BestEffort`](#policy-best-effort) (Windows only)\n\n#### None policy {#policy-none}\n\nThis is the default policy and does not affect the memory allocation in any way.\nIt acts the same as if the Memory Manager is not present at all.\n\nThe `None` policy returns default topology hint. This special hint denotes that Hint Provider\n(Memory Manager in this case) has no preference for NUMA affinity with any resource.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_c04",
      "question": "How does topology manager behavior differ for Guaranteed QoS pods with integer CPU vs fractional CPU?",
      "expected_answer": "integer CPU gets topology hints from CPU Manager; fractional CPU gets default hint only",
      "category": "COMPARISON",
      "latency_ms": 1802.4,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "## Placing a Pod in the Guaranteed QoS class\n\nIf the selected policy is anything other than `None`, the Memory Manager identifies pods\nthat are in the `Guaranteed` QoS class.\nThe Memory Manager provides specific topology hints to the Topology Manager for each `Guaranteed` pod.\nFor pods in a QoS class other than `Guaranteed`, the Memory Manager provides default topology hints\nto the Topology Manager.\n\nThe following excerpts from pod manifests assign a pod to the `Guaranteed` QoS class.\n\nA Pod with integer CPU(s) runs in the `Guaranteed` QoS class, when `requests` are equal to `limits`:\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n```\n\nAlso, a pod sharing CPU(s) runs in the `Guaranteed` QoS class, when `requests` are equal to `limits`.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n```\n\nNotice that both CPU and memory requests must be specified for a Pod to lend it to Guaranteed QoS class.\n\n## {{% heading \"whatsnext\" %}}\n\n- Read [Troubleshooting Topology Management](/docs/tasks/debug/debug-cluster/topology/)\n- Read the [KEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/1769-memory-manager) (Kubernetes enhancement proposal) for memory manager",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_12",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Pod interactions with topology manager policies\n\nConsider the containers in the following Pod manifest:\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n```\n\nThis pod runs in the `BestEffort` QoS class because no resource `requests` or `limits` are specified.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n      requests:\n        memory: \"100Mi\"\n```\n\nThis pod runs in the `Burstable` QoS class because requests are less than limits.\n\nIf the selected policy is anything other than `none`, the Topology Manager would consider these Pod\nspecifications. The Topology Manager would consult the Hint Providers to get topology hints.\nIn the case of the `static`, the CPU Manager policy would return default topology hint, because\nthese Pods do not explicitly request CPU resources.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n```\n\nThis pod with integer CPU request runs in the `Guaranteed` QoS class because `requests` are equal\nto `limits`.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n```\n\nThis pod with sharing CPU request runs in the `Guaranteed` QoS class because `requests` are equal\nto `limits`.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        example.com/deviceA: \"1\"\n        example.com/deviceB: \"1\"\n      requests:\n        example.com/deviceA: \"1\"\n        example.com/deviceB: \"1\"\n```\n\nThis pod runs in the `BestEffort` QoS class because there are no CPU and memory requests.\n\nThe Topology Manager would consider the above pods. The Topology Manager would consult the Hint\nProviders, which are CPU and Device Manager to get topology hints for the pods.\n\nIn the case of the `Guaranteed` pod with integer CPU request, the `static` CPU Manager policy\nwould return topology hints relating to the exclusive CPU and the Device Manager would send back\nhints for the requested device.\n\nIn the case of the `Guaranteed` pod with sharing CPU request, the `static` CPU Manager policy\nwould return default topology hint as there is no exclusive CPU request and the Device Manager\nwould send back hints for the requested device.\n\nIn the above two cases of the `Guaranteed` pod, the `none` CPU Manager policy would return default\ntopology hint.\n\nIn the case of the `BestEffort` pod, the `static` CPU Manager policy would send back the default\ntopology hint as there is no CPU request and the Device Manager would send back the hints for each\nof the requested devices.\n\nUsing this information the Topology Manager calculates the optimal hint for the pod and stores\nthis information, which will be used by the Hint Providers when they are making their resource\nassignments.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_0",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "---\ntitle: Control Memory Management Policies on a Node\nreviewers:\n- klueska\n- derekwaynecarr\ncontent_type: task\nmin-kubernetes-server-version: v1.32\nweight: 145\nmath: true\n---\n\n<!-- overview -->\n\n{{< feature-state feature_gate_name=\"MemoryManager\" >}}\n\nThe Kubernetes *Memory Manager* enables the feature of guaranteed memory (and hugepages)\nallocation for pods in the `Guaranteed` {{< glossary_tooltip text=\"QoS class\" term_id=\"qos-class\" >}}.\n\nThe Memory Manager employs a hint generation protocol to yield the most suitable NUMA affinity for a pod.\nThe Memory Manager feeds the central manager (*Topology Manager*) with these affinity hints.\nBased on both the hints and Topology Manager policy, the pod is rejected or admitted to the node.\n\nMoreover, the Memory Manager ensures that the memory which a pod requests\nis allocated from a minimum number of NUMA nodes.\n\nFor background about memory resources for Pods, read\n[Assign Memory Resources to Containers and Pods](/docs/tasks/configure-pod-container/assign-memory-resource/).",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Windows Support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nThe Topology Manager support can be enabled on Windows by using the `WindowsCPUAndMemoryAffinity` feature gate and\nit requires support in the container runtime.\n\n## Topology manager scopes and policies\n\nThe Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_policy_node-resource-managers_mdsem_1",
          "doc_id": "concepts_policy_node-resource-managers",
          "content": "## Hardware topology alignment policies\n\n_Topology Manager_ is a kubelet component that aims to coordinate the set of components that are\nresponsible for these optimizations. The overall resource management process is governed using\nthe policy you specify. To learn more, read\n[Control Topology Management Policies on a Node](/docs/tasks/administer-cluster/topology-manager/).\n\n## Policies for assigning CPUs to Pods\n\n{{< feature-state feature_gate_name=\"CPUManager\" >}}\n\nOnce a Pod is bound to a Node, the kubelet on that node may need to either multiplex the existing\nhardware (for example, sharing CPUs across multiple Pods) or allocate hardware by dedicating some\nresource (for example, assigning one of more CPUs for a Pod's exclusive use).\n\nBy default, the kubelet uses [CFS quota](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler)\nto enforce pod CPU limits. \u00a0When the node runs many CPU-bound pods, the workload can move to\ndifferent CPU cores depending on whether the pod is throttled and which CPU cores are available\nat scheduling time. Many workloads are not sensitive to this migration and thus\nwork fine without any intervention.\n\nHowever, in workloads where CPU cache affinity and scheduling latency significantly affect\nworkload performance, the kubelet allows alternative CPU\nmanagement policies to determine some placement preferences on the node.\nThis is implemented using the _CPU Manager_ and its policy.\nThere are two available policies:\n\n- `none`: the `none` policy explicitly enables the existing default CPU\n  affinity scheme, providing no affinity beyond what the OS scheduler does\n  automatically. \u00a0Limits on CPU usage for\n  [Guaranteed pods](/docs/concepts/workloads/pods/pod-qos/) and\n  [Burstable pods](/docs/concepts/workloads/pods/pod-qos/)\n  are enforced using CFS quota.\n- `static`: the `static` policy allows containers in `Guaranteed` pods with integer CPU\n  `requests` access to exclusive CPUs on the node. This exclusivity is enforced\n  using the [cpuset cgroup controller](https://www.kernel.org/doc/Documentation/cgroup-v2.txt).\n\n{{< note >}}\nSystem services such as the container runtime and the kubelet itself can continue to run on\nthese exclusive CPUs. \u00a0The exclusivity only extends to other pods.\n{{< /note >}}\n\nCPU Manager doesn't support offlining and onlining of CPUs at runtime.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_c05",
      "question": "What's the difference between TopologyManagerPolicyBetaOptions and TopologyManagerPolicyAlphaOptions feature gates?",
      "expected_answer": "Beta=enabled by default, Alpha=disabled by default; both control policy option visibility",
      "category": "COMPARISON",
      "latency_ms": 1003.1,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_9",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policy options\n\nSupport for the Topology Manager policy options requires `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) to be enabled\n(it is enabled by default).\n\nYou can toggle groups of options on and off based upon their maturity level using the following feature gates:\n\n* `TopologyManagerPolicyBetaOptions` default enabled. Enable to show beta-level options.\n* `TopologyManagerPolicyAlphaOptions` default disabled. Enable to show alpha-level options.\n\nYou will still have to enable each option using the `TopologyManagerPolicyOptions` kubelet option.",
          "is_needle": true
        },
        {
          "chunk_id": "reference_command-line-tools-reference_feature-gates_TopologyManagerPolicyAlphaOptions_mdsem_0",
          "doc_id": "reference_command-line-tools-reference_feature-gates_TopologyManagerPolicyAlphaOptions",
          "content": "---\ntitle: TopologyManagerPolicyAlphaOptions\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha \n    defaultValue: false\n    fromVersion: \"1.26\"\n---\nAllow fine-tuning of topology manager policies,\nexperimental, Alpha-quality options.\nThis feature gate guards *a group* of topology manager options whose quality level is alpha.\nThis feature gate will never graduate to beta or stable.\n",
          "is_needle": false
        },
        {
          "chunk_id": "reference_command-line-tools-reference_feature-gates_TopologyManagerPolicyBetaOptions_mdsem_0",
          "doc_id": "reference_command-line-tools-reference_feature-gates_TopologyManagerPolicyBetaOptions",
          "content": "---\ntitle: TopologyManagerPolicyBetaOptions\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: beta\n    defaultValue: false\n    fromVersion: \"1.26\"\n    toVersion: \"1.27\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.28\"\n---\nAllow fine-tuning of topology manager policies,\nexperimental, Beta-quality options.\nThis feature gate guards *a group* of topology manager options whose quality level is beta.\nThis feature gate will never graduate to stable.\n",
          "is_needle": false
        },
        {
          "chunk_id": "reference_command-line-tools-reference_feature-gates_TopologyManagerPolicyOptions_mdsem_0",
          "doc_id": "reference_command-line-tools-reference_feature-gates_TopologyManagerPolicyOptions",
          "content": "---\ntitle: TopologyManagerPolicyOptions\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha\n    defaultValue: false\n    fromVersion: \"1.26\"\n    toVersion: \"1.27\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.28\"\n    toVersion: \"1.31\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.32\"\n---\nEnable [fine-tuning](/docs/tasks/administer-cluster/topology-manager/#topology-manager-policy-options)\nof topology manager policies.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}}\n\n{{< version-check >}} If you are running an older version of Kubernetes, check the documentation\nfor the version of Kubernetes you are running.\n\n### Resource alignment prerequisites\n\nTo align memory resources with other requested resources in a Pod spec:\n\n- the CPU Manager should be enabled and proper CPU Manager policy should be configured on a Node.\n  See [control CPU Management Policies](/docs/tasks/administer-cluster/cpu-management-policies/);\n- the Topology Manager should be enabled and proper Topology Manager policy should be configured on a Node.\n  See [control Topology Management Policies](/docs/tasks/administer-cluster/topology-manager/).",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n01",
      "question": "Why is using more than 8 NUMA nodes not recommended with topology manager?",
      "expected_answer": "State explosion when enumerating NUMA affinities; use max-allowable-numa-nodes at own risk",
      "category": "NEGATION",
      "latency_ms": 1027.9,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_13",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Known limitations\n\n1. The maximum number of NUMA nodes that Topology Manager allows is 8. With more than 8 NUMA nodes,\n   there will be a state explosion when trying to enumerate the possible NUMA affinities and\n   generating their hints. See [`max-allowable-numa-nodes`](#policy-option-max-allowable-numa-nodes)\n   (beta) for more options.\n\n1. The scheduler is not topology-aware, so it is possible to be scheduled on a node and then fail\n   on the node due to the Topology Manager.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_extend-kubernetes_compute-storage-net_device-plugins_mdsem_12",
          "doc_id": "concepts_extend-kubernetes_compute-storage-net_device-plugins",
          "content": "## Device plugin integration with the Topology Manager\n\n{{< feature-state for_k8s_version=\"v1.27\" state=\"stable\" >}}\n\nThe Topology Manager is a Kubelet component that allows resources to be co-ordinated in a Topology\naligned manner. In order to do this, the Device Plugin API was extended to include a\n`TopologyInfo` struct.\n\n```gRPC\nmessage TopologyInfo {\n    repeated NUMANode nodes = 1;\n}\n\nmessage NUMANode {\n    int64 ID = 1;\n}\n```\n\nDevice Plugins that wish to leverage the Topology Manager can send back a populated TopologyInfo\nstruct as part of the device registration, along with the device IDs and the health of the device.\nThe device manager will then use this information to consult with the Topology Manager and make\nresource assignment decisions.\n\n`TopologyInfo` supports setting a `nodes` field to either `nil` or a list of NUMA nodes. This\nallows the Device Plugin to advertise a device that spans multiple NUMA nodes.\n\nSetting `TopologyInfo` to `nil` or providing an empty list of NUMA nodes for a given device\nindicates that the Device Plugin does not have a NUMA affinity preference for that device.\n\nAn example `TopologyInfo` struct populated for a device by a Device Plugin:\n\n```\npluginapi.Device{ID: \"25102017\", Health: pluginapi.Healthy, Topology:&pluginapi.TopologyInfo{Nodes: []*pluginapi.NUMANode{&pluginapi.NUMANode{ID: 0,},}}}\n```",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n02",
      "question": "What happens to a pod that fails topology affinity check with restricted policy? Can it be rescheduled?",
      "expected_answer": "Pod enters Terminated state; scheduler will NOT reschedule; need ReplicaSet/Deployment",
      "category": "NEGATION",
      "latency_ms": 1055.7,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_9",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "#### Scheduling Behavior\n\nWhen scheduling a new Pod, the Kubernetes scheduler evaluates the Pod's affinity/anti-affinity rules in the context of the current cluster state:\n\n1. Hard Constraints (Node Filtering):\n   - `podAffinity.requiredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler ensures the new Pod is assigned to nodes that satisfy these required affinity and anti-affinity rules based on existing Pods.\n\n2. Soft Constraints (Scoring):\n   - `podAffinity.preferredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler scores nodes based on how well they meet these preferred affinity and anti-affinity rules to optimize Pod placement.\n\n3. Ignored Fields:\n   - Existing Pods' `podAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - These preferred affinity rules are not considered during the scheduling decision for new Pods.\n   - Existing Pods' `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - Similarly, preferred anti-affinity rules of existing Pods are ignored during scheduling.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_policy_node-resource-managers_mdsem_1",
          "doc_id": "concepts_policy_node-resource-managers",
          "content": "## Hardware topology alignment policies\n\n_Topology Manager_ is a kubelet component that aims to coordinate the set of components that are\nresponsible for these optimizations. The overall resource management process is governed using\nthe policy you specify. To learn more, read\n[Control Topology Management Policies on a Node](/docs/tasks/administer-cluster/topology-manager/).\n\n## Policies for assigning CPUs to Pods\n\n{{< feature-state feature_gate_name=\"CPUManager\" >}}\n\nOnce a Pod is bound to a Node, the kubelet on that node may need to either multiplex the existing\nhardware (for example, sharing CPUs across multiple Pods) or allocate hardware by dedicating some\nresource (for example, assigning one of more CPUs for a Pod's exclusive use).\n\nBy default, the kubelet uses [CFS quota](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler)\nto enforce pod CPU limits. \u00a0When the node runs many CPU-bound pods, the workload can move to\ndifferent CPU cores depending on whether the pod is throttled and which CPU cores are available\nat scheduling time. Many workloads are not sensitive to this migration and thus\nwork fine without any intervention.\n\nHowever, in workloads where CPU cache affinity and scheduling latency significantly affect\nworkload performance, the kubelet allows alternative CPU\nmanagement policies to determine some placement preferences on the node.\nThis is implemented using the _CPU Manager_ and its policy.\nThere are two available policies:\n\n- `none`: the `none` policy explicitly enables the existing default CPU\n  affinity scheme, providing no affinity beyond what the OS scheduler does\n  automatically. \u00a0Limits on CPU usage for\n  [Guaranteed pods](/docs/concepts/workloads/pods/pod-qos/) and\n  [Burstable pods](/docs/concepts/workloads/pods/pod-qos/)\n  are enforced using CFS quota.\n- `static`: the `static` policy allows containers in `Guaranteed` pods with integer CPU\n  `requests` access to exclusive CPUs on the node. This exclusivity is enforced\n  using the [cpuset cgroup controller](https://www.kernel.org/doc/Documentation/cgroup-v2.txt).\n\n{{< note >}}\nSystem services such as the container runtime and the kubelet itself can continue to run on\nthese exclusive CPUs. \u00a0The exclusivity only extends to other pods.\n{{< /note >}}\n\nCPU Manager doesn't support offlining and onlining of CPUs at runtime.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_topology-spread-constraints_mdsem_15",
          "doc_id": "concepts_scheduling-eviction_topology-spread-constraints",
          "content": "## Comparison with podAffinity and podAntiAffinity {#comparison-with-podaffinity-podantiaffinity}\n\nIn Kubernetes, [inter-Pod affinity and anti-affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity)\ncontrol how Pods are scheduled in relation to one another - either more packed\nor more scattered.\n\n`podAffinity`\n: attracts Pods; you can try to pack any number of Pods into qualifying\n  topology domain(s).\n\n`podAntiAffinity`\n: repels Pods. If you set this to `requiredDuringSchedulingIgnoredDuringExecution` mode then\n  only a single Pod can be scheduled into a single topology domain; if you choose\n  `preferredDuringSchedulingIgnoredDuringExecution` then you lose the ability to enforce the\n  constraint.\n\nFor finer control, you can specify topology spread constraints to distribute\nPods across different topology domains - to achieve either high availability or\ncost-saving. This can also help on rolling update workloads and scaling out\nreplicas smoothly.\n\nFor more context, see the\n[Motivation](https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/895-pod-topology-spread#motivation)\nsection of the enhancement proposal about Pod topology spread constraints.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_topology-spread-constraints_mdsem_14",
          "doc_id": "concepts_scheduling-eviction_topology-spread-constraints",
          "content": "### Built-in default constraints {#internal-default-constraints}\n\n{{< feature-state for_k8s_version=\"v1.24\" state=\"stable\" >}}\n\nIf you don't configure any cluster-level default constraints for pod topology spreading,\nthen kube-scheduler acts as if you specified the following default topology constraints:\n\n```yaml\ndefaultConstraints:\n  - maxSkew: 3\n    topologyKey: \"kubernetes.io/hostname\"\n    whenUnsatisfiable: ScheduleAnyway\n  - maxSkew: 5\n    topologyKey: \"topology.kubernetes.io/zone\"\n    whenUnsatisfiable: ScheduleAnyway\n```\n\nAlso, the legacy `SelectorSpread` plugin, which provides an equivalent behavior,\nis disabled by default.\n\n{{< note >}}\nThe `PodTopologySpread` plugin does not score the nodes that don't have\nthe topology keys specified in the spreading constraints. This might result\nin a different default behavior compared to the legacy `SelectorSpread` plugin when\nusing the default topology constraints.\n\nIf your nodes are not expected to have **both** `kubernetes.io/hostname` and\n`topology.kubernetes.io/zone` labels set, define your own constraints\ninstead of using the Kubernetes defaults.\n{{< /note >}}\n\nIf you don't want to use the default Pod spreading constraints for your cluster,\nyou can disable those defaults by setting `defaultingType` to `List` and leaving\nempty `defaultConstraints` in the `PodTopologySpread` plugin configuration:\n\n```yaml\napiVersion: kubescheduler.config.k8s.io/v1\nkind: KubeSchedulerConfiguration\n\nprofiles:\n  - schedulerName: default-scheduler\n    pluginConfig:\n      - name: PodTopologySpread\n        args:\n          defaultConstraints: []\n          defaultingType: List\n```",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n03",
      "question": "Why can't the Kubernetes scheduler prevent pods from failing on nodes due to topology?",
      "expected_answer": "Scheduler is not topology-aware; this is a known limitation",
      "category": "NEGATION",
      "latency_ms": 1068.5,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_9",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "#### Scheduling Behavior\n\nWhen scheduling a new Pod, the Kubernetes scheduler evaluates the Pod's affinity/anti-affinity rules in the context of the current cluster state:\n\n1. Hard Constraints (Node Filtering):\n   - `podAffinity.requiredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler ensures the new Pod is assigned to nodes that satisfy these required affinity and anti-affinity rules based on existing Pods.\n\n2. Soft Constraints (Scoring):\n   - `podAffinity.preferredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler scores nodes based on how well they meet these preferred affinity and anti-affinity rules to optimize Pod placement.\n\n3. Ignored Fields:\n   - Existing Pods' `podAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - These preferred affinity rules are not considered during the scheduling decision for new Pods.\n   - Existing Pods' `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - Similarly, preferred anti-affinity rules of existing Pods are ignored during scheduling.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_8",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "### Inter-pod affinity and anti-affinity\n\nInter-pod affinity and anti-affinity allow you to constrain which nodes your\nPods can be scheduled on based on the labels of Pods already running on that\nnode, instead of the node labels.\n\n#### Types of Inter-pod Affinity and Anti-affinity\n\nInter-pod affinity and anti-affinity take the form \"this\nPod should (or, in the case of anti-affinity, should not) run in an X if that X\nis already running one or more Pods that meet rule Y\", where X is a topology\ndomain like node, rack, cloud provider zone or region, or similar and Y is the\nrule Kubernetes tries to satisfy.\n\nYou express these rules (Y) as [label selectors](/docs/concepts/overview/working-with-objects/labels/#label-selectors)\nwith an optional associated list of namespaces. Pods are namespaced objects in\nKubernetes, so Pod labels also implicitly have namespaces. Any label selectors\nfor Pod labels should specify the namespaces in which Kubernetes should look for those\nlabels.\n\nYou express the topology domain (X) using a `topologyKey`, which is the key for\nthe node label that the system uses to denote the domain. For examples, see\n[Well-Known Labels, Annotations and Taints](/docs/reference/labels-annotations-taints/).\n\n{{< note >}}\nInter-pod affinity and anti-affinity require substantial amounts of\nprocessing which can slow down scheduling in large clusters significantly. We do\nnot recommend using them in clusters larger than several hundred nodes.\n{{</note>}}\n\n{{< note >}}\nPod anti-affinity requires nodes to be consistently labeled, in other words,\nevery node in the cluster must have an appropriate label matching `topologyKey`.\nIf some or all nodes are missing the specified `topologyKey` label, it can lead\nto unintended behavior.\n{{</note>}}\n\nSimilar to [node affinity](#node-affinity) are two types of Pod affinity and\nanti-affinity as follows:\n\n- `requiredDuringSchedulingIgnoredDuringExecution`\n- `preferredDuringSchedulingIgnoredDuringExecution`\n\nFor example, you could use\n`requiredDuringSchedulingIgnoredDuringExecution` affinity to tell the scheduler to\nco-locate Pods of two services in the same cloud provider zone because they\ncommunicate with each other a lot. Similarly, you could use\n`preferredDuringSchedulingIgnoredDuringExecution` anti-affinity to spread Pods\nfrom a service across multiple cloud provider zones.\n\nTo use inter-pod affinity, use the `affinity.podAffinity` field in the Pod spec.\nFor inter-pod anti-affinity, use the `affinity.podAntiAffinity` field in the Pod\nspec.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_11",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "#### Pod Affinity Example {#an-example-of-a-pod-that-uses-pod-affinity}\n\nConsider the following Pod spec:\n\n{{% code_sample file=\"pods/pod-with-pod-affinity.yaml\" %}}\n\nThis example defines one Pod affinity rule and one Pod anti-affinity rule. The\nPod affinity rule uses the \"hard\"\n`requiredDuringSchedulingIgnoredDuringExecution`, while the anti-affinity rule\nuses the \"soft\" `preferredDuringSchedulingIgnoredDuringExecution`.\n\nThe affinity rule specifies that the scheduler is allowed to place the example Pod\non a node only if that node belongs to a specific [zone](/docs/concepts/scheduling-eviction/topology-spread-constraints/)\nwhere other Pods have been labeled with `security=S1`.\nFor instance, if we have a cluster with a designated zone, let's call it \"Zone V,\"\nconsisting of nodes labeled with `topology.kubernetes.io/zone=V`, the scheduler can\nassign the Pod to any node within Zone V, as long as there is at least one Pod within\nZone V already labeled with `security=S1`. Conversely, if there are no Pods with `security=S1`\nlabels in Zone V, the scheduler will not assign the example Pod to any node in that zone.\n\nThe anti-affinity rule specifies that the scheduler should try to avoid scheduling the Pod\non a node if that node belongs to a specific [zone](/docs/concepts/scheduling-eviction/topology-spread-constraints/)\nwhere other Pods have been labeled with `security=S2`.\nFor instance, if we have a cluster with a designated zone, let's call it \"Zone R,\"\nconsisting of nodes labeled with `topology.kubernetes.io/zone=R`, the scheduler should avoid\nassigning the Pod to any node within Zone R, as long as there is at least one Pod within\nZone R already labeled with `security=S2`. Conversely, the anti-affinity rule does not impact\nscheduling into Zone R if there are no Pods with `security=S2` labels.\n\nTo get yourself more familiar with the examples of Pod affinity and anti-affinity,\nrefer to the [design proposal](https://git.k8s.io/design-proposals-archive/scheduling/podaffinity.md).\n\nYou can use the `In`, `NotIn`, `Exists` and `DoesNotExist` values in the\n`operator` field for Pod affinity and anti-affinity.\n\nRead [Operators](#operators)\nto learn more about how these work.\n\nIn principle, the `topologyKey` can be any allowed label key with the following\nexceptions for performance and security reasons:\n\n- For Pod affinity and anti-affinity, an empty `topologyKey` field is not allowed in both\n  `requiredDuringSchedulingIgnoredDuringExecution`\n  and `preferredDuringSchedulingIgnoredDuringExecution`.\n- For `requiredDuringSchedulingIgnoredDuringExecution` Pod anti-affinity rules,\n  the admission controller `LimitPodHardAntiAffinityTopology` limits\n  `topologyKey` to `kubernetes.io/hostname`. You can modify or disable the\n  admission controller if you want to allow custom topologies.\n\nIn addition to `labelSelector` and `topologyKey`, you can optionally specify a list\nof namespaces which the `labelSelector` should match against using the\n`namespaces` field at the same level as `labelSelector` and `topologyKey`.\nIf omitted or empty, `namespaces` defaults to the namespace of the Pod where the\naffinity/anti-affinity definition appears.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_topology-spread-constraints_mdsem_15",
          "doc_id": "concepts_scheduling-eviction_topology-spread-constraints",
          "content": "## Comparison with podAffinity and podAntiAffinity {#comparison-with-podaffinity-podantiaffinity}\n\nIn Kubernetes, [inter-Pod affinity and anti-affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity)\ncontrol how Pods are scheduled in relation to one another - either more packed\nor more scattered.\n\n`podAffinity`\n: attracts Pods; you can try to pack any number of Pods into qualifying\n  topology domain(s).\n\n`podAntiAffinity`\n: repels Pods. If you set this to `requiredDuringSchedulingIgnoredDuringExecution` mode then\n  only a single Pod can be scheduled into a single topology domain; if you choose\n  `preferredDuringSchedulingIgnoredDuringExecution` then you lose the ability to enforce the\n  constraint.\n\nFor finer control, you can specify topology spread constraints to distribute\nPods across different topology domains - to achieve either high availability or\ncost-saving. This can also help on rolling update workloads and scaling out\nreplicas smoothly.\n\nFor more context, see the\n[Motivation](https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/895-pod-topology-spread#motivation)\nsection of the enhancement proposal about Pod topology spread constraints.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_topology-spread-constraints_mdsem_9",
          "doc_id": "concepts_scheduling-eviction_topology-spread-constraints",
          "content": "### Example: multiple topology spread constraints {#example-multiple-topologyspreadconstraints}\n\nThis builds upon the previous example. Suppose you have a 4-node cluster where 3\nexisting Pods labeled `foo: bar` are located on node1, node2 and node3 respectively:\n\n{{<mermaid>}}\ngraph BT\n    subgraph \"zoneB\"\n        p3(Pod) --> n3(Node3)\n        n4(Node4)\n    end\n    subgraph \"zoneA\"\n        p1(Pod) --> n1(Node1)\n        p2(Pod) --> n2(Node2)\n    end\n\n    classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;\n    classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;\n    classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;\n    class n1,n2,n3,n4,p1,p2,p3 k8s;\n    class p4 plain;\n    class zoneA,zoneB cluster;\n{{< /mermaid >}}\n\nYou can combine two topology spread constraints to control the spread of Pods both\nby node and by zone:\n\n{{% code_sample file=\"pods/topology-spread-constraints/two-constraints.yaml\" %}}\n\nIn this case, to match the first constraint, the incoming Pod can only be placed onto\nnodes in zone `B`; while in terms of the second constraint, the incoming Pod can only be\nscheduled to the node `node4`. The scheduler only considers options that satisfy all\ndefined constraints, so the only valid placement is onto node `node4`.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n04",
      "question": "What's wrong with using container scope for latency-sensitive applications?",
      "expected_answer": "Containers may end up on different NUMA nodes since there's no grouping",
      "category": "NEGATION",
      "latency_ms": 950.8,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_cluster-administration_flow-control_mdsem_23",
          "doc_id": "concepts_cluster-administration_flow-control",
          "content": "### Workload modifications {#good-practice-workload-modifications}\n\nTo prevent requests from queuing and adding latency or being dropped due to APF,\nyou can optimize your requests by:\n\n- Reducing the rate at which requests are executed. A fewer number of requests\n  over a fixed period will result in a fewer number of seats being needed at a\n  given time.\n- Avoid issuing a large number of expensive requests concurrently. Requests can\n  be optimized to use fewer seats or have lower latency so that these requests\n  hold those seats for a shorter duration. List requests can occupy more than 1\n  seat depending on the number of objects fetched during the request. Restricting\n  the number of objects retrieved in a list request, for example by using\n  pagination, will use less total seats over a shorter period. Furthermore,\n  replacing list requests with watch requests will require lower total concurrency\n  shares as watch requests only occupy 1 seat during its initial burst of\n  notifications. If using streaming lists in versions 1.27 and later, watch\n  requests will occupy the same number of seats as a list request for its initial\n  burst of notifications because the entire state of the collection has to be\n  streamed. Note that in both cases, a watch request will not hold any seats after\n  this initial phase.\n\nKeep in mind that queuing or rejected requests from APF could be induced by\neither an increase in the number of requests or an increase in latency for\nexisting requests. For example, if requests that normally take 1s to execute\nstart taking 60s, it is possible that APF will start rejecting requests because\nrequests are occupying seats for a longer duration than normal due to this\nincrease in latency. If APF starts rejecting requests across multiple priority\nlevels without a significant change in workload, it is possible there is an\nunderlying issue with control plane performance rather than the workload or APF\nsettings.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_cluster-administration_admission-webhooks-good-practices_mdsem_5",
          "doc_id": "concepts_cluster-administration_admission-webhooks-good-practices",
          "content": "## Performance and latency {#performance-latency}\n\nThis section describes recommendations for improving performance and reducing\nlatency. In summary, these are as follows:\n\n* Consolidate webhooks and limit the number of API calls per webhook.\n* Use audit logs to check for webhooks that repeatedly do the same action.\n* Use load balancing for webhook availability.\n* Set a small timeout value for each webhook.\n* Consider cluster availability needs during webhook design.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_containers_runtime-class_mdsem_1",
          "doc_id": "concepts_containers_runtime-class",
          "content": "## Motivation\n\nYou can set a different RuntimeClass between different Pods to provide a balance of\nperformance versus security. For example, if part of your workload deserves a high\nlevel of information security assurance, you might choose to schedule those Pods so\nthat they run in a container runtime that uses hardware virtualization. You'd then\nbenefit from the extra isolation of the alternative runtime, at the expense of some\nadditional overhead.\n\nYou can also use RuntimeClass to run different Pods with the same container runtime\nbut with different settings.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_cluster-administration_flow-control_mdsem_22",
          "doc_id": "concepts_cluster-administration_flow-control",
          "content": "## Good practices for using API Priority and Fairness\n\nWhen a given priority level exceeds its permitted concurrency, requests can\nexperience increased latency or be dropped with an HTTP 429 (Too Many Requests)\nerror. To prevent these side effects of APF, you can modify your workload or\ntweak your APF settings to ensure there are sufficient seats available to serve\nyour requests.\n\nTo detect whether requests are being rejected due to APF, check the following\nmetrics:\n\n- apiserver_flowcontrol_rejected_requests_total: the total number of requests\n  rejected per FlowSchema and PriorityLevelConfiguration.\n- apiserver_flowcontrol_current_inqueue_requests: the current number of requests\n  queued per FlowSchema and PriorityLevelConfiguration.\n- apiserver_flowcontrol_request_wait_duration_seconds: the latency added to\n  requests waiting in queues.\n- apiserver_flowcontrol_priority_level_seat_utilization: the seat utilization\n  per PriorityLevelConfiguration.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_cluster-administration_swap-memory-management_mdsem_14",
          "doc_id": "concepts_cluster-administration_swap-memory-management",
          "content": "### Protect system-critical daemons for I/O latency\n\nSwap can increase the I/O load on a node.\nWhen memory pressure causes the kernel to rapidly swap pages in and out,\nsystem-critical daemons and services that rely on I/O operations may\nexperience performance degradation.\n\nTo mitigate this, it is recommended for systemd users to prioritize the system slice in terms of I/O latency.\nFor non-systemd users,\nsetting up a dedicated cgroup for system daemons and processes and prioritizing I/O latency in the same way is advised.\nThis can be achieved by setting `io.latency` for the system slice,\nthereby granting it higher I/O priority.\nSee [cgroup's documentation](https://www.kernel.org/doc/Documentation/admin-guide/cgroup-v2.rst) for more info.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n05",
      "question": "When does single-numa-node policy reject a pod that would be admitted by restricted?",
      "expected_answer": "When pod needs resources from exactly 2+ NUMA nodes; restricted accepts any preferred, single-numa-node requires exactly 1",
      "category": "NEGATION",
      "latency_ms": 1144.3,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_cluster-administration_node-autoscaling_mdsem_2",
          "doc_id": "concepts_cluster-administration_node-autoscaling",
          "content": "### Pod scheduling constraints {#provisioning-pod-constraints}\n\nPods can express [scheduling constraints](/docs/concepts/scheduling-eviction/assign-pod-node/) to\nimpose limitations on the kind of Nodes they can be scheduled on. Node autoscalers take these\nconstraints into account to ensure that the pending Pods can be scheduled on the provisioned Nodes.\n\nThe most common kind of scheduling constraints are the resource requests specified by Pod\ncontainers. Autoscalers will make sure that the provisioned Nodes have enough resources to satisfy\nthe requests. However, they don't directly take into account the real resource usage of the Pods\nafter they start running. In order to autoscale Nodes based on actual workload resource usage, you\ncan combine [horizontal workload autoscaling](#horizontal-workload-autoscaling) with Node\nautoscaling.\n\nOther common Pod scheduling constraints include\n[Node affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity),\n[inter-Pod affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity),\nor a requirement for a particular [storage volume](/docs/concepts/storage/volumes/).",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_scheduling-eviction_assign-pod-node_mdsem_9",
          "doc_id": "concepts_scheduling-eviction_assign-pod-node",
          "content": "#### Scheduling Behavior\n\nWhen scheduling a new Pod, the Kubernetes scheduler evaluates the Pod's affinity/anti-affinity rules in the context of the current cluster state:\n\n1. Hard Constraints (Node Filtering):\n   - `podAffinity.requiredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler ensures the new Pod is assigned to nodes that satisfy these required affinity and anti-affinity rules based on existing Pods.\n\n2. Soft Constraints (Scoring):\n   - `podAffinity.preferredDuringSchedulingIgnoredDuringExecution` and `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - The scheduler scores nodes based on how well they meet these preferred affinity and anti-affinity rules to optimize Pod placement.\n\n3. Ignored Fields:\n   - Existing Pods' `podAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - These preferred affinity rules are not considered during the scheduling decision for new Pods.\n   - Existing Pods' `podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`:\n     - Similarly, preferred anti-affinity rules of existing Pods are ignored during scheduling.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_m01",
      "question": "How do I configure CPU placement policy in kubelet?",
      "expected_answer": "--topology-manager-policy flag",
      "category": "VOCABULARY",
      "latency_ms": 1074.0,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_cpu-management-policies_mdsem_0",
          "doc_id": "tasks_administer-cluster_cpu-management-policies",
          "content": "---\ntitle: Control CPU Management Policies on the Node\nreviewers:\n- sjenning\n- ConnorDoyle\n- balajismaniam\n\ncontent_type: task\nmin-kubernetes-server-version: v1.26\nweight: 140\n---\n\n<!-- overview -->\n\n{{< feature-state for_k8s_version=\"v1.26\" state=\"stable\" >}}\n\nKubernetes keeps many aspects of how pods execute on nodes abstracted\nfrom the user. This is by design. \u00a0However, some workloads require\nstronger guarantees in terms of latency and/or performance in order to operate\nacceptably. The kubelet provides methods to enable more complex workload\nplacement policies while keeping the abstraction free from explicit placement\ndirectives.\n\nFor detailed information on resource management, please refer to the\n[Resource Management for Pods and Containers](/docs/concepts/configuration/manage-resources-containers)\ndocumentation.\n\nFor detailed information on how the kubelet implements resource management, please refer to the\n[Node ResourceManagers](/docs/concepts/policy/node-resource-managers) documentation.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_policy_node-resource-managers_mdsem_1",
          "doc_id": "concepts_policy_node-resource-managers",
          "content": "## Hardware topology alignment policies\n\n_Topology Manager_ is a kubelet component that aims to coordinate the set of components that are\nresponsible for these optimizations. The overall resource management process is governed using\nthe policy you specify. To learn more, read\n[Control Topology Management Policies on a Node](/docs/tasks/administer-cluster/topology-manager/).\n\n## Policies for assigning CPUs to Pods\n\n{{< feature-state feature_gate_name=\"CPUManager\" >}}\n\nOnce a Pod is bound to a Node, the kubelet on that node may need to either multiplex the existing\nhardware (for example, sharing CPUs across multiple Pods) or allocate hardware by dedicating some\nresource (for example, assigning one of more CPUs for a Pod's exclusive use).\n\nBy default, the kubelet uses [CFS quota](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler)\nto enforce pod CPU limits. \u00a0When the node runs many CPU-bound pods, the workload can move to\ndifferent CPU cores depending on whether the pod is throttled and which CPU cores are available\nat scheduling time. Many workloads are not sensitive to this migration and thus\nwork fine without any intervention.\n\nHowever, in workloads where CPU cache affinity and scheduling latency significantly affect\nworkload performance, the kubelet allows alternative CPU\nmanagement policies to determine some placement preferences on the node.\nThis is implemented using the _CPU Manager_ and its policy.\nThere are two available policies:\n\n- `none`: the `none` policy explicitly enables the existing default CPU\n  affinity scheme, providing no affinity beyond what the OS scheduler does\n  automatically. \u00a0Limits on CPU usage for\n  [Guaranteed pods](/docs/concepts/workloads/pods/pod-qos/) and\n  [Burstable pods](/docs/concepts/workloads/pods/pod-qos/)\n  are enforced using CFS quota.\n- `static`: the `static` policy allows containers in `Guaranteed` pods with integer CPU\n  `requests` access to exclusive CPUs on the node. This exclusivity is enforced\n  using the [cpuset cgroup controller](https://www.kernel.org/doc/Documentation/cgroup-v2.txt).\n\n{{< note >}}\nSystem services such as the container runtime and the kubelet itself can continue to run on\nthese exclusive CPUs. \u00a0The exclusivity only extends to other pods.\n{{< /note >}}\n\nCPU Manager doesn't support offlining and onlining of CPUs at runtime.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_cpu-management-policies_mdsem_1",
          "doc_id": "tasks_administer-cluster_cpu-management-policies",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\nIf you are running an older version of Kubernetes, please look at the documentation for the version you are actually running.\n\n\n<!-- steps -->\n\n## Configuring CPU management policies\n\nBy default, the kubelet uses [CFS quota](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler)\nto enforce pod CPU limits. \u00a0When the node runs many CPU-bound pods,\nthe workload can move to different CPU cores depending on\nwhether the pod is throttled and which CPU cores are available at\nscheduling time. Many workloads are not sensitive to this migration and thus\nwork fine without any intervention.\n\nHowever, in workloads where CPU cache affinity and scheduling latency\nsignificantly affect workload performance, the kubelet allows alternative CPU\nmanagement policies to determine some placement preferences on the node.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_cpu-management-policies_mdsem_4",
          "doc_id": "tasks_administer-cluster_cpu-management-policies",
          "content": "### `none` policy configuration\n\nThis policy has no extra configuration items.\n\n### `static` policy configuration\n\nThis policy manages a shared pool of CPUs that initially contains all CPUs in the\nnode. The amount of exclusively allocatable CPUs is equal to the total\nnumber of CPUs in the node minus any CPU reservations by the kubelet `--kube-reserved` or\n`--system-reserved` options. From 1.17, the CPU reservation list can be specified\nexplicitly by kubelet `--reserved-cpus` option. The explicit CPU list specified by\n`--reserved-cpus` takes precedence over the CPU reservation specified by\n`--kube-reserved` and `--system-reserved`. CPUs reserved by these options are taken, in\ninteger quantity, from the initial shared pool in ascending order by physical\ncore ID. \u00a0This shared pool is the set of CPUs on which any containers in\n`BestEffort` and `Burstable` pods run. Containers in `Guaranteed` pods with fractional\nCPU `requests` also run on CPUs in the shared pool. Only containers that are\nboth part of a `Guaranteed` pod and have integer CPU `requests` are assigned\nexclusive CPUs.\n\n{{< note >}}\nThe kubelet requires a CPU reservation greater than zero be made\nusing either `--kube-reserved` and/or `--system-reserved` or `--reserved-cpus` when\nthe static policy is enabled. This is because zero CPU reservation would allow the shared\npool to become empty.\n{{< /note >}}",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_cpu-management-policies_mdsem_3",
          "doc_id": "tasks_administer-cluster_cpu-management-policies",
          "content": "## Changing the CPU Manager Policy\n\nSince the CPU manager policy can only be applied when kubelet spawns new pods, simply changing from\n\"none\" to \"static\" won't apply to existing pods. So in order to properly change the CPU manager\npolicy on a node, perform the following steps:\n\n1. [Drain](/docs/tasks/administer-cluster/safely-drain-node) the node.\n2. Stop kubelet.\n3. Remove the old CPU manager state file. The path to this file is\n`/var/lib/kubelet/cpu_manager_state` by default. This clears the state maintained by the\nCPUManager so that the cpu-sets set up by the new policy won\u2019t conflict with it.\n4. Edit the kubelet configuration to change the CPU manager policy to the desired value.\n5. Start kubelet.\n\nRepeat this process for every node that needs its CPU manager policy changed. Skipping this\nprocess will result in kubelet crashlooping with the following error:\n\n```\ncould not restore state from checkpoint: configured policy \"static\" differs from state checkpoint policy \"none\", please drain this node and delete the CPU manager checkpoint file \"/var/lib/kubelet/cpu_manager_state\" before restarting Kubelet\n```\n\n{{< note >}}\nif the set of online CPUs changes on the node, the node must be drained and CPU manager manually reset by deleting the\nstate file `cpu_manager_state` in the kubelet root directory.\n{{< /note >}}",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_m02",
      "question": "How do I enable NUMA awareness on Windows k8s nodes?",
      "expected_answer": "Enable WindowsCPUAndMemoryAffinity feature gate",
      "category": "VOCABULARY",
      "latency_ms": 1037.4,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_6",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "#### BestEffort policy {#policy-best-effort}\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\n**This policy is only supported on Windows.**\n\nOn Windows, NUMA node assignment works differently than Linux.\nThere is no mechanism to ensure that Memory access only comes from a specific NUMA node.\nInstead the Windows operating system scheduler selects the most optimal NUMA node based on the CPU(s) assignments.\nIt is possible that Windows might use other NUMA nodes if the Windows scheduler deems them optimal.\n\nThe policy does track the amount of memory available and requested through the internal _node map_.\nThe memory manager makes a best effort at ensuring that enough memory is available on a NUMA node before making\na resource assignment.  \nThis means that in most cases memory assignment should function as specified.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "### Windows support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nWindows support can be enabled via the `WindowsCPUAndMemoryAffinity` feature gate\nand it requires support in the container runtime.  \nOnly the [None](#policy-none) and [BestEffort](#policy-best-effort) policies are supported on Windows.\n\n## How does the Memory Manager operate?\n\nFor Linux nodes, the Memory Manager offers the guaranteed memory (and hugepages) allocation\nfor Pods in Guaranteed QoS class.\nTo immediately put the Memory Manager into operation follow the guidelines in the section\n[Memory Manager configuration](#memory-manager-configuration), and subsequently,\nprepare and deploy a `Guaranteed` Pod as illustrated in the section\n[Placing a Pod in the Guaranteed QoS class](#placing-a-pod-in-the-guaranteed-qos-class).\n\nThe Memory Manager is a hint provider, and it provides topology hints for\nthe Topology Manager which then aligns the requested resources according to these topology hints.\nOn Linux, it also enforces `cgroups` (specifically, `cpuset.mems`) for Pods.\nThe complete flow diagram concerning pod admission and deployment process is illustrated\nbelow:\n\n![Memory Manager in the pod admission and deployment process](/images/docs/memory-manager-diagram.svg)\n\nDuring this process, the Memory Manager updates its internal counters stored in\n[Node Map and Memory Maps][2] to manage guaranteed memory allocation.\n\nThe memory manager activates during kubelet startup if a node administrator configures\n`reservedMemory` for the kubelet (section [Reserved memory configuration](#reserved-memory-flag)).\nIn this case, the kubelet updates its node map to reflect this reservation.\n\nWhen the `Static` policy is configured, you **must** configure reserved memory for the node\n(for example, with the `reservedMemory` configuration field in the kubelet configuration).\n\nAn important topic in the context of Memory Manager operation is the management of NUMA groups.\nEach time pod's memory request is in excess of single NUMA node capacity, the Memory Manager\nattempts to create a group that comprises several NUMA nodes and that features extended memory\ncapacity.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "## Reserved memory configuration {#reserved-memory-flag}\n\nAs an administrator, you can configure the total amount of reserved memory\nfor a node. This pre-configured value is subsequently utilized to calculate\nthe real amount of [node allocatable](/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable) memory available to pods.\n\nThe Kubernetes scheduler incorporates allocatable memory information to optimise pod\n[scheduling](/docs/concepts/scheduling-eviction/).\n. The _node allocatable_ mechanism is commonly used by node administrators to reserve K8s node\nsystem resources for the kubelet or operating system processes to help assure node stability.\n\nThe relevant kubelet settings include `kubeReserved`, `systemReserved` and `reservedMemory`.\nThe `reservedMemory` setting allows you to split the total reserved memory and assign it\nacross many NUMA nodes.\n\nYou specify a comma-separated list of memory reservations, of different\nmemory types, per NUMA node.\nYou can also specify reservations that span multiple NUMA nodes, using a semicolon as separator.\n\nThe Memory Manager will not use this reserved memory for running container workloads.\n\nFor example, if you have a NUMA node \"NUMA0\" with 10GiB of memory available, and\nyou configure `reservedMemory`  to reserve `1Gi` (of memory) for NUMA0,\nthe Memory Manager assumes that only 9GiB is available for pods.\n\nYou can omit this parameter, however, you should be aware that the quantity of reserved memory\nfrom all NUMA nodes should be equal to the quantity of _node allocatable_ memory.\n\nIf at least one node allocatable parameter is non-zero, you will need to specify\n`reservedMemory` for at least one NUMA node.\nIn fact, the `evictionHard` threshold value is equal to `100Mi` by default, so\nif you use the `Static` policy, specifying `reservedMemory` is obligatory.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_m03",
      "question": "How does k8s coordinate resource co-location across multi-socket servers?",
      "expected_answer": "Topology Manager acts as source of truth for CPU Manager and Device Manager",
      "category": "VOCABULARY",
      "latency_ms": 1152.5,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_policy_node-resource-managers_mdsem_1",
          "doc_id": "concepts_policy_node-resource-managers",
          "content": "## Hardware topology alignment policies\n\n_Topology Manager_ is a kubelet component that aims to coordinate the set of components that are\nresponsible for these optimizations. The overall resource management process is governed using\nthe policy you specify. To learn more, read\n[Control Topology Management Policies on a Node](/docs/tasks/administer-cluster/topology-manager/).\n\n## Policies for assigning CPUs to Pods\n\n{{< feature-state feature_gate_name=\"CPUManager\" >}}\n\nOnce a Pod is bound to a Node, the kubelet on that node may need to either multiplex the existing\nhardware (for example, sharing CPUs across multiple Pods) or allocate hardware by dedicating some\nresource (for example, assigning one of more CPUs for a Pod's exclusive use).\n\nBy default, the kubelet uses [CFS quota](https://en.wikipedia.org/wiki/Completely_Fair_Scheduler)\nto enforce pod CPU limits. \u00a0When the node runs many CPU-bound pods, the workload can move to\ndifferent CPU cores depending on whether the pod is throttled and which CPU cores are available\nat scheduling time. Many workloads are not sensitive to this migration and thus\nwork fine without any intervention.\n\nHowever, in workloads where CPU cache affinity and scheduling latency significantly affect\nworkload performance, the kubelet allows alternative CPU\nmanagement policies to determine some placement preferences on the node.\nThis is implemented using the _CPU Manager_ and its policy.\nThere are two available policies:\n\n- `none`: the `none` policy explicitly enables the existing default CPU\n  affinity scheme, providing no affinity beyond what the OS scheduler does\n  automatically. \u00a0Limits on CPU usage for\n  [Guaranteed pods](/docs/concepts/workloads/pods/pod-qos/) and\n  [Burstable pods](/docs/concepts/workloads/pods/pod-qos/)\n  are enforced using CFS quota.\n- `static`: the `static` policy allows containers in `Guaranteed` pods with integer CPU\n  `requests` access to exclusive CPUs on the node. This exclusivity is enforced\n  using the [cpuset cgroup controller](https://www.kernel.org/doc/Documentation/cgroup-v2.txt).\n\n{{< note >}}\nSystem services such as the container runtime and the kubelet itself can continue to run on\nthese exclusive CPUs. \u00a0The exclusivity only extends to other pods.\n{{< /note >}}\n\nCPU Manager doesn't support offlining and onlining of CPUs at runtime.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_m04",
      "question": "What kubelet setting controls the granularity of resource alignment?",
      "expected_answer": "topologyManagerScope (container or pod)",
      "category": "VOCABULARY",
      "latency_ms": 964.7,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "setup_production-environment_tools_kubeadm_kubelet-integration_mdsem_1",
          "doc_id": "setup_production-environment_tools_kubeadm_kubelet-integration",
          "content": "## Kubelet configuration patterns\n\nThe following sections describe patterns to kubelet configuration that are simplified by\nusing kubeadm, rather than managing the kubelet configuration for each Node manually.\n\n### Propagating cluster-level configuration to each kubelet\n\nYou can provide the kubelet with default values to be used by `kubeadm init` and `kubeadm join`\ncommands. Interesting examples include using a different container runtime or setting the default subnet\nused by services.\n\nIf you want your services to use the subnet `10.96.0.0/12` as the default for services, you can pass\nthe `--service-cidr` parameter to kubeadm:\n\n```bash\nkubeadm init --service-cidr 10.96.0.0/12\n```\n\nVirtual IPs for services are now allocated from this subnet. You also need to set the DNS address used\nby the kubelet, using the `--cluster-dns` flag. This setting needs to be the same for every kubelet\non every manager and Node in the cluster. The kubelet provides a versioned, structured API object\nthat can configure most parameters in the kubelet and push out this configuration to each running\nkubelet in the cluster. This object is called\n[`KubeletConfiguration`](/docs/reference/config-api/kubelet-config.v1beta1/).\nThe `KubeletConfiguration` allows the user to specify flags such as the cluster DNS IP addresses expressed as\na list of values to a camelCased key, illustrated by the following example:\n\n```yaml\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\nclusterDNS:\n- 10.96.0.10\n```\n\nFor more details on the `KubeletConfiguration` have a look at [this section](#configure-kubelets-using-kubeadm).",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_memory-manager_mdsem_3",
          "doc_id": "tasks_administer-cluster_memory-manager",
          "content": "## Memory Manager configuration\n\nOther Managers should already be configured (see [resource alignment prerequisites](#resource-alignment-prerequisites).\nSet the `memoryManagerPolicy` configuration field within the [kubelet configuration]({{< relref \"/docs/reference/config-api/kubelet-config.v1beta1\" >}}), to the name of your chosen [policy](#policies).\n\nOptionally, some amount of memory can be reserved for system or kubelet processes to increase\nnode stability (section [Reserved memory configuration](#reserved-memory-flag)).",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_3",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager scopes\n\nThe Topology Manager can deal with the alignment of resources in a couple of distinct scopes:\n\n* `container` (default)\n* `pod`\n\nEither option can be selected at a time of the kubelet startup, by setting the\n`topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\n### `container` scope\n\nThe `container` scope is used by default. You can also explicitly set the\n`topologyManagerScope` to `container` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\nWithin this scope, the Topology Manager performs a number of sequential resource alignments, i.e.,\nfor each container (in a pod) a separate alignment is computed. In other words, there is no notion\nof grouping the containers to a specific set of NUMA nodes, for this particular scope. In effect,\nthe Topology Manager performs an arbitrary alignment of individual containers to NUMA nodes.\n\nThe notion of grouping the containers was endorsed and implemented on purpose in the following\nscope, for example the `pod` scope.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_reserve-compute-resources_mdsem_1",
          "doc_id": "tasks_administer-cluster_reserve-compute-resources",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}}\n\nYou can configure below kubelet [configuration settings](/docs/reference/config-api/kubelet-config.v1beta1/)\nusing the [kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\n<!-- steps -->\n\n## Node Allocatable\n\n![node capacity](/images/docs/node-capacity.svg)\n\n'Allocatable' on a Kubernetes node is defined as the amount of compute resources\nthat are available for pods. The scheduler does not over-subscribe\n'Allocatable'. 'CPU', 'memory' and 'ephemeral-storage' are supported as of now.\n\nNode Allocatable is exposed as part of `v1.Node` object in the API and as part\nof `kubectl describe node` in the CLI.\n\nResources can be reserved for two categories of system daemons in the `kubelet`.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_configuration_manage-resources-containers_mdsem_19",
          "doc_id": "concepts_configuration_manage-resources-containers",
          "content": "#### Extended resources allocation by DRA\n\nExtended resources allocation by DRA allows cluster administrators to specify an `extendedResourceName`\nin DeviceClass, then the devices matching the DeviceClass can be requested from a pod's extended\nresource requests. Read more about\n[Extended Resource allocation by DRA](/docs/concepts/scheduling-eviction/dynamic-resource-allocation/#extended-resource).\n\n### Consuming extended resources\n\nUsers can consume extended resources in Pod specs like CPU and memory.\nThe scheduler takes care of the resource accounting so that no more than the\navailable amount is simultaneously allocated to Pods.\n\nThe API server restricts quantities of extended resources to whole numbers.\nExamples of _valid_ quantities are `3`, `3000m` and `3Ki`. Examples of\n_invalid_ quantities are `0.5` and `1500m` (because `1500m` would result in `1.5`).\n\n{{< note >}}\nExtended resources replace Opaque Integer Resources.\nUsers can use any domain name prefix other than `kubernetes.io` which is reserved.\n{{< /note >}}\n\nTo consume an extended resource in a Pod, include the resource name as a key\nin the `spec.containers[].resources.limits` map in the container spec.\n\n{{< note >}}\nExtended resources cannot be overcommitted, so request and limit\nmust be equal if both are present in a container spec.\n{{< /note >}}\n\nA Pod is scheduled only if all of the resource requests are satisfied, including\nCPU, memory and any extended resources. The Pod remains in the `PENDING` state\nas long as the resource request cannot be satisfied.\n\n**Example:**\n\nThe Pod below requests 2 CPUs and 1 \"example.com/foo\" (an extended resource).\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: my-container\n    image: myimage\n    resources:\n      requests:\n        cpu: 2\n        example.com/foo: 1\n      limits:\n        example.com/foo: 1\n```\n\n## PID limiting\n\nProcess ID (PID) limits allow for the configuration of a kubelet\nto limit the number of PIDs that a given Pod can consume. See\n[PID Limiting](/docs/concepts/policy/pid-limiting/) for information.\n\n## Troubleshooting\n\n",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_m05",
      "question": "How do I optimize inter-process communication latency for pods?",
      "expected_answer": "Use pod scope with single-numa-node policy to eliminate inter-NUMA overhead",
      "category": "VOCABULARY",
      "latency_ms": 914.2,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_job_job-with-pod-to-pod-communication_mdsem_0",
          "doc_id": "tasks_job_job-with-pod-to-pod-communication",
          "content": "---\ntitle: Job with Pod-to-Pod Communication\ncontent_type: task\nmin-kubernetes-server-version: v1.21\nweight: 30\n---\n\n<!-- overview -->\n\nIn this example, you will run a Job in [Indexed completion mode](/blog/2021/04/19/introducing-indexed-jobs/)\nconfigured such that the pods created by the Job can communicate with each other using pod hostnames rather\nthan pod IP addresses.\n\nPods within a Job might need to communicate among themselves. The user workload running in each pod\ncould query the Kubernetes API server to learn the IPs of the other Pods, but it's much simpler to\nrely on Kubernetes' built-in DNS resolution.\n\nJobs in Indexed completion mode automatically set the pods' hostname to be in the format of\n`${jobName}-${completionIndex}`. You can use this format to deterministically build\npod hostnames and enable pod communication *without* needing to create a client connection to\nthe Kubernetes control plane to obtain pod hostnames/IPs via API requests.\n\nThis configuration is useful for use cases where pod networking is required but you don't want\nto depend on a network connection with the Kubernetes API server.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_security_multi-tenancy_mdsem_13",
          "doc_id": "concepts_security_multi-tenancy",
          "content": "### Quality-of-Service (QoS) {#qos}\n\nWhen you\u2019re running a SaaS application, you may want the ability to offer different\nQuality-of-Service (QoS) tiers of service to different tenants. For example, you may have freemium\nservice that comes with fewer performance guarantees and features and a for-fee service tier with\nspecific performance guarantees. Fortunately, there are several Kubernetes constructs that can\nhelp you accomplish this within a shared cluster, including network QoS, storage classes, and pod\npriority and preemption. The idea with each of these is to provide tenants with the quality of\nservice that they paid for. Let\u2019s start by looking at networking QoS.\n\nTypically, all pods on a node share a network interface. Without network QoS, some pods may\nconsume an unfair share of the available bandwidth at the expense of other pods.\nThe Kubernetes [bandwidth plugin](https://www.cni.dev/plugins/current/meta/bandwidth/) creates an\n[extended resource](/docs/concepts/configuration/manage-resources-containers/#extended-resources)\nfor networking that allows you to use Kubernetes resources constructs, i.e. requests/limits, to\napply rate limits to pods by using Linux tc queues.\nBe aware that the plugin is considered experimental as per the\n[Network Plugins](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping)\ndocumentation and should be thoroughly tested before use in production environments.\n\nFor storage QoS, you will likely want to create different storage classes or profiles with\ndifferent performance characteristics. Each storage profile can be associated with a different\ntier of service that is optimized for different workloads such IO, redundancy, or throughput.\nAdditional logic might be necessary to allow the tenant to associate the appropriate storage\nprofile with their workload.\n\nFinally, there\u2019s [pod priority and preemption](/docs/concepts/scheduling-eviction/pod-priority-preemption/)\nwhere you can assign priority values to pods. When scheduling pods, the scheduler will try\nevicting pods with lower priority when there are insufficient resources to schedule pods that are\nassigned a higher priority. If you have a use case where tenants have different service tiers in a\nshared cluster e.g. free and paid, you may want to give higher priority to certain tiers using\nthis feature.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_services-networking__index_mdsem_0",
          "doc_id": "concepts_services-networking__index",
          "content": "## The Kubernetes network model\n\nThe Kubernetes network model is built out of several pieces:\n\n* Each [pod](/docs/concepts/workloads/pods/) in a cluster gets its\n  own unique cluster-wide IP address.\n\n  * A pod has its own private network namespace which is shared by\n    all of the containers within the pod. Processes running in\n    different containers in the same pod can communicate with each\n    other over `localhost`.\n\n* The _pod network_ (also called a cluster network) handles communication\n  between pods. It ensures that (barring intentional network segmentation):\n\n  * All pods can communicate with all other pods, whether they are\n    on the same [node](/docs/concepts/architecture/nodes/) or on\n    different nodes. Pods can communicate with each other\n    directly, without the use of proxies or address translation (NAT).\n\n    On Windows, this rule does not apply to host-network pods.\n\n  * Agents on a node (such as system daemons, or kubelet) can\n    communicate with all pods on that node.\n\n* The [Service](/docs/concepts/services-networking/service/) API\n  lets you provide a stable (long lived) IP address or hostname for a service implemented\n  by one or more backend pods, where the individual pods making up\n  the service can change over time.\n\n  * Kubernetes automatically manages\n    [EndpointSlice](/docs/concepts/services-networking/endpoint-slices/)\n    objects to provide information about the pods currently backing a Service.\n\n  * A service proxy implementation monitors the set of Service and\n    EndpointSlice objects, and programs the data plane to route\n    service traffic to its backends, by using operating system or\n    cloud provider APIs to intercept or rewrite packets.\n\n* The [Gateway](/docs/concepts/services-networking/gateway/) API\n  (or its predecessor, [Ingress](/docs/concepts/services-networking/ingress/))\n  allows you to make Services accessible to clients that are outside the cluster.\n\n  * A simpler, but less-configurable, mechanism for cluster\n    ingress is available via the Service API's\n    [`type: LoadBalancer`](/docs/concepts/services-networking/service/#loadbalancer),\n    when using a supported {{< glossary_tooltip term_id=\"cloud-provider\">}}.\n\n* [NetworkPolicy](/docs/concepts/services-networking/network-policies) is a built-in\n  Kubernetes API that allows you to control traffic between pods, or between pods and\n  the outside world.\n\nIn older container systems, there was no automatic connectivity\nbetween containers on different hosts, and so it was often necessary\nto explicitly create links between containers, or to map container\nports to host ports to make them reachable by containers on other\nhosts. This is not needed in Kubernetes; Kubernetes's model is that\npods can be treated much like VMs or physical hosts from the\nperspectives of port allocation, naming, service discovery, load\nbalancing, application configuration, and migration.\n\nOnly a few parts of this model are implemented by Kubernetes itself.\nFor the other parts, Kubernetes defines the APIs, but the\ncorresponding functionality is provided by external components, some\nof which are optional:\n\n* Pod network namespace setup is handled by system-level software implementing the\n  [Container Runtime Interface](/docs/concepts/containers/cri/).\n\n* The pod network itself is managed by a\n  [pod network implementation](/docs/concepts/cluster-administration/addons/#networking-and-network-policy).\n  On Linux, most container runtimes use the\n  {{< glossary_tooltip text=\"Container Networking Interface (CNI)\" term_id=\"cni\" >}}\n  to interact with the pod network implementation, so these\n  implementations are often called _CNI plugins_.\n\n* Kubernetes provides a default implementation of service proxying,\n  called {{< glossary_tooltip term_id=\"kube-proxy\">}}, but some pod\n  network implementations instead use their own service proxy that\n  is more tightly integrated with the rest of the implementation.\n\n* NetworkPolicy is generally also implemented by the pod network\n  implementation. (Some simpler pod network implementations don't\n  implement NetworkPolicy, or an administrator may choose to\n  configure the pod network without NetworkPolicy support. In these\n  cases, the API will still be present, but it will have no effect.)\n\n* There are many [implementations of the Gateway API](https://gateway-api.sigs.k8s.io/implementations/),\n  some of which are specific to particular cloud environments, some more\n  focused on \"bare metal\" environments, and others more generic.\n\n## {{% heading \"whatsnext\" %}}\n\nThe [Connecting Applications with Services](/docs/tutorials/services/connect-applications-service/)\ntutorial lets you learn about Services and Kubernetes networking with a hands-on example.\n\n[Cluster Networking](/docs/concepts/cluster-administration/networking/) explains how to set\nup networking for your cluster, and also provides an overview of the technologies involved.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction__index_mdsem_1",
          "doc_id": "concepts_scheduling-eviction__index",
          "content": "## Scheduling\n\n* [Kubernetes Scheduler](/docs/concepts/scheduling-eviction/kube-scheduler/)\n* [Assigning Pods to Nodes](/docs/concepts/scheduling-eviction/assign-pod-node/)\n* [Pod Overhead](/docs/concepts/scheduling-eviction/pod-overhead/)\n* [Pod Topology Spread Constraints](/docs/concepts/scheduling-eviction/topology-spread-constraints/)\n* [Taints and Tolerations](/docs/concepts/scheduling-eviction/taint-and-toleration/)\n* [Scheduling Framework](/docs/concepts/scheduling-eviction/scheduling-framework)\n* [Dynamic Resource Allocation](/docs/concepts/scheduling-eviction/dynamic-resource-allocation)\n* [Scheduler Performance Tuning](/docs/concepts/scheduling-eviction/scheduler-perf-tuning/)\n* [Resource Bin Packing for Extended Resources](/docs/concepts/scheduling-eviction/resource-bin-packing/)\n* [Pod Scheduling Readiness](/docs/concepts/scheduling-eviction/pod-scheduling-readiness/)\n* [Gang Scheduling](/docs/concepts/scheduling-eviction/gang-scheduling/)\n* [Descheduler](https://github.com/kubernetes-sigs/descheduler#descheduler-for-kubernetes)\n* [Node Declared Features](/docs/concepts/scheduling-eviction/node-declared-features/)\n\n## Pod Disruption\n\n{{<glossary_definition term_id=\"pod-disruption\" length=\"all\">}}\n\n* [Pod Priority and Preemption](/docs/concepts/scheduling-eviction/pod-priority-preemption/)\n* [Node-pressure Eviction](/docs/concepts/scheduling-eviction/node-pressure-eviction/)\n* [API-initiated Eviction](/docs/concepts/scheduling-eviction/api-eviction/)",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_services-networking_service-traffic-policy_mdsem_0",
          "doc_id": "concepts_services-networking_service-traffic-policy",
          "content": "---\nreviewers:\n- maplain\ntitle: Service Internal Traffic Policy\ncontent_type: concept\nweight: 120\ndescription: >-\n  If two Pods in your cluster want to communicate, and both Pods are actually running on\n  the same node, use _Service Internal Traffic Policy_ to keep network traffic within that node.\n  Avoiding a round trip via the cluster network can help with reliability, performance\n  (network latency and throughput), or cost.\n---\n\n\n<!-- overview -->\n\n{{< feature-state for_k8s_version=\"v1.26\" state=\"stable\" >}}\n\n_Service Internal Traffic Policy_ enables internal traffic restrictions to only route\ninternal traffic to endpoints within the node the traffic originated from. The\n\"internal\" traffic here refers to traffic originated from Pods in the current\ncluster. This can help to reduce costs and improve performance.\n\n<!-- body -->",
          "is_needle": false
        }
      ]
    }
  ]
}