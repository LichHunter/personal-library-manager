{
  "benchmark_run_at": "2026-01-26T20:55:17.264538",
  "needle_doc_id": "tasks_administer-cluster_topology-manager",
  "total_documents": 200,
  "total_chunks": 1030,
  "needle_chunks": 14,
  "index_time_s": 16.8,
  "index_stats": {
    "num_chunks": 1030,
    "embedding_dim": 768,
    "bm25_avg_doc_len": 208.23203883495145,
    "rrf_k": 60,
    "enrichment_time_s": 0.04088592529296875,
    "rewrite_timeout_s": 5.0,
    "enricher_stats": {
      "total_processed": 0,
      "total_time_s": 0.0,
      "avg_time_ms": 0.0
    }
  },
  "summary": {
    "total_questions": 20,
    "needle_found_count": 17,
    "needle_found_rate": 85.0,
    "avg_latency_ms": 1070.8
  },
  "results": [
    {
      "question_id": "adv_v01",
      "question": "What's the minimum kubernetes version requirement for topology manager?",
      "expected_answer": "v1.18",
      "category": "VERSION",
      "latency_ms": 1181.1,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n<!-- steps -->\n\n## How topology manager works\n\nPrior to the introduction of Topology Manager, the CPU and Device Manager in Kubernetes make\nresource allocation decisions independently of each other. This can result in undesirable\nallocations on multiple-socketed systems, and performance/latency sensitive applications will suffer\ndue to these undesirable allocations. Undesirable in this case meaning, for example, CPUs and\ndevices being allocated from different NUMA Nodes, thus incurring additional latency.\n\nThe Topology Manager is a kubelet component, which acts as a source of truth so that other kubelet\ncomponents can make topology aligned resource allocation choices.\n\nThe Topology Manager provides an interface for components, called *Hint Providers*, to send and\nreceive topology information. The Topology Manager has a set of node level policies which are\nexplained below.\n\nThe Topology Manager receives topology information from the *Hint Providers* as a bitmask denoting\nNUMA Nodes available and a preferred allocation indication. The Topology Manager policies perform\na set of operations on the hints provided and converge on the hint determined by the policy to\ngive the optimal result. If an undesirable hint is stored, the preferred field for the hint will be\nset to false. In the current policies preferred is the narrowest preferred mask.\nThe selected hint is stored as part of the Topology Manager. Depending on the policy configured,\nthe pod can be accepted or rejected from the node based on the selected hint.\nThe hint is then stored in the Topology Manager for use by the *Hint Providers* when making the\nresource allocation decisions.\n\nThe flow can be seen in the following diagram.\n\n![topology_manager_flow](/images/docs/topology-manager-flow.png)",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_9",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policy options\n\nSupport for the Topology Manager policy options requires `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) to be enabled\n(it is enabled by default).\n\nYou can toggle groups of options on and off based upon their maturity level using the following feature gates:\n\n* `TopologyManagerPolicyBetaOptions` default enabled. Enable to show beta-level options.\n* `TopologyManagerPolicyAlphaOptions` default disabled. Enable to show alpha-level options.\n\nYou will still have to enable each option using the `TopologyManagerPolicyOptions` kubelet option.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_v02",
      "question": "Which Kubernetes release made Topology Manager GA/stable?",
      "expected_answer": "v1.27",
      "category": "VERSION",
      "latency_ms": 858.6,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n<!-- steps -->\n\n## How topology manager works\n\nPrior to the introduction of Topology Manager, the CPU and Device Manager in Kubernetes make\nresource allocation decisions independently of each other. This can result in undesirable\nallocations on multiple-socketed systems, and performance/latency sensitive applications will suffer\ndue to these undesirable allocations. Undesirable in this case meaning, for example, CPUs and\ndevices being allocated from different NUMA Nodes, thus incurring additional latency.\n\nThe Topology Manager is a kubelet component, which acts as a source of truth so that other kubelet\ncomponents can make topology aligned resource allocation choices.\n\nThe Topology Manager provides an interface for components, called *Hint Providers*, to send and\nreceive topology information. The Topology Manager has a set of node level policies which are\nexplained below.\n\nThe Topology Manager receives topology information from the *Hint Providers* as a bitmask denoting\nNUMA Nodes available and a preferred allocation indication. The Topology Manager policies perform\na set of operations on the hints provided and converge on the hint determined by the policy to\ngive the optimal result. If an undesirable hint is stored, the preferred field for the hint will be\nset to false. In the current policies preferred is the narrowest preferred mask.\nThe selected hint is stored as part of the Topology Manager. Depending on the policy configured,\nthe pod can be accepted or rejected from the node based on the selected hint.\nThe hint is then stored in the Topology Manager for use by the *Hint Providers* when making the\nresource allocation decisions.\n\nThe flow can be seen in the following diagram.\n\n![topology_manager_flow](/images/docs/topology-manager-flow.png)",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_v03",
      "question": "When did the prefer-closest-numa-nodes option become generally available?",
      "expected_answer": "Kubernetes 1.32",
      "category": "VERSION",
      "latency_ms": 949.3,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "reference_node_node-status_mdsem_4",
          "doc_id": "reference_node_node-status",
          "content": "## Info\n\nDescribes general information about the node, such as kernel version, Kubernetes\nversion (kubelet and kube-proxy version), container runtime details, and which\noperating system the node uses.\nThe kubelet gathers this information from the node and publishes it into\nthe Kubernetes API.\n\n## Declared features {#declaredfeatures}\n\n{{< feature-state feature_gate_name=\"NodeDeclaredFeatures\" >}}\n\nThis field lists specific Kubernetes features that are currently enabled on the\nnode's kubelet via [feature gates](/docs/reference/command-line-tools-reference/feature-gates/).\nThe features are reported by the kubelet as a list of strings in the\n`.status.declaredFeatures` field of the Node object.\n\nThis field is intended for newer features under active development; features that\nhave graduated and no longer require a feature gate are considered baseline and\nare not declared in this field. This reflects the enablement of Kubernetes\nfeatures, not the underlying operating system or kernel capabilities of the node.\n\nSee [Node Declared Features](/docs/concepts/scheduling-eviction/node-declared-features/)\nfor more details.",
          "is_needle": false
        },
        {
          "chunk_id": "reference_using-api_deprecation-policy_mdsem_2",
          "doc_id": "reference_using-api_deprecation-policy",
          "content": "## Deprecating parts of the API (continued)\n\n**Rule #3: An API version in a given track may not be deprecated in favor of a less stable API version.**\n\n* GA API versions can replace beta and alpha API versions.\n* Beta API versions can replace earlier beta and alpha API versions, but *may not* replace GA API versions.\n* Alpha API versions can replace earlier alpha API versions, but *may not* replace GA or beta API versions.\n\n**Rule #4a: API lifetime is determined by the API stability level**\n\n* GA API versions may be marked as deprecated, but must not be removed within a major version of Kubernetes\n* Beta API versions are deprecated no more than 9 months or 3 minor releases after introduction (whichever is longer),\n  and are no longer served 9 months or 3 minor releases after deprecation (whichever is longer)\n* Alpha API versions may be removed in any release without prior deprecation notice\n\nThis ensures beta API support covers the [maximum supported version skew of 2 releases](/releases/version-skew-policy/),\nand that APIs don't stagnate on unstable beta versions, accumulating production usage that will be\ndisrupted when support for the beta API ends.\n\n{{< note >}}\nThere are no current plans for a major version revision of Kubernetes that removes GA APIs.\n{{< /note >}}\n\n{{< note >}}\nUntil [#52185](https://github.com/kubernetes/kubernetes/issues/52185) is\nresolved, no API versions that have been persisted to storage may be removed.\nServing REST endpoints for those versions may be disabled (subject to the\ndeprecation timelines in this document), but the API server must remain capable\nof decoding/converting previously persisted data from storage.\n{{< /note >}}\n\n**Rule #4b: The \"preferred\" API version and the \"storage version\" for a given\ngroup may not advance until after a release has been made that supports both the\nnew version and the previous version**\n\nUsers must be able to upgrade to a new release of Kubernetes and then roll back\nto a previous release, without converting anything to the new API version or\nsuffering breakages (unless they explicitly used features only available in the\nnewer version). This is particularly evident in the stored representation of\nobjects.\n\nAll of this is best illustrated by examples. Imagine a Kubernetes release,\nversion X, which introduces a new API group. A new Kubernetes release is made\nevery approximately 4 months (3 per year). The following table describes which\nAPI versions are supported in a series of subsequent releases.",
          "is_needle": false
        },
        {
          "chunk_id": "reference_using-api_deprecation-policy_mdsem_6",
          "doc_id": "reference_using-api_deprecation-policy",
          "content": "### Future work\n\nOver time, Kubernetes will introduce more fine-grained API versions, at which\npoint these rules will be adjusted as needed.\n\n## Deprecating a flag or CLI\n\nThe Kubernetes system is comprised of several different programs cooperating.\nSometimes, a Kubernetes release might remove flags or CLI commands\n(collectively \"CLI elements\") in these programs. The individual programs\nnaturally sort into two main groups - user-facing and admin-facing programs,\nwhich vary slightly in their deprecation policies. Unless a flag is explicitly\nprefixed or documented as \"alpha\" or \"beta\", it is considered GA.\n\nCLI elements are effectively part of the API to the system, but since they are\nnot versioned in the same way as the REST API, the rules for deprecation are as\nfollows:\n\n**Rule #5a: CLI elements of user-facing components (e.g. kubectl) must function\nafter their announced deprecation for no less than:**\n\n* **GA: 12 months or 2 releases (whichever is longer)**\n* **Beta: 3 months or 1 release (whichever is longer)**\n* **Alpha: 0 releases**\n\n**Rule #5b: CLI elements of admin-facing components (e.g. kubelet) must function\nafter their announced deprecation for no less than:**\n\n* **GA: 6 months or 1 release (whichever is longer)**\n* **Beta: 3 months or 1 release (whichever is longer)**\n* **Alpha: 0 releases**\n\n**Rule #5c: Command line interface (CLI) elements cannot be deprecated in favor of\nless stable CLI elements**\n\nSimilar to the Rule #3 for APIs, if an element of a command line interface is being replaced with an\nalternative implementation, such as by renaming an existing element, or by switching to\nuse configuration sourced from a file\ninstead of a command line argument, that recommended alternative must be of\nthe same or higher stability level.\n\n**Rule #6: Deprecated CLI elements must emit warnings (optionally disable)\nwhen used.**",
          "is_needle": false
        },
        {
          "chunk_id": "reference_command-line-tools-reference_kube-apiserver_mdsem_15",
          "doc_id": "reference_command-line-tools-reference_kube-apiserver",
          "content": "## {{% heading \"synopsis\" %}} (continued)\n\nTo skip any prefixing, provide the value '-'.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--peer-advertise-ip string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If set and the UnknownVersionInteroperabilityProxy feature gate is enabled, this IP will be used by peer kube-apiservers to proxy requests to this kube-apiserver when the request cannot be handled by the peer due to version skew between the kube-apiservers. This flag is only used in clusters configured with multiple kube-apiservers for high availability.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--peer-advertise-port string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If set and the UnknownVersionInteroperabilityProxy feature gate is enabled, this port will be used by peer kube-apiservers to proxy requests to this kube-apiserver when the request cannot be handled by the peer due to version skew between the kube-apiservers. This flag is only used in clusters configured with multiple kube-apiservers for high availability.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--peer-ca-file string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If set and the UnknownVersionInteroperabilityProxy feature gate is enabled, this file will be used to verify serving certificates of peer kube-apiservers. This flag is only used in clusters configured with multiple kube-apiservers for high availability.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--permit-address-sharing</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, SO_REUSEADDR will be used when binding the port. This allows binding to wildcard IPs like 0.0.0.0 and specific IPs in parallel, and it avoids waiting for the kernel to release sockets in TIME_WAIT state. [default=false]</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--permit-port-sharing</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, SO_REUSEPORT will be used when binding the port, which allows more than one instance to bind on the same address and port. [default=false]</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--profiling&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Enable profiling via web interface host:port/debug/pprof/</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--proxy-client-cert-file string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Client certificate used to prove the identity of the aggregator or kube-apiserver when it must call out during a request. This includes proxying requests to a user api-server and calling out to webhook admission plugins. It is expected that this cert includes a signature from the CA in the --requestheader-client-ca-file flag. That CA is published in the 'extension-apiserver-authentication' configmap in the kube-system namespace. Components receiving calls from kube-aggregator should use that CA to perform their half of the mutual TLS verification.</p></td>\n</tr>",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_workloads_management_mdsem_7",
          "doc_id": "concepts_workloads_management",
          "content": "# don't wait for rollout to finish, just check the status\n\nkubectl rollout status statefulsets/backing-stateful-component --watch=false\n```\n\nYou can also pause, resume or cancel a rollout.\nVisit [`kubectl rollout`](/docs/reference/kubectl/generated/kubectl_rollout/) to learn more.\n\n## Canary deployments\n\n<!--TODO: make a task out of this for canary deployment, ref #42786-->\n\nAnother scenario where multiple labels are needed is to distinguish deployments of different\nreleases or configurations of the same component. It is common practice to deploy a *canary* of a\nnew application release (specified via image tag in the pod template) side by side with the\nprevious release so that the new release can receive live production traffic before fully rolling\nit out.\n\nFor instance, you can use a `track` label to differentiate different releases.\n\nThe primary, stable release would have a `track` label with value as `stable`:\n\n```none\nname: frontend\nreplicas: 3\n...\nlabels:\n   app: guestbook\n   tier: frontend\n   track: stable\n...\nimage: gb-frontend:v3\n```\n\nand then you can create a new release of the guestbook frontend that carries the `track` label\nwith different value (i.e. `canary`), so that two sets of pods would not overlap:\n\n```none\nname: frontend-canary\nreplicas: 1\n...\nlabels:\n   app: guestbook\n   tier: frontend\n   track: canary\n...\nimage: gb-frontend:v4\n```\n\nThe frontend service would span both sets of replicas by selecting the common subset of their\nlabels (i.e. omitting the `track` label), so that the traffic will be redirected to both\napplications:\n\n```yaml\nselector:\n   app: guestbook\n   tier: frontend\n```\n\nYou can tweak the number of replicas of the stable and canary releases to determine the ratio of\neach release that will receive live production traffic (in this case, 3:1).\nOnce you're confident, you can update the stable track to the new application release and remove\nthe canary one.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_v04",
      "question": "In what k8s version did max-allowable-numa-nodes become GA?",
      "expected_answer": "Kubernetes 1.35",
      "category": "VERSION",
      "latency_ms": 990.1,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "reference_node_node-status_mdsem_4",
          "doc_id": "reference_node_node-status",
          "content": "## Info\n\nDescribes general information about the node, such as kernel version, Kubernetes\nversion (kubelet and kube-proxy version), container runtime details, and which\noperating system the node uses.\nThe kubelet gathers this information from the node and publishes it into\nthe Kubernetes API.\n\n## Declared features {#declaredfeatures}\n\n{{< feature-state feature_gate_name=\"NodeDeclaredFeatures\" >}}\n\nThis field lists specific Kubernetes features that are currently enabled on the\nnode's kubelet via [feature gates](/docs/reference/command-line-tools-reference/feature-gates/).\nThe features are reported by the kubelet as a list of strings in the\n`.status.declaredFeatures` field of the Node object.\n\nThis field is intended for newer features under active development; features that\nhave graduated and no longer require a feature gate are considered baseline and\nare not declared in this field. This reflects the enablement of Kubernetes\nfeatures, not the underlying operating system or kernel capabilities of the node.\n\nSee [Node Declared Features](/docs/concepts/scheduling-eviction/node-declared-features/)\nfor more details.",
          "is_needle": false
        },
        {
          "chunk_id": "reference_using-api_deprecation-policy_mdsem_2",
          "doc_id": "reference_using-api_deprecation-policy",
          "content": "## Deprecating parts of the API (continued)\n\n**Rule #3: An API version in a given track may not be deprecated in favor of a less stable API version.**\n\n* GA API versions can replace beta and alpha API versions.\n* Beta API versions can replace earlier beta and alpha API versions, but *may not* replace GA API versions.\n* Alpha API versions can replace earlier alpha API versions, but *may not* replace GA or beta API versions.\n\n**Rule #4a: API lifetime is determined by the API stability level**\n\n* GA API versions may be marked as deprecated, but must not be removed within a major version of Kubernetes\n* Beta API versions are deprecated no more than 9 months or 3 minor releases after introduction (whichever is longer),\n  and are no longer served 9 months or 3 minor releases after deprecation (whichever is longer)\n* Alpha API versions may be removed in any release without prior deprecation notice\n\nThis ensures beta API support covers the [maximum supported version skew of 2 releases](/releases/version-skew-policy/),\nand that APIs don't stagnate on unstable beta versions, accumulating production usage that will be\ndisrupted when support for the beta API ends.\n\n{{< note >}}\nThere are no current plans for a major version revision of Kubernetes that removes GA APIs.\n{{< /note >}}\n\n{{< note >}}\nUntil [#52185](https://github.com/kubernetes/kubernetes/issues/52185) is\nresolved, no API versions that have been persisted to storage may be removed.\nServing REST endpoints for those versions may be disabled (subject to the\ndeprecation timelines in this document), but the API server must remain capable\nof decoding/converting previously persisted data from storage.\n{{< /note >}}\n\n**Rule #4b: The \"preferred\" API version and the \"storage version\" for a given\ngroup may not advance until after a release has been made that supports both the\nnew version and the previous version**\n\nUsers must be able to upgrade to a new release of Kubernetes and then roll back\nto a previous release, without converting anything to the new API version or\nsuffering breakages (unless they explicitly used features only available in the\nnewer version). This is particularly evident in the stored representation of\nobjects.\n\nAll of this is best illustrated by examples. Imagine a Kubernetes release,\nversion X, which introduces a new API group. A new Kubernetes release is made\nevery approximately 4 months (3 per year). The following table describes which\nAPI versions are supported in a series of subsequent releases.",
          "is_needle": false
        },
        {
          "chunk_id": "reference_command-line-tools-reference_kube-apiserver_mdsem_15",
          "doc_id": "reference_command-line-tools-reference_kube-apiserver",
          "content": "## {{% heading \"synopsis\" %}} (continued)\n\nTo skip any prefixing, provide the value '-'.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--peer-advertise-ip string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If set and the UnknownVersionInteroperabilityProxy feature gate is enabled, this IP will be used by peer kube-apiservers to proxy requests to this kube-apiserver when the request cannot be handled by the peer due to version skew between the kube-apiservers. This flag is only used in clusters configured with multiple kube-apiservers for high availability.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--peer-advertise-port string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If set and the UnknownVersionInteroperabilityProxy feature gate is enabled, this port will be used by peer kube-apiservers to proxy requests to this kube-apiserver when the request cannot be handled by the peer due to version skew between the kube-apiservers. This flag is only used in clusters configured with multiple kube-apiservers for high availability.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--peer-ca-file string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If set and the UnknownVersionInteroperabilityProxy feature gate is enabled, this file will be used to verify serving certificates of peer kube-apiservers. This flag is only used in clusters configured with multiple kube-apiservers for high availability.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--permit-address-sharing</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, SO_REUSEADDR will be used when binding the port. This allows binding to wildcard IPs like 0.0.0.0 and specific IPs in parallel, and it avoids waiting for the kernel to release sockets in TIME_WAIT state. [default=false]</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--permit-port-sharing</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, SO_REUSEPORT will be used when binding the port, which allows more than one instance to bind on the same address and port. [default=false]</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--profiling&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Enable profiling via web interface host:port/debug/pprof/</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--proxy-client-cert-file string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Client certificate used to prove the identity of the aggregator or kube-apiserver when it must call out during a request. This includes proxying requests to a user api-server and calling out to webhook admission plugins. It is expected that this cert includes a signature from the CA in the --requestheader-client-ca-file flag. That CA is published in the 'extension-apiserver-authentication' configmap in the kube-system namespace. Components receiving calls from kube-aggregator should use that CA to perform their half of the mutual TLS verification.</p></td>\n</tr>",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_run-application_configure-pdb_mdsem_0",
          "doc_id": "tasks_run-application_configure-pdb",
          "content": "---\ntitle: Specifying a Disruption Budget for your Application\ncontent_type: task\nweight: 110\nmin-kubernetes-server-version: v1.21\n---\n\n<!-- overview -->\n\n{{< feature-state for_k8s_version=\"v1.21\" state=\"stable\" >}}\n\nThis page shows how to limit the number of concurrent disruptions\nthat your application experiences, allowing for higher availability\nwhile permitting the cluster administrator to manage the clusters\nnodes.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n<!-- steps -->\n\n## How topology manager works\n\nPrior to the introduction of Topology Manager, the CPU and Device Manager in Kubernetes make\nresource allocation decisions independently of each other. This can result in undesirable\nallocations on multiple-socketed systems, and performance/latency sensitive applications will suffer\ndue to these undesirable allocations. Undesirable in this case meaning, for example, CPUs and\ndevices being allocated from different NUMA Nodes, thus incurring additional latency.\n\nThe Topology Manager is a kubelet component, which acts as a source of truth so that other kubelet\ncomponents can make topology aligned resource allocation choices.\n\nThe Topology Manager provides an interface for components, called *Hint Providers*, to send and\nreceive topology information. The Topology Manager has a set of node level policies which are\nexplained below.\n\nThe Topology Manager receives topology information from the *Hint Providers* as a bitmask denoting\nNUMA Nodes available and a preferred allocation indication. The Topology Manager policies perform\na set of operations on the hints provided and converge on the hint determined by the policy to\ngive the optimal result. If an undesirable hint is stored, the preferred field for the hint will be\nset to false. In the current policies preferred is the narrowest preferred mask.\nThe selected hint is stored as part of the Topology Manager. Depending on the policy configured,\nthe pod can be accepted or rejected from the node based on the selected hint.\nThe hint is then stored in the Topology Manager for use by the *Hint Providers* when making the\nresource allocation decisions.\n\nThe flow can be seen in the following diagram.\n\n![topology_manager_flow](/images/docs/topology-manager-flow.png)",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_v05",
      "question": "What's the default limit on NUMA nodes before kubelet refuses to start with topology manager?",
      "expected_answer": "8",
      "category": "VERSION",
      "latency_ms": 930.9,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_13",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Known limitations\n\n1. The maximum number of NUMA nodes that Topology Manager allows is 8. With more than 8 NUMA nodes,\n   there will be a state explosion when trying to enumerate the possible NUMA affinities and\n   generating their hints. See [`max-allowable-numa-nodes`](#policy-option-max-allowable-numa-nodes)\n   (beta) for more options.\n\n1. The scheduler is not topology-aware, so it is possible to be scheduled on a node and then fail\n   on the node due to the Topology Manager.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_c01",
      "question": "How does restricted policy differ from single-numa-node when pod can't get preferred affinity?",
      "expected_answer": "restricted rejects any non-preferred; single-numa-node only rejects if >1 NUMA needed",
      "category": "COMPARISON",
      "latency_ms": 1164.3,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_scheduling-eviction_kube-scheduler_mdsem_1",
          "doc_id": "concepts_scheduling-eviction_kube-scheduler",
          "content": "## kube-scheduler\n\n[kube-scheduler](/docs/reference/command-line-tools-reference/kube-scheduler/)\nis the default scheduler for Kubernetes and runs as part of the\n{{< glossary_tooltip text=\"control plane\" term_id=\"control-plane\" >}}.\nkube-scheduler is designed so that, if you want and need to, you can\nwrite your own scheduling component and use that instead.\n\nKube-scheduler selects an optimal node to run newly created or not yet\nscheduled (unscheduled) pods. Since containers in pods - and pods themselves -\ncan have different requirements, the scheduler filters out any nodes that\ndon't meet a Pod's specific scheduling needs. Alternatively, the API lets\nyou specify a node for a Pod when you create it, but this is unusual\nand is only done in special cases.\n\nIn a cluster, Nodes that meet the scheduling requirements for a Pod\nare called _feasible_ nodes. If none of the nodes are suitable, the pod\nremains unscheduled until the scheduler is able to place it.\n\nThe scheduler finds feasible Nodes for a Pod and then runs a set of\nfunctions to score the feasible Nodes and picks a Node with the highest\nscore among the feasible ones to run the Pod. The scheduler then notifies\nthe API server about this decision in a process called _binding_.\n\nFactors that need to be taken into account for scheduling decisions include\nindividual and collective resource requirements, hardware / software /\npolicy constraints, affinity and anti-affinity specifications, data\nlocality, inter-workload interference, and so on.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_c02",
      "question": "What's the key difference between container scope and pod scope for topology alignment?",
      "expected_answer": "container=individual alignment per container, no grouping; pod=groups all containers to common NUMA set",
      "category": "COMPARISON",
      "latency_ms": 1027.0,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_3",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager scopes\n\nThe Topology Manager can deal with the alignment of resources in a couple of distinct scopes:\n\n* `container` (default)\n* `pod`\n\nEither option can be selected at a time of the kubelet startup, by setting the\n`topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\n### `container` scope\n\nThe `container` scope is used by default. You can also explicitly set the\n`topologyManagerScope` to `container` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\nWithin this scope, the Topology Manager performs a number of sequential resource alignments, i.e.,\nfor each container (in a pod) a separate alignment is computed. In other words, there is no notion\nof grouping the containers to a specific set of NUMA nodes, for this particular scope. In effect,\nthe Topology Manager performs an arbitrary alignment of individual containers to NUMA nodes.\n\nThe notion of grouping the containers was endorsed and implemented on purpose in the following\nscope, for example the `pod` scope.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Windows Support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nThe Topology Manager support can be enabled on Windows by using the `WindowsCPUAndMemoryAffinity` feature gate and\nit requires support in the container runtime.\n\n## Topology manager scopes and policies\n\nThe Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_6",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `none` policy {#policy-none}\n\nThis is the default policy and does not perform any topology alignment.\n\n### `best-effort` policy {#policy-best-effort}\n\nFor each container in a Pod, the kubelet, with `best-effort` topology management policy, calls\neach Hint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will store this and admit the pod to the node anyway.\n\nThe *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_c03",
      "question": "Compare what happens with none policy vs best-effort policy when NUMA affinity can't be satisfied",
      "expected_answer": "none=no alignment attempted; best-effort=stores non-preferred hint, admits pod anyway",
      "category": "COMPARISON",
      "latency_ms": 1150.4,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_6",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `none` policy {#policy-none}\n\nThis is the default policy and does not perform any topology alignment.\n\n### `best-effort` policy {#policy-best-effort}\n\nFor each container in a Pod, the kubelet, with `best-effort` topology management policy, calls\neach Hint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will store this and admit the pod to the node anyway.\n\nThe *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_topology_mdsem_4",
          "doc_id": "tasks_debug_debug-cluster_topology",
          "content": "## Examples\n\n\n\n### Examine the memory manager state on a node\n\nLet us first deploy a sample `Guaranteed` pod whose specification is as follows:\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: guaranteed\nspec:\n  containers:\n  - name: guaranteed\n    image: consumer\n    imagePullPolicy: Never\n    resources:\n      limits:\n        cpu: \"2\"\n        memory: 150Gi\n      requests:\n        cpu: \"2\"\n        memory: 150Gi\n    command: [\"sleep\",\"infinity\"]\n```\n\nNext, log into the node where it was deployed and examine the state file in\n`/var/lib/kubelet/memory_manager_state`:\n\n```json\n{\n   \"policyName\":\"Static\",\n   \"machineState\":{\n      \"0\":{\n         \"numberOfAssignments\":1,\n         \"memoryMap\":{\n            \"hugepages-1Gi\":{\n               \"total\":0,\n               \"systemReserved\":0,\n               \"allocatable\":0,\n               \"reserved\":0,\n               \"free\":0\n            },\n            \"memory\":{\n               \"total\":134987354112,\n               \"systemReserved\":3221225472,\n               \"allocatable\":131766128640,\n               \"reserved\":131766128640,\n               \"free\":0\n            }\n         },\n         \"nodes\":[\n            0,\n            1\n         ]\n      },\n      \"1\":{\n         \"numberOfAssignments\":1,\n         \"memoryMap\":{\n            \"hugepages-1Gi\":{\n               \"total\":0,\n               \"systemReserved\":0,\n               \"allocatable\":0,\n               \"reserved\":0,\n               \"free\":0\n            },\n            \"memory\":{\n               \"total\":135286722560,\n               \"systemReserved\":2252341248,\n               \"allocatable\":133034381312,\n               \"reserved\":29295144960,\n               \"free\":103739236352\n            }\n         },\n         \"nodes\":[\n            0,\n            1\n         ]\n      }\n   },\n   \"entries\":{\n      \"fa9bdd38-6df9-4cf9-aa67-8c4814da37a8\":{\n         \"guaranteed\":[\n            {\n               \"numaAffinity\":[\n                  0,\n                  1\n               ],\n               \"type\":\"memory\",\n               \"size\":161061273600\n            }\n         ]\n      }\n   },\n   \"checksum\":4142013182\n}\n```\n\nIt can be deduced from the state file that the pod was pinned to both NUMA nodes, i.e.:\n\n```json\n\"numaAffinity\":[\n   0,\n   1\n],\n```\n\nPinned term means that pod's memory consumption is constrained (through `cgroups` configuration)\nto these NUMA nodes.\n\nThis automatically implies that Memory Manager instantiated a new group that\ncomprises these two NUMA nodes, i.e. `0` and `1` indexed NUMA nodes.\n\nIn order to analyse memory resources available in a group,the corresponding entries from\nNUMA nodes belonging to the group must be added up.\n\nFor example, the total amount of free \"conventional\" memory in the group can be computed\nby adding up the free memory available at every NUMA node in the group,\ni.e., in the `\"memory\"` section of NUMA node `0` (`\"free\":0`) and NUMA node `1` (`\"free\":103739236352`).\nSo, the total amount of free \"conventional\" memory in this group is equal to `0 + 103739236352` bytes.\n\nThe line `\"systemReserved\":3221225472` indicates that the administrator of this node reserved\n`3221225472` bytes (i.e. `3Gi`) to serve kubelet and system processes at NUMA node `0`,\nby using `--reserved-memory` flag.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_c04",
      "question": "How does topology manager behavior differ for Guaranteed QoS pods with integer CPU vs fractional CPU?",
      "expected_answer": "integer CPU gets topology hints from CPU Manager; fractional CPU gets default hint only",
      "category": "COMPARISON",
      "latency_ms": 1147.5,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_12",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Pod interactions with topology manager policies\n\nConsider the containers in the following Pod manifest:\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n```\n\nThis pod runs in the `BestEffort` QoS class because no resource `requests` or `limits` are specified.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n      requests:\n        memory: \"100Mi\"\n```\n\nThis pod runs in the `Burstable` QoS class because requests are less than limits.\n\nIf the selected policy is anything other than `none`, the Topology Manager would consider these Pod\nspecifications. The Topology Manager would consult the Hint Providers to get topology hints.\nIn the case of the `static`, the CPU Manager policy would return default topology hint, because\nthese Pods do not explicitly request CPU resources.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n```\n\nThis pod with integer CPU request runs in the `Guaranteed` QoS class because `requests` are equal\nto `limits`.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n```\n\nThis pod with sharing CPU request runs in the `Guaranteed` QoS class because `requests` are equal\nto `limits`.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        example.com/deviceA: \"1\"\n        example.com/deviceB: \"1\"\n      requests:\n        example.com/deviceA: \"1\"\n        example.com/deviceB: \"1\"\n```\n\nThis pod runs in the `BestEffort` QoS class because there are no CPU and memory requests.\n\nThe Topology Manager would consider the above pods. The Topology Manager would consult the Hint\nProviders, which are CPU and Device Manager to get topology hints for the pods.\n\nIn the case of the `Guaranteed` pod with integer CPU request, the `static` CPU Manager policy\nwould return topology hints relating to the exclusive CPU and the Device Manager would send back\nhints for the requested device.\n\nIn the case of the `Guaranteed` pod with sharing CPU request, the `static` CPU Manager policy\nwould return default topology hint as there is no exclusive CPU request and the Device Manager\nwould send back hints for the requested device.\n\nIn the above two cases of the `Guaranteed` pod, the `none` CPU Manager policy would return default\ntopology hint.\n\nIn the case of the `BestEffort` pod, the `static` CPU Manager policy would send back the default\ntopology hint as there is no CPU request and the Device Manager would send back the hints for each\nof the requested devices.\n\nUsing this information the Topology Manager calculates the optimal hint for the pod and stores\nthis information, which will be used by the Hint Providers when they are making their resource\nassignments.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Windows Support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nThe Topology Manager support can be enabled on Windows by using the `WindowsCPUAndMemoryAffinity` feature gate and\nit requires support in the container runtime.\n\n## Topology manager scopes and policies\n\nThe Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_6",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `none` policy {#policy-none}\n\nThis is the default policy and does not perform any topology alignment.\n\n### `best-effort` policy {#policy-best-effort}\n\nFor each container in a Pod, the kubelet, with `best-effort` topology management policy, calls\neach Hint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will store this and admit the pod to the node anyway.\n\nThe *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_c05",
      "question": "What's the difference between TopologyManagerPolicyBetaOptions and TopologyManagerPolicyAlphaOptions feature gates?",
      "expected_answer": "Beta=enabled by default, Alpha=disabled by default; both control policy option visibility",
      "category": "COMPARISON",
      "latency_ms": 1022.3,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_9",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policy options\n\nSupport for the Topology Manager policy options requires `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) to be enabled\n(it is enabled by default).\n\nYou can toggle groups of options on and off based upon their maturity level using the following feature gates:\n\n* `TopologyManagerPolicyBetaOptions` default enabled. Enable to show beta-level options.\n* `TopologyManagerPolicyAlphaOptions` default disabled. Enable to show alpha-level options.\n\nYou will still have to enable each option using the `TopologyManagerPolicyOptions` kubelet option.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Windows Support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nThe Topology Manager support can be enabled on Windows by using the `WindowsCPUAndMemoryAffinity` feature gate and\nit requires support in the container runtime.\n\n## Topology manager scopes and policies\n\nThe Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n<!-- steps -->\n\n## How topology manager works\n\nPrior to the introduction of Topology Manager, the CPU and Device Manager in Kubernetes make\nresource allocation decisions independently of each other. This can result in undesirable\nallocations on multiple-socketed systems, and performance/latency sensitive applications will suffer\ndue to these undesirable allocations. Undesirable in this case meaning, for example, CPUs and\ndevices being allocated from different NUMA Nodes, thus incurring additional latency.\n\nThe Topology Manager is a kubelet component, which acts as a source of truth so that other kubelet\ncomponents can make topology aligned resource allocation choices.\n\nThe Topology Manager provides an interface for components, called *Hint Providers*, to send and\nreceive topology information. The Topology Manager has a set of node level policies which are\nexplained below.\n\nThe Topology Manager receives topology information from the *Hint Providers* as a bitmask denoting\nNUMA Nodes available and a preferred allocation indication. The Topology Manager policies perform\na set of operations on the hints provided and converge on the hint determined by the policy to\ngive the optimal result. If an undesirable hint is stored, the preferred field for the hint will be\nset to false. In the current policies preferred is the narrowest preferred mask.\nThe selected hint is stored as part of the Topology Manager. Depending on the policy configured,\nthe pod can be accepted or rejected from the node based on the selected hint.\nThe hint is then stored in the Topology Manager for use by the *Hint Providers* when making the\nresource allocation decisions.\n\nThe flow can be seen in the following diagram.\n\n![topology_manager_flow](/images/docs/topology-manager-flow.png)",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_n01",
      "question": "Why is using more than 8 NUMA nodes not recommended with topology manager?",
      "expected_answer": "State explosion when enumerating NUMA affinities; use max-allowable-numa-nodes at own risk",
      "category": "NEGATION",
      "latency_ms": 1322.5,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_13",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Known limitations\n\n1. The maximum number of NUMA nodes that Topology Manager allows is 8. With more than 8 NUMA nodes,\n   there will be a state explosion when trying to enumerate the possible NUMA affinities and\n   generating their hints. See [`max-allowable-numa-nodes`](#policy-option-max-allowable-numa-nodes)\n   (beta) for more options.\n\n1. The scheduler is not topology-aware, so it is possible to be scheduled on a node and then fail\n   on the node due to the Topology Manager.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_n02",
      "question": "What happens to a pod that fails topology affinity check with restricted policy? Can it be rescheduled?",
      "expected_answer": "Pod enters Terminated state; scheduler will NOT reschedule; need ReplicaSet/Deployment",
      "category": "NEGATION",
      "latency_ms": 1007.5,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_topology_mdsem_2",
          "doc_id": "tasks_debug_debug-cluster_topology",
          "content": "## Troubleshoot `TopologyAffinityError` {#TopologyAffinityError}\n\nThis error typically occurs in the following situations:\n\n* a node has not enough resources available to satisfy the pod's request\n* the pod's request is rejected due to particular Topology Manager policy constraints\n\nThe error appears in the status of a pod:\n\n```shell\nkubectl get pods\n```\n\n```none\nNAME         READY   STATUS                  RESTARTS   AGE\nguaranteed   0/1     TopologyAffinityError   0          113s\n```\n\nUse `kubectl describe pod <id>` or `kubectl events` to obtain a detailed error message:\n\n```none\nWarning  TopologyAffinityError  10m   kubelet, dell8  Resources cannot be allocated with Topology locality\n```",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_kube-scheduler_mdsem_1",
          "doc_id": "concepts_scheduling-eviction_kube-scheduler",
          "content": "## kube-scheduler\n\n[kube-scheduler](/docs/reference/command-line-tools-reference/kube-scheduler/)\nis the default scheduler for Kubernetes and runs as part of the\n{{< glossary_tooltip text=\"control plane\" term_id=\"control-plane\" >}}.\nkube-scheduler is designed so that, if you want and need to, you can\nwrite your own scheduling component and use that instead.\n\nKube-scheduler selects an optimal node to run newly created or not yet\nscheduled (unscheduled) pods. Since containers in pods - and pods themselves -\ncan have different requirements, the scheduler filters out any nodes that\ndon't meet a Pod's specific scheduling needs. Alternatively, the API lets\nyou specify a node for a Pod when you create it, but this is unusual\nand is only done in special cases.\n\nIn a cluster, Nodes that meet the scheduling requirements for a Pod\nare called _feasible_ nodes. If none of the nodes are suitable, the pod\nremains unscheduled until the scheduler is able to place it.\n\nThe scheduler finds feasible Nodes for a Pod and then runs a set of\nfunctions to score the feasible Nodes and picks a Node with the highest\nscore among the feasible ones to run the Pod. The scheduler then notifies\nthe API server about this decision in a process called _binding_.\n\nFactors that need to be taken into account for scheduling decisions include\nindividual and collective resource requirements, hardware / software /\npolicy constraints, affinity and anti-affinity specifications, data\nlocality, inter-workload interference, and so on.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_topology_mdsem_1",
          "doc_id": "tasks_debug_debug-cluster_topology",
          "content": "## Sources of troubleshooting information\n\nYou can use the following means to troubleshoot the reason why a pod could not be deployed or\nbecame rejected at a node, in the context of topology management:\n\n- _Pod status_ - indicates topology affinity errors\n- _system logs_ - include valuable information for debugging; for example, about generated hints\n- _kubelet state file_ - the dump of internal state of the Memory Manager\n  (including the _node map_ and _memory maps_)\n- You can use the [device plugin resource API](#device-plugin-resource-api)\n  to retrieve information about the memory reserved for containers",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n03",
      "question": "Why can't the Kubernetes scheduler prevent pods from failing on nodes due to topology?",
      "expected_answer": "Scheduler is not topology-aware; this is a known limitation",
      "category": "NEGATION",
      "latency_ms": 1092.5,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_topology_mdsem_1",
          "doc_id": "tasks_debug_debug-cluster_topology",
          "content": "## Sources of troubleshooting information\n\nYou can use the following means to troubleshoot the reason why a pod could not be deployed or\nbecame rejected at a node, in the context of topology management:\n\n- _Pod status_ - indicates topology affinity errors\n- _system logs_ - include valuable information for debugging; for example, about generated hints\n- _kubelet state file_ - the dump of internal state of the Memory Manager\n  (including the _node map_ and _memory maps_)\n- You can use the [device plugin resource API](#device-plugin-resource-api)\n  to retrieve information about the memory reserved for containers",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_topology_mdsem_2",
          "doc_id": "tasks_debug_debug-cluster_topology",
          "content": "## Troubleshoot `TopologyAffinityError` {#TopologyAffinityError}\n\nThis error typically occurs in the following situations:\n\n* a node has not enough resources available to satisfy the pod's request\n* the pod's request is rejected due to particular Topology Manager policy constraints\n\nThe error appears in the status of a pod:\n\n```shell\nkubectl get pods\n```\n\n```none\nNAME         READY   STATUS                  RESTARTS   AGE\nguaranteed   0/1     TopologyAffinityError   0          113s\n```\n\nUse `kubectl describe pod <id>` or `kubectl events` to obtain a detailed error message:\n\n```none\nWarning  TopologyAffinityError  10m   kubelet, dell8  Resources cannot be allocated with Topology locality\n```",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_kube-scheduler_mdsem_1",
          "doc_id": "concepts_scheduling-eviction_kube-scheduler",
          "content": "## kube-scheduler\n\n[kube-scheduler](/docs/reference/command-line-tools-reference/kube-scheduler/)\nis the default scheduler for Kubernetes and runs as part of the\n{{< glossary_tooltip text=\"control plane\" term_id=\"control-plane\" >}}.\nkube-scheduler is designed so that, if you want and need to, you can\nwrite your own scheduling component and use that instead.\n\nKube-scheduler selects an optimal node to run newly created or not yet\nscheduled (unscheduled) pods. Since containers in pods - and pods themselves -\ncan have different requirements, the scheduler filters out any nodes that\ndon't meet a Pod's specific scheduling needs. Alternatively, the API lets\nyou specify a node for a Pod when you create it, but this is unusual\nand is only done in special cases.\n\nIn a cluster, Nodes that meet the scheduling requirements for a Pod\nare called _feasible_ nodes. If none of the nodes are suitable, the pod\nremains unscheduled until the scheduler is able to place it.\n\nThe scheduler finds feasible Nodes for a Pod and then runs a set of\nfunctions to score the feasible Nodes and picks a Node with the highest\nscore among the feasible ones to run the Pod. The scheduler then notifies\nthe API server about this decision in a process called _binding_.\n\nFactors that need to be taken into account for scheduling decisions include\nindividual and collective resource requirements, hardware / software /\npolicy constraints, affinity and anti-affinity specifications, data\nlocality, inter-workload interference, and so on.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n04",
      "question": "What's wrong with using container scope for latency-sensitive applications?",
      "expected_answer": "Containers may end up on different NUMA nodes since there's no grouping",
      "category": "NEGATION",
      "latency_ms": 1259.3,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "reference_kubernetes-api_workload-resources_workload-v1alpha1_mdsem_1",
          "doc_id": "reference_kubernetes-api_workload-resources_workload-v1alpha1",
          "content": "## Workload {#Workload}\n\nWorkload allows for expressing scheduling constraints that should be used when managing lifecycle of workloads from scheduling perspective, including scheduling, preemption, eviction and other phases.\n\n<hr>\n\n- **apiVersion**: scheduling.k8s.io/v1alpha1\n\n\n- **kind**: Workload\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/object-meta#ObjectMeta\" >}}\">ObjectMeta</a>)\n\n  Standard object's metadata. Name must be a DNS subdomain.\n\n- **spec** (<a href=\"{{< ref \"../workload-resources/workload-v1alpha1#WorkloadSpec\" >}}\">WorkloadSpec</a>), required\n\n  Spec defines the desired behavior of a Workload.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_security_multi-tenancy_mdsem_7",
          "doc_id": "concepts_security_multi-tenancy",
          "content": "### Quotas\n\nKubernetes workloads consume node resources, like CPU and memory.  In a multi-tenant environment,\nyou can use [Resource Quotas](/docs/concepts/policy/resource-quotas/) to manage resource usage of\ntenant workloads.  For the multiple teams use case, where tenants have access to the Kubernetes\nAPI, you can use resource quotas to limit the number of API resources (for example: the number of\nPods, or the number of ConfigMaps) that a tenant can create. Limits on object count ensure\nfairness and aim to avoid _noisy neighbor_ issues from affecting other tenants that share a\ncontrol plane.\n\nResource quotas are namespaced objects. By mapping tenants to namespaces, cluster admins can use\nquotas to ensure that a tenant cannot monopolize a cluster's resources or overwhelm its control\nplane. Namespace management tools simplify the administration of quotas. In addition, while\nKubernetes quotas only apply within a single namespace, some namespace management tools allow\ngroups of namespaces to share quotas, giving administrators far more flexibility with less effort\nthan built-in quotas.\n\nQuotas prevent a single tenant from consuming greater than their allocated share of resources\nhence minimizing the \u201cnoisy neighbor\u201d issue, where one tenant negatively impacts the performance\nof other tenants' workloads.\n\nWhen you apply a quota to namespace, Kubernetes requires you to also specify resource requests and\nlimits for each container. Limits are the upper bound for the amount of resources that a container\ncan consume. Containers that attempt to consume resources that exceed the configured limits will\neither be throttled or killed, based on the resource type. When resource requests are set lower\nthan limits, each container is guaranteed the requested amount but there may still be some\npotential for impact across workloads.\n\nQuotas cannot protect against all kinds of resource sharing, such as network traffic.\nNode isolation (described below) may be a better solution for this problem.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_configuration_windows-resource-management_mdsem_3",
          "doc_id": "concepts_configuration_windows-resource-management",
          "content": "## Resource reservation {#resource-reservation}\n\nTo account for memory and CPU used by the operating system, the container runtime, and by\nKubernetes host processes such as the kubelet, you can (and should) reserve\nmemory and CPU resources with the  `--kube-reserved` and/or `--system-reserved` kubelet flags.\nOn Windows these values are only used to calculate the node's\n[allocatable](/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable) resources.\n\n{{< caution >}}\nAs you deploy workloads, set resource memory and CPU limits on containers.\nThis also subtracts from `NodeAllocatable` and helps the cluster-wide scheduler in determining which pods to place on which nodes.\n\nScheduling pods without limits may over-provision the Windows nodes and in extreme\ncases can cause the nodes to become unhealthy.\n{{< /caution >}}\n\nOn Windows, a good practice is to reserve at least 2GiB of memory.\n\nTo determine how much CPU to reserve,\nidentify the maximum pod density for each node and monitor the CPU usage of\nthe system services running there, then choose a value that meets your workload needs.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_kube-scheduler_mdsem_3",
          "doc_id": "concepts_scheduling-eviction_kube-scheduler",
          "content": "## {{% heading \"whatsnext\" %}}\n\n* Read about [scheduler performance tuning](/docs/concepts/scheduling-eviction/scheduler-perf-tuning/)\n* Read about [Pod topology spread constraints](/docs/concepts/scheduling-eviction/topology-spread-constraints/)\n* Read the [reference documentation](/docs/reference/command-line-tools-reference/kube-scheduler/) for kube-scheduler\n* Read the [kube-scheduler config (v1)](/docs/reference/config-api/kube-scheduler-config.v1/) reference\n* Learn about [configuring multiple schedulers](/docs/tasks/extend-kubernetes/configure-multiple-schedulers/)\n* Learn about [topology management policies](/docs/tasks/administer-cluster/topology-manager/)\n* Learn about [Pod Overhead](/docs/concepts/scheduling-eviction/pod-overhead/)\n* Learn about scheduling of Pods that use volumes in:\n  * [Volume Topology Support](/docs/concepts/storage/storage-classes/#volume-binding-mode)\n  * [Storage Capacity Tracking](/docs/concepts/storage/storage-capacity/)\n  * [Node-specific Volume Limits](/docs/concepts/storage/storage-limits/)",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_security_multi-tenancy_mdsem_13",
          "doc_id": "concepts_security_multi-tenancy",
          "content": "### Quality-of-Service (QoS) {#qos}\n\nWhen you\u2019re running a SaaS application, you may want the ability to offer different\nQuality-of-Service (QoS) tiers of service to different tenants. For example, you may have freemium\nservice that comes with fewer performance guarantees and features and a for-fee service tier with\nspecific performance guarantees. Fortunately, there are several Kubernetes constructs that can\nhelp you accomplish this within a shared cluster, including network QoS, storage classes, and pod\npriority and preemption. The idea with each of these is to provide tenants with the quality of\nservice that they paid for. Let\u2019s start by looking at networking QoS.\n\nTypically, all pods on a node share a network interface. Without network QoS, some pods may\nconsume an unfair share of the available bandwidth at the expense of other pods.\nThe Kubernetes [bandwidth plugin](https://www.cni.dev/plugins/current/meta/bandwidth/) creates an\n[extended resource](/docs/concepts/configuration/manage-resources-containers/#extended-resources)\nfor networking that allows you to use Kubernetes resources constructs, i.e. requests/limits, to\napply rate limits to pods by using Linux tc queues.\nBe aware that the plugin is considered experimental as per the\n[Network Plugins](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping)\ndocumentation and should be thoroughly tested before use in production environments.\n\nFor storage QoS, you will likely want to create different storage classes or profiles with\ndifferent performance characteristics. Each storage profile can be associated with a different\ntier of service that is optimized for different workloads such IO, redundancy, or throughput.\nAdditional logic might be necessary to allow the tenant to associate the appropriate storage\nprofile with their workload.\n\nFinally, there\u2019s [pod priority and preemption](/docs/concepts/scheduling-eviction/pod-priority-preemption/)\nwhere you can assign priority values to pods. When scheduling pods, the scheduler will try\nevicting pods with lower priority when there are insufficient resources to schedule pods that are\nassigned a higher priority. If you have a use case where tenants have different service tiers in a\nshared cluster e.g. free and paid, you may want to give higher priority to certain tiers using\nthis feature.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_n05",
      "question": "When does single-numa-node policy reject a pod that would be admitted by restricted?",
      "expected_answer": "When pod needs resources from exactly 2+ NUMA nodes; restricted accepts any preferred, single-numa-node requires exactly 1",
      "category": "NEGATION",
      "latency_ms": 961.0,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_security_security-checklist_mdsem_3",
          "doc_id": "concepts_security_security-checklist",
          "content": "## Pod security\n\n- [ ] RBAC rights to `create`, `update`, `patch`, `delete` workloads is only granted if necessary.\n- [ ] Appropriate Pod Security Standards policy is applied for all namespaces and enforced.\n- [ ] Memory limit is set for the workloads with a limit equal or inferior to the request.\n- [ ] CPU limit might be set on sensitive workloads.\n- [ ] For nodes that support it, Seccomp is enabled with appropriate syscalls\n  profile for programs.\n- [ ] For nodes that support it, AppArmor or SELinux is enabled with appropriate\n  profile for programs.\n\nRBAC authorization is crucial but\n[cannot be granular enough to have authorization on the Pods' resources](/docs/concepts/security/rbac-good-practices/#workload-creation)\n(or on any resource that manages Pods). The only granularity is the API verbs\non the resource itself, for example, `create` on Pods. Without\nadditional admission, the authorization to create these resources allows direct\nunrestricted access to the schedulable nodes of a cluster.\n\nThe [Pod Security Standards](/docs/concepts/security/pod-security-standards/)\ndefine three different policies, privileged, baseline and restricted that limit\nhow fields can be set in the `PodSpec` regarding security.\nThese standards can be enforced at the namespace level with the new\n[Pod Security](/docs/concepts/security/pod-security-admission/) admission,\nenabled by default, or by third-party admission webhook. Please note that,\ncontrary to the removed PodSecurityPolicy admission it replaces,\n[Pod Security](/docs/concepts/security/pod-security-admission/)\nadmission can be easily combined with admission webhooks and external services.\n\nPod Security admission `restricted` policy, the most restrictive policy of the\n[Pod Security Standards](/docs/concepts/security/pod-security-standards/) set,\n[can operate in several modes](/docs/concepts/security/pod-security-admission/#pod-security-admission-labels-for-namespaces),\n`warn`, `audit` or `enforce` to gradually apply the most appropriate\n[security context](/docs/tasks/configure-pod-container/security-context/)\naccording to security best practices. Nevertheless, pods'\n[security context](/docs/tasks/configure-pod-container/security-context/)\nshould be separately investigated to limit the privileges and access pods may\nhave on top of the predefined security standards, for specific use cases.\n\nFor a hands-on tutorial on [Pod Security](/docs/concepts/security/pod-security-admission/),\nsee the blog post\n[Kubernetes 1.23: Pod Security Graduates to Beta](/blog/2021/12/09/pod-security-admission-beta/).\n\n[Memory and CPU limits](/docs/concepts/configuration/manage-resources-containers/)\nshould be set in order to restrict the memory and CPU resources a pod can\nconsume on a node, and therefore prevent potential DoS attacks from malicious or\nbreached workloads. Such policy can be enforced by an admission controller.\nPlease note that CPU limits will throttle usage and thus can have unintended\neffects on auto-scaling features or efficiency i.e. running the process in best\neffort with the CPU resource available.\n\n{{< caution >}}\nMemory limit superior to request can expose the whole node to OOM issues.\n{{< /caution >}}",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_m01",
      "question": "How do I configure CPU placement policy in kubelet?",
      "expected_answer": "--topology-manager-policy flag",
      "category": "VOCABULARY",
      "latency_ms": 1026.8,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_configuration_windows-resource-management_mdsem_3",
          "doc_id": "concepts_configuration_windows-resource-management",
          "content": "## Resource reservation {#resource-reservation}\n\nTo account for memory and CPU used by the operating system, the container runtime, and by\nKubernetes host processes such as the kubelet, you can (and should) reserve\nmemory and CPU resources with the  `--kube-reserved` and/or `--system-reserved` kubelet flags.\nOn Windows these values are only used to calculate the node's\n[allocatable](/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable) resources.\n\n{{< caution >}}\nAs you deploy workloads, set resource memory and CPU limits on containers.\nThis also subtracts from `NodeAllocatable` and helps the cluster-wide scheduler in determining which pods to place on which nodes.\n\nScheduling pods without limits may over-provision the Windows nodes and in extreme\ncases can cause the nodes to become unhealthy.\n{{< /caution >}}\n\nOn Windows, a good practice is to reserve at least 2GiB of memory.\n\nTo determine how much CPU to reserve,\nidentify the maximum pod density for each node and monitor the CPU usage of\nthe system services running there, then choose a value that meets your workload needs.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_5",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager policies\n\nThe Topology Manager supports four allocation policies. You can set a policy via a kubelet flag,\n`--topology-manager-policy`. There are four supported policies:\n\n* `none` (default)\n* `best-effort`\n* `restricted`\n* `single-numa-node`\n\n{{< note >}}\nIf the Topology Manager is configured with the **pod** scope, the container, which is considered by\nthe policy, is reflecting requirements of the entire pod, and thus each container from the pod\nwill result with **the same** topology alignment decision.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_6",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `none` policy {#policy-none}\n\nThis is the default policy and does not perform any topology alignment.\n\n### `best-effort` policy {#policy-best-effort}\n\nFor each container in a Pod, the kubelet, with `best-effort` topology management policy, calls\neach Hint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will store this and admit the pod to the node anyway.\n\nThe *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n<!-- steps -->\n\n## How topology manager works\n\nPrior to the introduction of Topology Manager, the CPU and Device Manager in Kubernetes make\nresource allocation decisions independently of each other. This can result in undesirable\nallocations on multiple-socketed systems, and performance/latency sensitive applications will suffer\ndue to these undesirable allocations. Undesirable in this case meaning, for example, CPUs and\ndevices being allocated from different NUMA Nodes, thus incurring additional latency.\n\nThe Topology Manager is a kubelet component, which acts as a source of truth so that other kubelet\ncomponents can make topology aligned resource allocation choices.\n\nThe Topology Manager provides an interface for components, called *Hint Providers*, to send and\nreceive topology information. The Topology Manager has a set of node level policies which are\nexplained below.\n\nThe Topology Manager receives topology information from the *Hint Providers* as a bitmask denoting\nNUMA Nodes available and a preferred allocation indication. The Topology Manager policies perform\na set of operations on the hints provided and converge on the hint determined by the policy to\ngive the optimal result. If an undesirable hint is stored, the preferred field for the hint will be\nset to false. In the current policies preferred is the narrowest preferred mask.\nThe selected hint is stored as part of the Topology Manager. Depending on the policy configured,\nthe pod can be accepted or rejected from the node based on the selected hint.\nThe hint is then stored in the Topology Manager for use by the *Hint Providers* when making the\nresource allocation decisions.\n\nThe flow can be seen in the following diagram.\n\n![topology_manager_flow](/images/docs/topology-manager-flow.png)",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_m02",
      "question": "How do I enable NUMA awareness on Windows k8s nodes?",
      "expected_answer": "Enable WindowsCPUAndMemoryAffinity feature gate",
      "category": "VOCABULARY",
      "latency_ms": 1007.1,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_11",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `max-allowable-numa-nodes` {#policy-option-max-allowable-numa-nodes}\n\nThe `max-allowable-numa-nodes` option is GA since Kubernetes 1.35. In Kubernetes {{< skew currentVersion >}},\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe time to admit a pod is tied to the number of NUMA nodes on the physical machine.\nBy default, Kubernetes does not run a kubelet with the Topology Manager enabled, on any (Kubernetes) node where\nmore than 8 NUMA nodes are detected.\n\n{{< note >}}\nIf you select the `max-allowable-numa-nodes` policy option, nodes with more than 8 NUMA nodes can\nbe allowed to run with the Topology Manager enabled. The Kubernetes project only has limited data on the impact\nof using the Topology Manager on (Kubernetes) nodes with more than 8 NUMA nodes. Because of that\nlack of data, using this policy option with Kubernetes {{< skew currentVersion >}} is **not** recommended and is\nat your own risk.\n{{< /note >}}\n\nYou can enable this option by adding `max-allowable-numa-nodes=true` to the Topology Manager policy options.\n\nSetting a value of `max-allowable-numa-nodes` does not (in and of itself) affect the\nlatency of pod admission, but binding a Pod to a (Kubernetes) node with many NUMA does have an impact.\nFuture, potential improvements to Kubernetes may improve Pod admission performance and the high\nlatency that happens as the number of NUMA nodes increases.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_10",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `prefer-closest-numa-nodes` {#policy-option-prefer-closest-numa-nodes}\n\nThe `prefer-closest-numa-nodes` option is GA since Kubernetes 1.32. In Kubernetes {{< skew currentVersion >}}\nthis policy option is visible by default provided that the `TopologyManagerPolicyOptions`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) is enabled.\n\nThe Topology Manager is not aware by default of NUMA distances, and does not take them into account when making\nPod admission decisions. This limitation surfaces in multi-socket, as well as single-socket multi NUMA systems,\nand can cause significant performance degradation in latency-critical execution and high-throughput applications\nif the Topology Manager decides to align resources on non-adjacent NUMA nodes.\n\nIf you specify the `prefer-closest-numa-nodes` policy option, the `best-effort` and `restricted`\npolicies favor sets of NUMA nodes with shorter distance between them when making admission decisions.\n\nYou can enable this option by adding `prefer-closest-numa-nodes=true` to the Topology Manager policy options.\n\nBy default (without this option), the Topology Manager aligns resources on either a single NUMA node or,\nin the case where more than one NUMA node is required, using the minimum number of NUMA nodes.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_4",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `pod` scope\n\nTo select the `pod` scope, set `topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/) to `pod`.\n\nThis scope allows for grouping all containers in a pod to a common set of NUMA nodes. That is, the\nTopology Manager treats a pod as a whole and attempts to allocate the entire pod (all containers)\nto either a single NUMA node or a common set of NUMA nodes. The following examples illustrate the\nalignments produced by the Topology Manager on different occasions:\n\n* all containers can be and are allocated to a single NUMA node;\n* all containers can be and are allocated to a shared set of NUMA nodes.\n\nThe total amount of particular resource demanded for the entire pod is calculated according to\n[effective requests/limits](/docs/concepts/workloads/pods/init-containers/#resource-sharing-within-containers)\nformula, and thus, this total value is equal to the maximum of:\n\n* the sum of all app container requests,\n* the maximum of init container requests,\n\nfor a resource.\n\nUsing the `pod` scope in tandem with `single-numa-node` Topology Manager policy is specifically\nvaluable for workloads that are latency sensitive or for high-throughput applications that perform\nIPC. By combining both options, you are able to place all containers in a pod onto a single NUMA\nnode; hence, the inter-NUMA communication overhead can be eliminated for that pod.\n\nIn the case of `single-numa-node` policy, a pod is accepted only if a suitable set of NUMA nodes\nis present among possible allocations. Reconsider the example above:\n\n* a set containing only a single NUMA node - it leads to pod being admitted,\n* whereas a set containing more NUMA nodes - it results in pod rejection (because instead of one\n  NUMA node, two or more NUMA nodes are required to satisfy the allocation).\n\nTo recap, the Topology Manager first computes a set of NUMA nodes and then tests it against the Topology\nManager policy, which either leads to the rejection or admission of the pod.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_topology_mdsem_4",
          "doc_id": "tasks_debug_debug-cluster_topology",
          "content": "## Examples\n\n\n\n### Examine the memory manager state on a node\n\nLet us first deploy a sample `Guaranteed` pod whose specification is as follows:\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: guaranteed\nspec:\n  containers:\n  - name: guaranteed\n    image: consumer\n    imagePullPolicy: Never\n    resources:\n      limits:\n        cpu: \"2\"\n        memory: 150Gi\n      requests:\n        cpu: \"2\"\n        memory: 150Gi\n    command: [\"sleep\",\"infinity\"]\n```\n\nNext, log into the node where it was deployed and examine the state file in\n`/var/lib/kubelet/memory_manager_state`:\n\n```json\n{\n   \"policyName\":\"Static\",\n   \"machineState\":{\n      \"0\":{\n         \"numberOfAssignments\":1,\n         \"memoryMap\":{\n            \"hugepages-1Gi\":{\n               \"total\":0,\n               \"systemReserved\":0,\n               \"allocatable\":0,\n               \"reserved\":0,\n               \"free\":0\n            },\n            \"memory\":{\n               \"total\":134987354112,\n               \"systemReserved\":3221225472,\n               \"allocatable\":131766128640,\n               \"reserved\":131766128640,\n               \"free\":0\n            }\n         },\n         \"nodes\":[\n            0,\n            1\n         ]\n      },\n      \"1\":{\n         \"numberOfAssignments\":1,\n         \"memoryMap\":{\n            \"hugepages-1Gi\":{\n               \"total\":0,\n               \"systemReserved\":0,\n               \"allocatable\":0,\n               \"reserved\":0,\n               \"free\":0\n            },\n            \"memory\":{\n               \"total\":135286722560,\n               \"systemReserved\":2252341248,\n               \"allocatable\":133034381312,\n               \"reserved\":29295144960,\n               \"free\":103739236352\n            }\n         },\n         \"nodes\":[\n            0,\n            1\n         ]\n      }\n   },\n   \"entries\":{\n      \"fa9bdd38-6df9-4cf9-aa67-8c4814da37a8\":{\n         \"guaranteed\":[\n            {\n               \"numaAffinity\":[\n                  0,\n                  1\n               ],\n               \"type\":\"memory\",\n               \"size\":161061273600\n            }\n         ]\n      }\n   },\n   \"checksum\":4142013182\n}\n```\n\nIt can be deduced from the state file that the pod was pinned to both NUMA nodes, i.e.:\n\n```json\n\"numaAffinity\":[\n   0,\n   1\n],\n```\n\nPinned term means that pod's memory consumption is constrained (through `cgroups` configuration)\nto these NUMA nodes.\n\nThis automatically implies that Memory Manager instantiated a new group that\ncomprises these two NUMA nodes, i.e. `0` and `1` indexed NUMA nodes.\n\nIn order to analyse memory resources available in a group,the corresponding entries from\nNUMA nodes belonging to the group must be added up.\n\nFor example, the total amount of free \"conventional\" memory in the group can be computed\nby adding up the free memory available at every NUMA node in the group,\ni.e., in the `\"memory\"` section of NUMA node `0` (`\"free\":0`) and NUMA node `1` (`\"free\":103739236352`).\nSo, the total amount of free \"conventional\" memory in this group is equal to `0 + 103739236352` bytes.\n\nThe line `\"systemReserved\":3221225472` indicates that the administrator of this node reserved\n`3221225472` bytes (i.e. `3Gi`) to serve kubelet and system processes at NUMA node `0`,\nby using `--reserved-memory` flag.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_windows_mdsem_2",
          "doc_id": "tasks_debug_debug-cluster_windows",
          "content": "### Flannel troubleshooting\n\n1. With Flannel, my nodes are having issues after rejoining a cluster\n\n   Whenever a previously deleted node is being re-joined to the cluster, flannelD\n   tries to assign a new pod subnet to the node. Users should remove the old pod\n   subnet configuration files in the following paths:\n\n   ```powershell\n   Remove-Item C:\\k\\SourceVip.json\n   Remove-Item C:\\k\\SourceVipRequest.json\n   ```\n\n1. Flanneld is stuck in \"Waiting for the Network to be created\"\n\n   There are numerous reports of this [issue](https://github.com/coreos/flannel/issues/1066);\n   most likely it is a timing issue for when the management IP of the flannel network is set.\n   A workaround is to relaunch `start.ps1` or relaunch it manually as follows:\n\n   ```powershell\n   [Environment]::SetEnvironmentVariable(\"NODE_NAME\", \"<Windows_Worker_Hostname>\")\n   C:\\flannel\\flanneld.exe --kubeconfig-file=c:\\k\\config --iface=<Windows_Worker_Node_IP> --ip-masq=1 --kube-subnet-mgr=1\n   ```\n\n1. My Windows Pods cannot launch because of missing `/run/flannel/subnet.env`\n\n   This indicates that Flannel didn't launch correctly. You can either try\n   to restart `flanneld.exe` or you can copy the files over manually from\n   `/run/flannel/subnet.env` on the Kubernetes master to `C:\\run\\flannel\\subnet.env`\n   on the Windows worker node and modify the `FLANNEL_SUBNET` row to a different\n   number. For example, if node subnet 10.244.4.1/24 is desired:\n\n   ```env\n   FLANNEL_NETWORK=10.244.0.0/16\n   FLANNEL_SUBNET=10.244.4.1/24\n   FLANNEL_MTU=1500\n   FLANNEL_IPMASQ=true\n   ```\n\n### Further investigation\n\nIf these steps don't resolve your problem, you can get help running Windows containers on Windows nodes in Kubernetes through:\n\n* StackOverflow [Windows Server Container](https://stackoverflow.com/questions/tagged/windows-server-container) topic\n* Kubernetes Official Forum [discuss.kubernetes.io](https://discuss.kubernetes.io/)\n* Kubernetes Slack [#SIG-Windows Channel](https://kubernetes.slack.com/messages/sig-windows)",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_m03",
      "question": "How does k8s coordinate resource co-location across multi-socket servers?",
      "expected_answer": "Topology Manager acts as source of truth for CPU Manager and Device Manager",
      "category": "VOCABULARY",
      "latency_ms": 1211.6,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_1",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## {{% heading \"prerequisites\" %}}\n\n{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n<!-- steps -->\n\n## How topology manager works\n\nPrior to the introduction of Topology Manager, the CPU and Device Manager in Kubernetes make\nresource allocation decisions independently of each other. This can result in undesirable\nallocations on multiple-socketed systems, and performance/latency sensitive applications will suffer\ndue to these undesirable allocations. Undesirable in this case meaning, for example, CPUs and\ndevices being allocated from different NUMA Nodes, thus incurring additional latency.\n\nThe Topology Manager is a kubelet component, which acts as a source of truth so that other kubelet\ncomponents can make topology aligned resource allocation choices.\n\nThe Topology Manager provides an interface for components, called *Hint Providers*, to send and\nreceive topology information. The Topology Manager has a set of node level policies which are\nexplained below.\n\nThe Topology Manager receives topology information from the *Hint Providers* as a bitmask denoting\nNUMA Nodes available and a preferred allocation indication. The Topology Manager policies perform\na set of operations on the hints provided and converge on the hint determined by the policy to\ngive the optimal result. If an undesirable hint is stored, the preferred field for the hint will be\nset to false. In the current policies preferred is the narrowest preferred mask.\nThe selected hint is stored as part of the Topology Manager. Depending on the policy configured,\nthe pod can be accepted or rejected from the node based on the selected hint.\nThe hint is then stored in the Topology Manager for use by the *Hint Providers* when making the\nresource allocation decisions.\n\nThe flow can be seen in the following diagram.\n\n![topology_manager_flow](/images/docs/topology-manager-flow.png)",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_12",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Pod interactions with topology manager policies\n\nConsider the containers in the following Pod manifest:\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n```\n\nThis pod runs in the `BestEffort` QoS class because no resource `requests` or `limits` are specified.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n      requests:\n        memory: \"100Mi\"\n```\n\nThis pod runs in the `Burstable` QoS class because requests are less than limits.\n\nIf the selected policy is anything other than `none`, the Topology Manager would consider these Pod\nspecifications. The Topology Manager would consult the Hint Providers to get topology hints.\nIn the case of the `static`, the CPU Manager policy would return default topology hint, because\nthese Pods do not explicitly request CPU resources.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"2\"\n        example.com/device: \"1\"\n```\n\nThis pod with integer CPU request runs in the `Guaranteed` QoS class because `requests` are equal\nto `limits`.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n      requests:\n        memory: \"200Mi\"\n        cpu: \"300m\"\n        example.com/device: \"1\"\n```\n\nThis pod with sharing CPU request runs in the `Guaranteed` QoS class because `requests` are equal\nto `limits`.\n\n```yaml\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n        example.com/deviceA: \"1\"\n        example.com/deviceB: \"1\"\n      requests:\n        example.com/deviceA: \"1\"\n        example.com/deviceB: \"1\"\n```\n\nThis pod runs in the `BestEffort` QoS class because there are no CPU and memory requests.\n\nThe Topology Manager would consider the above pods. The Topology Manager would consult the Hint\nProviders, which are CPU and Device Manager to get topology hints for the pods.\n\nIn the case of the `Guaranteed` pod with integer CPU request, the `static` CPU Manager policy\nwould return topology hints relating to the exclusive CPU and the Device Manager would send back\nhints for the requested device.\n\nIn the case of the `Guaranteed` pod with sharing CPU request, the `static` CPU Manager policy\nwould return default topology hint as there is no exclusive CPU request and the Device Manager\nwould send back hints for the requested device.\n\nIn the above two cases of the `Guaranteed` pod, the `none` CPU Manager policy would return default\ntopology hint.\n\nIn the case of the `BestEffort` pod, the `static` CPU Manager policy would send back the default\ntopology hint as there is no CPU request and the Device Manager would send back the hints for each\nof the requested devices.\n\nUsing this information the Topology Manager calculates the optimal hint for the pod and stores\nthis information, which will be used by the Hint Providers when they are making their resource\nassignments.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_8",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `single-numa-node` policy {#policy-single-numa-node}\n\nFor each container in a Pod, the kubelet, with `single-numa-node` topology management policy,\ncalls each Hint Provider to discover their resource availability. Using this information, the\nTopology Manager determines if a single NUMA Node affinity is possible. If it is, Topology\nManager will store this and the *Hint Providers* can then use this information when making the\nresource allocation decision. If, however, this is not possible then the Topology Manager will\nreject the pod from the node. This will result in a pod in a `Terminated` state with a pod\nadmission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a Deployment with replicas to trigger a redeployment of\nthe Pod. An external control loop could be also implemented to trigger a redeployment of pods\nthat have the `Topology Affinity` error.",
          "is_needle": true
        },
        {
          "chunk_id": "concepts_scheduling-eviction_kube-scheduler_mdsem_3",
          "doc_id": "concepts_scheduling-eviction_kube-scheduler",
          "content": "## {{% heading \"whatsnext\" %}}\n\n* Read about [scheduler performance tuning](/docs/concepts/scheduling-eviction/scheduler-perf-tuning/)\n* Read about [Pod topology spread constraints](/docs/concepts/scheduling-eviction/topology-spread-constraints/)\n* Read the [reference documentation](/docs/reference/command-line-tools-reference/kube-scheduler/) for kube-scheduler\n* Read the [kube-scheduler config (v1)](/docs/reference/config-api/kube-scheduler-config.v1/) reference\n* Learn about [configuring multiple schedulers](/docs/tasks/extend-kubernetes/configure-multiple-schedulers/)\n* Learn about [topology management policies](/docs/tasks/administer-cluster/topology-manager/)\n* Learn about [Pod Overhead](/docs/concepts/scheduling-eviction/pod-overhead/)\n* Learn about scheduling of Pods that use volumes in:\n  * [Volume Topology Support](/docs/concepts/storage/storage-classes/#volume-binding-mode)\n  * [Storage Capacity Tracking](/docs/concepts/storage/storage-capacity/)\n  * [Node-specific Volume Limits](/docs/concepts/storage/storage-limits/)",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_7",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "### `restricted` policy {#policy-restricted}\n\nFor each container in a Pod, the kubelet, with `restricted` topology management policy, calls each\nHint Provider to discover their resource availability. Using this information, the Topology\nManager stores the preferred NUMA Node affinity for that container. If the affinity is not\npreferred, the Topology Manager will reject this pod from the node. This will result in a pod entering a\n`Terminated` state with a pod admission failure.\n\nOnce the pod is in a `Terminated` state, the Kubernetes scheduler will **not** attempt to\nreschedule the pod. It is recommended to use a ReplicaSet or Deployment to trigger a redeployment of\nthe pod. An external control loop could be also implemented to trigger a redeployment of pods that\nhave the `Topology Affinity` error.\n\nIf the pod is admitted, the *Hint Providers* can then use this information when making the\nresource allocation decision.",
          "is_needle": true
        }
      ]
    },
    {
      "question_id": "adv_m04",
      "question": "What kubelet setting controls the granularity of resource alignment?",
      "expected_answer": "topologyManagerScope (container or pod)",
      "category": "VOCABULARY",
      "latency_ms": 1136.0,
      "needle_found": true,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_configuration_windows-resource-management_mdsem_3",
          "doc_id": "concepts_configuration_windows-resource-management",
          "content": "## Resource reservation {#resource-reservation}\n\nTo account for memory and CPU used by the operating system, the container runtime, and by\nKubernetes host processes such as the kubelet, you can (and should) reserve\nmemory and CPU resources with the  `--kube-reserved` and/or `--system-reserved` kubelet flags.\nOn Windows these values are only used to calculate the node's\n[allocatable](/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable) resources.\n\n{{< caution >}}\nAs you deploy workloads, set resource memory and CPU limits on containers.\nThis also subtracts from `NodeAllocatable` and helps the cluster-wide scheduler in determining which pods to place on which nodes.\n\nScheduling pods without limits may over-provision the Windows nodes and in extreme\ncases can cause the nodes to become unhealthy.\n{{< /caution >}}\n\nOn Windows, a good practice is to reserve at least 2GiB of memory.\n\nTo determine how much CPU to reserve,\nidentify the maximum pod density for each node and monitor the CPU usage of\nthe system services running there, then choose a value that meets your workload needs.",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_3",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Topology manager scopes\n\nThe Topology Manager can deal with the alignment of resources in a couple of distinct scopes:\n\n* `container` (default)\n* `pod`\n\nEither option can be selected at a time of the kubelet startup, by setting the\n`topologyManagerScope` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\n### `container` scope\n\nThe `container` scope is used by default. You can also explicitly set the\n`topologyManagerScope` to `container` in the\n[kubelet configuration file](/docs/tasks/administer-cluster/kubelet-config-file/).\n\nWithin this scope, the Topology Manager performs a number of sequential resource alignments, i.e.,\nfor each container (in a pod) a separate alignment is computed. In other words, there is no notion\nof grouping the containers to a specific set of NUMA nodes, for this particular scope. In effect,\nthe Topology Manager performs an arbitrary alignment of individual containers to NUMA nodes.\n\nThe notion of grouping the containers was endorsed and implemented on purpose in the following\nscope, for example the `pod` scope.",
          "is_needle": true
        },
        {
          "chunk_id": "tasks_administer-cluster_topology-manager_mdsem_2",
          "doc_id": "tasks_administer-cluster_topology-manager",
          "content": "## Windows Support\n\n{{< feature-state feature_gate_name=\"WindowsCPUAndMemoryAffinity\" >}}\n\nThe Topology Manager support can be enabled on Windows by using the `WindowsCPUAndMemoryAffinity` feature gate and\nit requires support in the container runtime.\n\n## Topology manager scopes and policies\n\nThe Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
          "is_needle": true
        },
        {
          "chunk_id": "setup_best-practices_cluster-large_mdsem_4",
          "doc_id": "setup_best-practices_cluster-large",
          "content": "## Addon resources\n\nKubernetes [resource limits](/docs/concepts/configuration/manage-resources-containers/)\nhelp to minimize the impact of memory leaks and other ways that pods and containers can\nimpact on other components. These resource limits apply to\n{{< glossary_tooltip text=\"addon\" term_id=\"addons\" >}} resources just as they apply to application workloads.\n\nFor example, you can set CPU and memory limits for a logging component:\n\n```yaml\n  ...\n  containers:\n  - name: fluentd-cloud-logging\n    image: fluent/fluentd-kubernetes-daemonset:v1\n    resources:\n      limits:\n        cpu: 100m\n        memory: 200Mi\n```\n\nAddons' default limits are typically based on data collected from experience running\neach addon on small or medium Kubernetes clusters. When running on large\nclusters, addons often consume more of some resources than their default limits.\nIf a large cluster is deployed without adjusting these values, the addon(s)\nmay continuously get killed because they keep hitting the memory limit.\nAlternatively, the addon may run but with poor performance due to CPU time\nslice restrictions.\n\nTo avoid running into cluster addon resource issues, when creating a cluster with\nmany nodes, consider the following:\n\n* Some addons scale vertically - there is one replica of the addon for the cluster\n  or serving a whole failure zone. For these addons, increase requests and limits\n  as you scale out your cluster.\n* Many addons scale horizontally - you add capacity by running more pods - but with\n  a very large cluster you may also need to raise CPU or memory limits slightly.\n  The [Vertical Pod Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#readme) can run in _recommender_ mode to provide suggested\n  figures for requests and limits.\n* Some addons run as one copy per node, controlled by a {{< glossary_tooltip text=\"DaemonSet\"\n  term_id=\"daemonset\" >}}: for example, a node-level log aggregator. Similar to\n  the case with horizontally-scaled addons, you may also need to raise CPU or memory\n  limits slightly.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_configuration_windows-resource-management_mdsem_2",
          "doc_id": "concepts_configuration_windows-resource-management",
          "content": "## CPU management {#resource-management-cpu}\n\nWindows can limit the amount of CPU time allocated for different processes but cannot\nguarantee a minimum amount of CPU time.\n\nOn Windows, the kubelet supports a command-line flag to set the\n[scheduling priority](https://docs.microsoft.com/windows/win32/procthread/scheduling-priorities) of the\nkubelet process: `--windows-priorityclass`. This flag allows the kubelet process to get\nmore CPU time slices when compared to other processes running on the Windows host.\nMore information on the allowable values and their meaning is available at\n[Windows Priority Classes](https://docs.microsoft.com/en-us/windows/win32/procthread/scheduling-priorities#priority-class).\nTo ensure that running Pods do not starve the kubelet of CPU cycles, set this flag to `ABOVE_NORMAL_PRIORITY_CLASS` or above.",
          "is_needle": false
        }
      ]
    },
    {
      "question_id": "adv_m05",
      "question": "How do I optimize inter-process communication latency for pods?",
      "expected_answer": "Use pod scope with single-numa-node policy to eliminate inter-NUMA overhead",
      "category": "VOCABULARY",
      "latency_ms": 971.0,
      "needle_found": false,
      "retrieved_chunks": [
        {
          "chunk_id": "concepts_security_multi-tenancy_mdsem_13",
          "doc_id": "concepts_security_multi-tenancy",
          "content": "### Quality-of-Service (QoS) {#qos}\n\nWhen you\u2019re running a SaaS application, you may want the ability to offer different\nQuality-of-Service (QoS) tiers of service to different tenants. For example, you may have freemium\nservice that comes with fewer performance guarantees and features and a for-fee service tier with\nspecific performance guarantees. Fortunately, there are several Kubernetes constructs that can\nhelp you accomplish this within a shared cluster, including network QoS, storage classes, and pod\npriority and preemption. The idea with each of these is to provide tenants with the quality of\nservice that they paid for. Let\u2019s start by looking at networking QoS.\n\nTypically, all pods on a node share a network interface. Without network QoS, some pods may\nconsume an unfair share of the available bandwidth at the expense of other pods.\nThe Kubernetes [bandwidth plugin](https://www.cni.dev/plugins/current/meta/bandwidth/) creates an\n[extended resource](/docs/concepts/configuration/manage-resources-containers/#extended-resources)\nfor networking that allows you to use Kubernetes resources constructs, i.e. requests/limits, to\napply rate limits to pods by using Linux tc queues.\nBe aware that the plugin is considered experimental as per the\n[Network Plugins](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping)\ndocumentation and should be thoroughly tested before use in production environments.\n\nFor storage QoS, you will likely want to create different storage classes or profiles with\ndifferent performance characteristics. Each storage profile can be associated with a different\ntier of service that is optimized for different workloads such IO, redundancy, or throughput.\nAdditional logic might be necessary to allow the tenant to associate the appropriate storage\nprofile with their workload.\n\nFinally, there\u2019s [pod priority and preemption](/docs/concepts/scheduling-eviction/pod-priority-preemption/)\nwhere you can assign priority values to pods. When scheduling pods, the scheduler will try\nevicting pods with lower priority when there are insufficient resources to schedule pods that are\nassigned a higher priority. If you have a use case where tenants have different service tiers in a\nshared cluster e.g. free and paid, you may want to give higher priority to certain tiers using\nthis feature.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_scheduling-eviction_kube-scheduler_mdsem_3",
          "doc_id": "concepts_scheduling-eviction_kube-scheduler",
          "content": "## {{% heading \"whatsnext\" %}}\n\n* Read about [scheduler performance tuning](/docs/concepts/scheduling-eviction/scheduler-perf-tuning/)\n* Read about [Pod topology spread constraints](/docs/concepts/scheduling-eviction/topology-spread-constraints/)\n* Read the [reference documentation](/docs/reference/command-line-tools-reference/kube-scheduler/) for kube-scheduler\n* Read the [kube-scheduler config (v1)](/docs/reference/config-api/kube-scheduler-config.v1/) reference\n* Learn about [configuring multiple schedulers](/docs/tasks/extend-kubernetes/configure-multiple-schedulers/)\n* Learn about [topology management policies](/docs/tasks/administer-cluster/topology-manager/)\n* Learn about [Pod Overhead](/docs/concepts/scheduling-eviction/pod-overhead/)\n* Learn about scheduling of Pods that use volumes in:\n  * [Volume Topology Support](/docs/concepts/storage/storage-classes/#volume-binding-mode)\n  * [Storage Capacity Tracking](/docs/concepts/storage/storage-capacity/)\n  * [Node-specific Volume Limits](/docs/concepts/storage/storage-limits/)",
          "is_needle": false
        },
        {
          "chunk_id": "tasks_debug_debug-cluster_topology_mdsem_0",
          "doc_id": "tasks_debug_debug-cluster_topology",
          "content": "---\ntitle: Troubleshooting Topology Management\nweight: 60\ncontent_type: task\n---\n\n<!-- overview -->\n\nKubernetes keeps many aspects of how pods execute on nodes abstracted\nfrom the user. This is by design. However, some workloads require\nstronger guarantees in terms of latency and/or performance in order to operate\nacceptably. The `kubelet` provides methods to enable more complex workload\nplacement policies while keeping the abstraction free from explicit placement\ndirectives.\n\nYou can manage topology within nodes. This means helping the kubelet to configure the host operating system so that\nPods and containers are placed on the correct side of inner boundaries, such as _NUMA domains_. (NUMA is an abbreviation\nof _non-uniform memory access_, and refers to an idea that CPUs might be topologically closer to specific regions of\nmemory, due to the physical layout of the hardware components and the way that these are connected).",
          "is_needle": false
        },
        {
          "chunk_id": "tutorials_kubernetes-basics_explore_explore-intro_mdsem_1",
          "doc_id": "tutorials_kubernetes-basics_explore_explore-intro",
          "content": "### Pods overview\n\n{{< figure src=\"/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg\" class=\"diagram-medium\" >}}\n\n{{% alert %}}\n_Containers should only be scheduled together in a single Pod if they are tightly\ncoupled and need to share resources such as disk._\n{{% /alert %}}\n\n## Nodes\n\nA Pod always runs on a **Node**. A Node is a worker machine in Kubernetes and may\nbe either a virtual or a physical machine, depending on the cluster. Each Node is\nmanaged by the control plane. A Node can have multiple pods, and the Kubernetes\ncontrol plane automatically handles scheduling the pods across the Nodes in the\ncluster. The control plane's automatic scheduling takes into account the available\nresources on each Node.\n\nEvery Kubernetes Node runs at least:\n\n* Kubelet, a process responsible for communication between the Kubernetes control\nplane and the Node; it manages the Pods and the containers running on a machine.\n\n* A container runtime (like Docker) responsible for pulling the container image\nfrom a registry, unpacking the container, and running the application.",
          "is_needle": false
        },
        {
          "chunk_id": "concepts_security_multi-tenancy_mdsem_7",
          "doc_id": "concepts_security_multi-tenancy",
          "content": "### Quotas\n\nKubernetes workloads consume node resources, like CPU and memory.  In a multi-tenant environment,\nyou can use [Resource Quotas](/docs/concepts/policy/resource-quotas/) to manage resource usage of\ntenant workloads.  For the multiple teams use case, where tenants have access to the Kubernetes\nAPI, you can use resource quotas to limit the number of API resources (for example: the number of\nPods, or the number of ConfigMaps) that a tenant can create. Limits on object count ensure\nfairness and aim to avoid _noisy neighbor_ issues from affecting other tenants that share a\ncontrol plane.\n\nResource quotas are namespaced objects. By mapping tenants to namespaces, cluster admins can use\nquotas to ensure that a tenant cannot monopolize a cluster's resources or overwhelm its control\nplane. Namespace management tools simplify the administration of quotas. In addition, while\nKubernetes quotas only apply within a single namespace, some namespace management tools allow\ngroups of namespaces to share quotas, giving administrators far more flexibility with less effort\nthan built-in quotas.\n\nQuotas prevent a single tenant from consuming greater than their allocated share of resources\nhence minimizing the \u201cnoisy neighbor\u201d issue, where one tenant negatively impacts the performance\nof other tenants' workloads.\n\nWhen you apply a quota to namespace, Kubernetes requires you to also specify resource requests and\nlimits for each container. Limits are the upper bound for the amount of resources that a container\ncan consume. Containers that attempt to consume resources that exceed the configured limits will\neither be throttled or killed, based on the resource type. When resource requests are set lower\nthan limits, each container is guaranteed the requested amount but there may still be some\npotential for impact across workloads.\n\nQuotas cannot protect against all kinds of resource sharing, such as network traffic.\nNode isolation (described below) may be a better solution for this problem.",
          "is_needle": false
        }
      ]
    }
  ]
}