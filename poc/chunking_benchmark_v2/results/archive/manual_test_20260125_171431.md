# Manual Testing Report

Generated: 2026-01-25 17:15:40
Strategy: enriched_hybrid_llm
Questions: 10

## Summary

- **Average Score**: 7.2 / 10
- **Benchmark Claim**: 88.7% coverage
- **Validation**: INCONCLUSIVE
- **Status**: ✗ BELOW BENCHMARK

## Results

| # | Question (truncated) | Score | Verdict | Source |
|---|---------------------|-------|---------|--------|
| 1 | What is the default API request limit per minute? | 10 | PASS | api_reference |
| 2 | How long do CloudFlow JWT tokens remain valid? | 5 | PARTIAL | api_reference |
| 3 | What authentication methods does CloudFlow support... | 8 | PASS | api_reference |
| 4 | How can I handle a 429 Too Many Requests error fro... | 9 | PASS | api_reference |
| 5 | What are the maximum concurrent workflow execution... | 5 | PARTIAL | user_guide |
| 6 | How do I add error handling to a workflow? | 9 | PASS | user_guide |
| 7 | What database connection limits exist in CloudFlow... | 6 | PARTIAL | deployment_guide |
| 8 | What are the recovery time objectives for CloudFlo... | 8 | PASS | deployment_guide |
| 9 | What are the three supported authentication method... | 7 | PASS | api_reference |
| 10 | How do I troubleshoot workflow execution failures? | 5 | PARTIAL | troubleshooting_guide |

## Detailed Findings

### Question 1: What is the default API request limit per minute?

**Expected Answer**: 100 requests per minute per authenticated user, 20 requests per minute for unauthenticated requests

**Score**: 10/10 (PASS)

**Explanation**: The retrieved content from Chunk 1 (api_reference document) provides a perfect, direct answer to the question. It specifies the exact rate limits: 100 requests per minute for authenticated users and 20 requests per minute for unauthenticated requests. The information is clear, precise, and matches the expected answer word-for-word. Additional details about burst allowance and rate limit headers provide supplementary context without diluting the core response.

**Retrieved Chunks**:

1. **[api_reference]** ## Rate Limiting To ensure fair usage and system stability, CloudFlow enforces rate limits on all API endpoints. **Default Limits:** - 100 requests per minute per authenticated user - 20 requests per ...
2. **[troubleshooting_guide]** Waiting {retry_after} seconds...") time.sleep(retry_after) continue remaining = int(response.headers.get('X-RateLimit-Remaining', 0)) if remaining < 10: print(f"Warning: Only {remaining} requests rema...
3. **[architecture_overview]** **Technology**: Node.js with Express.js framework **Replicas**: 12 pods (production), auto-scaling 8-20 based on CPU **Resource Allocation**: 2 vCPU, 4GB RAM per pod **Key Responsibilities**: - JWT to...
4. **[troubleshooting_guide]** Data Validation Errors** ``` ValidationError: Field 'customer_id' is required but missing in 234 records ``` **Resolution:** ```bash # Add data quality checks cloudflow workflows update wf_9k2n4m8p1q ...
5. **[api_reference]** ### Error Response Format ```json { "error": { "code": "invalid_parameter", "message": "The 'limit' parameter must be between 1 and 100", "field": "limit", "request_id": "req_8k3m9x2p" } } ``` ### HTT...

### Question 2: How long do CloudFlow JWT tokens remain valid?

**Expected Answer**: All tokens expire after 3600 seconds (1 hour). Implement token refresh logic in your application.

**Score**: 5/10 (PARTIAL)

**Explanation**: While the retrieved content discusses JWT tokens and authentication in CloudFlow, no specific documentation chunk directly states the token expiration time of 3600 seconds. Chunk 2 mentions JWT token validation and Chunk 5 references time-based expiration strategies, but neither explicitly confirms the 1-hour token validity. The retrieved content is tangentially related but does not clearly answer the specific question about JWT token duration.

**Retrieved Chunks**:

1. **[api_reference]** # CloudFlow API Reference Version 2.1.0 \| Last Updated: January 2026 ## Overview The CloudFlow API is a RESTful service that enables developers to programmatically manage cloud workflows, data pipelin...
2. **[architecture_overview]** **Technology**: Node.js with Express.js framework **Replicas**: 12 pods (production), auto-scaling 8-20 based on CPU **Resource Allocation**: 2 vCPU, 4GB RAM per pod **Key Responsibilities**: - JWT to...
3. **[troubleshooting_guide]** # CloudFlow Platform Troubleshooting Guide **Version:** 3.2.1 **Last Updated:** January 2026 **Audience:** Platform Engineers, DevOps, Support Teams ## Table of Contents 1. [Overview](#overview) 2. [A...
4. **[troubleshooting_guide]** **Diagnosis:** ```bash # Check system time timedatectl status # Compare with NTP server ntpdate -q pool.ntp.org # Check JWT issued time vs current time jwt_iat=$(echo $CF_ACCESS_TOKEN \| cut -d'.' -f2 ...
5. **[architecture_overview]** ### Cache Invalidation Strategies **Time-Based Expiration (TTL)**: - Short-lived data: 5-15 minutes (session tokens, rate limit counters) - Medium-lived data: 1 hour (workflow definitions, templates) ...

### Question 3: What authentication methods does CloudFlow support?

**Expected Answer**: CloudFlow supports three authentication methods: API Keys, OAuth 2.0, and JWT Tokens

**Score**: 8/10 (PASS)

**Explanation**: The retrieved chunks contain the exact answer about CloudFlow authentication methods in the first chunk, matching the expected answer of 'API Keys, OAuth 2.0, and JWT Tokens'. The content is directly from an API reference document and provides clear, accurate information. While the full details are cut off in the retrieved text, the core information is present. Some additional context about authentication is found in the troubleshooting guide, providing supporting evidence. The information is somewhat buried and requires a bit of parsing, hence the score of 8 rather than a perfect 10.

**Retrieved Chunks**:

1. **[api_reference]** # CloudFlow API Reference Version 2.1.0 \| Last Updated: January 2026 ## Overview The CloudFlow API is a RESTful service that enables developers to programmatically manage cloud workflows, data pipelin...
2. **[api_reference]** **Supported Events:** - `workflow.started` - `workflow.completed` - `workflow.failed` - `pipeline.completed` - `pipeline.failed` **Webhook Payload Example:** ```json { "event": "workflow.completed", "...
3. **[troubleshooting_guide]** # CloudFlow Platform Troubleshooting Guide **Version:** 3.2.1 **Last Updated:** January 2026 **Audience:** Platform Engineers, DevOps, Support Teams ## Table of Contents 1. [Overview](#overview) 2. [A...
4. **[troubleshooting_guide]** Leverage caching:** ```bash # Enable client-side caching export CLOUDFLOW_CACHE_ENABLED=true export CLOUDFLOW_CACHE_TTL=300 # Cache workflow metadata cloudflow workflows list --use-cache --cache-ttl 6...
5. **[deployment_guide]** create cluster -f cluster-config.yaml ``` ### Storage Configuration Install the EBS CSI driver for persistent volumes: ```bash eksctl create addon --name aws-ebs-csi-driver \ --cluster cloudflow-produ...

### Question 4: How can I handle a 429 Too Many Requests error from the CloudFlow API?

**Expected Answer**: When you exceed the rate limit, you'll receive a 429 Too Many Requests response. Best practices include monitoring `X-RateLimit-Remaining` header values, implementing exponential backoff, and caching responses to reduce API calls.

**Score**: 9/10 (PASS)

**Explanation**: Retrieved content directly addresses the 429 Too Many Requests error with excellent technical details. Chunk 1 from api_reference provides precise rate limit information, including default limits (100 requests/minute) and rate limit headers. Chunk 5 offers a concrete code snippet demonstrating retry logic and rate limit checking. The answer perfectly matches the expected response by highlighting monitoring X-RateLimit-Remaining headers, suggesting exponential backoff, and demonstrating practical error handling strategies. Small amount of tangential content prevents a perfect 10, but the core answer is comprehensive and highly actionable.

**Retrieved Chunks**:

1. **[api_reference]** ## Rate Limiting To ensure fair usage and system stability, CloudFlow enforces rate limits on all API endpoints. **Default Limits:** - 100 requests per minute per authenticated user - 20 requests per ...
2. **[troubleshooting_guide]** Data Validation Errors** ``` ValidationError: Field 'customer_id' is required but missing in 234 records ``` **Resolution:** ```bash # Add data quality checks cloudflow workflows update wf_9k2n4m8p1q ...
3. **[api_reference]** ### Error Response Format ```json { "error": { "code": "invalid_parameter", "message": "The 'limit' parameter must be between 1 and 100", "field": "limit", "request_id": "req_8k3m9x2p" } } ``` ### HTT...
4. **[user_guide]** Save and activate **Testing Schedules:** Use the built-in schedule calculator to preview upcoming executions: ``` Next 5 executions: 1. 2026-01-24 14:00:00 UTC 2. 2026-01-25 14:00:00 UTC 3. 2026-01-26...
5. **[troubleshooting_guide]** Waiting {retry_after} seconds...") time.sleep(retry_after) continue remaining = int(response.headers.get('X-RateLimit-Remaining', 0)) if remaining < 10: print(f"Warning: Only {remaining} requests rema...

### Question 5: What are the maximum concurrent workflow executions allowed?

**Expected Answer**: Rate Limit: 100 concurrent executions per workflow, 10 executions per second

**Score**: 5/10 (PARTIAL)

**Explanation**: The retrieved content lacks a direct, precise answer to the specific question about maximum concurrent workflow executions. While chunk 5 discusses rate limiting (100 requests per minute), and chunk 3 discusses execution rates (500 per second), neither definitively states the 100 concurrent executions per workflow limit specified in the expected answer. The content is tangentially related but does not provide the exact requested information, requiring significant inference.

**Retrieved Chunks**:

1. **[user_guide]** Filter by error type, date range, or execution ID 3. Click an execution to view full details 4. Click **"Retry"** to reprocess with the same input data ### Error Notifications Get notified when workfl...
2. **[troubleshooting_guide]** Workflow Context Accumulation** Large workflow executions may accumulate state in memory. **Solution:** ```bash # Configure context cleanup cloudflow config set workflow.context.max_size_mb 100 cloudf...
3. **[architecture_overview]** - Execution start rate: 500 per second - Completion rate: 450 per second (average 2-second execution time) **Database**: - Read throughput: 50,000 queries per second (across replicas) - Write throughp...
4. **[troubleshooting_guide]** Data Validation Errors** ``` ValidationError: Field 'customer_id' is required but missing in 234 records ``` **Resolution:** ```bash # Add data quality checks cloudflow workflows update wf_9k2n4m8p1q ...
5. **[api_reference]** ## Rate Limiting To ensure fair usage and system stability, CloudFlow enforces rate limits on all API endpoints. **Default Limits:** - 100 requests per minute per authenticated user - 20 requests per ...

### Question 6: How do I add error handling to a workflow?

**Expected Answer**: Always implement error handling for external API calls and database operations. Use retry policies with exponential backoff and set up fallback actions for critical steps.

**Score**: 9/10 (PASS)

**Explanation**: The retrieved content directly addresses error handling with multiple high-quality examples. Chunk 4 specifically provides an excellent template for error handling in workflows, matching the expected answer almost perfectly. The example shows retry policies (max_attempts: 3, exponential backoff), logging errors, and handling external API calls. The content also includes recommendations like setting up fallback actions and logging errors in a database. The retrieval captures the essential points about robust error handling, including retry mechanisms, logging, and graceful error management.

**Retrieved Chunks**:

1. **[troubleshooting_guide]** exec_7h3j6k9m2n --show-bottlenecks ``` #### Solutions **1. Increase workflow timeout (if justified):** ```bash # Update workflow configuration cloudflow workflows update wf_9k2n4m8p1q \ --timeout 7200...
2. **[troubleshooting_guide]** Waiting {retry_after} seconds...") time.sleep(retry_after) continue remaining = int(response.headers.get('X-RateLimit-Remaining', 0)) if remaining < 10: print(f"Warning: Only {remaining} requests rema...
3. **[user_guide]** Save and activate **Testing Schedules:** Use the built-in schedule calculator to preview upcoming executions: ``` Next 5 executions: 1. 2026-01-24 14:00:00 UTC 2. 2026-01-25 14:00:00 UTC 3. 2026-01-26...
4. **[user_guide]** Handle Errors Gracefully Always implement error handling for external API calls and database operations: ```yaml - id: fetch_data action: http_request config: url: "https://api.example.com/data" retry...
5. **[user_guide]** # CloudFlow User Guide Welcome to CloudFlow, the modern workflow automation platform that helps you connect your apps, automate repetitive tasks, and build powerful integrations without writing code. ...

### Question 7: What database connection limits exist in CloudFlow?

**Expected Answer**: PostgreSQL is configured with a maximum of 100 connections, with connection pooling handled via PgBouncer.

**Score**: 6/10 (PARTIAL)

**Explanation**: The retrieved content contains a database connection reference in chunk 5 showing '2,000 concurrent connections', but this does not specifically match the expected PostgreSQL with 100 connection limit and PgBouncer detail. While there is tangentially related database information, the specific configuration requested is not directly present. The retrieved chunks do not confirm the PostgreSQL-specific connection configuration, making the answer incomplete but not entirely irrelevant.

**Retrieved Chunks**:

1. **[troubleshooting_guide]** Workflow Context Accumulation** Large workflow executions may accumulate state in memory. **Solution:** ```bash # Configure context cleanup cloudflow config set workflow.context.max_size_mb 100 cloudf...
2. **[architecture_overview]** Success/failure events published back to Kafka ``` **Event Schema**: ```json { "event_id": "uuid-v4", "event_type": "workflow.execution.completed", "timestamp": "2026-01-15T10:30:00.000Z", "correlatio...
3. **[deployment_guide]** create cluster -f cluster-config.yaml ``` ### Storage Configuration Install the EBS CSI driver for persistent volumes: ```bash eksctl create addon --name aws-ebs-csi-driver \ --cluster cloudflow-produ...
4. **[deployment_guide]** **Verify Service Health**: ```bash kubectl get pods -n cloudflow-prod curl https://api.cloudflow.io/health ``` **Recovery Time Objective (RTO)**: 4 hours **Recovery Point Objective (RPO)**: 24 hours -...
5. **[architecture_overview]** - Execution start rate: 500 per second - Completion rate: 450 per second (average 2-second execution time) **Database**: - Read throughput: 50,000 queries per second (across replicas) - Write throughp...

### Question 8: What are the recovery time objectives for CloudFlow?

**Expected Answer**: Recovery Point Objective (RPO): 1 hour, Recovery Time Objective (RTO): 4 hours

**Score**: 8/10 (PASS)

**Explanation**: The retrieved content contains the RTO (4 hours) directly in Chunk 3, which matches the expected answer. However, the RPO is listed as 24 hours in the same chunk, which differs from the expected 1 hour. The discrepancy prevents a perfect score. The answer is present and clear, but requires parsing through the deployment guide section to extract the specific RTO/RPO details.

**Retrieved Chunks**:

1. **[architecture_overview]** - Execution start rate: 500 per second - Completion rate: 450 per second (average 2-second execution time) **Database**: - Read throughput: 50,000 queries per second (across replicas) - Write throughp...
2. **[deployment_guide]** Configure log aggregation: ```bash # Install Fluent Bit for log forwarding helm install fluent-bit fluent/fluent-bit \ --namespace logging \ --create-namespace \ --set cloudWatch.enabled=true \ --set ...
3. **[deployment_guide]** **Verify Service Health**: ```bash kubectl get pods -n cloudflow-prod curl https://api.cloudflow.io/health ``` **Recovery Time Objective (RTO)**: 4 hours **Recovery Point Objective (RPO)**: 24 hours -...
4. **[architecture_overview]** Service (2) - PostgreSQL Primary - PostgreSQL Replica - PostgreSQL Replica - Redis Primary (2) - Redis Replica (2) - Redis Replica (2) - Kafka Broker (2) - Kafka Broker (2) - Kafka Broker (1) ``` **Au...
5. **[architecture_overview]** Resume normal operations - Recovery time: 1-3 hours depending on data volume - Data loss: None if corruption detected quickly ### Testing & Validation **DR Drill Schedule**: - Monthly: Automated failo...

### Question 9: What are the three supported authentication methods?

**Expected Answer**: CloudFlow supports three authentication methods: API Keys, OAuth 2.0, and JWT Tokens with RS256 signing algorithm

**Score**: 7/10 (PASS)

**Explanation**: The retrieved content partially answers the authentication methods question. Chunk 2 mentions 'Authentication: Basic Auth, Bearer Token, API Key, OAuth 2.0', which covers most of the expected answer. However, the specific detail about JWT Tokens with RS256 signing is missing. The chunk from the API Reference section (Chunk 3) starts to discuss authentication but is cut off, potentially hiding additional details. While the core of the answer is present, the retrieval is not complete and requires some inference to construct the full expected response.

**Retrieved Chunks**:

1. **[api_reference]** **Supported Events:** - `workflow.started` - `workflow.completed` - `workflow.failed` - `pipeline.completed` - `pipeline.failed` **Webhook Payload Example:** ```json { "event": "workflow.completed", "...
2. **[user_guide]** ### HTTP Requests Make HTTP requests to any API endpoint: **Configuration:** - **Method**: GET, POST, PUT, PATCH, DELETE, HEAD - **URL**: Full endpoint URL (supports variable interpolation) - **Header...
3. **[api_reference]** # CloudFlow API Reference Version 2.1.0 \| Last Updated: January 2026 ## Overview The CloudFlow API is a RESTful service that enables developers to programmatically manage cloud workflows, data pipelin...
4. **[troubleshooting_guide]** # CloudFlow Platform Troubleshooting Guide **Version:** 3.2.1 **Last Updated:** January 2026 **Audience:** Platform Engineers, DevOps, Support Teams ## Table of Contents 1. [Overview](#overview) 2. [A...
5. **[architecture_overview]** per API key (default: 1000 RPM) ### Secrets Management **HashiCorp Vault Integration**: - Dynamic database credentials: Generated on-demand, 1-hour TTL - Encryption keys: Transit secrets engine for en...

### Question 10: How do I troubleshoot workflow execution failures?

**Expected Answer**: Use the workflows executions get command with verbose flag to view execution details, check step-by-step breakdown, and identify bottleneck steps.

**Score**: 5/10 (PARTIAL)

**Explanation**: The retrieved content contains a troubleshooting guide section header mentioning 'Workflow Execution Failures', but does not provide specific details about how to troubleshoot workflow execution failures. None of the chunks directly answer the question about using the 'workflows executions get' command or providing a step-by-step breakdown. The content is mostly related to deployment configurations, metrics, and database optimization, which are tangentially related but not specific to workflow execution troubleshooting.

**Retrieved Chunks**:

1. **[deployment_guide]** --set prometheus.prometheusSpec.retention=30d \ --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=100Gi ``` CloudFlow exposes Prometheus metrics on port 9...
2. **[troubleshooting_guide]** # CloudFlow Platform Troubleshooting Guide **Version:** 3.2.1 **Last Updated:** January 2026 **Audience:** Platform Engineers, DevOps, Support Teams ## Table of Contents 1. [Overview](#overview) 2. [A...
3. **[deployment_guide]** Deploy PostgreSQL using the Bitnami Helm chart: ```yaml # postgres-values.yaml global: postgresql: auth: username: cloudflow database: cloudflow existingSecret: postgres-credentials image: tag: "14.10...
4. **[architecture_overview]** # CloudFlow Platform - System Architecture Overview **Document Version:** 2.3.1 **Last Updated:** January 15, 2026 **Owner:** Platform Architecture Team **Status:** Production ## Executive Summary Clo...
5. **[troubleshooting_guide]** **Implement connection pooling optimization:** ```bash # Use PgBouncer for connection pooling kubectl apply -f cloudflow-pgbouncer.yaml # Configure CloudFlow to use PgBouncer cloudflow config set db.h...

## Conclusion

⚠ **INCONCLUSIVE**: Average score of 7.2/10 falls in the inconclusive range (5.5-7.4). Results show mixed performance. More testing is needed to validate or invalidate the 88.7% benchmark claim.
