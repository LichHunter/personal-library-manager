{"original_content": "Service (2) - PostgreSQL Primary - PostgreSQL Replica - PostgreSQL Replica - Redis Primary (2) - Redis Replica (2) - Redis Replica (2) - Kafka Broker (2) - Kafka Broker (2) - Kafka Broker (1) ``` **Automatic Failover**: - Database: 30-60 seconds (automatic promotion of replica) - Redis: < 10 seconds (Sentinel-based failover) - Kafka: < 30 seconds (controller election) - Services: Kubernetes health checks with 10-second liveness probes ### Backup Strategy **Database Backups**: - Automated snapshots: Daily at 02:00 UTC - Retention: 30 days for daily, 90 days for monthly - Cross-region replication: Async replication to us-west-2 (15-minute lag) - Backup verification: Weekly automated restore test in staging environment **Backup Schedule**: ``` Daily: Full snapshot \u2192 S3 (encrypted) Hourly: WAL archives \u2192 S3 (point-in-time recovery) Weekly: Backup validation test Monthly: Long-term archive to Glacier ``` **Configuration Backups**: - Kubernetes manifests: Stored in Git (GitOps with ArgoCD) - Vault secrets: Automated snapshot every 6 hours - Kafka topic configurations: Exported daily to S3 ### Disaster Recovery Procedures **Scenario 1: Single AZ Failure** - Detection: Health checks fail for entire AZ (< 30 seconds) - Action: Traffic automatically routed to healthy AZs by ALB - Recovery time: < 5 minutes (no manual intervention) - Data loss: None (multi-AZ replication) **Scenario 2: Database Primary Failure** - Detection: Health check fails for primary database (< 30 seconds) - Action: Automatic promotion of read replica to primary - Recovery time: 30-60 seconds - Data loss: Minimal (< 1 second due to synchronous replication) **Scenario 3: Full Region Failure** - Detection: Multiple health check failures across all AZs (< 2 minutes) - Action: Manual failover to DR region (us-west-2) - Procedure: 1. Update DNS to point to DR region (TTL: 60 seconds) 2. Promote DR database replica to primary 3. Scale up DR region services to production capacity 4. Verify data consistency and integrity 5. Update monitoring dashboards - Recovery time: 2-4 hours (includes verification) - Data loss: < 1 hour (last cross-region replication) **Scenario 4: Data Corruption** - Detection: Data validation checks or user report - Action: Point-in-time recovery from WAL archives - Procedure: 1. Identify corruption time window 2. Restore from snapshot prior to corruption 3. Replay WAL logs up to corruption point 4. Verify data integrity 5.", "enhanced_content": "Kafka Broker, Redis Replica, Backup Strategy, Backup Schedule, Kubernetes health, Weekly automated, automatic promotion | Redis Replica, Kafka Broker, Sentinel, S3, Glacier\n\nService (2) - PostgreSQL Primary - PostgreSQL Replica - PostgreSQL Replica - Redis Primary (2) - Redis Replica (2) - Redis Replica (2) - Kafka Broker (2) - Kafka Broker (2) - Kafka Broker (1) ``` **Automatic Failover**: - Database: 30-60 seconds (automatic promotion of replica) - Redis: < 10 seconds (Sentinel-based failover) - Kafka: < 30 seconds (controller election) - Services: Kubernetes health checks with 10-second liveness probes ### Backup Strategy **Database Backups**: - Automated snapshots: Daily at 02:00 UTC - Retention: 30 days for daily, 90 days for monthly - Cross-region replication: Async replication to us-west-2 (15-minute lag) - Backup verification: Weekly automated restore test in staging environment **Backup Schedule**: ``` Daily: Full snapshot \u2192 S3 (encrypted) Hourly: WAL archives \u2192 S3 (point-in-time recovery) Weekly: Backup validation test Monthly: Long-term archive to Glacier ``` **Configuration Backups**: - Kubernetes manifests: Stored in Git (GitOps with ArgoCD) - Vault secrets: Automated snapshot every 6 hours - Kafka topic configurations: Exported daily to S3 ### Disaster Recovery Procedures **Scenario 1: Single AZ Failure** - Detection: Health checks fail for entire AZ (< 30 seconds) - Action: Traffic automatically routed to healthy AZs by ALB - Recovery time: < 5 minutes (no manual intervention) - Data loss: None (multi-AZ replication) **Scenario 2: Database Primary Failure** - Detection: Health check fails for primary database (< 30 seconds) - Action: Automatic promotion of read replica to primary - Recovery time: 30-60 seconds - Data loss: Minimal (< 1 second due to synchronous replication) **Scenario 3: Full Region Failure** - Detection: Multiple health check failures across all AZs (< 2 minutes) - Action: Manual failover to DR region (us-west-2) - Procedure: 1. Update DNS to point to DR region (TTL: 60 seconds) 2. Promote DR database replica to primary 3. Scale up DR region services to production capacity 4. Verify data consistency and integrity 5. Update monitoring dashboards - Recovery time: 2-4 hours (includes verification) - Data loss: < 1 hour (last cross-region replication) **Scenario 4: Data Corruption** - Detection: Data validation checks or user report - Action: Point-in-time recovery from WAL archives - Procedure: 1. Identify corruption time window 2. Restore from snapshot prior to corruption 3. Replay WAL logs up to corruption point 4. Verify data integrity 5.", "enrichment_type": "fast", "metadata": {"code_ratio": 0.23, "processing_time_ms": 76.61, "keyword_count": 10, "entity_count": 9}, "keywords": ["Kafka Broker", "Redis Replica", "Backup Strategy", "Backup Schedule", "Kubernetes health", "Weekly automated", "automatic promotion", "Multiple health", "Configuration Backups", "Exported daily"], "questions": [], "summary": "", "entities": {"PERSON": ["Redis Replica", "Kafka Broker"], "ORG": ["Sentinel", "S3", "WAL", "AZ", "ALB - Recovery"], "NORP": ["Glacier"], "GPE": ["DR"]}, "contextual_prefix": ""}