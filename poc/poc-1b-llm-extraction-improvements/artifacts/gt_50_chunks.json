{
  "metadata": {
    "started_at": "2026-02-08T21:18:37.357385",
    "random_seed": 42,
    "target_chunks": 50,
    "model": "claude-opus-4-5-20251101",
    "total_cost_usd": 3.616635000000002,
    "last_saved": "2026-02-08T21:30:25.172218",
    "completed_at": "2026-02-08T21:30:26.184918",
    "total_chunks": 50,
    "total_terms": 1154,
    "average_terms_per_chunk": 23.08
  },
  "completed_chunks": [
    {
      "chunk_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions_sec0",
      "doc_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions",
      "heading": "Introduction",
      "source_file": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions.md",
      "content": "---\ntitle: Extend the Kubernetes API with CustomResourceDefinitions\nreviewers:\n- deads2k\n- jpbetz\n- liggitt\n- roycaihw\n- sttts\ncontent_type: task\nmin-kubernetes-server-version: 1.16\nweight: 20\n---\n\n<!-- overview -->\nThis page shows how to install a\n[custom resource](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\ninto the Kubernetes API by creating a\n[CustomResourceDefinition](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#customresourcedefinition-v1-apiextensions-k8s-io).",
      "terms": [
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core Kubernetes component that serves as the primary interface for cluster operations and resource management."
        },
        {
          "term": "CustomResourceDefinitions",
          "tier": 1,
          "reasoning": "Named Kubernetes API object used to extend the API with custom resources."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Singular form of the API object for defining custom resources in Kubernetes."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Domain concept referring to user-defined extensions to the Kubernetes API."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually important for Kubernetes extension."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform that is the subject of this documentation."
        },
        {
          "term": "kubernetes-server-version",
          "tier": 2,
          "reasoning": "Technical metadata indicating minimum Kubernetes server version compatibility."
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Domain concept referring to the mechanism for extending Kubernetes API capabilities."
        },
        {
          "term": "apiextensions-k8s-io",
          "tier": 1,
          "reasoning": "Named API group in Kubernetes that handles API extension resources like CRDs."
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "API version indicator denoting stable API version in Kubernetes."
        },
        {
          "term": "1.16",
          "tier": 3,
          "reasoning": "Specific Kubernetes version number indicating minimum compatibility requirement."
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T21:18:44.587066",
      "elapsed_time": 7.229344844818115
    },
    {
      "chunk_id": "concepts_workloads_management_sec10",
      "doc_id": "concepts_workloads_management",
      "heading": "In-place updates of resources",
      "source_file": "concepts_workloads_management.md",
      "content": "Sometimes it's necessary to make narrow, non-disruptive updates to resources you've created.\n\n### kubectl apply\n\nIt is suggested to maintain a set of configuration files in source control\n(see [configuration as code](https://martinfowler.com/bliki/InfrastructureAsCode.html)),\nso that they can be maintained and versioned along with the code for the resources they configure.\nThen, you can use [`kubectl apply`](/docs/reference/kubectl/generated/kubectl_apply/)\nto push your configuration changes to the cluster.\n\nThis command will compare the version of the configuration that you're pushing with the previous\nversion and apply the changes you've made, without overwriting any automated changes to properties\nyou haven't specified.\n\n```shell\nkubectl apply -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml\n```\n\n```none\ndeployment.apps/my-nginx configured\n```\n\nTo learn more about the underlying mechanism, read [server-side apply](/docs/reference/using-api/server-side-apply/).\n\n### kubectl edit\n\nAlternatively, you may also update resources with [`kubectl edit`](/docs/reference/kubectl/generated/kubectl_edit/):\n\n```shell\nkubectl edit deployment/my-nginx\n```\n\nThis is equivalent to first `get` the resource, edit it in text editor, and then `apply` the\nresource with the updated version:\n\n```shell\nkubectl get deployment my-nginx -o yaml > /tmp/nginx.yaml\nvi /tmp/nginx.yaml",
      "terms": [
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for applying configuration changes to cluster resources."
        },
        {
          "term": "kubectl edit",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for editing resources directly."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line tool referenced throughout the documentation."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object/resource type shown in examples (deployment.apps/my-nginx, deployment/my-nginx)."
        },
        {
          "term": "my-nginx",
          "tier": 1,
          "reasoning": "Specific named deployment resource used in the examples."
        },
        {
          "term": "nginx-deployment.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file name referenced in the kubectl apply example."
        },
        {
          "term": "deployment.apps",
          "tier": 1,
          "reasoning": "Kubernetes API group and resource type shown in command output."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes objects that can be created and managed."
        },
        {
          "term": "configuration files",
          "tier": 2,
          "reasoning": "Technical concept for files containing resource definitions and settings."
        },
        {
          "term": "source control",
          "tier": 2,
          "reasoning": "Technical concept for version control systems used to manage configuration."
        },
        {
          "term": "configuration as code",
          "tier": 2,
          "reasoning": "Infrastructure/DevOps concept explicitly referenced with link to Martin Fowler's definition."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "configuration changes",
          "tier": 2,
          "reasoning": "Technical concept describing modifications to resource definitions."
        },
        {
          "term": "server-side apply",
          "tier": 2,
          "reasoning": "Kubernetes-specific mechanism for applying configuration changes mentioned as underlying mechanism."
        },
        {
          "term": "automated changes",
          "tier": 2,
          "reasoning": "Technical concept referring to system-generated modifications to resource properties."
        },
        {
          "term": "properties",
          "tier": 2,
          "reasoning": "Technical term for attributes/fields of Kubernetes resources."
        },
        {
          "term": "text editor",
          "tier": 3,
          "reasoning": "General technical tool referenced in the kubectl edit workflow."
        },
        {
          "term": "yaml",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes configuration files, shown in -o yaml flag."
        },
        {
          "term": "get",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for retrieving resource information."
        },
        {
          "term": "apply",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for applying configuration, used both as command and concept."
        },
        {
          "term": "-o yaml",
          "tier": 2,
          "reasoning": "kubectl output format flag for YAML serialization."
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Technical concept referring to configuration versions being compared during apply."
        },
        {
          "term": "versioned",
          "tier": 3,
          "reasoning": "Technical concept describing configuration files maintained with version history."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Technical context indicator for command-line examples."
        },
        {
          "term": "configured",
          "tier": 2,
          "reasoning": "Kubernetes command output status indicating successful configuration update."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:18:59.331028",
      "elapsed_time": 13.743110179901123
    },
    {
      "chunk_id": "concepts_extend-kubernetes_operator_sec7",
      "doc_id": "concepts_extend-kubernetes_operator",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "concepts_extend-kubernetes_operator.md",
      "content": "* Read the {{< glossary_tooltip text=\"CNCF\" term_id=\"cncf\" >}}\n  [Operator White Paper](https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md).\n* Learn more about [Custom Resources](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\n* Find ready-made operators on [OperatorHub.io](https://operatorhub.io/) to suit your use case\n* [Publish](https://operatorhub.io/) your operator for other people to use\n* Read [CoreOS' original article](https://web.archive.org/web/20170129131616/https://coreos.com/blog/introducing-operators.html)\n  that introduced the operator pattern (this is an archived version of the original article).\n* Read an [article](https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps)\n  from Google Cloud about best practices for building operators",
      "terms": [
        {
          "term": "CNCF",
          "tier": 1,
          "reasoning": "Cloud Native Computing Foundation - a specific organization and proper noun in the cloud-native ecosystem"
        },
        {
          "term": "Operator",
          "tier": 1,
          "reasoning": "A Kubernetes-specific pattern and resource type for managing applications"
        },
        {
          "term": "operator",
          "tier": 1,
          "reasoning": "Appears in lowercase form throughout the text referring to the Kubernetes operator pattern"
        },
        {
          "term": "operators",
          "tier": 1,
          "reasoning": "Plural form of the Kubernetes operator pattern, used multiple times in the chunk"
        },
        {
          "term": "Operator White Paper",
          "tier": 1,
          "reasoning": "A specific CNCF document about the operator pattern"
        },
        {
          "term": "Custom Resources",
          "tier": 1,
          "reasoning": "A Kubernetes API extension mechanism, capitalized as a proper concept"
        },
        {
          "term": "OperatorHub.io",
          "tier": 1,
          "reasoning": "A specific platform/registry for finding and publishing Kubernetes operators"
        },
        {
          "term": "CoreOS",
          "tier": 1,
          "reasoning": "A specific company/organization that introduced the operator pattern"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform, referenced in URLs and context"
        },
        {
          "term": "operator pattern",
          "tier": 2,
          "reasoning": "A specific architectural pattern in Kubernetes for application management"
        },
        {
          "term": "stateful apps",
          "tier": 2,
          "reasoning": "Applications that maintain state, a key concept in Kubernetes application management"
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Kubernetes API extension mechanism referenced in the URL path"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core concept in container orchestration, appears in Google Cloud URL"
        },
        {
          "term": "best practices",
          "tier": 3,
          "reasoning": "Technical guidance term used in the context of building operators"
        },
        {
          "term": "Google Cloud",
          "tier": 1,
          "reasoning": "A specific cloud provider mentioned as source of operator best practices"
        },
        {
          "term": "Publish",
          "tier": 3,
          "reasoning": "Action term in context of distributing operators to OperatorHub"
        },
        {
          "term": "tag-app-delivery",
          "tier": 2,
          "reasoning": "CNCF Technical Advisory Group for application delivery, referenced in path"
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:19:11.530532",
      "elapsed_time": 11.198503732681274
    },
    {
      "chunk_id": "reference_glossary_sysctl_sec0",
      "doc_id": "reference_glossary_sysctl",
      "heading": "Introduction",
      "source_file": "reference_glossary_sysctl.md",
      "content": "---\ntitle: sysctl\nid: sysctl\ndate: 2019-02-12\nfull_link: /docs/tasks/administer-cluster/sysctl-cluster/\nshort_description: >\n  An interface for getting and setting Unix kernel parameters\n\naka:\ntags:\n- tool\n---\n `sysctl` is a semi-standardized interface for reading or changing the\n attributes of the running Unix kernel.\n\n<!--more-->\n\nOn Unix-like systems, `sysctl` is both the name of the tool that administrators\nuse to view and modify these settings, and also the system call that the tool\nuses.\n\n{{< glossary_tooltip text=\"Container\" term_id=\"container\" >}} runtimes and\nnetwork plugins may rely on `sysctl` values being set a certain way.",
      "terms": [
        {
          "term": "sysctl",
          "tier": 1,
          "reasoning": "Named Unix tool and system call for kernel parameter management, the primary subject of this documentation."
        },
        {
          "term": "Unix kernel",
          "tier": 2,
          "reasoning": "Core operating system component whose parameters sysctl manages."
        },
        {
          "term": "kernel parameters",
          "tier": 2,
          "reasoning": "Technical concept referring to configurable settings of the Unix kernel."
        },
        {
          "term": "Unix kernel parameters",
          "tier": 2,
          "reasoning": "Compound term describing the specific settings that sysctl reads and modifies."
        },
        {
          "term": "Unix-like systems",
          "tier": 3,
          "reasoning": "Category of operating systems where sysctl operates."
        },
        {
          "term": "system call",
          "tier": 2,
          "reasoning": "Technical concept describing the programmatic interface sysctl uses to interact with the kernel."
        },
        {
          "term": "Container",
          "tier": 2,
          "reasoning": "Core Kubernetes/infrastructure concept; container runtimes depend on sysctl values."
        },
        {
          "term": "network plugins",
          "tier": 2,
          "reasoning": "Infrastructure components that may depend on specific sysctl configurations."
        },
        {
          "term": "interface",
          "tier": 3,
          "reasoning": "Technical term describing sysctl's role as a standardized access method."
        },
        {
          "term": "running",
          "tier": 3,
          "reasoning": "Technical context indicating the kernel is active/executing."
        },
        {
          "term": "attributes",
          "tier": 3,
          "reasoning": "Technical term for the kernel properties that can be read or modified."
        },
        {
          "term": "tool",
          "tier": 3,
          "reasoning": "Explicitly tagged as a tool in the metadata; describes sysctl's classification."
        },
        {
          "term": "administrators",
          "tier": 3,
          "reasoning": "Role-based term for users who manage sysctl settings."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Referenced in the documentation path; core Kubernetes infrastructure concept."
        },
        {
          "term": "administer-cluster",
          "tier": 2,
          "reasoning": "Task category indicating cluster administration context for sysctl usage."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:19:22.297958",
      "elapsed_time": 9.766122341156006
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec18",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`TCPTransport`     {#apiserver-k8s-io-v1beta1-TCPTransport}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [Transport](#apiserver-k8s-io-v1beta1-Transport)\n\n\n<p>TCPTransport provides the information to connect to konnectivity server via TCP</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>URL is the location of the konnectivity server to connect to.\nAs an example it might be &quot;https://127.0.0.1:8131&quot;</p>\n</td>\n</tr>\n<tr><td><code>tlsConfig</code><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-TLSConfig\"><code>TLSConfig</code></a>\n</td>\n<td>\n   <p>TLSConfig is the config needed to use TLS when connecting to konnectivity server</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Transport",
          "tier": 1,
          "reasoning": "Kubernetes API object type referenced in the documentation for network transport configuration."
        },
        {
          "term": "TCPTransport",
          "tier": 1,
          "reasoning": "Specific Kubernetes API resource type that provides TCP connection configuration to konnectivity server."
        },
        {
          "term": "konnectivity server",
          "tier": 1,
          "reasoning": "Named Kubernetes infrastructure component for network connectivity between control plane and nodes."
        },
        {
          "term": "TLSConfig",
          "tier": 1,
          "reasoning": "Kubernetes API object type for TLS configuration settings."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-Transport",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the Transport resource."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-TLSConfig",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the TLSConfig resource."
        },
        {
          "term": "TCP",
          "tier": 2,
          "reasoning": "Network protocol used for transport layer communication to konnectivity server."
        },
        {
          "term": "TLS",
          "tier": 2,
          "reasoning": "Transport Layer Security protocol for encrypted connections to konnectivity server."
        },
        {
          "term": "url",
          "tier": 2,
          "reasoning": "Configuration field specifying the location/address of the konnectivity server."
        },
        {
          "term": "tlsConfig",
          "tier": 2,
          "reasoning": "Configuration field name for TLS settings in TCPTransport."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "API version indicating beta maturity level of the Kubernetes API."
        },
        {
          "term": "apiserver",
          "tier": 2,
          "reasoning": "Part of the API group name, referring to the Kubernetes API server component."
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Protocol shown in the example URL for secure connection to konnectivity server."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing configuration parameters in the API object schema."
        },
        {
          "term": "connect",
          "tier": 3,
          "reasoning": "Technical action describing establishing network connection to konnectivity server."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:19:33.223246",
      "elapsed_time": 9.92405080795288
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec24",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`UserValidationRule`     {#apiserver-config-k8s-io-v1-UserValidationRule}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>UserValidationRule provides the configuration for a single user info validation rule.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>expression</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>expression represents the expression which will be evaluated by CEL.\nMust return true for the validation to pass.</p>\n<p>CEL expressions have access to the contents of UserInfo, organized into CEL variable:</p>\n<ul>\n<li>'user' - authentication.k8s.io/v1, Kind=UserInfo object\nRefer to https://github.com/kubernetes/api/blob/release-1.28/authentication/v1/types.go#L105-L122 for the definition.\nAPI documentation: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#userinfo-v1-authentication-k8s-io</li>\n</ul>\n<p>Documentation on CEL: https://kubernetes.io/docs/reference/using-api/cel/</p>\n</td>\n</tr>\n<tr><td><code>message</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>message customizes the returned error message when rule returns false.\nmessage is a literal string.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration."
        },
        {
          "term": "UserValidationRule",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration object for user info validation rules."
        },
        {
          "term": "UserInfo",
          "tier": 1,
          "reasoning": "Named Kubernetes API object representing authenticated user information."
        },
        {
          "term": "CEL",
          "tier": 2,
          "reasoning": "Common Expression Language - domain-specific language used for validation expressions in Kubernetes."
        },
        {
          "term": "expression",
          "tier": 2,
          "reasoning": "Technical field name representing the CEL expression to be evaluated for validation."
        },
        {
          "term": "validation",
          "tier": 2,
          "reasoning": "Domain concept referring to the process of verifying user information meets requirements."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Security concept for verifying identity, referenced in the API group path."
        },
        {
          "term": "authentication.k8s.io/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for authentication-related resources."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - general technical term used in context of Kubernetes API."
        },
        {
          "term": "CEL variable",
          "tier": 2,
          "reasoning": "Technical concept referring to variables accessible within CEL expressions."
        },
        {
          "term": "CEL expressions",
          "tier": 2,
          "reasoning": "Technical concept for expressions written in Common Expression Language."
        },
        {
          "term": "user",
          "tier": 2,
          "reasoning": "CEL variable name providing access to UserInfo object in validation context."
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Technical field name for customizing error messages when validation fails."
        },
        {
          "term": "error message",
          "tier": 3,
          "reasoning": "Technical concept for messages returned when validation rules fail."
        },
        {
          "term": "literal string",
          "tier": 3,
          "reasoning": "Technical term describing the type of value the message field accepts."
        },
        {
          "term": "rule",
          "tier": 2,
          "reasoning": "Domain concept referring to a single validation condition to be evaluated."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API configuration group reference for apiserver configuration."
        },
        {
          "term": "Kind",
          "tier": 2,
          "reasoning": "Kubernetes API concept identifying the type of resource object."
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API documentation and specification."
        },
        {
          "term": "release-1.28",
          "tier": 2,
          "reasoning": "Kubernetes version reference indicating specific API version compatibility."
        },
        {
          "term": "v1.28",
          "tier": 2,
          "reasoning": "Kubernetes version number referenced in documentation links."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T21:19:48.131367",
      "elapsed_time": 13.906741857528687
    },
    {
      "chunk_id": "reference_access-authn-authz_validating-admission-policy_sec0",
      "doc_id": "reference_access-authn-authz_validating-admission-policy",
      "heading": "Introduction",
      "source_file": "reference_access-authn-authz_validating-admission-policy.md",
      "content": "---\nreviewers:\n- liggitt\n- jpbetz\n- cici37\ntitle: Validating Admission Policy\ncontent_type: concept\n---\n\n<!-- overview -->\n\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.30\" >}}\n\nThis page provides an overview of Validating Admission Policy.\n\n\n<!-- body -->",
      "terms": [
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource and the primary subject of this documentation page."
        },
        {
          "term": "Admission Policy",
          "tier": 2,
          "reasoning": "Domain concept referring to policies that control admission of resources to the cluster."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating the feature has reached production-ready status in Kubernetes."
        },
        {
          "term": "v1.30",
          "tier": 3,
          "reasoning": "Specific Kubernetes version identifier indicating when the feature became stable."
        },
        {
          "term": "feature-state",
          "tier": 3,
          "reasoning": "Kubernetes documentation concept indicating the maturity level of a feature."
        }
      ],
      "term_count": 5,
      "generated_at": "2026-02-08T21:19:53.521722",
      "elapsed_time": 4.388874530792236
    },
    {
      "chunk_id": "concepts_workloads_management_sec0",
      "doc_id": "concepts_workloads_management",
      "heading": "Introduction",
      "source_file": "concepts_workloads_management.md",
      "content": "---\ntitle: Managing Workloads\ncontent_type: concept\nreviewers:\n- janetkuo\nweight: 40\n---\n\n<!-- overview -->\n\nYou've deployed your application and exposed it via a Service. Now what? Kubernetes provides a\nnumber of tools to help you manage your application deployment, including scaling and updating.\n\n<!-- body -->",
      "terms": [
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to applications running on the cluster, appears in title 'Managing Workloads'"
        },
        {
          "term": "Managing Workloads",
          "tier": 2,
          "reasoning": "Kubernetes operational concept describing the lifecycle management of applications"
        },
        {
          "term": "application",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context referring to containerized workloads deployed on the cluster"
        },
        {
          "term": "deployed",
          "tier": 2,
          "reasoning": "Technical process term describing the act of running applications on Kubernetes"
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource that exposes applications, capitalized indicating the specific K8s resource type"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary platform/proper noun this documentation is about"
        },
        {
          "term": "application deployment",
          "tier": 2,
          "reasoning": "Domain concept referring to the process and state of running applications on Kubernetes"
        },
        {
          "term": "scaling",
          "tier": 2,
          "reasoning": "Core Kubernetes operational concept for adjusting the number of replicas/resources"
        },
        {
          "term": "updating",
          "tier": 2,
          "reasoning": "Technical process term for modifying deployed applications, relates to rolling updates and deployments"
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Domain concept referring to the act of deploying or the state of deployed applications"
        },
        {
          "term": "exposed",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context meaning making an application accessible via networking/Service"
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T21:20:02.612850",
      "elapsed_time": 8.089533567428589
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "How apply calculates differences and merges changes",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "{{< caution >}}\nA *patch* is an update operation that is scoped to specific fields of an object\ninstead of the entire object. This enables updating only a specific set of fields\non an object without reading the object first.\n{{< /caution >}}\n\nWhen `kubectl apply` updates the live configuration for an object,\nit does so by sending a patch request to the API server. The\npatch defines updates scoped to specific fields of the live object\nconfiguration. The `kubectl apply` command calculates this patch request\nusing the configuration file, the live configuration, and the\n`last-applied-configuration` annotation stored in the live configuration.\n\n### Merge patch calculation\n\nThe `kubectl apply` command writes the contents of the configuration file to the\n`kubectl.kubernetes.io/last-applied-configuration` annotation. This\nis used to identify fields that have been removed from the configuration\nfile and need to be cleared from the live configuration. Here are the steps used\nto calculate which fields should be deleted or set:\n\n1. Calculate the fields to delete. These are the fields present in\n   `last-applied-configuration` and missing from the configuration file.\n2. Calculate the fields to add or set. These are the fields present in\n   the configuration file whose values don't match the live configuration.\n\nHere's an example. Suppose this is the configuration file for a Deployment object:\n\n{{% code_sample file=\"application/update_deployment.yaml\" %}}\n\nAlso, suppose this is the live configuration for the same Deployment object:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # note that the annotation does not contain replicas\n    # because it was not updated through apply\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"minReadySeconds\":5,\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.14.2\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n  # ...\nspec:\n  replicas: 2 # written by scale\n  # ...\n  minReadySeconds: 5\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n      # ...\n```\n\nHere are the merge calculations that would be performed by `kubectl apply`:\n\n1. Calculate the fields to delete by reading values from\n   `last-applied-configuration` and comparing them to values in the\n   configuration file.\n   Clear fields explicitly set to null in the local object configuration file\n   regardless of whether they appear in the `last-applied-configuration`.\n   In this example, `minReadySeconds` appears in the\n   `last-applied-configuration` annotation, but does not appear in the configuration file.\n   **Action:** Clear `minReadySeconds` from the live configuration.\n2. Calculate the fields to set by reading values from the configuration\n   file and comparing them to values in the live configuration. In this example,\n   the value of `image` in the configuration file does not match\n   the value in the live configuration. **Action:** Set the value of `image` in the live configuration.\n3. Set the `last-applied-configuration` annotation to match the value\n   of the configuration file.\n4. Merge the results from 1, 2, 3 into a single patch request to the API server.\n\nHere is the live configuration that is the result of the merge:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # The annotation contains the updated image to nginx 1.16.1,\n    # but does not contain the updated replicas to 2\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.16.1\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n    # ...\nspec:\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  replicas: 2 # Set by `kubectl scale`.  Ignored by `kubectl apply`.\n  # minReadySeconds cleared by `kubectl apply`\n  # ...\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.16.1 # Set by `kubectl apply`\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n        # ...\n      # ...\n    # ...\n  # ...\n```\n\n### How different types of fields are merged\n\nHow a particular field in a configuration file is merged with\nthe live configuration depends on the\ntype of the field. There are several types of fields:\n\n- *primitive*: A field of type string, integer, or boolean.\n  For example, `image` and `replicas` are primitive fields. **Action:** Replace.\n\n- *map*, also called *object*: A field of type map or a complex type that contains subfields. For example, `labels`,\n  `annotations`,`spec` and `metadata` are all maps. **Action:** Merge elements or subfields.\n\n- *list*: A field containing a list of items that can be either primitive types or maps.\n  For example, `containers`, `ports`, and `args` are lists. **Action:** Varies.\n\nWhen `kubectl apply` updates a map or list field, it typically does\nnot replace the entire field, but instead updates the individual subelements.\nFor instance, when merging the `spec` on a Deployment, the entire `spec` is\nnot replaced. Instead the subfields of `spec`, such as `replicas`, are compared\nand merged.\n\n### Merging changes to primitive fields\n\nPrimitive fields are replaced or cleared.\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Field in object configuration file  | Field in live object configuration | Field in last-applied-configuration | Action                                    |\n|-------------------------------------|------------------------------------|-------------------------------------|-------------------------------------------|\n| Yes                                 | Yes                                | -                                   | Set live to configuration file value.  |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.           |\n| No                                  | -                                  | Yes                                 | Clear from live configuration.            |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.             |\n\n### Merging changes to map fields\n\nFields that represent maps are merged by comparing each of the subfields or elements of the map:\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Key in object configuration file    | Key in live object configuration   | Field in last-applied-configuration | Action                           |\n|-------------------------------------|------------------------------------|-------------------------------------|----------------------------------|\n| Yes                                 | Yes                                | -                                   | Compare sub fields values.        |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.  |\n| No                                  | -                                  | Yes                                 | Delete from live configuration.   |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.     |\n\n### Merging changes for fields of type list\n\nMerging changes to a list uses one of three strategies:\n\n* Replace the list if all its elements are primitives.\n* Merge individual elements in a list of complex elements.\n* Merge a list of primitive elements.\n\nThe choice of strategy is made on a per-field basis.\n\n#### Replace the list if all its elements are primitives\n\nTreat the list the same as a primitive field. Replace or delete the\nentire list. This preserves ordering.\n\n**Example:** Use `kubectl apply` to update the `args` field of a Container in a Pod. This sets\nthe value of `args` in the live configuration to the value in the configuration file.\nAny `args` elements that had previously been added to the live configuration are lost.\nThe order of the `args` elements defined in the configuration file is\nretained in the live configuration.\n\n```yaml",
      "terms": [
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Core technical concept describing an update operation scoped to specific fields of an object"
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for applying configuration changes to Kubernetes objects"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool referenced throughout the documentation"
        },
        {
          "term": "live configuration",
          "tier": 2,
          "reasoning": "Domain concept referring to the current state of an object in the cluster"
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes component that receives patch requests"
        },
        {
          "term": "patch request",
          "tier": 2,
          "reasoning": "Technical concept describing the type of request sent to update specific fields"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Domain concept referring to the local YAML/JSON file defining desired state"
        },
        {
          "term": "last-applied-configuration",
          "tier": 1,
          "reasoning": "Specific Kubernetes annotation used to track previously applied configuration"
        },
        {
          "term": "kubectl.kubernetes.io/last-applied-configuration",
          "tier": 1,
          "reasoning": "Full annotation key used by kubectl apply to store configuration state"
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching arbitrary non-identifying metadata to objects"
        },
        {
          "term": "Merge patch calculation",
          "tier": 2,
          "reasoning": "Specific process/algorithm used by kubectl apply to determine changes"
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource type shown in the example"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Kubernetes domain term for API resources/entities"
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term referring to specific properties within a Kubernetes object specification"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployment resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the type of resource"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes object section containing identifying information and annotations"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes object section defining the desired state specification"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment field specifying the number of pod instances"
        },
        {
          "term": "minReadySeconds",
          "tier": 2,
          "reasoning": "Deployment spec field controlling minimum ready time before considering pod available"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field used to identify which pods belong to a resource"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Selector type that matches pods based on label equality"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within a Deployment"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata used for identifying and selecting objects"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod spec field defining the container specifications"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container spec field specifying the container image to run"
        },
        {
          "term": "nginx:1.14.2",
          "tier": 3,
          "reasoning": "Specific container image version used in the example"
        },
        {
          "term": "nginx:1.16.1",
          "tier": 3,
          "reasoning": "Updated container image version referenced in the merge result"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Container spec field defining exposed ports"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Port specification field for container network ports"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for logical resource isolation, referenced in metadata"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "Default Kubernetes namespace referenced in the example"
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes operation for adjusting replica count, mentioned as source of replicas value"
        },
        {
          "term": "null",
          "tier": 3,
          "reasoning": "Technical value used to explicitly clear fields in configuration"
        },
        {
          "term": "merge",
          "tier": 2,
          "reasoning": "Technical process of combining patch calculations into a single request"
        },
        {
          "term": "update operation",
          "tier": 2,
          "reasoning": "Technical concept describing the type of change being made to objects"
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:20:24.771097",
      "elapsed_time": 21.156017780303955
    },
    {
      "chunk_id": "tasks_administer-cluster_topology-manager_sec3",
      "doc_id": "tasks_administer-cluster_topology-manager",
      "heading": "Topology manager scopes and policies",
      "source_file": "tasks_administer-cluster_topology-manager.md",
      "content": "The Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
      "terms": [
        {
          "term": "Topology Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for resource alignment across NUMA nodes."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object and workload unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the fundamental Kubernetes workload unit, referenced in 'pod' scope."
        },
        {
          "term": "QoS classes",
          "tier": 2,
          "reasoning": "Quality of Service classification system for Pods in Kubernetes."
        },
        {
          "term": "Hint Provider",
          "tier": 1,
          "reasoning": "Named component that provides topology hints for resource alignment."
        },
        {
          "term": "topology hints",
          "tier": 2,
          "reasoning": "Domain concept describing hints used for NUMA-aware resource placement."
        },
        {
          "term": "scope",
          "tier": 2,
          "reasoning": "Configuration option defining granularity of resource alignment in Topology Manager."
        },
        {
          "term": "policy",
          "tier": 2,
          "reasoning": "Configuration option defining the alignment strategy used by Topology Manager."
        },
        {
          "term": "resource alignment",
          "tier": 2,
          "reasoning": "Technical process of aligning resources across topology domains."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing the unit of compute within a Pod."
        },
        {
          "term": "best-effort",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for resource alignment."
        },
        {
          "term": "restricted",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for stricter resource alignment."
        },
        {
          "term": "single-numa-node",
          "tier": 2,
          "reasoning": "Named Topology Manager policy requiring all resources from a single NUMA node."
        },
        {
          "term": "CPU resources",
          "tier": 2,
          "reasoning": "Domain concept for compute resources managed by CPU Manager."
        },
        {
          "term": "CPU Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for CPU resource management on nodes."
        },
        {
          "term": "CPU Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for CPU Manager behavior."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "System resource type managed by Memory Manager."
        },
        {
          "term": "hugepages",
          "tier": 2,
          "reasoning": "Linux memory feature for large memory pages, managed by Memory Manager."
        },
        {
          "term": "Memory Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for memory resource management."
        },
        {
          "term": "Memory Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for Memory Manager behavior."
        },
        {
          "term": "Pod spec",
          "tier": 2,
          "reasoning": "The specification section of a Pod definition containing resource requests."
        },
        {
          "term": "requested resources",
          "tier": 2,
          "reasoning": "Domain concept for resources explicitly requested in Pod specifications."
        },
        {
          "term": "CPU Management Policies",
          "tier": 2,
          "reasoning": "Named feature for controlling CPU allocation behavior on nodes."
        },
        {
          "term": "scopes",
          "tier": 2,
          "reasoning": "Plural form of scope configuration options for Topology Manager."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Plural form of policy configuration options for Topology Manager."
        },
        {
          "term": "resources",
          "tier": 3,
          "reasoning": "General term for compute resources (CPU, memory) in Kubernetes context."
        }
      ],
      "term_count": 27,
      "generated_at": "2026-02-08T21:20:39.745274",
      "elapsed_time": 13.97149658203125
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec1",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Terminology",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "For clarity, this guide defines the following terms:\n\n* Node: A worker machine in Kubernetes, part of a cluster.\n* Cluster: A set of Nodes that run containerized applications managed by Kubernetes.\n  For this example, and in most common Kubernetes deployments, nodes in the cluster\n  are not part of the public internet.\n* Edge router: A router that enforces the firewall policy for your cluster. This\n  could be a gateway managed by a cloud provider or a physical piece of hardware.\n* Cluster network: A set of links, logical or physical, that facilitate communication\n  within a cluster according to the Kubernetes [networking model](/docs/concepts/cluster-administration/networking/).\n* Service: A Kubernetes {{< glossary_tooltip term_id=\"service\" >}} that identifies\n  a set of Pods using {{< glossary_tooltip text=\"label\" term_id=\"label\" >}} selectors.\n  Unless mentioned otherwise, Services are assumed to have virtual IPs only routable within the cluster network.",
      "terms": [
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Core Kubernetes resource representing a worker machine in the cluster."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "containerized applications",
          "tier": 2,
          "reasoning": "Domain concept describing applications packaged in containers."
        },
        {
          "term": "Edge router",
          "tier": 2,
          "reasoning": "Network infrastructure component that enforces firewall policy at cluster boundary."
        },
        {
          "term": "router",
          "tier": 3,
          "reasoning": "General networking term with specific meaning in cluster context."
        },
        {
          "term": "firewall policy",
          "tier": 2,
          "reasoning": "Security concept governing network traffic rules for the cluster."
        },
        {
          "term": "gateway",
          "tier": 2,
          "reasoning": "Network component that can serve as edge router, managed by cloud provider."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Infrastructure concept referring to managed cloud services hosting Kubernetes."
        },
        {
          "term": "Cluster network",
          "tier": 2,
          "reasoning": "Kubernetes networking concept describing internal cluster communication links."
        },
        {
          "term": "networking model",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept defining how network communication works."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that identifies a set of Pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing the smallest deployable unit."
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes concept for key-value pairs used to organize and select resources."
        },
        {
          "term": "selectors",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for identifying resources based on labels."
        },
        {
          "term": "virtual IPs",
          "tier": 2,
          "reasoning": "Networking concept for IP addresses assigned to Services for internal routing."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Infrastructure term describing the role of a Node in the cluster."
        },
        {
          "term": "public internet",
          "tier": 3,
          "reasoning": "Networking context term distinguishing internal cluster network from external access."
        },
        {
          "term": "nodes in the cluster",
          "tier": 2,
          "reasoning": "Phrase describing the relationship between Nodes and Cluster architecture."
        },
        {
          "term": "Nodes",
          "tier": 1,
          "reasoning": "Plural form of the core Kubernetes Node resource."
        },
        {
          "term": "cluster network",
          "tier": 2,
          "reasoning": "Lowercase variant appearing in context of Service routing scope."
        },
        {
          "term": "hardware",
          "tier": 3,
          "reasoning": "Infrastructure term describing physical edge router implementation."
        },
        {
          "term": "communication",
          "tier": 3,
          "reasoning": "Technical term in context of cluster networking and inter-node connectivity."
        },
        {
          "term": "routable",
          "tier": 3,
          "reasoning": "Networking term describing accessibility of virtual IPs within cluster."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:20:54.878118",
      "elapsed_time": 14.129920721054077
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec19",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "You might already have removed the next set",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "kubectl delete configmaps/special-config configmaps/env-config\nkubectl delete configmap -l 'game-config in (config-4,config-5)'\n```\n\nRemove the `kustomization.yaml` file that you used to generate the ConfigMap:\n\n```bash\nrm kustomization.yaml\n```\n\nIf you created a directory `configure-pod-container` and no longer need it, you should remove that too,\nor move it into the trash can / deleted files location.\n\n```bash\nrm -r configure-pod-container\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used for cluster management and resource operations."
        },
        {
          "term": "configmaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing non-confidential configuration data as key-value pairs."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API resource referenced in the context of generation and deletion."
        },
        {
          "term": "special-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "env-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "config-4",
          "tier": 1,
          "reasoning": "Named configuration resource referenced in label selector."
        },
        {
          "term": "config-5",
          "tier": 1,
          "reasoning": "Named configuration resource referenced in label selector."
        },
        {
          "term": "game-config",
          "tier": 1,
          "reasoning": "Label key used for selecting ConfigMap resources."
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Kustomize configuration file used to generate Kubernetes resources."
        },
        {
          "term": "configure-pod-container",
          "tier": 2,
          "reasoning": "Directory name related to pod and container configuration workflow."
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation/command for removing resources from the cluster."
        },
        {
          "term": "kubectl delete",
          "tier": 2,
          "reasoning": "Compound command for deleting Kubernetes resources."
        },
        {
          "term": "-l",
          "tier": 3,
          "reasoning": "kubectl flag for label selector filtering of resources."
        },
        {
          "term": "rm",
          "tier": 3,
          "reasoning": "Unix/Linux command for removing files, used in cleanup operations."
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Unix shell environment in which the commands are executed."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "File system concept relevant to organizing Kubernetes configuration files."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource referenced in directory name 'configure-pod-container'."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept referenced in directory name 'configure-pod-container'."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T21:21:07.120881",
      "elapsed_time": 11.239883422851562
    },
    {
      "chunk_id": "reference_node_node-status_sec6",
      "doc_id": "reference_node_node-status",
      "heading": "Declared features {#declaredfeatures}",
      "source_file": "reference_node_node-status.md",
      "content": "{{< feature-state feature_gate_name=\"NodeDeclaredFeatures\" >}}\n\nThis field lists specific Kubernetes features that are currently enabled on the\nnode's kubelet via [feature gates](/docs/reference/command-line-tools-reference/feature-gates/).\nThe features are reported by the kubelet as a list of strings in the\n`.status.declaredFeatures` field of the Node object.\n\nThis field is intended for newer features under active development; features that\nhave graduated and no longer require a feature gate are considered baseline and\nare not declared in this field. This reflects the enablement of Kubernetes\nfeatures, not the underlying operating system or kernel capabilities of the node.\n\nSee [Node Declared Features](/docs/concepts/scheduling-eviction/node-declared-features/)\nfor more details.",
      "terms": [
        {
          "term": "NodeDeclaredFeatures",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature gate name that controls node feature declaration functionality."
        },
        {
          "term": "feature_gate_name",
          "tier": 2,
          "reasoning": "Technical parameter reference for specifying feature gate identifiers in Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform this documentation describes."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine in the cluster."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages pod lifecycle."
        },
        {
          "term": "feature gates",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": ".status.declaredFeatures",
          "tier": 1,
          "reasoning": "Specific API field path in the Node object for reporting enabled features."
        },
        {
          "term": "Node object",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a node in the cluster."
        },
        {
          "term": "features",
          "tier": 2,
          "reasoning": "Technical concept referring to specific Kubernetes capabilities that can be enabled or disabled."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type used to represent the feature list in the API field."
        },
        {
          "term": "active development",
          "tier": 2,
          "reasoning": "Technical lifecycle stage indicating features still being developed."
        },
        {
          "term": "graduated",
          "tier": 2,
          "reasoning": "Kubernetes feature lifecycle term indicating a feature has reached stable status."
        },
        {
          "term": "baseline",
          "tier": 2,
          "reasoning": "Technical term describing features that are standard and no longer require explicit enablement."
        },
        {
          "term": "enablement",
          "tier": 2,
          "reasoning": "Technical process of activating features in Kubernetes."
        },
        {
          "term": "operating system",
          "tier": 3,
          "reasoning": "Underlying system software context distinguished from Kubernetes features."
        },
        {
          "term": "kernel",
          "tier": 3,
          "reasoning": "Core OS component whose capabilities are distinguished from Kubernetes features."
        },
        {
          "term": "capabilities",
          "tier": 2,
          "reasoning": "Technical term for system or feature abilities in the context of nodes."
        },
        {
          "term": "Node Declared Features",
          "tier": 1,
          "reasoning": "Named Kubernetes concept/feature for declaring node capabilities."
        },
        {
          "term": "scheduling-eviction",
          "tier": 2,
          "reasoning": "Kubernetes domain area related to pod placement and removal decisions."
        },
        {
          "term": "field",
          "tier": 3,
          "reasoning": "API object attribute terminology used in Kubernetes resource specifications."
        },
        {
          "term": "list",
          "tier": 3,
          "reasoning": "Data structure type used to represent multiple features in the API."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API object section containing runtime state information."
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T21:21:21.004748",
      "elapsed_time": 12.881136417388916
    },
    {
      "chunk_id": "concepts_policy__index_sec3",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using ValidatingAdmissionPolicy",
      "source_file": "concepts_policy__index.md",
      "content": "Validating admission policies allow configurable validation checks to be executed in the API server using the Common Expression Language (CEL). For example, a `ValidatingAdmissionPolicy` can be used to disallow use of the `latest` image tag.\n\nA `ValidatingAdmissionPolicy` operates on an API request and can be used to block, audit, and warn users about non-compliant configurations.\n\nDetails on the `ValidatingAdmissionPolicy` API, with examples, are documented in a dedicated section:\n* [Validating Admission Policy](/docs/reference/access-authn-authz/validating-admission-policy/)",
      "terms": [
        {
          "term": "ValidatingAdmissionPolicy",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for configurable validation checks in the API server."
        },
        {
          "term": "Validating admission policies",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for admission control validation."
        },
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Proper noun reference to the Kubernetes API resource as it appears in documentation link."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that processes API requests."
        },
        {
          "term": "Common Expression Language",
          "tier": 2,
          "reasoning": "Domain-specific language used for writing validation expressions in Kubernetes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Acronym for Common Expression Language, a technical standard used in Kubernetes validation."
        },
        {
          "term": "API request",
          "tier": 2,
          "reasoning": "Technical concept referring to requests made to the Kubernetes API server."
        },
        {
          "term": "validation checks",
          "tier": 2,
          "reasoning": "Domain concept describing the verification process for admission policies."
        },
        {
          "term": "image tag",
          "tier": 2,
          "reasoning": "Container image concept referring to version identifiers for container images."
        },
        {
          "term": "latest",
          "tier": 2,
          "reasoning": "Specific image tag value with technical significance in container best practices."
        },
        {
          "term": "block",
          "tier": 2,
          "reasoning": "Admission control action that prevents non-compliant configurations."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Admission control action for logging policy violations without blocking."
        },
        {
          "term": "warn",
          "tier": 2,
          "reasoning": "Admission control action that alerts users about non-compliant configurations."
        },
        {
          "term": "non-compliant configurations",
          "tier": 2,
          "reasoning": "Domain concept describing configurations that violate defined policies."
        },
        {
          "term": "configurable validation",
          "tier": 2,
          "reasoning": "Technical concept describing customizable validation mechanisms."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually relevant to Kubernetes."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container concept referring to container images used in Kubernetes workloads."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:21:32.742429",
      "elapsed_time": 10.733844995498657
    },
    {
      "chunk_id": "concepts_policy__index_sec1",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using API objects",
      "source_file": "concepts_policy__index.md",
      "content": "Some API objects act as policies. Here are some examples:\n* [NetworkPolicies](/docs/concepts/services-networking/network-policies/) can be used to restrict ingress and egress traffic for a workload.\n* [LimitRanges](/docs/concepts/policy/limit-range/) manage resource allocation constraints across different object kinds.\n* [ResourceQuotas](/docs/concepts/policy/resource-quotas/) limit resource consumption for a {{< glossary_tooltip text=\"namespace\" term_id=\"namespace\" >}}.",
      "terms": [
        {
          "term": "API objects",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the persistent entities in the system that represent cluster state."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Domain concept describing API objects that enforce rules and constraints on cluster behavior."
        },
        {
          "term": "NetworkPolicies",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource for controlling network traffic flow."
        },
        {
          "term": "ingress",
          "tier": 2,
          "reasoning": "Networking concept referring to incoming traffic to a workload."
        },
        {
          "term": "egress",
          "tier": 2,
          "reasoning": "Networking concept referring to outgoing traffic from a workload."
        },
        {
          "term": "traffic",
          "tier": 3,
          "reasoning": "Networking term describing data flow in the context of network policies."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running on the cluster."
        },
        {
          "term": "LimitRanges",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource for managing resource allocation constraints."
        },
        {
          "term": "resource allocation",
          "tier": 2,
          "reasoning": "Domain concept describing how compute resources are distributed to objects."
        },
        {
          "term": "constraints",
          "tier": 2,
          "reasoning": "Technical term describing limitations or rules applied to resources."
        },
        {
          "term": "object kinds",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the types/categories of API objects."
        },
        {
          "term": "ResourceQuotas",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource for limiting resource consumption per namespace."
        },
        {
          "term": "resource consumption",
          "tier": 2,
          "reasoning": "Domain concept describing the usage of compute resources by workloads."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for logical partitioning of cluster resources."
        },
        {
          "term": "ingress and egress traffic",
          "tier": 2,
          "reasoning": "Compound networking concept describing bidirectional network flow control."
        },
        {
          "term": "restrict",
          "tier": 3,
          "reasoning": "Technical action term in the context of policy enforcement on traffic."
        },
        {
          "term": "limit",
          "tier": 3,
          "reasoning": "Technical action term describing resource consumption boundaries."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:21:43.099081",
      "elapsed_time": 9.353590726852417
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec7",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Types of Ingress",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "### Ingress backed by a single Service {#single-service-ingress}\n\nThere are existing Kubernetes concepts that allow you to expose a single Service\n(see [alternatives](#alternatives)). You can also do this with an Ingress by specifying a\n*default backend* with no rules.\n\n{{% code_sample file=\"service/networking/test-ingress.yaml\" %}}\n\nIf you create it using `kubectl apply -f` you should be able to view the state\nof the Ingress you added:\n\n```bash\nkubectl get ingress test-ingress\n```\n\n```\nNAME           CLASS         HOSTS   ADDRESS         PORTS   AGE\ntest-ingress   external-lb   *       203.0.113.123   80      59s\n```\n\nWhere `203.0.113.123` is the IP allocated by the Ingress controller to satisfy\nthis Ingress.\n\n{{< note >}}\nIngress controllers and load balancers may take a minute or two to allocate an IP address.\nUntil that time, you often see the address listed as `<pending>`.\n{{< /note >}}\n\n### Simple fanout\n\nA fanout configuration routes traffic from a single IP address to more than one Service,\nbased on the HTTP URI being requested. An Ingress allows you to keep the number of load balancers\ndown to a minimum. For example, a setup like:\n\n{{< figure src=\"/docs/images/ingressFanOut.svg\" alt=\"ingress-fanout-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Fan Out\" link=\"https://mermaid.live/edit#pako:eNqNUslOwzAQ_RXLvYCUhMQpUFzUUzkgcUBwbHpw4klr4diR7bCo8O8k2FFbFomLPZq3jP00O1xpDpjijWHtFt09zAuFUCUFKHey8vf6NE7QrdoYsDZumGIb4Oi6NAskNeOoZJKpCgxK4oXwrFVgRyi7nCVXWZKRPMlysv5yD6Q4Xryf1Vq_WzDPooJs9egLNDbolKTpT03JzKgh3zWEztJZ0Niu9L-qZGcdmAMfj4cxvWmreba613z9C0B-AMQD-V_AdA-A4j5QZu0SatRKJhSqhZR0wjmPrDP6CeikrutQxy-Cuy2dtq9RpaU2dJKm6fzI5Glmg0VOLio4_5dLjx27hFSC015KJ2VZHtuQvY2fuHcaE43G0MaCREOow_FV5cMxHZ5-oPX75UM5avuXhXuOI9yAaZjg_aLuBl6B3RYaKDDtSw4166QrcKE-emrXcubghgunDaY1kxYizDqnH99UhakzHYykpWD9hjS--fEJoIELqQ\" >}}\n\nIt would require an Ingress such as:\n\n{{% code_sample file=\"service/networking/simple-fanout-example.yaml\" %}}\n\nWhen you create the Ingress with `kubectl apply -f`:\n\n```shell\nkubectl describe ingress simple-fanout-example\n```\n\n```\nName:             simple-fanout-example\nNamespace:        default\nAddress:          178.91.123.132\nDefault backend:  default-http-backend:80 (10.8.2.3:8080)\nRules:\n  Host         Path  Backends\n  ----         ----  --------\n  foo.bar.com\n               /foo   service1:4200 (10.8.0.90:4200)\n               /bar   service2:8080 (10.8.0.91:8080)\nEvents:\n  Type     Reason  Age                From                     Message\n  ----     ------  ----               ----                     -------\n  Normal   ADD     22s                loadbalancer-controller  default/test\n```\n\nThe Ingress controller provisions an implementation-specific load balancer\nthat satisfies the Ingress, as long as the Services (`service1`, `service2`) exist.\nWhen it has done so, you can see the address of the load balancer at the\nAddress field.\n\n{{< note >}}\nDepending on the [Ingress controller](/docs/concepts/services-networking/ingress-controllers/)\nyou are using, you may need to create a default-http-backend\n[Service](/docs/concepts/services-networking/service/).\n{{< /note >}}\n\n### Name based virtual hosting\n\nName-based virtual hosts support routing HTTP traffic to multiple host names at the same IP address.\n\n{{< figure src=\"/docs/images/ingressNameBased.svg\" alt=\"ingress-namebase-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Name Based Virtual hosting\" link=\"https://mermaid.live/edit#pako:eNqNkl9PwyAUxb8KYS-atM1Kp05m9qSJJj4Y97jugcLtRqTQAPVPdN_dVlq3qUt8gZt7zvkBN7xjbgRgiteW1Rt0_zjLNUJcSdD-ZBn21WmcoDu9tuBcXDHN1iDQVWHnSBkmUMEU0xwsSuK5DK5l745QejFNLtMkJVmSZmT1Re9NcTz_uDXOU1QakxTMJtxUHw7ss-SQLhehQEODTsdH4l20Q-zFyc84-Y67pghv5apxHuweMuj9eS2_NiJdPhix-kMgvwQShOyYMNkJoEUYM3PuGkpUKyY1KqVSdCSEiJy35gnoqCzLvo5fpPAbOqlfI26UsXQ0Ho9nB5CnqesRGTnncPYvSqsdUvqp9KRdlI6KojjEkB0mnLgjDRONhqENBYm6oXbLV5V1y6S7-l42_LowlIN2uFm_twqOcAW2YlK0H_i9c-bYb6CCHNO2FFCyRvkc53rbWptaMA83QnpjMS2ZchBh1nizeNMcU28bGEzXkrV_pArN7Sc0rBTu\" >}}\n\nThe following Ingress tells the backing load balancer to route requests based on\nthe [Host header](https://tools.ietf.org/html/rfc7230#section-5.4).\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress.yaml\" %}}\n\nIf you create an Ingress resource without any hosts defined in the rules, then any\nweb traffic to the IP address of your Ingress controller can be matched without a name based\nvirtual host being required.\n\nFor example, the following Ingress routes traffic\nrequested for `first.bar.com` to `service1`, `second.bar.com` to `service2`,\nand any traffic whose request host header doesn't match `first.bar.com`\nand `second.bar.com` to `service3`.\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress-no-third-host.yaml\" %}}\n\n### TLS\n\nYou can secure an Ingress by specifying a {{< glossary_tooltip term_id=\"secret\" >}}\nthat contains a TLS private key and certificate. The Ingress resource only\nsupports a single TLS port, 443, and assumes TLS termination at the ingress point\n(traffic to the Service and its Pods is in plaintext).\nIf the TLS configuration section in an Ingress specifies different hosts, they are\nmultiplexed on the same port according to the hostname specified through the\nSNI TLS extension (provided the Ingress controller supports SNI). The TLS secret\nmust contain keys named `tls.crt` and `tls.key` that contain the certificate\nand private key to use for TLS. For example:\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: testsecret-tls\n  namespace: default\ndata:\n  tls.crt: base64 encoded cert\n  tls.key: base64 encoded key\ntype: kubernetes.io/tls\n```\n\nReferencing this secret in an Ingress tells the Ingress controller to\nsecure the channel from the client to the load balancer using TLS. You need to make\nsure the TLS secret you created came from a certificate that contains a Common\nName (CN), also known as a Fully Qualified Domain Name (FQDN) for `https-example.foo.com`.\n\n{{< note >}}\nKeep in mind that TLS will not work on the default rule because the\ncertificates would have to be issued for all the possible sub-domains. Therefore,\n`hosts` in the `tls` section need to explicitly match the `host` in the `rules`\nsection.\n{{< /note >}}\n\n{{% code_sample file=\"service/networking/tls-example-ingress.yaml\" %}}\n\n{{< note >}}\nThere is a gap between TLS features supported by various ingress controllers.\nYou should refer to the documentation for the ingress controller(s) you've chosen to\nunderstand how TLS works in your environment.\n{{< /note >}}\n\n### Load balancing {#load-balancing}\n\nAn Ingress controller is bootstrapped with some load balancing policy settings\nthat it applies to all Ingress, such as the load balancing algorithm, backend\nweight scheme, and others. More advanced load balancing concepts\n(e.g. persistent sessions, dynamic weights) are not yet exposed through the\nIngress. You can instead get these features through the load balancer used for\na Service.\n\nIt's also worth noting that even though health checks are not exposed directly\nthrough the Ingress, there exist parallel concepts in Kubernetes such as\n[readiness probes](/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)\nthat allow you to achieve the same end result. Please review the controller\nspecific documentation to see how they handle health checks.",
      "terms": [
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing external access to services in a cluster."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object that exposes applications running on pods."
        },
        {
          "term": "default backend",
          "tier": 2,
          "reasoning": "Ingress configuration concept specifying where traffic goes when no rules match."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used for cluster management."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for applying configuration to resources."
        },
        {
          "term": "kubectl get ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for retrieving Ingress resources."
        },
        {
          "term": "kubectl describe ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for detailed Ingress information."
        },
        {
          "term": "Ingress controller",
          "tier": 1,
          "reasoning": "Kubernetes component that implements Ingress resources and manages load balancing."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Infrastructure component that distributes network traffic across services."
        },
        {
          "term": "IP address",
          "tier": 3,
          "reasoning": "Network addressing concept essential for Ingress routing."
        },
        {
          "term": "fanout",
          "tier": 2,
          "reasoning": "Ingress routing pattern that distributes traffic from single IP to multiple services."
        },
        {
          "term": "HTTP URI",
          "tier": 3,
          "reasoning": "Protocol-specific identifier used for routing decisions in Ingress."
        },
        {
          "term": "Name based virtual hosting",
          "tier": 2,
          "reasoning": "Ingress routing technique supporting multiple hostnames at same IP address."
        },
        {
          "term": "HTTP traffic",
          "tier": 3,
          "reasoning": "Network protocol traffic type that Ingress manages."
        },
        {
          "term": "host names",
          "tier": 3,
          "reasoning": "DNS names used for virtual host routing in Ingress."
        },
        {
          "term": "Namespace",
          "tier": 1,
          "reasoning": "Kubernetes resource for organizing and isolating cluster resources."
        },
        {
          "term": "Address",
          "tier": 2,
          "reasoning": "Ingress field showing the allocated external IP or hostname."
        },
        {
          "term": "default-http-backend",
          "tier": 1,
          "reasoning": "Specific Service name required by some Ingress controllers for fallback routing."
        },
        {
          "term": "Rules",
          "tier": 2,
          "reasoning": "Ingress configuration element defining routing paths and backends."
        },
        {
          "term": "Host",
          "tier": 2,
          "reasoning": "Ingress rule field specifying the hostname for routing."
        },
        {
          "term": "Path",
          "tier": 2,
          "reasoning": "Ingress rule field specifying URL path for routing decisions."
        },
        {
          "term": "Backends",
          "tier": 2,
          "reasoning": "Ingress configuration specifying target Services for routed traffic."
        },
        {
          "term": "PORTS",
          "tier": 2,
          "reasoning": "Network ports exposed by the Ingress resource."
        },
        {
          "term": "CLASS",
          "tier": 2,
          "reasoning": "Ingress field specifying which Ingress controller should handle the resource."
        },
        {
          "term": "external-lb",
          "tier": 1,
          "reasoning": "Specific Ingress class name shown in the example output."
        },
        {
          "term": "test-ingress",
          "tier": 1,
          "reasoning": "Specific Ingress resource name used in the documentation example."
        },
        {
          "term": "simple-fanout-example",
          "tier": 1,
          "reasoning": "Specific Ingress resource name demonstrating fanout configuration."
        },
        {
          "term": "foo.bar.com",
          "tier": 3,
          "reasoning": "Example hostname used in Ingress routing rules."
        },
        {
          "term": "service1",
          "tier": 1,
          "reasoning": "Example Service name used as Ingress backend target."
        },
        {
          "term": "service2",
          "tier": 1,
          "reasoning": "Example Service name used as Ingress backend target."
        },
        {
          "term": "loadbalancer-controller",
          "tier": 1,
          "reasoning": "Component name shown in Events that manages load balancer provisioning."
        },
        {
          "term": "Events",
          "tier": 2,
          "reasoning": "Kubernetes resource field showing cluster events related to the resource."
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "Default Kubernetes namespace where resources are created."
        }
      ],
      "term_count": 33,
      "generated_at": "2026-02-08T21:22:02.817691",
      "elapsed_time": 18.714346170425415
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec19",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Key`     {#apiserver-config-k8s-io-v1-Key}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [AESConfiguration](#apiserver-config-k8s-io-v1-AESConfiguration)\n\n- [SecretboxConfiguration](#apiserver-config-k8s-io-v1-SecretboxConfiguration)\n\n\n<p>Key contains name and secret of the provided key for a transformer.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>name</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>name is the name of the key to be used while storing data to disk.</p>\n</td>\n</tr>\n<tr><td><code>secret</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>secret is the actual key, encoded in base64.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for AES encryption settings."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for Secretbox encryption settings."
        },
        {
          "term": "Key",
          "tier": 1,
          "reasoning": "Named API object/struct that contains name and secret for a transformer."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept referring to a component that transforms/encrypts data in Kubernetes."
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Required field identifier used for storing data to disk in the Key configuration."
        },
        {
          "term": "secret",
          "tier": 2,
          "reasoning": "Technical term referring to the actual encryption key value in Kubernetes context."
        },
        {
          "term": "base64",
          "tier": 3,
          "reasoning": "Encoding standard used for representing the secret key data."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the configuration fields."
        },
        {
          "term": "apiserver-config-k8s-io-v1-AESConfiguration",
          "tier": 1,
          "reasoning": "Full API group/version/kind reference for AESConfiguration resource."
        },
        {
          "term": "apiserver-config-k8s-io-v1-SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Full API group/version/kind reference for SecretboxConfiguration resource."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing configuration structure elements in API documentation."
        },
        {
          "term": "disk",
          "tier": 3,
          "reasoning": "Storage medium referenced in context of data persistence."
        },
        {
          "term": "key",
          "tier": 2,
          "reasoning": "Cryptographic concept referring to the encryption key used for data protection."
        },
        {
          "term": "encoded",
          "tier": 3,
          "reasoning": "Technical process term describing how the secret is represented."
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T21:22:12.605177",
      "elapsed_time": 8.783101320266724
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec6",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`AnonymousAuthCondition`     {#apiserver-k8s-io-v1beta1-AnonymousAuthCondition}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [AnonymousAuthConfig](#apiserver-k8s-io-v1beta1-AnonymousAuthConfig)\n\n\n<p>AnonymousAuthCondition describes the condition under which anonymous auth\nshould be enabled.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>path</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>Path for which anonymous auth is enabled.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for anonymous authentication settings."
        },
        {
          "term": "AnonymousAuthCondition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type that describes conditions for anonymous authentication."
        },
        {
          "term": "apiserver-k8s-io-v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version identifier for the apiserver configuration."
        },
        {
          "term": "anonymous auth",
          "tier": 2,
          "reasoning": "Domain concept referring to authentication mechanism allowing unauthenticated access."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Technical field specifying the URL path for which anonymous authentication applies."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing a configuration property in the API object schema."
        },
        {
          "term": "condition",
          "tier": 2,
          "reasoning": "Domain concept describing a state or requirement that must be met for a feature to be enabled."
        },
        {
          "term": "enabled",
          "tier": 3,
          "reasoning": "Technical state indicating a feature or configuration is active."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the path field in the API schema."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "API version indicating beta maturity level in Kubernetes API versioning scheme."
        }
      ],
      "term_count": 10,
      "generated_at": "2026-02-08T21:22:21.730841",
      "elapsed_time": 8.122105598449707
    },
    {
      "chunk_id": "tasks_administer-cluster_coredns_sec3",
      "doc_id": "tasks_administer-cluster_coredns",
      "heading": "Upgrading CoreDNS",
      "source_file": "tasks_administer-cluster_coredns.md",
      "content": "You can check the version of CoreDNS that kubeadm installs for each version of\nKubernetes in the page\n[CoreDNS version in Kubernetes](https://github.com/coredns/deployment/blob/master/kubernetes/CoreDNS-k8s_version.md).\n\nCoreDNS can be upgraded manually in case you want to only upgrade CoreDNS\nor use your own custom image.\nThere is a helpful [guideline and walkthrough](https://github.com/coredns/deployment/blob/master/kubernetes/Upgrading_CoreDNS.md)\navailable to ensure a smooth upgrade.\nMake sure the existing CoreDNS configuration (\"Corefile\") is retained when\nupgrading your cluster.\n\nIf you are upgrading your cluster using the `kubeadm` tool, `kubeadm`\ncan take care of retaining the existing CoreDNS configuration automatically.",
      "terms": [
        {
          "term": "CoreDNS",
          "tier": 1,
          "reasoning": "Core Kubernetes DNS component and proper noun, a specific infrastructure component for cluster DNS resolution."
        },
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster bootstrapping and management."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform this documentation describes."
        },
        {
          "term": "Corefile",
          "tier": 1,
          "reasoning": "CoreDNS-specific configuration file name, a proper noun for the configuration resource."
        },
        {
          "term": "CoreDNS configuration",
          "tier": 2,
          "reasoning": "Domain concept referring to the settings and rules that define CoreDNS behavior."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process for updating Kubernetes components to newer versions."
        },
        {
          "term": "upgrading",
          "tier": 2,
          "reasoning": "Technical process term as used in context of cluster and component version management."
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Technical concept for software release identification, critical for compatibility management."
        },
        {
          "term": "custom image",
          "tier": 2,
          "reasoning": "Container/Kubernetes concept referring to user-provided container images rather than defaults."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept, fundamental to Kubernetes workload deployment."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical concept for system settings and parameters that control component behavior."
        },
        {
          "term": "manually",
          "tier": 3,
          "reasoning": "Operational term indicating human-driven intervention versus automated processes."
        },
        {
          "term": "retained",
          "tier": 3,
          "reasoning": "Technical term in context of preserving configuration during upgrade operations."
        },
        {
          "term": "automatically",
          "tier": 3,
          "reasoning": "Operational term indicating tool-driven automation versus manual intervention."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:22:33.343978",
      "elapsed_time": 10.607872724533081
    },
    {
      "chunk_id": "tasks_debug_debug-application_debug-statefulset_sec1",
      "doc_id": "tasks_debug_debug-application_debug-statefulset",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_debug_debug-application_debug-statefulset.md",
      "content": "* You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with your cluster.\n* You should have a StatefulSet running that you want to investigate.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes cluster",
          "tier": 1,
          "reasoning": "Core infrastructure resource - a complete Kubernetes deployment environment"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster communication and management"
        },
        {
          "term": "command-line tool",
          "tier": 2,
          "reasoning": "Technical term describing the type of interface kubectl provides"
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/workload resource for managing stateful applications"
        },
        {
          "term": "configured",
          "tier": 3,
          "reasoning": "Technical term in context referring to proper setup of kubectl to communicate with cluster"
        }
      ],
      "term_count": 7,
      "generated_at": "2026-02-08T21:22:41.272685",
      "elapsed_time": 6.924311876296997
    },
    {
      "chunk_id": "concepts_overview_working-with-objects_annotations_sec1",
      "doc_id": "concepts_overview_working-with-objects_annotations",
      "heading": "Attaching metadata to objects",
      "source_file": "concepts_overview_working-with-objects_annotations.md",
      "content": "You can use either labels or annotations to attach metadata to Kubernetes\nobjects. Labels can be used to select objects and to find\ncollections of objects that satisfy certain conditions. In contrast, annotations\nare not used to identify and select objects. The metadata\nin an annotation can be small or large, structured or unstructured, and can\ninclude characters not permitted by labels. It is possible to use labels as \nwell as annotations in the metadata of the same object.\n\nAnnotations, like labels, are key/value maps:\n\n```json\n\"metadata\": {\n  \"annotations\": {\n    \"key1\" : \"value1\",\n    \"key2\" : \"value2\"\n  }\n}\n```\n\n{{<note>}}\nThe keys and the values in the map must be strings. In other words, you cannot use\nnumeric, boolean, list or other types for either the keys or the values.\n{{</note>}}\n\nHere are some examples of information that could be recorded in annotations:\n\n* Fields managed by a declarative configuration layer. Attaching these fields\n  as annotations distinguishes them from default values set by clients or\n  servers, and from auto-generated fields and fields set by\n  auto-sizing or auto-scaling systems.\n\n* Build, release, or image information like timestamps, release IDs, git branch,\n  PR numbers, image hashes, and registry address.\n\n* Pointers to logging, monitoring, analytics, or audit repositories.\n\n* Client library or tool information that can be used for debugging purposes:\n  for example, name, version, and build information.\n\n* User or tool/system provenance information, such as URLs of related objects\n  from other ecosystem components.\n\n* Lightweight rollout tool metadata: for example, config or checkpoints.\n\n* Phone or pager numbers of persons responsible, or directory entries that\n  specify where that information can be found, such as a team web site.\n\n* Directives from the end-user to the implementations to modify behavior or\n  engage non-standard features.\n\nInstead of using annotations, you could store this type of information in an\nexternal database or directory, but that would make it much harder to produce\nshared client libraries and tools for deployment, management, introspection,\nand the like.",
      "terms": [
        {
          "term": "labels",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for object selection and identification."
        },
        {
          "term": "annotations",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for attaching non-identifying information to objects."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform this documentation describes."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Technical concept referring to data about Kubernetes objects."
        },
        {
          "term": "objects",
          "tier": 2,
          "reasoning": "Kubernetes domain term for persistent entities in the system (Pods, Services, etc.)."
        },
        {
          "term": "key/value maps",
          "tier": 2,
          "reasoning": "Data structure concept describing how annotations and labels are stored."
        },
        {
          "term": "key/value",
          "tier": 2,
          "reasoning": "Technical data structure pattern used for metadata storage."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type constraint for annotation and label keys/values."
        },
        {
          "term": "declarative configuration layer",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept for managing desired state through configuration."
        },
        {
          "term": "clients",
          "tier": 2,
          "reasoning": "Technical term for systems or tools that interact with Kubernetes API."
        },
        {
          "term": "servers",
          "tier": 2,
          "reasoning": "Technical term for systems that serve the Kubernetes API."
        },
        {
          "term": "auto-generated fields",
          "tier": 2,
          "reasoning": "Kubernetes concept for fields automatically populated by the system."
        },
        {
          "term": "auto-sizing",
          "tier": 2,
          "reasoning": "Kubernetes operational concept for automatic resource adjustment."
        },
        {
          "term": "auto-scaling systems",
          "tier": 2,
          "reasoning": "Kubernetes systems that automatically adjust workload replicas or resources."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept central to Kubernetes workloads."
        },
        {
          "term": "release IDs",
          "tier": 3,
          "reasoning": "Deployment metadata concept for tracking software versions."
        },
        {
          "term": "git branch",
          "tier": 3,
          "reasoning": "Version control concept used in build/release metadata."
        },
        {
          "term": "PR numbers",
          "tier": 3,
          "reasoning": "Pull request identifiers used in build metadata tracking."
        },
        {
          "term": "image hashes",
          "tier": 2,
          "reasoning": "Container image identification mechanism for integrity verification."
        },
        {
          "term": "registry address",
          "tier": 2,
          "reasoning": "Container registry location for image storage and retrieval."
        },
        {
          "term": "logging",
          "tier": 2,
          "reasoning": "Observability concept for recording system events."
        },
        {
          "term": "monitoring",
          "tier": 2,
          "reasoning": "Observability concept for tracking system health and metrics."
        },
        {
          "term": "analytics",
          "tier": 2,
          "reasoning": "Data analysis concept for understanding system behavior."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Security and compliance concept for tracking system access and changes."
        },
        {
          "term": "repositories",
          "tier": 3,
          "reasoning": "Storage locations for code, logs, or other artifacts."
        },
        {
          "term": "client library",
          "tier": 2,
          "reasoning": "SDK or library for programmatic Kubernetes API interaction."
        },
        {
          "term": "debugging",
          "tier": 3,
          "reasoning": "Technical process for troubleshooting system issues."
        },
        {
          "term": "provenance information",
          "tier": 2,
          "reasoning": "Metadata concept tracking origin and history of objects."
        },
        {
          "term": "ecosystem components",
          "tier": 2,
          "reasoning": "Related tools and systems in the Kubernetes ecosystem."
        },
        {
          "term": "rollout tool",
          "tier": 2,
          "reasoning": "Deployment tooling for managing application updates."
        },
        {
          "term": "config",
          "tier": 2,
          "reasoning": "Configuration data for applications or systems."
        },
        {
          "term": "checkpoints",
          "tier": 2,
          "reasoning": "State snapshots used in rollout and recovery processes."
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Process of releasing applications to Kubernetes (also a resource type)."
        },
        {
          "term": "management",
          "tier": 2,
          "reasoning": "Operational concept for administering Kubernetes resources."
        },
        {
          "term": "introspection",
          "tier": 2,
          "reasoning": "Technical capability to examine object state and metadata."
        },
        {
          "term": "external database",
          "tier": 3,
          "reasoning": "Storage system outside Kubernetes for persistent data."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "Storage or lookup system for organizational information."
        },
        {
          "term": "shared client libraries",
          "tier": 2,
          "reasoning": "Reusable code libraries for Kubernetes API interaction."
        },
        {
          "term": "tools",
          "tier": 3,
          "reasoning": "Software utilities for Kubernetes operations and management."
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T21:23:01.485844",
      "elapsed_time": 19.20917797088623
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster_sec7",
      "doc_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster.md",
      "content": "* [Learn more about DRA](/docs/concepts/scheduling-eviction/dynamic-resource-allocation)\n* [Allocate Devices to Workloads with DRA](/docs/tasks/configure-pod-container/assign-resources/allocate-devices-dra)",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Abbreviation for Dynamic Resource Allocation, a specific Kubernetes feature/API for resource management."
        },
        {
          "term": "Dynamic Resource Allocation",
          "tier": 1,
          "reasoning": "Full name of DRA, a core Kubernetes scheduling feature for allocating resources dynamically."
        },
        {
          "term": "Devices",
          "tier": 2,
          "reasoning": "Technical term referring to hardware resources (GPUs, FPGAs, etc.) that can be allocated to workloads in Kubernetes."
        },
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Domain concept referring to applications or jobs running in a Kubernetes cluster that consume resources."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the process of assigning pods to nodes based on resource requirements."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the process of terminating pods, often due to resource constraints."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Implied by 'configure-pod-container' in the URL path; fundamental Kubernetes API object and workload unit."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Appears in 'configure-pod-container' path; core concept for isolated application runtime environments."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Appears in 'assign-resources' and 'Dynamic Resource Allocation'; refers to compute resources like CPU, memory, devices."
        },
        {
          "term": "Allocate",
          "tier": 2,
          "reasoning": "Technical process term describing the assignment of resources to workloads in the scheduling context."
        }
      ],
      "term_count": 10,
      "generated_at": "2026-02-08T21:23:11.300937",
      "elapsed_time": 8.810391187667847
    },
    {
      "chunk_id": "reference_config-api_apiserver-admission.v1_sec2",
      "doc_id": "reference_config-api_apiserver-admission.v1",
      "heading": "`AdmissionResponse`     {#admission-k8s-io-v1-AdmissionResponse}",
      "source_file": "reference_config-api_apiserver-admission.v1.md",
      "content": "**Appears in:**\n\n- [AdmissionReview](#admission-k8s-io-v1-AdmissionReview)\n\n\n<p>AdmissionResponse describes an admission response.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>uid</code> <B>[Required]</B><br/>\n<a href=\"https://pkg.go.dev/k8s.io/apimachinery/pkg/types#UID\"><code>k8s.io/apimachinery/pkg/types.UID</code></a>\n</td>\n<td>\n   <p>uid is an identifier for the individual request/response.\nThis must be copied over from the corresponding AdmissionRequest.</p>\n</td>\n</tr>\n<tr><td><code>allowed</code> <B>[Required]</B><br/>\n<code>bool</code>\n</td>\n<td>\n   <p>allowed indicates whether or not the admission request was permitted.</p>\n</td>\n</tr>\n<tr><td><code>status</code><br/>\n<a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.35/#status-v1-meta\"><code>meta/v1.Status</code></a>\n</td>\n<td>\n   <p>status is the result contains extra details into why an admission request was denied.\nThis field IS NOT consulted in any way if &quot;Allowed&quot; is &quot;true&quot;.</p>\n</td>\n</tr>\n<tr><td><code>patch</code><br/>\n<code>[]byte</code>\n</td>\n<td>\n   <p>patch is the patch body. Currently we only support &quot;JSONPatch&quot; which implements RFC 6902.</p>\n</td>\n</tr>\n<tr><td><code>patchType</code><br/>\n<a href=\"#admission-k8s-io-v1-PatchType\"><code>PatchType</code></a>\n</td>\n<td>\n   <p>patchType is the type of Patch. Currently we only allow &quot;JSONPatch&quot;.</p>\n</td>\n</tr>\n<tr><td><code>auditAnnotations</code><br/>\n<code>map[string]string</code>\n</td>\n<td>\n   <p>auditAnnotations is an unstructured key value map set by remote admission controller (e.g. error=image-blacklisted).\nMutatingAdmissionWebhook and ValidatingAdmissionWebhook admission controller will prefix the keys with\nadmission webhook name (e.g. imagepolicy.example.com/error=image-blacklisted). AuditAnnotations will be provided by\nthe admission webhook to add additional context to the audit log for this request.</p>\n</td>\n</tr>\n<tr><td><code>warnings</code><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>warnings is a list of warning messages to return to the requesting API client.\nWarning messages describe a problem the client making the API request should correct or be aware of.\nLimit warnings to 120 characters if possible.\nWarnings over 256 characters and large numbers of warnings may be truncated.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AdmissionReview",
          "tier": 1,
          "reasoning": "Kubernetes API object for admission control review requests and responses."
        },
        {
          "term": "AdmissionResponse",
          "tier": 1,
          "reasoning": "Kubernetes API object that describes an admission response structure."
        },
        {
          "term": "AdmissionRequest",
          "tier": 1,
          "reasoning": "Kubernetes API object representing an admission request that AdmissionResponse corresponds to."
        },
        {
          "term": "uid",
          "tier": 2,
          "reasoning": "Field identifier for individual request/response tracking in admission control."
        },
        {
          "term": "UID",
          "tier": 2,
          "reasoning": "Type reference from k8s.io/apimachinery for unique identifiers."
        },
        {
          "term": "k8s.io/apimachinery/pkg/types.UID",
          "tier": 1,
          "reasoning": "Full package path reference to the UID type in Kubernetes apimachinery."
        },
        {
          "term": "allowed",
          "tier": 2,
          "reasoning": "Boolean field indicating whether an admission request was permitted."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Field containing extra details about why an admission request was denied."
        },
        {
          "term": "meta/v1.Status",
          "tier": 1,
          "reasoning": "Kubernetes meta API type for status information."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Field containing the patch body for mutating admission responses."
        },
        {
          "term": "JSONPatch",
          "tier": 2,
          "reasoning": "Patch format implementing RFC 6902 for JSON document modifications."
        },
        {
          "term": "RFC 6902",
          "tier": 3,
          "reasoning": "Internet standard specification for JSON Patch operations."
        },
        {
          "term": "patchType",
          "tier": 2,
          "reasoning": "Field specifying the type of patch being applied."
        },
        {
          "term": "PatchType",
          "tier": 1,
          "reasoning": "Kubernetes admission API type for specifying patch formats."
        },
        {
          "term": "auditAnnotations",
          "tier": 2,
          "reasoning": "Field for key-value annotations added by admission controllers for audit logging."
        },
        {
          "term": "admission controller",
          "tier": 2,
          "reasoning": "Kubernetes component that intercepts requests to the API server for validation or mutation."
        },
        {
          "term": "remote admission controller",
          "tier": 2,
          "reasoning": "External admission controller that processes admission requests via webhooks."
        },
        {
          "term": "MutatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Kubernetes admission controller type that can modify objects during admission."
        },
        {
          "term": "ValidatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Kubernetes admission controller type that validates objects during admission."
        },
        {
          "term": "admission webhook",
          "tier": 2,
          "reasoning": "Webhook-based mechanism for implementing custom admission control logic."
        },
        {
          "term": "audit log",
          "tier": 2,
          "reasoning": "Kubernetes logging mechanism for recording API server requests and responses."
        },
        {
          "term": "warnings",
          "tier": 2,
          "reasoning": "Field containing warning messages returned to API clients about potential issues."
        },
        {
          "term": "API client",
          "tier": 2,
          "reasoning": "Client making requests to the Kubernetes API server."
        },
        {
          "term": "API request",
          "tier": 2,
          "reasoning": "Request made to the Kubernetes API server."
        },
        {
          "term": "admission request",
          "tier": 2,
          "reasoning": "Request processed by admission controllers before persistence."
        },
        {
          "term": "map[string]string",
          "tier": 3,
          "reasoning": "Go type representing a string-to-string map data structure."
        },
        {
          "term": "[]byte",
          "tier": 3,
          "reasoning": "Go type representing a byte slice for binary data."
        },
        {
          "term": "[]string",
          "tier": 3,
          "reasoning": "Go type representing a slice of strings."
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "Boolean data type used for the allowed field."
        },
        {
          "term": "admission-k8s-io-v1-AdmissionReview",
          "tier": 1,
          "reasoning": "API reference anchor for AdmissionReview in admission.k8s.io/v1."
        },
        {
          "term": "admission-k8s-io-v1-PatchType",
          "tier": 1,
          "reasoning": "API reference anchor for PatchType in admission.k8s.io/v1."
        }
      ],
      "term_count": 31,
      "generated_at": "2026-02-08T21:23:30.290429",
      "elapsed_time": 17.98514199256897
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec1",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "{{< version-check >}}\n\n- You are the owner of an application running on a Kubernetes cluster that requires\n  high availability.\n- You should know how to deploy [Replicated Stateless Applications](/docs/tasks/run-application/run-stateless-application-deployment/)\n  and/or [Replicated Stateful Applications](/docs/tasks/run-application/run-replicated-stateful-application/).\n- You should have read about [Pod Disruptions](/docs/concepts/workloads/pods/disruptions/).\n- You should confirm with your cluster owner or service provider that they respect\n  Pod Disruption Budgets.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes cluster",
          "tier": 1,
          "reasoning": "Core infrastructure resource - the primary container orchestration platform being discussed."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the central subject of this documentation."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental architectural concept referring to a set of nodes running containerized applications."
        },
        {
          "term": "high availability",
          "tier": 2,
          "reasoning": "Critical architectural concept describing system design for continuous operation."
        },
        {
          "term": "application",
          "tier": 2,
          "reasoning": "Domain concept referring to workloads running on the cluster."
        },
        {
          "term": "Replicated Stateless Applications",
          "tier": 1,
          "reasoning": "Specific Kubernetes workload pattern and documentation reference for applications without persistent state."
        },
        {
          "term": "Replicated Stateful Applications",
          "tier": 1,
          "reasoning": "Specific Kubernetes workload pattern for applications requiring persistent state management."
        },
        {
          "term": "Pod Disruptions",
          "tier": 1,
          "reasoning": "Core Kubernetes concept describing voluntary and involuntary interruptions to Pod availability."
        },
        {
          "term": "Pod Disruption Budgets",
          "tier": 1,
          "reasoning": "Specific Kubernetes API object (PDB) that limits disruptions to Pods during voluntary operations."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object - the smallest deployable unit in Kubernetes."
        },
        {
          "term": "owner",
          "tier": 2,
          "reasoning": "Domain concept referring to the entity responsible for managing an application or resource."
        },
        {
          "term": "cluster owner",
          "tier": 2,
          "reasoning": "Role-based concept describing the administrator responsible for cluster operations."
        },
        {
          "term": "service provider",
          "tier": 2,
          "reasoning": "Domain concept referring to managed Kubernetes service operators."
        },
        {
          "term": "deploy",
          "tier": 2,
          "reasoning": "Technical process of releasing and running applications on the cluster."
        },
        {
          "term": "Stateless Applications",
          "tier": 2,
          "reasoning": "Application architecture pattern where instances don't maintain persistent state."
        },
        {
          "term": "Stateful Applications",
          "tier": 2,
          "reasoning": "Application architecture pattern where instances maintain persistent state across restarts."
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:23:41.336265",
      "elapsed_time": 10.041298627853394
    },
    {
      "chunk_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information_sec2",
      "doc_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information",
      "heading": "Store container fields",
      "source_file": "tasks_inject-data-application_downward-api-volume-expose-pod-information.md",
      "content": "The preceding exercise, you made Pod-level fields accessible using the\ndownward API.\nIn this next exercise, you are going to pass fields that are part of the Pod\ndefinition, but taken from the specific\n[container](/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container)\nrather than from the Pod overall. Here is a manifest for a Pod that again has\njust one container:\n\n{{% code_sample file=\"pods/inject/dapi-volume-resources.yaml\" %}}\n\nIn the manifest, you can see that the Pod has a\n[`downwardAPI` volume](/docs/concepts/storage/volumes/#downwardapi),\nand that the single container in that Pod mounts the volume at `/etc/podinfo`.\n\nLook at the `items` array under `downwardAPI`. Each element of the array\ndefines a file in the downward API volume.\n\nThe first element specifies that in the container named `client-container`,\nthe value of the `limits.cpu` field in the format specified by `1m` should be\npublished as a file named `cpu_limit`. The `divisor` field is optional and has the\ndefault value of `1`. A divisor of 1 means cores for `cpu` resources, or\nbytes for `memory` resources.\n\nCreate the Pod:\n\n```shell\nkubectl apply -f https://k8s.io/examples/pods/inject/dapi-volume-resources.yaml\n```\n\nGet a shell into the container that is running in your Pod:\n\n```shell\nkubectl exec -it kubernetes-downwardapi-volume-example-2 -- sh\n```\n\nIn your shell, view the `cpu_limit` file:\n\n```shell",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and workload resource explicitly discussed throughout the chunk."
        },
        {
          "term": "downward API",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature for exposing Pod and container information to containers."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing the runtime unit within a Pod."
        },
        {
          "term": "Pod-level fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata and spec fields defined at the Pod scope."
        },
        {
          "term": "manifest",
          "tier": 2,
          "reasoning": "Technical term for the YAML/JSON file that declares Kubernetes resources."
        },
        {
          "term": "downwardAPI volume",
          "tier": 1,
          "reasoning": "Specific Kubernetes volume type that exposes Pod/container information as files."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Core Kubernetes storage concept for providing persistent or ephemeral storage to containers."
        },
        {
          "term": "client-container",
          "tier": 1,
          "reasoning": "Specific container name referenced in the example manifest."
        },
        {
          "term": "limits.cpu",
          "tier": 2,
          "reasoning": "Kubernetes resource field specifying CPU resource limits for a container."
        },
        {
          "term": "divisor",
          "tier": 2,
          "reasoning": "Technical field in downward API configuration that specifies unit conversion."
        },
        {
          "term": "cpu",
          "tier": 3,
          "reasoning": "Computing resource type managed by Kubernetes resource limits and requests."
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "Computing resource type managed by Kubernetes resource limits and requests."
        },
        {
          "term": "cores",
          "tier": 3,
          "reasoning": "Unit of CPU measurement referenced in the context of resource divisors."
        },
        {
          "term": "bytes",
          "tier": 3,
          "reasoning": "Unit of memory measurement referenced in the context of resource divisors."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for creating or updating resources declaratively."
        },
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for executing commands inside a container."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes command-line interface tool."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for interacting with containers."
        },
        {
          "term": "cpu_limit",
          "tier": 2,
          "reasoning": "Specific file name created by the downward API to expose CPU limit information."
        },
        {
          "term": "kubernetes-downwardapi-volume-example-2",
          "tier": 1,
          "reasoning": "Specific Pod name used in the example commands."
        },
        {
          "term": "1m",
          "tier": 2,
          "reasoning": "Kubernetes resource quantity format representing millicores for CPU."
        },
        {
          "term": "/etc/podinfo",
          "tier": 2,
          "reasoning": "Mount path where the downward API volume is mounted in the container."
        },
        {
          "term": "mounts",
          "tier": 2,
          "reasoning": "Technical operation of attaching a volume to a container filesystem."
        },
        {
          "term": "file",
          "tier": 3,
          "reasoning": "Filesystem object created by downward API to expose container/Pod information."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kubernetes concept for CPU and memory allocations to containers."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:23:56.619507",
      "elapsed_time": 14.2784583568573
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec10",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a deployment.yaml file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF > deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx\n        ports:\n        - containerPort: 80\nEOF",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource for managing replicated applications."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource."
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployment resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field that specifies the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section containing resource identification information."
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Kubernetes metadata field used to identify resources within a namespace."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section defining the desired state specification of a resource."
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching and selecting resources based on labels."
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector field for exact label matching to identify target pods."
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes Deployment field specifying the desired number of pod instances."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Kubernetes pod template specification embedded within a Deployment."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes pod spec field defining the container workloads to run."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core virtualization concept for isolated application runtime environments."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image reference specifying the packaged application to deploy."
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container image name referring to the NGINX web server software."
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Kubernetes container spec field for defining network port configurations."
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes field specifying the port number exposed by a container."
        },
        {
          "term": "deployment.yaml",
          "tier": 3,
          "reasoning": "Kubernetes manifest file naming convention for Deployment resources."
        },
        {
          "term": "my-nginx",
          "tier": 3,
          "reasoning": "Resource name and label value used to identify this specific Deployment and its pods."
        },
        {
          "term": "run",
          "tier": 3,
          "reasoning": "Label key used in this manifest for pod selection and identification."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T21:24:09.261500",
      "elapsed_time": 11.637039184570312
    },
    {
      "chunk_id": "reference_node_node-status_sec3",
      "doc_id": "reference_node_node-status",
      "heading": "Conditions {#condition}",
      "source_file": "reference_node_node-status.md",
      "content": "The `conditions` field describes the status of all `Running` nodes. Examples of conditions include:\n\n{{< table caption = \"Node conditions, and a description of when each condition applies.\" >}}\n| Node Condition       | Description |\n|----------------------|-------------|\n| `Ready`              | `True` if the node is healthy and ready to accept pods, `False` if the node is not healthy and is not accepting pods, and `Unknown` if the node controller has not heard from the node in the last `node-monitor-grace-period` (default is 50 seconds) |\n| `DiskPressure`       | `True` if pressure exists on the disk size\u2014that is, if the disk capacity is low; otherwise `False` |\n| `MemoryPressure`     | `True` if pressure exists on the node memory\u2014that is, if the node memory is low; otherwise `False` |\n| `PIDPressure`        | `True` if pressure exists on the processes\u2014that is, if there are too many processes on the node; otherwise `False` |\n| `NetworkUnavailable` | `True` if the network for the node is not correctly configured, otherwise `False` |\n{{< /table >}}\n\n{{< note >}}\nIf you use command-line tools to print details of a cordoned Node, the Condition includes\n`SchedulingDisabled`. `SchedulingDisabled` is not a Condition in the Kubernetes API; instead,\ncordoned nodes are marked Unschedulable in their spec.\n{{< /note >}}\n\nIn the Kubernetes API, a node's condition is represented as part of the `.status`\nof the Node resource. For example, the following JSON structure describes a healthy node:\n\n```json\n\"conditions\": [\n  {\n    \"type\": \"Ready\",\n    \"status\": \"True\",\n    \"reason\": \"KubeletReady\",\n    \"message\": \"kubelet is posting ready status\",\n    \"lastHeartbeatTime\": \"2019-06-05T18:38:35Z\",\n    \"lastTransitionTime\": \"2019-06-05T11:41:27Z\"\n  }\n]\n```\n\nWhen problems occur on nodes, the Kubernetes control plane automatically creates\n[taints](/docs/concepts/scheduling-eviction/taint-and-toleration/) that match the conditions\naffecting the node. An example of this is when the `status` of the Ready condition\nremains `Unknown` or `False` for longer than the kube-controller-manager's `NodeMonitorGracePeriod`,\nwhich defaults to 50 seconds. This will cause either an `node.kubernetes.io/unreachable` taint, for an `Unknown` status,\nor a `node.kubernetes.io/not-ready` taint, for a `False` status, to be added to the Node.\n\nThese taints affect pending pods as the scheduler takes the Node's taints into consideration when\nassigning a pod to a Node. Existing pods scheduled to the node may be evicted due to the application\nof `NoExecute` taints. Pods may also have {{< glossary_tooltip text=\"tolerations\" term_id=\"toleration\" >}} that let\nthem schedule to and continue running on a Node even though it has a specific taint.\n\nSee [Taint Based Evictions](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-based-evictions) and\n[Taint Nodes by Condition](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-nodes-by-condition)\nfor more details.",
      "terms": [
        {
          "term": "conditions",
          "tier": 2,
          "reasoning": "Domain concept describing the status field of node resources in Kubernetes API"
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "Node status state indicating operational nodes"
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing worker machines in a cluster"
        },
        {
          "term": "Node Condition",
          "tier": 2,
          "reasoning": "Specific Kubernetes concept for describing node health states"
        },
        {
          "term": "Ready",
          "tier": 1,
          "reasoning": "Named node condition type in Kubernetes API"
        },
        {
          "term": "DiskPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low disk capacity"
        },
        {
          "term": "MemoryPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low node memory"
        },
        {
          "term": "PIDPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating too many processes"
        },
        {
          "term": "NetworkUnavailable",
          "tier": 1,
          "reasoning": "Named node condition type indicating network misconfiguration"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing deployable units"
        },
        {
          "term": "node controller",
          "tier": 1,
          "reasoning": "Kubernetes control plane component managing node lifecycle"
        },
        {
          "term": "node-monitor-grace-period",
          "tier": 1,
          "reasoning": "Specific configuration parameter for node monitoring timeout"
        },
        {
          "term": "disk capacity",
          "tier": 3,
          "reasoning": "Technical term for storage space relevant to DiskPressure condition"
        },
        {
          "term": "node memory",
          "tier": 2,
          "reasoning": "Technical concept for memory resources on a node"
        },
        {
          "term": "processes",
          "tier": 3,
          "reasoning": "OS-level concept relevant to PIDPressure condition"
        },
        {
          "term": "network",
          "tier": 3,
          "reasoning": "Infrastructure concept relevant to NetworkUnavailable condition"
        },
        {
          "term": "cordoned Node",
          "tier": 2,
          "reasoning": "Kubernetes operational concept for nodes marked to prevent new pod scheduling"
        },
        {
          "term": "SchedulingDisabled",
          "tier": 1,
          "reasoning": "Condition label shown in CLI for cordoned nodes"
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for interacting with Kubernetes resources"
        },
        {
          "term": "Unschedulable",
          "tier": 2,
          "reasoning": "Node spec field marking nodes as not accepting new pods"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes resource specification field"
        },
        {
          "term": ".status",
          "tier": 2,
          "reasoning": "Kubernetes resource status field containing runtime state"
        },
        {
          "term": "Node resource",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a cluster node"
        },
        {
          "term": "type",
          "tier": 2,
          "reasoning": "Field in condition structure identifying the condition kind"
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Field in condition structure indicating True/False/Unknown state"
        },
        {
          "term": "reason",
          "tier": 2,
          "reasoning": "Field in condition structure providing machine-readable cause"
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Field in condition structure providing human-readable description"
        },
        {
          "term": "lastHeartbeatTime",
          "tier": 2,
          "reasoning": "Condition field tracking last node heartbeat timestamp"
        },
        {
          "term": "lastTransitionTime",
          "tier": 2,
          "reasoning": "Condition field tracking when condition last changed"
        },
        {
          "term": "KubeletReady",
          "tier": 1,
          "reasoning": "Specific reason value indicating kubelet is operational"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component"
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept for cluster management components"
        },
        {
          "term": "taints",
          "tier": 2,
          "reasoning": "Kubernetes scheduling mechanism to repel pods from nodes"
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component running controllers"
        },
        {
          "term": "NodeMonitorGracePeriod",
          "tier": 1,
          "reasoning": "Specific kube-controller-manager configuration parameter"
        },
        {
          "term": "node.kubernetes.io/unreachable",
          "tier": 1,
          "reasoning": "Specific taint key applied when node status is Unknown"
        },
        {
          "term": "node.kubernetes.io/not-ready",
          "tier": 1,
          "reasoning": "Specific taint key applied when node status is False"
        },
        {
          "term": "Unknown",
          "tier": 2,
          "reasoning": "Condition status value indicating uncertain node state"
        },
        {
          "term": "False",
          "tier": 2,
          "reasoning": "Condition status value indicating negative/unhealthy state"
        },
        {
          "term": "True",
          "tier": 2,
          "reasoning": "Condition status value indicating positive/healthy state"
        },
        {
          "term": "pending pods",
          "tier": 2,
          "reasoning": "Pods waiting to be scheduled to a node"
        },
        {
          "term": "scheduler",
          "tier": 1,
          "reasoning": "Kubernetes control plane component assigning pods to nodes"
        },
        {
          "term": "evicted",
          "tier": 2,
          "reasoning": "Process of removing pods from nodes"
        },
        {
          "term": "NoExecute",
          "tier": 1,
          "reasoning": "Taint effect that evicts existing pods and prevents new scheduling"
        },
        {
          "term": "tolerations",
          "tier": 2,
          "reasoning": "Pod specification allowing scheduling despite node taints"
        },
        {
          "term": "Taint Based Evictions",
          "tier": 2,
          "reasoning": "Kubernetes concept for evicting pods based on node taints"
        },
        {
          "term": "Taint Nodes by Condition",
          "tier": 2,
          "reasoning": "Kubernetes feature automatically tainting nodes based on conditions"
        }
      ],
      "term_count": 47,
      "generated_at": "2026-02-08T21:24:33.478951",
      "elapsed_time": 23.211890935897827
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec21",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`ProviderConfiguration`     {#apiserver-config-k8s-io-v1-ProviderConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [ResourceConfiguration](#apiserver-config-k8s-io-v1-ResourceConfiguration)\n\n\n<p>ProviderConfiguration stores the provided configuration for an encryption provider.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>aesgcm</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aesgcm is the configuration for the AES-GCM transformer.</p>\n</td>\n</tr>\n<tr><td><code>aescbc</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aescbc is the configuration for the AES-CBC transformer.</p>\n</td>\n</tr>\n<tr><td><code>secretbox</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-SecretboxConfiguration\"><code>SecretboxConfiguration</code></a>\n</td>\n<td>\n   <p>secretbox is the configuration for the Secretbox based transformer.</p>\n</td>\n</tr>\n<tr><td><code>identity</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-IdentityConfiguration\"><code>IdentityConfiguration</code></a>\n</td>\n<td>\n   <p>identity is the (empty) configuration for the identity transformer.</p>\n</td>\n</tr>\n<tr><td><code>kms</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-KMSConfiguration\"><code>KMSConfiguration</code></a>\n</td>\n<td>\n   <p>kms contains the name, cache size and path to configuration file for a KMS based envelope transformer.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "ResourceConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for resource encryption settings."
        },
        {
          "term": "ProviderConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration structure that stores encryption provider settings."
        },
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for AES encryption transformers."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for Secretbox-based encryption."
        },
        {
          "term": "IdentityConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for the identity transformer."
        },
        {
          "term": "KMSConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for KMS-based envelope encryption."
        },
        {
          "term": "encryption provider",
          "tier": 2,
          "reasoning": "Domain concept referring to a pluggable encryption mechanism for Kubernetes secrets at rest."
        },
        {
          "term": "aesgcm",
          "tier": 2,
          "reasoning": "Configuration field name for AES-GCM encryption transformer in Kubernetes."
        },
        {
          "term": "AES-GCM transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using AES in Galois/Counter Mode for data encryption."
        },
        {
          "term": "aescbc",
          "tier": 2,
          "reasoning": "Configuration field name for AES-CBC encryption transformer in Kubernetes."
        },
        {
          "term": "AES-CBC transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using AES in Cipher Block Chaining mode."
        },
        {
          "term": "secretbox",
          "tier": 2,
          "reasoning": "Configuration field for Secretbox-based encryption transformer."
        },
        {
          "term": "Secretbox based transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using NaCl Secretbox authenticated encryption."
        },
        {
          "term": "identity",
          "tier": 2,
          "reasoning": "Configuration field for the identity transformer that performs no encryption."
        },
        {
          "term": "identity transformer",
          "tier": 2,
          "reasoning": "A transformer that passes data through unchanged without encryption."
        },
        {
          "term": "kms",
          "tier": 2,
          "reasoning": "Configuration field for Key Management Service based encryption."
        },
        {
          "term": "KMS based envelope transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using external KMS for envelope encryption of data."
        },
        {
          "term": "envelope transformer",
          "tier": 2,
          "reasoning": "Encryption pattern where data encryption keys are wrapped by a master key."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept for a component that transforms data during encryption/decryption."
        },
        {
          "term": "cache size",
          "tier": 3,
          "reasoning": "Technical parameter for KMS configuration affecting key caching behavior."
        },
        {
          "term": "configuration file",
          "tier": 3,
          "reasoning": "Technical term for the file containing KMS transformer settings."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version identifier for apiserver configuration resources."
        },
        {
          "term": "AES-GCM",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Galois/Counter Mode, a cryptographic algorithm."
        },
        {
          "term": "AES-CBC",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Cipher Block Chaining mode, a cryptographic algorithm."
        },
        {
          "term": "KMS",
          "tier": 3,
          "reasoning": "Key Management Service, external service for managing encryption keys."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:24:46.574551",
      "elapsed_time": 12.087833404541016
    },
    {
      "chunk_id": "reference_setup-tools_kubeadm_kubeadm-upgrade_sec1",
      "doc_id": "reference_setup-tools_kubeadm_kubeadm-upgrade",
      "heading": "kubeadm upgrade guidance",
      "source_file": "reference_setup-tools_kubeadm_kubeadm-upgrade.md",
      "content": "The steps for performing an upgrade using kubeadm are outlined in [this document](/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/).\nFor older versions of kubeadm, please refer to older documentation sets of the Kubernetes website.\n\nYou can use `kubeadm upgrade diff` to see the changes that would be applied to static pod manifests.\n\nIn Kubernetes v1.15.0 and later, `kubeadm upgrade apply` and `kubeadm upgrade node` will also\nautomatically renew the kubeadm managed certificates on this node, including those stored in kubeconfig files.\nTo opt-out, it is possible to pass the flag `--certificate-renewal=false`. For more details about certificate\nrenewal see the [certificate management documentation](/docs/tasks/administer-cluster/kubeadm/kubeadm-certs).\n\n{{< note >}}\nThe commands `kubeadm upgrade apply` and `kubeadm upgrade plan` have a legacy `--config`\nflag which makes it possible to reconfigure the cluster, while performing planning or upgrade of that particular\ncontrol-plane node. Please be aware that the upgrade workflow was not designed for this scenario and there are\nreports of unexpected results.\n{{</ note >}}",
      "terms": [
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI tool for cluster bootstrapping and management"
        },
        {
          "term": "kubeadm upgrade",
          "tier": 1,
          "reasoning": "Specific kubeadm subcommand for performing cluster upgrades"
        },
        {
          "term": "kubeadm upgrade diff",
          "tier": 1,
          "reasoning": "Specific kubeadm command to preview changes to static pod manifests"
        },
        {
          "term": "kubeadm upgrade apply",
          "tier": 1,
          "reasoning": "Specific kubeadm command to apply cluster upgrades"
        },
        {
          "term": "kubeadm upgrade node",
          "tier": 1,
          "reasoning": "Specific kubeadm command to upgrade a node"
        },
        {
          "term": "kubeadm upgrade plan",
          "tier": 1,
          "reasoning": "Specific kubeadm command for planning cluster upgrades"
        },
        {
          "term": "static pod manifests",
          "tier": 2,
          "reasoning": "Domain concept referring to pod definitions managed directly by kubelet"
        },
        {
          "term": "static pod",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for pods managed directly by kubelet without API server"
        },
        {
          "term": "manifests",
          "tier": 2,
          "reasoning": "Technical term for Kubernetes resource definition files"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented"
        },
        {
          "term": "certificates",
          "tier": 2,
          "reasoning": "Security concept for TLS/PKI certificates used in cluster authentication"
        },
        {
          "term": "certificate renewal",
          "tier": 2,
          "reasoning": "Process of renewing expiring certificates in the cluster"
        },
        {
          "term": "kubeconfig files",
          "tier": 1,
          "reasoning": "Configuration files containing cluster access credentials and settings"
        },
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Core Kubernetes configuration file format for cluster access"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine in the cluster"
        },
        {
          "term": "--certificate-renewal=false",
          "tier": 1,
          "reasoning": "Specific CLI flag to disable automatic certificate renewal"
        },
        {
          "term": "--config",
          "tier": 1,
          "reasoning": "CLI flag for specifying configuration during upgrade operations"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core architectural concept representing a set of Kubernetes nodes"
        },
        {
          "term": "control-plane node",
          "tier": 2,
          "reasoning": "Node running control plane components that manage the cluster"
        },
        {
          "term": "control-plane",
          "tier": 2,
          "reasoning": "Architectural concept for the components that manage cluster state"
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process of updating Kubernetes version or components"
        },
        {
          "term": "upgrade workflow",
          "tier": 2,
          "reasoning": "The defined process and steps for performing cluster upgrades"
        },
        {
          "term": "certificate management",
          "tier": 2,
          "reasoning": "Domain concept for handling PKI certificates in the cluster"
        },
        {
          "term": "reconfigure",
          "tier": 2,
          "reasoning": "Technical process of changing cluster configuration"
        },
        {
          "term": "v1.15.0",
          "tier": 3,
          "reasoning": "Specific Kubernetes version reference indicating feature availability"
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:25:01.014628",
      "elapsed_time": 13.434211730957031
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec18",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "{{% heading \"cleanup\" %}}",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "Delete the ConfigMaps and Pods that you made:\n\n```bash\nkubectl delete configmaps/game-config configmaps/game-config-2 configmaps/game-config-3 \\\n               configmaps/game-config-env-file\nkubectl delete pod dapi-test-pod --now",
      "terms": [
        {
          "term": "ConfigMaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data as key-value pairs"
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Kubernetes API object representing the smallest deployable unit"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used to interact with the cluster"
        },
        {
          "term": "kubectl delete",
          "tier": 1,
          "reasoning": "Specific kubectl command for removing Kubernetes resources"
        },
        {
          "term": "game-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance being deleted"
        },
        {
          "term": "game-config-2",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance being deleted"
        },
        {
          "term": "game-config-3",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance being deleted"
        },
        {
          "term": "game-config-env-file",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance created from environment file"
        },
        {
          "term": "dapi-test-pod",
          "tier": 1,
          "reasoning": "Named Pod resource instance being deleted, likely for Downward API testing"
        },
        {
          "term": "configmaps",
          "tier": 1,
          "reasoning": "Resource type specifier used in kubectl command syntax"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Resource type specifier used in kubectl delete command"
        },
        {
          "term": "--now",
          "tier": 2,
          "reasoning": "kubectl flag that forces immediate deletion without waiting for graceful termination"
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation to remove resources from the cluster"
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Unix shell environment in which the kubectl commands are executed"
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T21:25:10.441721",
      "elapsed_time": 8.421381711959839
    },
    {
      "chunk_id": "reference_instrumentation_node-metrics_sec0",
      "doc_id": "reference_instrumentation_node-metrics",
      "heading": "Introduction",
      "source_file": "reference_instrumentation_node-metrics.md",
      "content": "---\ntitle: Node metrics data\ncontent_type: reference\nweight: 50\ndescription: >-\n  Mechanisms for accessing metrics at node, volume, pod and container level,\n  as seen by the kubelet.\n---\n\nThe [kubelet](/docs/reference/command-line-tools-reference/kubelet/)\ngathers metric statistics at the node, volume, pod and container level,\nand emits this information in the\n[Summary API](/docs/reference/config-api/kubelet-stats.v1alpha1/).\n\nYou can send a proxied request to the stats summary API via the\nKubernetes API server.\n\nHere is an example of a Summary API request for a node named `minikube`:\n\n```shell\nkubectl get --raw \"/api/v1/nodes/minikube/proxy/stats/summary\"\n```\n\nHere is the same API call using `curl`:\n\n```shell",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for node-level operations, explicitly referenced and linked in the documentation."
        },
        {
          "term": "Summary API",
          "tier": 1,
          "reasoning": "Specific Kubernetes API for accessing kubelet statistics, a named API endpoint."
        },
        {
          "term": "Kubernetes API server",
          "tier": 1,
          "reasoning": "Core control plane component that proxies requests to the stats summary API."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used in the example command."
        },
        {
          "term": "minikube",
          "tier": 1,
          "reasoning": "Named Kubernetes distribution/tool used as an example node name."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine where pods run."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Kubernetes storage abstraction, one of the levels at which metrics are gathered."
        },
        {
          "term": "pod",
          "tier": 2,
          "reasoning": "Core Kubernetes workload unit, one of the levels at which metrics are gathered."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental unit of deployment in Kubernetes, one of the levels at which metrics are gathered."
        },
        {
          "term": "metric statistics",
          "tier": 2,
          "reasoning": "Domain concept referring to the quantitative data collected by the kubelet."
        },
        {
          "term": "metrics",
          "tier": 2,
          "reasoning": "Core observability concept central to the document's purpose."
        },
        {
          "term": "Node metrics data",
          "tier": 2,
          "reasoning": "The main topic of the document, referring to metrics collected at the node level."
        },
        {
          "term": "stats summary API",
          "tier": 2,
          "reasoning": "Alternative reference to the Summary API for kubelet statistics."
        },
        {
          "term": "proxied request",
          "tier": 2,
          "reasoning": "Technical concept describing how requests are forwarded through the API server."
        },
        {
          "term": "container level",
          "tier": 2,
          "reasoning": "Hierarchical scope at which metrics are collected."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface, used in context of Kubernetes APIs."
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool for making HTTP requests, shown as alternative to kubectl."
        },
        {
          "term": "kubectl get",
          "tier": 3,
          "reasoning": "Specific kubectl subcommand used to retrieve resources or make raw API calls."
        },
        {
          "term": "--raw",
          "tier": 3,
          "reasoning": "kubectl flag that allows making raw API requests to the Kubernetes API server."
        },
        {
          "term": "proxy",
          "tier": 3,
          "reasoning": "Technical concept for forwarding requests, used in the API path structure."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T21:25:25.155939",
      "elapsed_time": 13.707784175872803
    },
    {
      "chunk_id": "concepts_cluster-administration_system-logs_sec1",
      "doc_id": "concepts_cluster-administration_system-logs",
      "heading": "Klog",
      "source_file": "concepts_cluster-administration_system-logs.md",
      "content": "klog is the Kubernetes logging library. [klog](https://github.com/kubernetes/klog)\ngenerates log messages for the Kubernetes system components.\n\nKubernetes is in the process of simplifying logging in its components.\nThe following klog command line flags\n[are deprecated](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/2845-deprecate-klog-specific-flags-in-k8s-components)\nstarting with Kubernetes v1.23 and removed in Kubernetes v1.26:\n\n- `--add-dir-header`\n- `--alsologtostderr`\n- `--log-backtrace-at`\n- `--log-dir`\n- `--log-file`\n- `--log-file-max-size`\n- `--logtostderr`\n- `--one-output`\n- `--skip-headers`\n- `--skip-log-headers`\n- `--stderrthreshold`\n\nOutput will always be written to stderr, regardless of the output format. Output redirection is\nexpected to be handled by the component which invokes a Kubernetes component. This can be a POSIX\nshell or a tool like systemd.\n\nIn some cases, for example a distroless container or a Windows system service, those options are\nnot available. Then the\n[`kube-log-runner`](https://github.com/kubernetes/kubernetes/blob/d2a8a81639fcff8d1221b900f66d28361a170654/staging/src/k8s.io/component-base/logs/kube-log-runner/README.md)\nbinary can be used as wrapper around a Kubernetes component to redirect\noutput. A prebuilt binary is included in several Kubernetes base images under\nits traditional name as `/go-runner` and as `kube-log-runner` in server and\nnode release archives.\n\nThis table shows how `kube-log-runner` invocations correspond to shell redirection:\n\n| Usage                                    | POSIX shell (such as bash) | `kube-log-runner <options> <cmd>`                           |\n| -----------------------------------------|----------------------------|-------------------------------------------------------------|\n| Merge stderr and stdout, write to stdout | `2>&1`                     | `kube-log-runner` (default behavior)                        |\n| Redirect both into log file              | `1>>/tmp/log 2>&1`         | `kube-log-runner -log-file=/tmp/log`                        |\n| Copy into log file and to stdout         | `2>&1 \\| tee -a /tmp/log`  | `kube-log-runner -log-file=/tmp/log -also-stdout`           |\n| Redirect only stdout into log file       | `>/tmp/log`                | `kube-log-runner -log-file=/tmp/log -redirect-stderr=false` |\n\n### Klog output\n\nAn example of the traditional klog native format:\n\n```\nI1025 00:15:15.525108       1 httplog.go:79] GET /api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-57c75779f-9p8wg: (1.512ms) 200 [pod_nanny/v0.0.0 (linux/amd64) kubernetes/$Format 10.56.1.19:51756]\n```\n\nThe message string may contain line breaks:\n\n```\nI1025 00:15:15.525108       1 example.go:79] This is a message\nwhich has a line break.\n```\n\n### Structured Logging\n\n{{< feature-state for_k8s_version=\"v1.23\" state=\"beta\" >}}\n\n{{< warning >}}\nMigration to structured log messages is an ongoing process. Not all log messages are structured in\nthis version. When parsing log files, you must also handle unstructured log messages.\n\nLog formatting and value serialization are subject to change.\n{{< /warning>}}\n\nStructured logging introduces a uniform structure in log messages allowing for programmatic\nextraction of information. You can store and process structured logs with less effort and cost.\nThe code which generates a log message determines whether it uses the traditional unstructured\nklog output or structured logging.\n\nThe default formatting of structured log messages is as text, with a format that is backward\ncompatible with traditional klog:\n\n```\n<klog header> \"<message>\" <key1>=\"<value1>\" <key2>=\"<value2>\" ...\n```\n\nExample:\n\n```\nI1025 00:15:15.525108       1 controller_utils.go:116] \"Pod status updated\" pod=\"kube-system/kubedns\" status=\"ready\"\n```\n\nStrings are quoted. Other values are formatted with\n[`%+v`](https://pkg.go.dev/fmt#hdr-Printing), which may cause log messages to\ncontinue on the next line [depending on the data](https://github.com/kubernetes/kubernetes/issues/106428).\n\n```\nI1025 00:15:15.525108       1 example.go:116] \"Example\" data=\"This is text with a line break\\nand \\\"quotation marks\\\".\" someInt=1 someFloat=0.1 someStruct={StringField: First line,\nsecond line.}\n```\n\n### Contextual Logging\n\n{{< feature-state for_k8s_version=\"v1.30\" state=\"beta\" >}}\n\nContextual logging builds on top of structured logging. It is primarily about\nhow developers use logging calls: code based on that concept is more flexible\nand supports additional use cases as described in the [Contextual Logging\nKEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/3077-contextual-logging).\n\nIf developers use additional functions like `WithValues` or `WithName` in\ntheir components, then log entries contain additional information that gets\npassed into functions by their caller.\n\nFor Kubernetes {{< skew currentVersion >}}, this is gated behind the `ContextualLogging`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) and is\nenabled by default. The infrastructure for this was added in 1.24 without\nmodifying components. The\n[`component-base/logs/example`](https://github.com/kubernetes/kubernetes/blob/v1.24.0-beta.0/staging/src/k8s.io/component-base/logs/example/cmd/logger.go)\ncommand demonstrates how to use the new logging calls and how a component\nbehaves that supports contextual logging.\n\n```console\n$ cd $GOPATH/src/k8s.io/kubernetes/staging/src/k8s.io/component-base/logs/example/cmd/\n$ go run . --help\n...\n      --feature-gates mapStringBool  A set of key=value pairs that describe feature gates for alpha/experimental features. Options are:\n                                     AllAlpha=true|false (ALPHA - default=false)\n                                     AllBeta=true|false (BETA - default=false)\n                                     ContextualLogging=true|false (BETA - default=true)\n$ go run . --feature-gates ContextualLogging=true\n...\nI0222 15:13:31.645988  197901 example.go:54] \"runtime\" logger=\"example.myname\" foo=\"bar\" duration=\"1m0s\"\nI0222 15:13:31.646007  197901 example.go:55] \"another runtime\" logger=\"example\" foo=\"bar\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\nThe `logger` key and `foo=\"bar\"` were added by the caller of the function\nwhich logs the `runtime` message and `duration=\"1m0s\"` value, without having to\nmodify that function.\n\nWith contextual logging disable, `WithValues` and `WithName` do nothing and log\ncalls go through the global klog logger. Therefore this additional information\nis not in the log output anymore:\n\n```console\n$ go run . --feature-gates ContextualLogging=false\n...\nI0222 15:14:40.497333  198174 example.go:54] \"runtime\" duration=\"1m0s\"\nI0222 15:14:40.497346  198174 example.go:55] \"another runtime\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\n### JSON log format\n\n{{< feature-state for_k8s_version=\"v1.19\" state=\"alpha\" >}}\n\n{{<warning >}}\nJSON output does not support many standard klog flags. For list of unsupported klog flags, see the\n[Command line tool reference](/docs/reference/command-line-tools-reference/).\n\nNot all logs are guaranteed to be written in JSON format (for example, during process start).\nIf you intend to parse logs, make sure you can handle log lines that are not JSON as well.\n\nField names and JSON serialization are subject to change.\n{{< /warning >}}\n\nThe `--logging-format=json` flag changes the format of logs from klog native format to JSON format.\nExample of JSON log format (pretty printed):\n\n```json\n{\n   \"ts\": 1580306777.04728,\n   \"v\": 4,\n   \"msg\": \"Pod status updated\",\n   \"pod\":{\n      \"name\": \"nginx-1\",\n      \"namespace\": \"default\"\n   },\n   \"status\": \"ready\"\n}\n```\n\nKeys with special meaning:\n\n* `ts` - timestamp as Unix time (required, float)\n* `v` - verbosity (only for info and not for error messages, int)\n* `err` - error string (optional, string)\n* `msg` - message (required, string)\n\nList of components currently supporting JSON format:\n\n* {{< glossary_tooltip term_id=\"kube-controller-manager\" text=\"kube-controller-manager\" >}}\n* {{< glossary_tooltip term_id=\"kube-apiserver\" text=\"kube-apiserver\" >}}\n* {{< glossary_tooltip term_id=\"kube-scheduler\" text=\"kube-scheduler\" >}}\n* {{< glossary_tooltip term_id=\"kubelet\" text=\"kubelet\" >}}\n\n### Log verbosity level\n\nThe `-v` flag controls log verbosity. Increasing the value increases the number of logged events.\nDecreasing the value decreases the number of logged events.  Increasing verbosity settings logs\nincreasingly less severe events. A verbosity setting of 0 logs only critical events.\n\n### Log location\n\nThere are two types of system components: those that run in a container and those\nthat do not run in a container. For example:\n\n* The Kubernetes scheduler and kube-proxy run in a container.\n* The kubelet and {{<glossary_tooltip term_id=\"container-runtime\" text=\"container runtime\">}}\n  do not run in containers.\n\nOn machines with systemd, the kubelet and container runtime write to journald.\nOtherwise, they write to `.log` files in the `/var/log` directory.\nSystem components inside containers always write to `.log` files in the `/var/log` directory,\nbypassing the default logging mechanism.\nSimilar to the container logs, you should rotate system component logs in the `/var/log` directory.\nIn Kubernetes clusters created by the `kube-up.sh` script, log rotation is configured by the `logrotate` tool.\nThe `logrotate` tool rotates logs daily, or once the log size is greater than 100MB.",
      "terms": [
        {
          "term": "klog",
          "tier": 1,
          "reasoning": "Named Kubernetes logging library, a specific component for system logging."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core domain proper noun, the container orchestration platform being documented."
        },
        {
          "term": "logging library",
          "tier": 2,
          "reasoning": "Technical concept describing the type of component klog is."
        },
        {
          "term": "log messages",
          "tier": 2,
          "reasoning": "Domain concept referring to the output generated by logging systems."
        },
        {
          "term": "system components",
          "tier": 2,
          "reasoning": "Technical term referring to the various parts of the Kubernetes system."
        },
        {
          "term": "klog command line flags",
          "tier": 2,
          "reasoning": "Technical concept referring to CLI configuration options for klog."
        },
        {
          "term": "--add-dir-header",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--alsologtostderr",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-backtrace-at",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-dir",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-file",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-file-max-size",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--logtostderr",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--one-output",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--skip-headers",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--skip-log-headers",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--stderrthreshold",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "stderr",
          "tier": 3,
          "reasoning": "Standard error stream, OS-level concept relevant to log output handling."
        },
        {
          "term": "stdout",
          "tier": 3,
          "reasoning": "Standard output stream, OS-level concept relevant to log output handling."
        },
        {
          "term": "output format",
          "tier": 2,
          "reasoning": "Technical concept describing how log data is structured."
        },
        {
          "term": "output redirection",
          "tier": 2,
          "reasoning": "Technical process for directing output streams to different destinations."
        },
        {
          "term": "Kubernetes component",
          "tier": 2,
          "reasoning": "Domain term referring to individual parts of the Kubernetes system."
        },
        {
          "term": "POSIX shell",
          "tier": 3,
          "reasoning": "Technical standard for shell environments, used for comparison with kube-log-runner."
        },
        {
          "term": "systemd",
          "tier": 3,
          "reasoning": "Linux system and service manager, mentioned as a tool for handling output."
        },
        {
          "term": "distroless container",
          "tier": 2,
          "reasoning": "Container concept referring to minimal containers without shell utilities."
        },
        {
          "term": "Windows system service",
          "tier": 3,
          "reasoning": "OS-specific concept for background services on Windows."
        },
        {
          "term": "kube-log-runner",
          "tier": 1,
          "reasoning": "Named Kubernetes binary tool for log output redirection."
        },
        {
          "term": "/go-runner",
          "tier": 1,
          "reasoning": "Traditional name for the kube-log-runner binary in base images."
        },
        {
          "term": "Kubernetes base images",
          "tier": 2,
          "reasoning": "Domain concept referring to foundational container images for Kubernetes."
        },
        {
          "term": "-log-file",
          "tier": 1,
          "reasoning": "CLI option for kube-log-runner to specify log file destination."
        },
        {
          "term": "-also-stdout",
          "tier": 1,
          "reasoning": "CLI option for kube-log-runner to copy output to stdout."
        },
        {
          "term": "-redirect-stderr",
          "tier": 1,
          "reasoning": "CLI option for kube-log-runner to control stderr redirection."
        },
        {
          "term": "klog native format",
          "tier": 2,
          "reasoning": "Technical term for the traditional log message format used by klog."
        },
        {
          "term": "klog header",
          "tier": 2,
          "reasoning": "Component of structured log format containing metadata."
        },
        {
          "term": "Structured Logging",
          "tier": 2,
          "reasoning": "Core logging concept introducing uniform structure to log messages."
        },
        {
          "term": "structured log messages",
          "tier": 2,
          "reasoning": "Log messages with programmatically parseable format."
        },
        {
          "term": "unstructured log messages",
          "tier": 2,
          "reasoning": "Traditional log messages without uniform structure."
        },
        {
          "term": "log formatting",
          "tier": 2,
          "reasoning": "Technical concept for how log data is presented."
        },
        {
          "term": "value serialization",
          "tier": 2,
          "reasoning": "Technical process of converting values to string representation in logs."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object, referenced in log message examples."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Lowercase reference to Pod resource in structured log key-value pairs."
        },
        {
          "term": "namespaces",
          "tier": 2,
          "reasoning": "Kubernetes concept for resource isolation, appears in API path."
        },
        {
          "term": "kube-system",
          "tier": 1,
          "reasoning": "Named Kubernetes namespace for system components."
        },
        {
          "term": "metrics-server",
          "tier": 1,
          "reasoning": "Named Kubernetes component for resource metrics."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Technical term for application programming interface, used in API paths."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating pre-stable functionality."
        },
        {
          "term": "log file",
          "tier": 2,
          "reasoning": "Technical concept for persistent storage of log output."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept for isolated runtime environments."
        },
        {
          "term": "linux/amd64",
          "tier": 3,
          "reasoning": "Platform identifier indicating operating system and architecture."
        }
      ],
      "term_count": 49,
      "generated_at": "2026-02-08T21:25:52.003442",
      "elapsed_time": 25.840669870376587
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates.md",
      "content": "---\ntitle: DefaultHostNetworkHostPortsInPodTemplates\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: deprecated\n    defaultValue: false\n    fromVersion: \"1.28\"\n    toVersion: \"1.30\"\n\nremoved: true\n---\nThis feature gate controls the point at which a default value for\n`.spec.containers[*].ports[*].hostPort`\nis assigned, for Pods using `hostNetwork: true`. The default since Kubernetes v1.28 is to only set a default\nvalue in Pods.\n\nEnabling this means a default will be assigned even to the `.spec` of an embedded\n[PodTemplate](/docs/concepts/workloads/pods/#pod-templates) (for example, in a Deployment),\nwhich is the way that older releases of Kubernetes worked.\nYou should migrate your code so that it does not rely on the legacy behavior.",
      "terms": [
        {
          "term": "DefaultHostNetworkHostPortsInPodTemplates",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": "feature gate",
          "tier": 1,
          "reasoning": "Alternative form of feature_gate, a core Kubernetes configuration mechanism."
        },
        {
          "term": ".spec.containers[*].ports[*].hostPort",
          "tier": 1,
          "reasoning": "A specific API field path in the Pod specification for container port configuration."
        },
        {
          "term": "hostPort",
          "tier": 1,
          "reasoning": "A specific Kubernetes Pod container port configuration field."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "hostNetwork",
          "tier": 1,
          "reasoning": "A specific Pod spec field that controls network namespace sharing with the host."
        },
        {
          "term": "PodTemplate",
          "tier": 1,
          "reasoning": "A Kubernetes API object that defines a template for creating Pods."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "A core Kubernetes workload API object for managing replicated applications."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": ".spec",
          "tier": 2,
          "reasoning": "The specification section of a Kubernetes API object, a key structural concept."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Technical term referring to container definitions within a Pod spec."
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Network port configuration concept within container specifications."
        },
        {
          "term": "deprecated",
          "tier": 2,
          "reasoning": "A feature lifecycle stage indicating the feature is being phased out."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Configuration concept for the default state of a feature gate."
        },
        {
          "term": "default value",
          "tier": 2,
          "reasoning": "Technical concept referring to automatically assigned configuration values."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running on the cluster."
        },
        {
          "term": "embedded",
          "tier": 2,
          "reasoning": "Technical concept describing nested object specifications within parent resources."
        },
        {
          "term": "stages",
          "tier": 2,
          "reasoning": "Feature gate lifecycle concept describing the progression of a feature."
        },
        {
          "term": "removed",
          "tier": 2,
          "reasoning": "Feature lifecycle state indicating the feature gate has been eliminated."
        },
        {
          "term": "legacy behavior",
          "tier": 2,
          "reasoning": "Technical concept referring to older, deprecated functionality patterns."
        },
        {
          "term": "migrate",
          "tier": 2,
          "reasoning": "Technical process of updating code or configurations to newer patterns."
        },
        {
          "term": "v1.28",
          "tier": 3,
          "reasoning": "Specific Kubernetes version reference indicating when behavior changed."
        },
        {
          "term": "1.28",
          "tier": 3,
          "reasoning": "Version number marking the introduction of the new default behavior."
        },
        {
          "term": "1.30",
          "tier": 3,
          "reasoning": "Version number marking the end of this feature gate's availability."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Configuration metadata indicating the starting version for a feature stage."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Configuration metadata indicating the ending version for a feature stage."
        },
        {
          "term": "code",
          "tier": 3,
          "reasoning": "Technical term referring to application source code that may depend on this behavior."
        }
      ],
      "term_count": 28,
      "generated_at": "2026-02-08T21:26:08.541023",
      "elapsed_time": 15.52647066116333
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a password.txt file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF >./password.txt\nusername=admin\npassword=secret\nEOF\n\ncat <<EOF >deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  labels:\n    app: my-app\nspec:\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: app\n        image: my-app\n        volumeMounts:\n        - name: password\n          mountPath: /secrets\n      volumes:\n      - name: password\n        secret:\n          secretName: example-secret-1\nEOF\n\ncat <<EOF >./kustomization.yaml\nresources:\n- deployment.yaml\nsecretGenerator:\n- name: example-secret-1\n  files:\n  - password.txt\nEOF\n```\n\n#### generatorOptions\n\nThe generated ConfigMaps and Secrets have a content hash suffix appended. This ensures that\na new ConfigMap or Secret is generated when the contents are changed. To disable the behavior\nof appending a suffix, one can use `generatorOptions`. Besides that, it is also possible to\nspecify cross-cutting options for generated ConfigMaps and Secrets.\n\n```shell\ncat <<EOF >./kustomization.yaml\nconfigMapGenerator:\n- name: example-configmap-3\n  literals:\n  - FOO=Bar\ngeneratorOptions:\n  disableNameSuffixHash: true\n  labels:\n    type: generated\n  annotations:\n    note: generated\nEOF\n```\n\nRun`kubectl kustomize ./` to view the generated ConfigMap:\n\n```yaml\napiVersion: v1\ndata:\n  FOO: Bar\nkind: ConfigMap\nmetadata:\n  annotations:\n    note: generated\n  labels:\n    type: generated\n  name: example-configmap-3\n```\n\n### Setting cross-cutting fields\n\nIt is quite common to set cross-cutting fields for all Kubernetes resources in a project.\nSome use cases for setting cross-cutting fields:\n\n* setting the same namespace for all resources\n* adding the same name prefix or suffix\n* adding the same set of labels\n* adding the same set of annotations\n\nHere is an example:\n\n```shell",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing application deployments"
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data"
        },
        {
          "term": "Secret",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing sensitive data like passwords"
        },
        {
          "term": "secretGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating Secret resources"
        },
        {
          "term": "configMapGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating ConfigMap resources"
        },
        {
          "term": "generatorOptions",
          "tier": 1,
          "reasoning": "Kustomize configuration block for controlling generator behavior"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "kustomize",
          "tier": 1,
          "reasoning": "Kubernetes configuration management tool referenced via kubectl kustomize"
        },
        {
          "term": "kubectl kustomize",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for running kustomize"
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Configuration file for Kustomize tool"
        },
        {
          "term": "deployment.yaml",
          "tier": 1,
          "reasoning": "YAML file defining a Kubernetes Deployment resource"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying API version"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API version for apps resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying resource type"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource metadata"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource specification"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for matching resources by labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector mechanism for label matching"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within Deployment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes spec field defining container configurations"
        },
        {
          "term": "volumeMounts",
          "tier": 2,
          "reasoning": "Kubernetes field for mounting volumes into containers"
        },
        {
          "term": "volumes",
          "tier": 2,
          "reasoning": "Kubernetes field for defining volume sources"
        },
        {
          "term": "mountPath",
          "tier": 2,
          "reasoning": "Path where volume is mounted inside container"
        },
        {
          "term": "secretName",
          "tier": 2,
          "reasoning": "Reference to a Secret resource by name"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for organizing and selecting resources"
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata for attaching non-identifying information"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for resource isolation and organization"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kustomize field listing Kubernetes resource files"
        },
        {
          "term": "name prefix",
          "tier": 2,
          "reasoning": "Kustomize feature for adding prefix to resource names"
        },
        {
          "term": "content hash suffix",
          "tier": 2,
          "reasoning": "Auto-generated suffix based on content hash for ConfigMaps/Secrets"
        },
        {
          "term": "disableNameSuffixHash",
          "tier": 2,
          "reasoning": "Kustomize option to disable automatic hash suffix generation"
        },
        {
          "term": "cross-cutting fields",
          "tier": 2,
          "reasoning": "Configuration fields applied across all resources in a project"
        },
        {
          "term": "literals",
          "tier": 2,
          "reasoning": "Kustomize field for defining key-value pairs inline"
        },
        {
          "term": "files",
          "tier": 2,
          "reasoning": "Kustomize field for referencing external files"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image specification in Kubernetes"
        },
        {
          "term": "Kubernetes resources",
          "tier": 2,
          "reasoning": "General term for objects managed by Kubernetes API"
        },
        {
          "term": "password.txt",
          "tier": 3,
          "reasoning": "Example file containing credentials for Secret generation"
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "Kubernetes core API version shown in ConfigMap output"
        },
        {
          "term": "data",
          "tier": 3,
          "reasoning": "Field in ConfigMap/Secret containing stored data"
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T21:26:25.199129",
      "elapsed_time": 15.65053939819336
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_options__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_options__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_options__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for options</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "-h",
          "tier": 1,
          "reasoning": "CLI flag shorthand for help option, a specific command-line interface element."
        },
        {
          "term": "--help",
          "tier": 1,
          "reasoning": "CLI flag for displaying help information, a standard command-line option."
        },
        {
          "term": "help",
          "tier": 3,
          "reasoning": "In CLI context, 'help' refers to the built-in documentation/usage information system."
        },
        {
          "term": "options",
          "tier": 3,
          "reasoning": "In CLI context, 'options' refers to command-line flags and parameters that modify command behavior."
        }
      ],
      "term_count": 4,
      "generated_at": "2026-02-08T21:26:29.962553",
      "elapsed_time": 3.7550439834594727
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation.md",
      "content": "---\ntitle: CronJobsScheduledAnnotation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.28\"\n    toVersion: \"1.31\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.32\"\n\n---\nSet the scheduled job time as an\n{{< glossary_tooltip text=\"annotation\" term_id=\"annotation\" >}} on Jobs that were created\non behalf of a CronJob.",
      "terms": [
        {
          "term": "CronJobsScheduledAnnotation",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling optional features, appearing as the content_type."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "A Kubernetes concept for attaching non-identifying metadata to objects."
        },
        {
          "term": "Jobs",
          "tier": 1,
          "reasoning": "A Kubernetes API object/resource that runs tasks to completion."
        },
        {
          "term": "CronJob",
          "tier": 1,
          "reasoning": "A Kubernetes API object that creates Jobs on a time-based schedule."
        },
        {
          "term": "scheduled job time",
          "tier": 2,
          "reasoning": "A domain concept referring to the time when a job is scheduled to run."
        },
        {
          "term": "beta",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is well-tested but not yet stable."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is production-ready and enabled by default."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "A configuration concept indicating the default state of a feature gate."
        },
        {
          "term": "stage",
          "tier": 3,
          "reasoning": "Technical term describing the maturity phase of a feature in Kubernetes feature gate lifecycle."
        },
        {
          "term": "fromVersion",
          "tier": 2,
          "reasoning": "A versioning concept indicating the starting Kubernetes version for a feature stage."
        },
        {
          "term": "toVersion",
          "tier": 2,
          "reasoning": "A versioning concept indicating the ending Kubernetes version for a feature stage."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:26:38.780345",
      "elapsed_time": 7.810666084289551
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec16",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Issuer`     {#apiserver-config-k8s-io-v1-Issuer}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>Issuer provides the configuration for an external provider's specific settings.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>url points to the issuer URL in a format https://url or https://url/path.\nThis must match the &quot;iss&quot; claim in the presented JWT, and the issuer returned from discovery.\nSame value as the --oidc-issuer-url flag.\nDiscovery information is fetched from &quot;{url}/.well-known/openid-configuration&quot; unless overridden by discoveryURL.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>discoveryURL</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>discoveryURL, if specified, overrides the URL used to fetch discovery\ninformation instead of using &quot;{url}/.well-known/openid-configuration&quot;.\nThe exact value specified is used, so &quot;/.well-known/openid-configuration&quot;\nmust be included in discoveryURL if needed.</p>\n<p>The &quot;issuer&quot; field in the fetched discovery information must match the &quot;issuer.url&quot; field\nin the AuthenticationConfiguration and will be used to validate the &quot;iss&quot; claim in the presented JWT.\nThis is for scenarios where the well-known and jwks endpoints are hosted at a different\nlocation than the issuer (such as locally in the cluster).</p>\n<p>Example:\nA discovery url that is exposed using kubernetes service 'oidc' in namespace 'oidc-namespace'\nand discovery information is available at '/.well-known/openid-configuration'.\ndiscoveryURL: &quot;https://oidc.oidc-namespace/.well-known/openid-configuration&quot;\ncertificateAuthority is used to verify the TLS connection and the hostname on the leaf certificate\nmust be set to 'oidc.oidc-namespace'.</p>\n<p>curl https://oidc.oidc-namespace/.well-known/openid-configuration (.discoveryURL field)\n{\nissuer: &quot;https://oidc.example.com&quot; (.url field)\n}</p>\n<p>discoveryURL must be different from url.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>certificateAuthority</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>certificateAuthority contains PEM-encoded certificate authority certificates\nused to validate the connection when fetching discovery information.\nIf unset, the system verifier is used.\nSame value as the content of the file referenced by the --oidc-ca-file flag.</p>\n</td>\n</tr>\n<tr><td><code>audiences</code> <B>[Required]</B><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>audiences is the set of acceptable audiences the JWT must be issued to.\nAt least one of the entries must match the &quot;aud&quot; claim in presented JWTs.\nSame value as the --oidc-client-id flag (though this field supports an array).\nRequired to be non-empty.</p>\n</td>\n</tr>\n<tr><td><code>audienceMatchPolicy</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AudienceMatchPolicyType\"><code>AudienceMatchPolicyType</code></a>\n</td>\n<td>\n   <p>audienceMatchPolicy defines how the &quot;audiences&quot; field is used to match the &quot;aud&quot; claim in the presented JWT.\nAllowed values are:</p>\n<ol>\n<li>&quot;MatchAny&quot; when multiple audiences are specified and</li>\n<li>empty (or unset) or &quot;MatchAny&quot; when a single audience is specified.</li>\n</ol>\n<ul>\n<li>\n<p>MatchAny: the &quot;aud&quot; claim in the presented JWT must match at least one of the entries in the &quot;audiences&quot; field.\nFor example, if &quot;audiences&quot; is [&quot;foo&quot;, &quot;bar&quot;], the &quot;aud&quot; claim in the presented JWT must contain either &quot;foo&quot; or &quot;bar&quot; (and may contain both).</p>\n</li>\n<li>\n<p>&quot;&quot;: The match policy can be empty (or unset) when a single audience is specified in the &quot;audiences&quot; field. The &quot;aud&quot; claim in the presented JWT must contain the single audience (and may contain others).</p>\n</li>\n</ul>\n<p>For more nuanced audience validation, use claimValidationRules.\nexample: claimValidationRule[].expression: 'sets.equivalent(claims.aud, [&quot;bar&quot;, &quot;foo&quot;, &quot;baz&quot;])' to require an exact match.</p>\n</td>\n</tr>\n<tr><td><code>egressSelectorType</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-EgressSelectorType\"><code>EgressSelectorType</code></a>\n</td>\n<td>\n   <p>egressSelectorType is an indicator of which egress selection should be used for sending all traffic related\nto this issuer (discovery, JWKS, distributed claims, etc).  If unspecified, no custom dialer is used.\nWhen specified, the valid choices are &quot;controlplane&quot; and &quot;cluster&quot;.  These correspond to the associated\nvalues in the --egress-selector-config-file.</p>\n<ul>\n<li>\n<p>controlplane: for traffic intended to go to the control plane.</p>\n</li>\n<li>\n<p>cluster: for traffic intended to go to the system being managed by Kubernetes.</p>\n</li>\n</ul>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration"
        },
        {
          "term": "Issuer",
          "tier": 1,
          "reasoning": "Named configuration component for external provider settings in JWT authentication"
        },
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for authentication settings"
        },
        {
          "term": "AudienceMatchPolicyType",
          "tier": 1,
          "reasoning": "Named Kubernetes API type for defining audience matching behavior"
        },
        {
          "term": "url",
          "tier": 2,
          "reasoning": "Configuration field pointing to the issuer URL for JWT validation"
        },
        {
          "term": "discoveryURL",
          "tier": 2,
          "reasoning": "Configuration field that overrides the default OIDC discovery endpoint"
        },
        {
          "term": "certificateAuthority",
          "tier": 2,
          "reasoning": "Configuration field containing PEM-encoded CA certificates for TLS validation"
        },
        {
          "term": "audiences",
          "tier": 2,
          "reasoning": "Configuration field defining acceptable JWT audience values"
        },
        {
          "term": "audienceMatchPolicy",
          "tier": 2,
          "reasoning": "Configuration field defining how audience claims are matched"
        },
        {
          "term": "JWT",
          "tier": 2,
          "reasoning": "JSON Web Token - core authentication token format being configured"
        },
        {
          "term": "iss",
          "tier": 2,
          "reasoning": "Standard JWT claim identifying the token issuer"
        },
        {
          "term": "aud",
          "tier": 2,
          "reasoning": "Standard JWT claim identifying the intended audience"
        },
        {
          "term": "OIDC",
          "tier": 2,
          "reasoning": "OpenID Connect protocol referenced for discovery and authentication"
        },
        {
          "term": "discovery",
          "tier": 2,
          "reasoning": "OIDC discovery mechanism for fetching provider configuration"
        },
        {
          "term": "discovery information",
          "tier": 2,
          "reasoning": "Metadata fetched from OIDC discovery endpoint"
        },
        {
          "term": "openid-configuration",
          "tier": 2,
          "reasoning": "Standard OIDC discovery endpoint path"
        },
        {
          "term": ".well-known/openid-configuration",
          "tier": 2,
          "reasoning": "Full well-known path for OIDC discovery endpoint"
        },
        {
          "term": "--oidc-issuer-url",
          "tier": 1,
          "reasoning": "CLI flag for configuring OIDC issuer URL"
        },
        {
          "term": "--oidc-ca-file",
          "tier": 1,
          "reasoning": "CLI flag for configuring OIDC CA certificate file"
        },
        {
          "term": "--oidc-client-id",
          "tier": 1,
          "reasoning": "CLI flag for configuring OIDC client ID"
        },
        {
          "term": "JWT authenticators",
          "tier": 2,
          "reasoning": "Authentication components that validate JWT tokens"
        },
        {
          "term": "PEM-encoded",
          "tier": 3,
          "reasoning": "Certificate encoding format used for certificate authority configuration"
        },
        {
          "term": "certificate authority certificates",
          "tier": 2,
          "reasoning": "CA certificates used for validating TLS connections"
        },
        {
          "term": "TLS connection",
          "tier": 3,
          "reasoning": "Secure transport layer connection being validated"
        },
        {
          "term": "leaf certificate",
          "tier": 3,
          "reasoning": "End-entity certificate in TLS certificate chain"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Network hostname validated on leaf certificate"
        },
        {
          "term": "egress selection configuration",
          "tier": 2,
          "reasoning": "Kubernetes network egress configuration mechanism"
        },
        {
          "term": "kubernetes service",
          "tier": 2,
          "reasoning": "Kubernetes Service resource for network access"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes namespace for resource isolation"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster where services are hosted"
        },
        {
          "term": "jwks",
          "tier": 2,
          "reasoning": "JSON Web Key Set endpoint for JWT signature verification"
        },
        {
          "term": "MatchAny",
          "tier": 2,
          "reasoning": "Audience match policy value requiring any audience to match"
        },
        {
          "term": "issuer",
          "tier": 2,
          "reasoning": "Entity that issues and signs JWT tokens"
        },
        {
          "term": "system verifier",
          "tier": 2,
          "reasoning": "Default system-level certificate verification mechanism"
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Secure HTTP protocol required for issuer URLs"
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool shown in example for fetching discovery information"
        },
        {
          "term": "external provider",
          "tier": 2,
          "reasoning": "Third-party identity provider for authentication"
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:26:57.525597",
      "elapsed_time": 17.738083839416504
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_logs__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_logs__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_logs__index.md",
      "content": "```\n  # Return snapshot logs from pod nginx with only one container\n  kubectl logs nginx\n  \n  # Return snapshot logs from pod nginx, prefixing each line with the source pod and container name\n  kubectl logs nginx --prefix\n  \n  # Return snapshot logs from pod nginx, limiting output to 500 bytes\n  kubectl logs nginx --limit-bytes=500\n  \n  # Return snapshot logs from pod nginx, waiting up to 20 seconds for it to start running.\n  kubectl logs nginx --pod-running-timeout=20s\n  \n  # Return snapshot logs from pod nginx with multi containers\n  kubectl logs nginx --all-containers=true\n  \n  # Return snapshot logs from all pods in the deployment nginx\n  kubectl logs deployment/nginx --all-pods=true\n  \n  # Return snapshot logs from all containers in pods defined by label app=nginx\n  kubectl logs -l app=nginx --all-containers=true\n  \n  # Return snapshot logs from all pods defined by label app=nginx, limiting concurrent log requests to 10 pods\n  kubectl logs -l app=nginx --max-log-requests=10\n  \n  # Return snapshot of previous terminated ruby container logs from pod web-1\n  kubectl logs -p -c ruby web-1\n  \n  # Begin streaming the logs from pod nginx, continuing even if errors occur\n  kubectl logs nginx -f --ignore-errors=true\n  \n  # Begin streaming the logs of the ruby container in pod web-1\n  kubectl logs -f -c ruby web-1\n  \n  # Begin streaming the logs from all containers in pods defined by label app=nginx\n  kubectl logs -f -l app=nginx --all-containers=true\n  \n  # Display only the most recent 20 lines of output in pod nginx\n  kubectl logs --tail=20 nginx\n  \n  # Show all logs from pod nginx written in the last hour\n  kubectl logs --since=1h nginx\n  \n  # Show all logs with timestamps from pod nginx starting from August 30, 2024, at 06:00:00 UTC\n  kubectl logs nginx --since-time=2024-08-30T06:00:00Z --timestamps=true\n  \n  # Show logs from a kubelet with an expired serving certificate\n  kubectl logs --insecure-skip-tls-verify-backend nginx\n  \n  # Return snapshot logs from first container of a job named hello\n  kubectl logs job/hello\n  \n  # Return snapshot logs from container nginx-1 of a deployment named nginx\n  kubectl logs deployment/nginx -c nginx-1\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout all examples"
        },
        {
          "term": "logs",
          "tier": 2,
          "reasoning": "Kubectl subcommand for retrieving container/pod log output"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental deployment unit referenced throughout"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container/pod name used as example throughout the documentation"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing isolated runtime environment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form used in --all-containers flag context"
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing pod replicas, referenced as deployment/nginx"
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept used for selecting pods with -l flag"
        },
        {
          "term": "ruby",
          "tier": 1,
          "reasoning": "Specific container name used in examples"
        },
        {
          "term": "web-1",
          "tier": 1,
          "reasoning": "Specific pod name used in examples"
        },
        {
          "term": "job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running batch workloads, referenced as job/hello"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component explicitly mentioned"
        },
        {
          "term": "--prefix",
          "tier": 3,
          "reasoning": "CLI flag for prefixing log lines with source pod and container name"
        },
        {
          "term": "--limit-bytes",
          "tier": 3,
          "reasoning": "CLI flag for limiting log output size"
        },
        {
          "term": "--pod-running-timeout",
          "tier": 3,
          "reasoning": "CLI flag for setting pod startup wait time"
        },
        {
          "term": "--all-containers",
          "tier": 3,
          "reasoning": "CLI flag for retrieving logs from all containers in a pod"
        },
        {
          "term": "--all-pods",
          "tier": 3,
          "reasoning": "CLI flag for retrieving logs from all pods in a deployment"
        },
        {
          "term": "--max-log-requests",
          "tier": 3,
          "reasoning": "CLI flag for limiting concurrent log requests"
        },
        {
          "term": "-p",
          "tier": 3,
          "reasoning": "CLI flag shorthand for previous terminated container logs"
        },
        {
          "term": "-c",
          "tier": 3,
          "reasoning": "CLI flag shorthand for specifying container name"
        },
        {
          "term": "-f",
          "tier": 3,
          "reasoning": "CLI flag shorthand for following/streaming logs"
        },
        {
          "term": "--ignore-errors",
          "tier": 3,
          "reasoning": "CLI flag for continuing log streaming despite errors"
        },
        {
          "term": "--tail",
          "tier": 3,
          "reasoning": "CLI flag for limiting output to most recent lines"
        },
        {
          "term": "--since",
          "tier": 3,
          "reasoning": "CLI flag for filtering logs by relative time duration"
        },
        {
          "term": "--since-time",
          "tier": 3,
          "reasoning": "CLI flag for filtering logs by absolute timestamp"
        },
        {
          "term": "--timestamps",
          "tier": 3,
          "reasoning": "CLI flag for including timestamps in log output"
        },
        {
          "term": "--insecure-skip-tls-verify-backend",
          "tier": 3,
          "reasoning": "CLI flag for bypassing TLS verification for backend connections"
        },
        {
          "term": "-l",
          "tier": 3,
          "reasoning": "CLI flag shorthand for label selector"
        },
        {
          "term": "snapshot logs",
          "tier": 2,
          "reasoning": "Technical concept describing point-in-time log retrieval vs streaming"
        },
        {
          "term": "streaming",
          "tier": 2,
          "reasoning": "Technical concept for continuous real-time log following"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol referenced in --insecure-skip-tls-verify-backend"
        },
        {
          "term": "serving certificate",
          "tier": 2,
          "reasoning": "TLS certificate concept used for kubelet authentication"
        },
        {
          "term": "terminated",
          "tier": 2,
          "reasoning": "Container lifecycle state for retrieving previous container logs"
        },
        {
          "term": "app=nginx",
          "tier": 2,
          "reasoning": "Label selector syntax example for filtering pods"
        },
        {
          "term": "multi containers",
          "tier": 2,
          "reasoning": "Concept of pods containing multiple containers"
        },
        {
          "term": "nginx-1",
          "tier": 1,
          "reasoning": "Specific container name used in deployment example"
        },
        {
          "term": "hello",
          "tier": 1,
          "reasoning": "Specific job name used in example"
        },
        {
          "term": "UTC",
          "tier": 3,
          "reasoning": "Timezone standard used in timestamp specification"
        }
      ],
      "term_count": 38,
      "generated_at": "2026-02-08T21:27:16.470359",
      "elapsed_time": 17.93152356147766
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec6",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Ingress class",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "Ingresses can be implemented by different controllers, often with different\nconfiguration. Each Ingress should specify a class, a reference to an\nIngressClass resource that contains additional configuration including the name\nof the controller that should implement the class.\n\n{{% code_sample file=\"service/networking/external-lb.yaml\" %}}\n\nThe `.spec.parameters` field of an IngressClass lets you reference another\nresource that provides configuration related to that IngressClass.\n\nThe specific type of parameters to use depends on the ingress controller\nthat you specify in the `.spec.controller` field of the IngressClass.\n\n### IngressClass scope\n\nDepending on your ingress controller, you may be able to use parameters\nthat you set cluster-wide, or just for one namespace.\n\n{{< tabs name=\"tabs_ingressclass_parameter_scope\" >}}\n{{% tab name=\"Cluster\" %}}\nThe default scope for IngressClass parameters is cluster-wide.\n\nIf you set the `.spec.parameters` field and don't set\n`.spec.parameters.scope`, or if you set `.spec.parameters.scope` to\n`Cluster`, then the IngressClass refers to a cluster-scoped resource.\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a cluster-scoped API (possibly a custom resource), and\nthe `name` of the parameters identifies a specific cluster scoped\nresource for that API.\n\nFor example:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-1\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in a\n    # ClusterIngressParameter (API group k8s.example.net) named\n    # \"external-config-1\". This definition tells Kubernetes to\n    # look for a cluster-scoped parameter resource.\n    scope: Cluster\n    apiGroup: k8s.example.net\n    kind: ClusterIngressParameter\n    name: external-config-1\n```\n\n{{% /tab %}}\n{{% tab name=\"Namespaced\" %}}\n{{< feature-state for_k8s_version=\"v1.23\" state=\"stable\" >}}\n\nIf you set the `.spec.parameters` field and set\n`.spec.parameters.scope` to `Namespace`, then the IngressClass refers\nto a namespaced-scoped resource. You must also set the `namespace`\nfield within `.spec.parameters` to the namespace that contains\nthe parameters you want to use.\n\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a namespaced API (for example: ConfigMap), and\nthe `name` of the parameters identifies a specific resource\nin the namespace you specified in `namespace`.\n\nNamespace-scoped parameters help the cluster operator delegate control over the\nconfiguration (for example: load balancer settings, API gateway definition)\nthat is used for a workload. If you used a cluster-scoped parameter then either:\n\n- the cluster operator team needs to approve a different team's changes every\n  time there's a new configuration change being applied.\n- the cluster operator must define specific access controls, such as\n  [RBAC](/docs/reference/access-authn-authz/rbac/) roles and bindings, that let\n  the application team make changes to the cluster-scoped parameters resource.\n\nThe IngressClass API itself is always cluster-scoped.\n\nHere is an example of an IngressClass that refers to parameters that are\nnamespaced:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-2\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in an\n    # IngressParameter (API group k8s.example.com) named \"external-config\",\n    # that's in the \"external-configuration\" namespace.\n    scope: Namespace\n    apiGroup: k8s.example.com\n    kind: IngressParameter\n    namespace: external-configuration\n    name: external-config\n```\n\n{{% /tab %}}\n{{< /tabs >}}\n\n### Deprecated annotation\n\nBefore the IngressClass resource and `ingressClassName` field were added in\nKubernetes 1.18, Ingress classes were specified with a\n`kubernetes.io/ingress.class` annotation on the Ingress. This annotation was\nnever formally defined, but was widely supported by Ingress controllers.\n\nThe newer `ingressClassName` field on Ingresses is a replacement for that\nannotation, but is not a direct equivalent. While the annotation was generally\nused to reference the name of the Ingress controller that should implement the\nIngress, the field is a reference to an IngressClass resource that contains\nadditional Ingress configuration, including the name of the Ingress controller.\n\n### Default IngressClass {#default-ingress-class}\n\nYou can mark a particular IngressClass as default for your cluster. Setting the\n`ingressclass.kubernetes.io/is-default-class` annotation to `true` on an\nIngressClass resource will ensure that new Ingresses without an\n`ingressClassName` field specified will be assigned this default IngressClass.\n\n{{< caution >}}\nIf you have more than one IngressClass marked as the default for your cluster,\nthe admission controller prevents creating new Ingress objects that don't have\nan `ingressClassName` specified. You can resolve this by ensuring that at most 1\nIngressClass is marked as default in your cluster.\n{{< /caution >}}\n\nStart by defining a\ndefault IngressClass. It is recommended though, to specify the default\nIngressClass:\n\n{{% code_sample file=\"service/networking/default-ingressclass.yaml\" %}}",
      "terms": [
        {
          "term": "Ingresses",
          "tier": 1,
          "reasoning": "Kubernetes API resource for managing external access to services in a cluster."
        },
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Kubernetes API object that manages external access to services, typically HTTP."
        },
        {
          "term": "controllers",
          "tier": 2,
          "reasoning": "Components that implement the control loop pattern to manage Kubernetes resources."
        },
        {
          "term": "IngressClass",
          "tier": 1,
          "reasoning": "Kubernetes API resource that contains configuration for Ingress controllers."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "A component that watches the state of the cluster and makes changes to move toward desired state."
        },
        {
          "term": ".spec.parameters",
          "tier": 1,
          "reasoning": "Specific field path in IngressClass resource for referencing configuration parameters."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "A Kubernetes API object that represents cluster state."
        },
        {
          "term": "ingress controller",
          "tier": 1,
          "reasoning": "Controller that fulfills Ingress resources, typically with a load balancer."
        },
        {
          "term": ".spec.controller",
          "tier": 1,
          "reasoning": "Field in IngressClass that specifies which controller should implement the class."
        },
        {
          "term": "IngressClass scope",
          "tier": 2,
          "reasoning": "Concept describing whether IngressClass parameters are cluster-wide or namespace-scoped."
        },
        {
          "term": "cluster-wide",
          "tier": 2,
          "reasoning": "Scope indicating a resource or configuration applies across the entire cluster."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for isolating groups of resources within a cluster."
        },
        {
          "term": "cluster-scoped",
          "tier": 2,
          "reasoning": "Resources that exist at the cluster level rather than within a namespace."
        },
        {
          "term": ".spec.parameters.scope",
          "tier": 1,
          "reasoning": "Field that determines whether IngressClass parameters are cluster or namespace scoped."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Scope value indicating cluster-wide parameter reference."
        },
        {
          "term": "cluster-scoped resource",
          "tier": 2,
          "reasoning": "A Kubernetes resource that is not namespaced and exists at cluster level."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource."
        },
        {
          "term": "apiGroup",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the API group a resource belongs to."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Extension of the Kubernetes API that allows users to define their own resource types."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for networking resources."
        },
        {
          "term": "ClusterIngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for cluster-scoped Ingress parameters."
        },
        {
          "term": "Namespaced",
          "tier": 2,
          "reasoning": "Scope value indicating namespace-level parameter reference."
        },
        {
          "term": "namespaced-scoped resource",
          "tier": 2,
          "reasoning": "A Kubernetes resource that exists within a specific namespace."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object used to store non-confidential configuration data."
        },
        {
          "term": "cluster operator",
          "tier": 2,
          "reasoning": "Role responsible for managing and operating a Kubernetes cluster."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Component that distributes network traffic across multiple servers."
        },
        {
          "term": "API gateway",
          "tier": 2,
          "reasoning": "Service that manages API traffic and provides features like routing and authentication."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "An application running on Kubernetes, typically as pods."
        },
        {
          "term": "RBAC",
          "tier": 1,
          "reasoning": "Role-Based Access Control - Kubernetes authorization mechanism."
        },
        {
          "term": "roles",
          "tier": 2,
          "reasoning": "RBAC resources that define permissions within a namespace."
        },
        {
          "term": "bindings",
          "tier": 2,
          "reasoning": "RBAC resources that associate roles with users or service accounts."
        },
        {
          "term": "IngressClass API",
          "tier": 1,
          "reasoning": "The Kubernetes API for IngressClass resources."
        },
        {
          "term": "IngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for namespaced Ingress parameters."
        },
        {
          "term": "ingressClassName",
          "tier": 1,
          "reasoning": "Field in Ingress spec that references an IngressClass."
        },
        {
          "term": "kubernetes.io/ingress.class",
          "tier": 1,
          "reasoning": "Deprecated annotation used to specify Ingress class before IngressClass resource existed."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata attached to objects for non-identifying information."
        },
        {
          "term": "Kubernetes 1.18",
          "tier": 2,
          "reasoning": "Specific Kubernetes version when IngressClass resource was introduced."
        },
        {
          "term": "v1.23",
          "tier": 2,
          "reasoning": "Kubernetes version when namespaced IngressClass parameters became stable."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready functionality."
        },
        {
          "term": "access controls",
          "tier": 2,
          "reasoning": "Mechanisms for controlling who can access or modify resources."
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T21:27:37.702942",
      "elapsed_time": 20.223953008651733
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec3",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "JSONSchemaProps {#JSONSchemaProps}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "JSONSchemaProps is a JSON-Schema following Specification Draft 4 (http://json-schema.org/).\n\n<hr>\n\n- **$ref** (string)\n\n\n- **$schema** (string)\n\n\n- **additionalItems** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **additionalProperties** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **allOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **anyOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **default** (JSON)\n\n  default is a default value for undefined object fields. Defaulting is a beta feature under the CustomResourceDefaulting feature gate. Defaulting requires spec.preserveUnknownFields to be false.\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **definitions** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **dependencies** (map[string]JSONSchemaPropsOrStringArray)\n\n\n  <a name=\"JSONSchemaPropsOrStringArray\"></a>\n  *JSONSchemaPropsOrStringArray represents a JSONSchemaProps or a string array.*\n\n- **description** (string)\n\n\n- **enum** ([]JSON)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **example** (JSON)\n\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **exclusiveMaximum** (boolean)\n\n\n- **exclusiveMinimum** (boolean)\n\n\n- **externalDocs** (ExternalDocumentation)\n\n\n  <a name=\"ExternalDocumentation\"></a>\n  *ExternalDocumentation allows referencing an external resource for extended documentation.*\n\n  - **externalDocs.description** (string)\n\n\n  - **externalDocs.url** (string)\n\n\n- **format** (string)\n\n  format is an OpenAPI v3 format string. Unknown formats are ignored. The following formats are validated:\n  \n  - bsonobjectid: a bson object ID, i.e. a 24 characters hex string - uri: an URI as parsed by Golang net/url.ParseRequestURI - email: an email address as parsed by Golang net/mail.ParseAddress - hostname: a valid representation for an Internet host name, as defined by RFC 1034, section 3.1 [RFC1034]. - ipv4: an IPv4 IP as parsed by Golang net.ParseIP - ipv6: an IPv6 IP as parsed by Golang net.ParseIP - cidr: a CIDR as parsed by Golang net.ParseCIDR - mac: a MAC address as parsed by Golang net.ParseMAC - uuid: an UUID that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid3: an UUID3 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?3[0-9a-f]{3}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid4: an UUID4 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?4[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - uuid5: an UUID5 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?5[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - isbn: an ISBN10 or ISBN13 number string like \"0321751043\" or \"978-0321751041\" - isbn10: an ISBN10 number string like \"0321751043\" - isbn13: an ISBN13 number string like \"978-0321751041\" - creditcard: a credit card number defined by the regex ^(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|6(?:011|5[0-9][0-9])[0-9]{12}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|(?:2131|1800|35\\\\d{3})\\\\d{11})$ with any non digit characters mixed in - ssn: a U.S. social security number following the regex ^\\\\d{3}[- ]?\\\\d{2}[- ]?\\\\d{4}$ - hexcolor: an hexadecimal color code like \"#FFFFFF: following the regex ^#?([0-9a-fA-F]{3}|[0-9a-fA-F]{6})$ - rgbcolor: an RGB color code like rgb like \"rgb(255,255,2559\" - byte: base64 encoded binary data - password: any kind of string - date: a date string like \"2006-01-02\" as defined by full-date in RFC3339 - duration: a duration string like \"22 ns\" as parsed by Golang time.ParseDuration or compatible with Scala duration format - datetime: a date time string like \"2014-12-15T19:30:20.000Z\" as defined by date-time in RFC3339.\n\n- **id** (string)\n\n\n- **items** (JSONSchemaPropsOrArray)\n\n\n  <a name=\"JSONSchemaPropsOrArray\"></a>\n  *JSONSchemaPropsOrArray represents a value that can either be a JSONSchemaProps or an array of JSONSchemaProps. Mainly here for serialization purposes.*\n\n- **maxItems** (int64)\n\n\n- **maxLength** (int64)\n\n\n- **maxProperties** (int64)\n\n\n- **maximum** (double)\n\n\n- **minItems** (int64)\n\n\n- **minLength** (int64)\n\n\n- **minProperties** (int64)\n\n\n- **minimum** (double)\n\n\n- **multipleOf** (double)\n\n\n- **not** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **nullable** (boolean)\n\n\n- **oneOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **pattern** (string)\n\n\n- **patternProperties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **properties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **required** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **title** (string)\n\n\n- **type** (string)\n\n\n- **uniqueItems** (boolean)\n\n\n- **x-kubernetes-embedded-resource** (boolean)\n\n  x-kubernetes-embedded-resource defines that the value is an embedded Kubernetes runtime.Object, with TypeMeta and ObjectMeta. The type must be object. It is allowed to further restrict the embedded object. kind, apiVersion and metadata are validated automatically. x-kubernetes-preserve-unknown-fields is allowed to be true, but does not have to be if the object is fully specified (up to kind, apiVersion, metadata).\n\n- **x-kubernetes-int-or-string** (boolean)\n\n  x-kubernetes-int-or-string specifies that this value is either an integer or a string. If this is true, an empty type is allowed and type as child of anyOf is permitted if following one of the following patterns:\n  \n  1) anyOf:\n     - type: integer\n     - type: string\n  2) allOf:\n     - anyOf:\n       - type: integer\n       - type: string\n     - ... zero or more\n\n- **x-kubernetes-list-map-keys** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  x-kubernetes-list-map-keys annotates an array with the x-kubernetes-list-type `map` by specifying the keys used as the index of the map.\n  \n  This tag MUST only be used on lists that have the \"x-kubernetes-list-type\" extension set to \"map\". Also, the values specified for this attribute must be a scalar typed field of the child structure (no nesting is supported).\n  \n  The properties specified must either be required or have a default value, to ensure those properties are present for all list items.\n\n- **x-kubernetes-list-type** (string)\n\n  x-kubernetes-list-type annotates an array to further describe its topology. This extension must only be used on lists and may have 3 possible values:\n  \n  1) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic lists will be entirely replaced when updated. This extension\n       may be used on any type of list (struct, scalar, ...).\n  2) `set`:\n       Sets are lists that must not have multiple items with the same value. Each\n       value must be a scalar, an object with x-kubernetes-map-type `atomic` or an\n       array with x-kubernetes-list-type `atomic`.\n  3) `map`:\n       These lists are like maps in that their elements have a non-index key\n       used to identify them. Order is preserved upon merge. The map tag\n       must only be used on a list with elements of type object.\n  Defaults to atomic for arrays.\n\n- **x-kubernetes-map-type** (string)\n\n  x-kubernetes-map-type annotates an object to further describe its topology. This extension must only be used when type is object and may have 2 possible values:\n  \n  1) `granular`:\n       These maps are actual maps (key-value pairs) and each fields are independent\n       from each other (they can each be manipulated by separate actors). This is\n       the default behaviour for all maps.\n  2) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic maps will be entirely replaced when updated.\n\n- **x-kubernetes-preserve-unknown-fields** (boolean)\n\n  x-kubernetes-preserve-unknown-fields stops the API server decoding step from pruning fields which are not specified in the validation schema. This affects fields recursively, but switches back to normal pruning behaviour if nested properties or additionalProperties are specified in the schema. This can either be true or undefined. False is forbidden.\n\n- **x-kubernetes-validations** ([]ValidationRule)\n\n  *Patch strategy: merge on key `rule`*\n  \n  *Map: unique values on key rule will be kept during a merge*\n  \n  x-kubernetes-validations describes a list of validation rules written in the CEL expression language.\n\n  <a name=\"ValidationRule\"></a>\n  *ValidationRule describes a validation rule written in the CEL expression language.*\n\n  - **x-kubernetes-validations.rule** (string), required\n\n    Rule represents the expression which will be evaluated by CEL. ref: https://github.com/google/cel-spec The Rule is scoped to the location of the x-kubernetes-validations extension in the schema. The `self` variable in the CEL expression is bound to the scoped value. Example: - Rule scoped to the root of a resource with a status subresource: {\"rule\": \"self.status.actual \\<= self.spec.maxDesired\"}\n    \n    If the Rule is scoped to an object with properties, the accessible properties of the object are field selectable via `self.field` and field presence can be checked via `has(self.field)`. Null valued fields are treated as absent fields in CEL expressions. If the Rule is scoped to an object with additionalProperties (i.e. a map) the value of the map are accessible via `self[mapKey]`, map containment can be checked via `mapKey in self` and all entries of the map are accessible via CEL macros and functions such as `self.all(...)`. If the Rule is scoped to an array, the elements of the array are accessible via `self[i]` and also by macros and functions. If the Rule is scoped to a scalar, `self` is bound to the scalar value. Examples: - Rule scoped to a map of objects: {\"rule\": \"self.components['Widget'].priority \\< 10\"} - Rule scoped to a list of integers: {\"rule\": \"self.values.all(value, value >= 0 && value \\< 100)\"} - Rule scoped to a string value: {\"rule\": \"self.startsWith('kube')\"}\n    \n    The `apiVersion`, `kind`, `metadata.name` and `metadata.generateName` are always accessible from the root of the object and from any x-kubernetes-embedded-resource annotated objects. No other metadata properties are accessible.\n    \n    Unknown data preserved in custom resources via x-kubernetes-preserve-unknown-fields is not accessible in CEL expressions. This includes: - Unknown field values that are preserved by object schemas with x-kubernetes-preserve-unknown-fields. - Object properties where the property schema is of an \"unknown type\". An \"unknown type\" is recursively defined as:\n      - A schema with no type and x-kubernetes-preserve-unknown-fields set to true\n      - An array where the items schema is of an \"unknown type\"\n      - An object where the additionalProperties schema is of an \"unknown type\"\n    \n    Only property names of the form `[a-zA-Z_.-/][a-zA-Z0-9_.-/]*` are accessible. Accessible property names are escaped according to the following rules when accessed in the expression: - '__' escapes to '__underscores__' - '.' escapes to '__dot__' - '-' escapes to '__dash__' - '/' escapes to '__slash__' - Property names that exactly match a CEL RESERVED keyword escape to '__{keyword}__'. The keywords are:\n    \t  \"true\", \"false\", \"null\", \"in\", \"as\", \"break\", \"const\", \"continue\", \"else\", \"for\", \"function\", \"if\",\n    \t  \"import\", \"let\", \"loop\", \"package\", \"namespace\", \"return\".\n    Examples:\n      - Rule accessing a property named \"namespace\": {\"rule\": \"self.__namespace__ > 0\"}\n      - Rule accessing a property named \"x-prop\": {\"rule\": \"self.x__dash__prop > 0\"}\n      - Rule accessing a property named \"redact__d\": {\"rule\": \"self.redact__underscores__d > 0\"}\n    \n    Equality on arrays with x-kubernetes-list-type of 'set' or 'map' ignores element order, i.e. [1, 2] == [2, 1]. Concatenation on arrays with x-kubernetes-list-type use the semantics of the list type:\n      - 'set': `X + Y` performs a union where the array positions of all elements in `X` are preserved and\n        non-intersecting elements in `Y` are appended, retaining their partial order.\n      - 'map': `X + Y` performs a merge where the array positions of all keys in `X` are preserved but the values\n        are overwritten by values in `Y` when the key sets of `X` and `Y` intersect. Elements in `Y` with\n        non-intersecting keys are appended, retaining their partial order.\n    \n    If `rule` makes use of the `oldSelf` variable it is implicitly a `transition rule`.\n    \n    By default, the `oldSelf` variable is the same type as `self`. When `optionalOldSelf` is true, the `oldSelf` variable is a CEL optional\n     variable whose value() is the same type as `self`.\n    See the documentation for the `optionalOldSelf` field for details.\n    \n    Transition rules by default are applied only on UPDATE requests and are skipped if an old value could not be found. You can opt a transition rule into unconditional evaluation by setting `optionalOldSelf` to true.\n\n  - **x-kubernetes-validations.fieldPath** (string)\n\n    fieldPath represents the field path returned when the validation fails. It must be a relative JSON path (i.e. with array notation) scoped to the location of this x-kubernetes-validations extension in the schema and refer to an existing field. e.g. when validation checks if a specific attribute `foo` under a map `testMap`, the fieldPath could be set to `.testMap.foo` If the validation checks two lists must have unique attributes, the fieldPath could be set to either of the list: e.g. `.testList` It does not support list numeric index. It supports child operation to refer to an existing field currently. Refer to [JSONPath support in Kubernetes](https://kubernetes.io/docs/reference/kubectl/jsonpath/) for more info. Numeric index of array is not supported. For field name which contains special characters, use `['specialName']` to refer the field name. e.g. for attribute `foo.34$` appears in a list `testList`, the fieldPath could be set to `.testList['foo.34$']`\n\n  - **x-kubernetes-validations.message** (string)\n\n    Message represents the message displayed when validation fails. The message is required if the Rule contains line breaks. The message must not contain line breaks. If unset, the message is \"failed rule: {Rule}\". e.g. \"must be a URL with the host matching spec.host\"\n\n  - **x-kubernetes-validations.messageExpression** (string)\n\n    MessageExpression declares a CEL expression that evaluates to the validation failure message that is returned when this rule fails. Since messageExpression is used as a failure message, it must evaluate to a string. If both message and messageExpression are present on a rule, then messageExpression will be used if validation fails. If messageExpression results in a runtime error, the runtime error is logged, and the validation failure message is produced as if the messageExpression field were unset. If messageExpression evaluates to an empty string, a string with only spaces, or a string that contains line breaks, then the validation failure message will also be produced as if the messageExpression field were unset, and the fact that messageExpression produced an empty string/string with only spaces/string with line breaks will be logged. messageExpression has access to all the same variables as the rule; the only difference is the return type. Example: \"x must be less than max (\"+string(self.max)+\")\"\n\n  - **x-kubernetes-validations.optionalOldSelf** (boolean)\n\n    optionalOldSelf is used to opt a transition rule into evaluation even when the object is first created, or if the old object is missing the value.\n    \n    When enabled `oldSelf` will be a CEL optional whose value will be `None` if there is no old value, or when the object is initially created.\n    \n    You may check for presence of oldSelf using `oldSelf.hasValue()` and unwrap it after checking using `oldSelf.value()`. Check the CEL documentation for Optional types for more information: https://pkg.go.dev/github.com/google/cel-go/cel#OptionalTypes\n    \n    May not be set unless `oldSelf` is used in `rule`.\n\n  - **x-kubernetes-validations.reason** (string)\n\n    reason provides a machine-readable validation failure reason that is returned to the caller when a request fails this validation rule. The HTTP status code returned to the caller will match the reason of the reason of the first failed validation rule. The currently supported reasons are: \"FieldValueInvalid\", \"FieldValueForbidden\", \"FieldValueRequired\", \"FieldValueDuplicate\". If not set, default to use \"FieldValueInvalid\". All future added reasons must be accepted by clients when reading this value and unknown reasons should be treated as FieldValueInvalid.\n    \n    Possible enum values:\n     - `\"FieldValueDuplicate\"` is used to report collisions of values that must be unique (e.g. unique IDs).\n     - `\"FieldValueForbidden\"` is used to report valid (as per formatting rules) values which would be accepted under some conditions, but which are not permitted by the current conditions (such as security policy).\n     - `\"FieldValueInvalid\"` is used to report malformed values (e.g. failed regex match, too long, out of bounds).\n     - `\"FieldValueRequired\"` is used to report required values that are not provided (e.g. empty strings, null values, or empty arrays).",
      "terms": [
        {
          "term": "JSONSchemaProps",
          "tier": 1,
          "reasoning": "Core API object type for defining JSON Schema properties in Kubernetes CRDs"
        },
        {
          "term": "JSON-Schema",
          "tier": 2,
          "reasoning": "Domain standard specification that JSONSchemaProps follows"
        },
        {
          "term": "Specification Draft 4",
          "tier": 2,
          "reasoning": "Specific version of JSON Schema specification referenced"
        },
        {
          "term": "$ref",
          "tier": 3,
          "reasoning": "JSON Schema keyword for referencing other schemas"
        },
        {
          "term": "$schema",
          "tier": 3,
          "reasoning": "JSON Schema keyword for declaring schema version"
        },
        {
          "term": "additionalItems",
          "tier": 2,
          "reasoning": "JSON Schema property for controlling additional array items validation"
        },
        {
          "term": "JSONSchemaPropsOrBool",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or boolean value"
        },
        {
          "term": "additionalProperties",
          "tier": 2,
          "reasoning": "JSON Schema property for controlling additional object properties validation"
        },
        {
          "term": "allOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical AND"
        },
        {
          "term": "Atomic",
          "tier": 2,
          "reasoning": "Kubernetes merge strategy annotation indicating replacement during merge"
        },
        {
          "term": "anyOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical OR"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "JSON Schema property for specifying default values for undefined fields"
        },
        {
          "term": "JSON",
          "tier": 2,
          "reasoning": "Data format type representing valid JSON values in the schema"
        },
        {
          "term": "CustomResourceDefaulting",
          "tier": 1,
          "reasoning": "Kubernetes feature gate controlling defaulting behavior for custom resources"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling features"
        },
        {
          "term": "spec.preserveUnknownFields",
          "tier": 1,
          "reasoning": "Kubernetes CRD spec field controlling unknown field preservation"
        },
        {
          "term": "definitions",
          "tier": 2,
          "reasoning": "JSON Schema keyword for reusable schema definitions"
        },
        {
          "term": "dependencies",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining property dependencies"
        },
        {
          "term": "JSONSchemaPropsOrStringArray",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or string array"
        },
        {
          "term": "description",
          "tier": 3,
          "reasoning": "JSON Schema property for human-readable descriptions"
        },
        {
          "term": "enum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining allowed values"
        },
        {
          "term": "example",
          "tier": 3,
          "reasoning": "JSON Schema property for providing example values"
        },
        {
          "term": "exclusiveMaximum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive upper bound validation"
        },
        {
          "term": "exclusiveMinimum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive lower bound validation"
        },
        {
          "term": "externalDocs",
          "tier": 2,
          "reasoning": "OpenAPI/JSON Schema property for external documentation references"
        },
        {
          "term": "ExternalDocumentation",
          "tier": 1,
          "reasoning": "Kubernetes type for referencing external documentation resources"
        },
        {
          "term": "format",
          "tier": 2,
          "reasoning": "JSON Schema/OpenAPI property for string format validation"
        },
        {
          "term": "OpenAPI v3",
          "tier": 2,
          "reasoning": "API specification standard that defines format strings"
        },
        {
          "term": "bsonobjectid",
          "tier": 3,
          "reasoning": "Format string for BSON object ID validation"
        },
        {
          "term": "uri",
          "tier": 3,
          "reasoning": "Format string for URI validation"
        },
        {
          "term": "email",
          "tier": 3,
          "reasoning": "Format string for email address validation"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Format string for Internet host name validation"
        },
        {
          "term": "RFC 1034",
          "tier": 3,
          "reasoning": "Internet standard defining hostname format"
        },
        {
          "term": "ipv4",
          "tier": 3,
          "reasoning": "Format string for IPv4 address validation"
        },
        {
          "term": "ipv6",
          "tier": 3,
          "reasoning": "Format string for IPv6 address validation"
        },
        {
          "term": "cidr",
          "tier": 3,
          "reasoning": "Format string for CIDR notation validation"
        },
        {
          "term": "mac",
          "tier": 3,
          "reasoning": "Format string for MAC address validation"
        },
        {
          "term": "uuid",
          "tier": 3,
          "reasoning": "Format string for UUID validation"
        },
        {
          "term": "uuid3",
          "tier": 3,
          "reasoning": "Format string for UUID version 3 validation"
        },
        {
          "term": "uuid4",
          "tier": 3,
          "reasoning": "Format string for UUID version 4 validation"
        },
        {
          "term": "uuid5",
          "tier": 3,
          "reasoning": "Format string for UUID version 5 validation"
        },
        {
          "term": "isbn",
          "tier": 3,
          "reasoning": "Format string for ISBN number validation"
        },
        {
          "term": "isbn10",
          "tier": 3,
          "reasoning": "Format string for ISBN-10 number validation"
        },
        {
          "term": "isbn13",
          "tier": 3,
          "reasoning": "Format string for ISBN-13 number validation"
        },
        {
          "term": "creditcard",
          "tier": 3,
          "reasoning": "Format string for credit card number validation"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating defaulting is a beta feature"
        },
        {
          "term": "custom-resource-definition-v1",
          "tier": 1,
          "reasoning": "Reference to CustomResourceDefinition API version"
        },
        {
          "term": "extend-resources",
          "tier": 2,
          "reasoning": "Kubernetes documentation category for resource extension mechanisms"
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "int64",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "float64",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "regex",
          "tier": 3,
          "reasoning": "Regular expression pattern used for format validation"
        }
      ],
      "term_count": 53,
      "generated_at": "2026-02-08T21:28:00.199041",
      "elapsed_time": 21.482445240020752
    },
    {
      "chunk_id": "concepts_storage_volume-pvc-datasource_sec0",
      "doc_id": "concepts_storage_volume-pvc-datasource",
      "heading": "Introduction",
      "source_file": "concepts_storage_volume-pvc-datasource.md",
      "content": "---\nreviewers:\n- jsafrane\n- saad-ali\n- thockin\n- msau42\ntitle: CSI Volume Cloning\ncontent_type: concept\nweight: 70\n---\n\n<!-- overview -->\n\nThis document describes the concept of cloning existing CSI Volumes in Kubernetes.\nFamiliarity with [Volumes](/docs/concepts/storage/volumes) is suggested.\n\n<!-- body -->",
      "terms": [
        {
          "term": "CSI",
          "tier": 1,
          "reasoning": "Container Storage Interface - a core Kubernetes storage standard/protocol for volume plugins."
        },
        {
          "term": "CSI Volumes",
          "tier": 1,
          "reasoning": "Specific Kubernetes storage resource type using the Container Storage Interface."
        },
        {
          "term": "CSI Volume Cloning",
          "tier": 2,
          "reasoning": "A specific Kubernetes storage feature/process for duplicating CSI-based volumes."
        },
        {
          "term": "Volumes",
          "tier": 1,
          "reasoning": "Core Kubernetes storage API object/resource for persistent data."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "cloning",
          "tier": 2,
          "reasoning": "Technical process of duplicating storage volumes in the Kubernetes context."
        }
      ],
      "term_count": 6,
      "generated_at": "2026-02-08T21:28:08.506096",
      "elapsed_time": 7.297876834869385
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_run__index_sec3",
      "doc_id": "reference_kubectl_generated_kubectl_run__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_run__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--allow-missing-template-keys&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--annotations strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Annotations to apply to the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--attach</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for the Pod to start running, and then attach to the Pod as if 'kubectl attach ...' were called.  Default false, unless '-i/--stdin' is set, in which case the default is true. With '--restart=Never' the exit code of the container process is returned.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cascade string[=\"background\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"background\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;background&quot;, &quot;orphan&quot;, or &quot;foreground&quot;. Selects the deletion cascading strategy for the dependents (e.g. Pods created by a ReplicationController). Defaults to background.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--command</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true and extra arguments are present, use them as the 'command' field in the container, rather than the 'args' field which is the default.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--dry-run string[=\"unchanged\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;none&quot;, &quot;server&quot;, or &quot;client&quot;. If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--env strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Environment variables to set in the container.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--expose --port</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, create a ClusterIP service associated with the pod.  Requires --port.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--field-manager string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"kubectl-run\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the manager used to track field ownership.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-f, --filename strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>to use to replace the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--force</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, immediately remove resources from API and bypass graceful deletion. Note that immediate deletion of some resources may result in inconsistency or data loss and requires confirmation.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--grace-period int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: -1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Period of time in seconds given to the resource to terminate gracefully. Ignored if negative. Set to 1 for immediate shutdown. Can only be set to 0 when --force is true (force deletion).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for run</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image for the container to run.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image-pull-policy string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image pull policy for the container.  If left empty, this value will not be specified by the client and defaulted by the server.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-k, --kustomize string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process a kustomization directory. This flag can't be used together with -f or -R.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-l, --labels string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Comma separated labels to apply to the pod. Will override previous values.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--leave-stdin-open</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If the pod is started in interactive mode or with stdin, leave stdin open after the first attach completes. By default, stdin will be closed after the first attach completes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-o, --output string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Output format. One of: (json, yaml, kyaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--override-type string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"merge\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The method used to override the generated object: json, merge, or strategic.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--overrides string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>An inline JSON override for the generated object. If this is non-empty, it is used to override the generated object. Requires that the object supply a valid apiVersion field.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--pod-running-timeout duration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1m0s</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time (like 5s, 2m, or 3h, higher than zero) to wait until at least one pod is running</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--port string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The port that this container exposes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--privileged</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, run the container in privileged mode.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-q, --quiet</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, suppress prompt messages.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-R, --recursive</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--restart string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"Always\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The restart policy for this Pod.  Legal values [Always, OnFailure, Never].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--rm</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, delete the pod after it exits.  Only valid when attaching to the container, e.g. with '--attach' or with '-i/--stdin'.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--save-config</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the configuration of current object will be saved in its annotation. Otherwise, the annotation will be unchanged. This flag is useful when you want to perform kubectl apply on this object in the future.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--show-managed-fields</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, keep the managedFields when printing objects in JSON or YAML format.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-i, --stdin</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Keep stdin open on the container in the pod, even if nothing is attached.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--template string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--timeout duration</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time to wait before giving up on a delete, zero means determine a timeout from the size of the object</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-t, --tty</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Allocate a TTY for the container in the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--wait</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for resources to be gone before returning. This waits for finalizers.</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Kubernetes API object that ensures a specified number of pod replicas are running."
        },
        {
          "term": "ClusterIP service",
          "tier": 1,
          "reasoning": "Specific Kubernetes Service type that exposes the service on a cluster-internal IP."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool, referenced as 'kubectl attach' and 'kubectl-run'."
        },
        {
          "term": "kubectl attach",
          "tier": 1,
          "reasoning": "Specific kubectl command for attaching to a running container."
        },
        {
          "term": "kubectl-run",
          "tier": 1,
          "reasoning": "Field manager name for the kubectl run command."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing an isolated runtime environment for applications."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Technical concept for output formatting in golang and jsonpath contexts."
        },
        {
          "term": "golang",
          "tier": 3,
          "reasoning": "Programming language referenced as an output format type."
        },
        {
          "term": "jsonpath",
          "tier": 2,
          "reasoning": "Query language for JSON used as an output format in kubectl."
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching arbitrary non-identifying metadata to objects."
        },
        {
          "term": "cascade",
          "tier": 2,
          "reasoning": "Deletion strategy concept controlling how dependent resources are handled."
        },
        {
          "term": "deletion cascading strategy",
          "tier": 2,
          "reasoning": "Technical concept describing how dependents are deleted when a parent resource is removed."
        },
        {
          "term": "dependents",
          "tier": 2,
          "reasoning": "Technical term for resources that depend on a parent resource."
        },
        {
          "term": "dry-run",
          "tier": 2,
          "reasoning": "Operational mode that simulates an action without persisting changes."
        },
        {
          "term": "server-side request",
          "tier": 2,
          "reasoning": "Technical concept for requests processed by the API server."
        },
        {
          "term": "client strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where operations are simulated client-side only."
        },
        {
          "term": "server strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where requests are submitted to server without persisting."
        },
        {
          "term": "environment variables",
          "tier": 2,
          "reasoning": "Configuration mechanism for passing runtime settings to containers."
        },
        {
          "term": "field-manager",
          "tier": 2,
          "reasoning": "Server-side apply concept for tracking which manager owns which fields."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Concept in server-side apply for tracking who manages specific fields."
        },
        {
          "term": "graceful deletion",
          "tier": 2,
          "reasoning": "Kubernetes concept for allowing resources time to terminate cleanly."
        },
        {
          "term": "grace-period",
          "tier": 2,
          "reasoning": "Time period given to resources to terminate gracefully before forced deletion."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image that defines what runs inside a container."
        },
        {
          "term": "image-pull-policy",
          "tier": 2,
          "reasoning": "Policy controlling when container images are pulled from registries."
        },
        {
          "term": "stdin",
          "tier": 3,
          "reasoning": "Standard input stream, referenced as -i/--stdin flag for interactive mode."
        },
        {
          "term": "attach",
          "tier": 2,
          "reasoning": "Operation to connect to a running container's input/output streams."
        },
        {
          "term": "exit code",
          "tier": 3,
          "reasoning": "Process termination status returned by container processes."
        },
        {
          "term": "container process",
          "tier": 2,
          "reasoning": "The main process running inside a container."
        },
        {
          "term": "command",
          "tier": 2,
          "reasoning": "Container specification field defining the entrypoint command."
        },
        {
          "term": "args",
          "tier": 2,
          "reasoning": "Container specification field for arguments passed to the command."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Generic term for Kubernetes API objects that can be created and managed."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in context of removing resources from API."
        },
        {
          "term": "--port",
          "tier": 2,
          "reasoning": "CLI flag for specifying port configuration, required for expose functionality."
        },
        {
          "term": "force deletion",
          "tier": 2,
          "reasoning": "Immediate removal of resources bypassing graceful termination."
        },
        {
          "term": "output formats",
          "tier": 2,
          "reasoning": "Different ways kubectl can format command output (golang, jsonpath)."
        },
        {
          "term": "--restart=Never",
          "tier": 2,
          "reasoning": "Pod restart policy option that prevents automatic restarts."
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:28:32.448183",
      "elapsed_time": 22.93202257156372
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_patch__index_sec2",
      "doc_id": "reference_kubectl_generated_kubectl_patch__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_patch__index.md",
      "content": "```\n  # Partially update a node using a strategic merge patch, specifying the patch as JSON\n  kubectl patch node k8s-node-1 -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Partially update a node using a strategic merge patch, specifying the patch as YAML\n  kubectl patch node k8s-node-1 -p $'spec:\\n unschedulable: true'\n  \n  # Partially update a node identified by the type and name specified in \"node.json\" using strategic merge patch\n  kubectl patch -f node.json -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Update a container's image; spec.containers[*].name is required because it's a merge key\n  kubectl patch pod valid-pod -p '{\"spec\":{\"containers\":[{\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"}]}}'\n  \n  # Update a container's image using a JSON patch with positional arrays\n  kubectl patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"}]'\n  \n  # Update a deployment's replicas through the 'scale' subresource using a merge patch\n  kubectl patch deployment nginx-deployment --subresource='scale' --type='merge' -p '{\"spec\":{\"replicas\":2}}'\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout the documentation chunk."
        },
        {
          "term": "node",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing replicated applications."
        },
        {
          "term": "k8s-node-1",
          "tier": 1,
          "reasoning": "Specific node name used as an example in the commands."
        },
        {
          "term": "valid-pod",
          "tier": 1,
          "reasoning": "Specific pod name used as an example in the commands."
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific deployment name used as an example in the commands."
        },
        {
          "term": "kubernetes-serve-hostname",
          "tier": 1,
          "reasoning": "Specific container name used as an example in the patch command."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Kubernetes operation for partially updating resources without replacing them entirely."
        },
        {
          "term": "strategic merge patch",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch strategy that understands the schema of Kubernetes objects."
        },
        {
          "term": "JSON patch",
          "tier": 2,
          "reasoning": "RFC 6902 standard patch format supported by Kubernetes for precise updates."
        },
        {
          "term": "merge patch",
          "tier": 2,
          "reasoning": "Patch type that merges the provided fields with existing object fields."
        },
        {
          "term": "subresource",
          "tier": 2,
          "reasoning": "Kubernetes concept for accessing specific aspects of a resource like scale or status."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes subresource used to adjust the number of replicas."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Standard Kubernetes object field containing the desired state specification."
        },
        {
          "term": "unschedulable",
          "tier": 2,
          "reasoning": "Node spec field that prevents new pods from being scheduled on the node."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Spec field containing the list of containers in a pod."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container specification field defining the container image to run."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment/scale spec field defining the desired number of pod instances."
        },
        {
          "term": "merge key",
          "tier": 2,
          "reasoning": "Field used by strategic merge patch to identify list items for merging."
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Metadata field used as merge key for containers in strategic merge patch."
        },
        {
          "term": "positional arrays",
          "tier": 2,
          "reasoning": "JSON patch technique using array indices to target specific elements."
        },
        {
          "term": "JSON",
          "tier": 3,
          "reasoning": "Data format used for specifying patch content in kubectl commands."
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data format alternative to JSON for specifying patch content."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core concept in Kubernetes representing an isolated runtime environment."
        },
        {
          "term": "-p",
          "tier": 3,
          "reasoning": "kubectl patch flag for specifying the patch content."
        },
        {
          "term": "-f",
          "tier": 3,
          "reasoning": "kubectl flag for specifying a file containing resource definition."
        },
        {
          "term": "--type",
          "tier": 3,
          "reasoning": "kubectl patch flag for specifying the patch type (json, merge, strategic)."
        },
        {
          "term": "--subresource",
          "tier": 3,
          "reasoning": "kubectl flag for targeting a specific subresource of an object."
        },
        {
          "term": "node.json",
          "tier": 3,
          "reasoning": "Example file name containing node resource definition."
        },
        {
          "term": "op",
          "tier": 3,
          "reasoning": "JSON patch operation field specifying the action (replace, add, remove)."
        },
        {
          "term": "replace",
          "tier": 3,
          "reasoning": "JSON patch operation that replaces a value at a specified path."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "JSON patch field specifying the location in the object to modify."
        },
        {
          "term": "value",
          "tier": 3,
          "reasoning": "JSON patch field containing the new value to set."
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T21:28:50.369698",
      "elapsed_time": 16.91165852546692
    },
    {
      "chunk_id": "tasks_debug_debug-application_get-shell-running-container_sec0",
      "doc_id": "tasks_debug_debug-application_get-shell-running-container",
      "heading": "Introduction",
      "source_file": "tasks_debug_debug-application_get-shell-running-container.md",
      "content": "---\nreviewers:\n- caesarxuchao\n- mikedanese\ntitle: Get a Shell to a Running Container\ncontent_type: task\n---\n\n<!-- overview -->\n\nThis page shows how to use `kubectl exec` to get a shell to a\nrunning container.",
      "terms": [
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for executing commands in containers, a core Kubernetes CLI operation."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool, a core CLI component."
        },
        {
          "term": "exec",
          "tier": 2,
          "reasoning": "A specific kubectl command/operation for executing commands inside containers."
        },
        {
          "term": "shell",
          "tier": 2,
          "reasoning": "Technical term referring to command-line interface access to a container's environment."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes/containerization concept representing an isolated runtime environment."
        },
        {
          "term": "running container",
          "tier": 2,
          "reasoning": "Domain-specific phrase describing a container in active execution state."
        },
        {
          "term": "task",
          "tier": 3,
          "reasoning": "Content type classification indicating procedural documentation in Kubernetes docs."
        }
      ],
      "term_count": 7,
      "generated_at": "2026-02-08T21:28:57.468186",
      "elapsed_time": 6.08925724029541
    },
    {
      "chunk_id": "reference_glossary_host-aliases_sec0",
      "doc_id": "reference_glossary_host-aliases",
      "heading": "Introduction",
      "source_file": "reference_glossary_host-aliases.md",
      "content": "---\ntitle: HostAliases\nid: HostAliases\ndate: 2019-01-31\nfull_link: /docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core\nshort_description: >\n  A HostAliases is a mapping between the IP address and hostname to be injected into a Pod's hosts file.\n\naka:\ntags:\n- operation\n---\n A HostAliases is a mapping between the IP address and hostname to be injected into a {{< glossary_tooltip text=\"Pod\" term_id=\"pod\" >}}'s hosts file.\n\n<!--more-->\n\n[HostAliases](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core) is an optional list of hostnames and IP addresses that will be injected into the Pod's hosts file if specified. This is only valid for non-hostNetwork Pods.",
      "terms": [
        {
          "term": "HostAliases",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for mapping IP addresses to hostnames in Pod hosts files"
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that HostAliases is injected into"
        },
        {
          "term": "IP address",
          "tier": 2,
          "reasoning": "Network addressing concept that is mapped to hostnames in HostAliases"
        },
        {
          "term": "hostname",
          "tier": 2,
          "reasoning": "Network identity concept that IP addresses are mapped to in HostAliases"
        },
        {
          "term": "hosts file",
          "tier": 3,
          "reasoning": "Operating system file that HostAliases entries are injected into"
        },
        {
          "term": "hostNetwork",
          "tier": 2,
          "reasoning": "Kubernetes Pod networking mode that affects HostAliases validity"
        },
        {
          "term": "non-hostNetwork Pods",
          "tier": 2,
          "reasoning": "Specific Pod configuration context where HostAliases is valid"
        },
        {
          "term": "mapping",
          "tier": 3,
          "reasoning": "Technical concept describing the relationship between IP and hostname"
        },
        {
          "term": "injected",
          "tier": 3,
          "reasoning": "Technical process term describing how HostAliases entries are added to hosts file"
        },
        {
          "term": "v1-core",
          "tier": 2,
          "reasoning": "Kubernetes API version and group identifier for the HostAlias resource"
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API documentation and specification"
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T21:29:06.044698",
      "elapsed_time": 7.559743881225586
    },
    {
      "chunk_id": "concepts_scheduling-eviction_dynamic-resource-allocation_sec1",
      "doc_id": "concepts_scheduling-eviction_dynamic-resource-allocation",
      "heading": "About DRA {#about-dra}",
      "source_file": "concepts_scheduling-eviction_dynamic-resource-allocation.md",
      "content": "{{< glossary_definition prepend=\"DRA is\" term_id=\"dra\" length=\"all\" >}}\n\nAllocating resources with DRA is a similar experience to\n[dynamic volume provisioning](/docs/concepts/storage/dynamic-provisioning/), in\nwhich you use PersistentVolumeClaims to claim storage capacity from storage\nclasses and request the claimed capacity in your Pods.\n\n### Benefits of DRA {#dra-benefits}\n\nDRA provides a flexible way to categorize, request, and use devices in your\ncluster. Using DRA provides benefits like the following:\n\n* **Flexible device filtering**: use common expression language (CEL) to perform\n  fine-grained filtering for specific device attributes.\n* **Device sharing**: share the same resource with multiple containers or Pods\n  by referencing the corresponding resource claim.\n* **Centralized device categorization**: device drivers and cluster admins can\n  use device classes to provide app operators with hardware categories that are\n  optimized for various use cases. For example, you can create a cost-optimized\n  device class for general-purpose workloads, and a high-performance device\n  class for critical jobs.\n* **Simplified Pod requests**: with DRA, app operators don't need to specify\n  device quantities in Pod resource requests. Instead, the Pod references a\n  resource claim, and the device configuration in that claim applies to the Pod.\n\nThese benefits provide significant improvements in the device allocation\nworkflow when compared to\n[device plugins](/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/),\nwhich require per-container device requests, don't support device sharing, and\ndon't support expression-based device filtering.\n\n### Types of DRA users {#dra-user-types}\n\nThe workflow of using DRA to allocate devices involves the following types of\nusers:\n\n* **Device owner**: responsible for devices. Device owners might be commercial\n  vendors, the cluster operator, or another entity. To use DRA, devices must\n  have DRA-compatible drivers that do the following:\n\n  * Create ResourceSlices that provide Kubernetes with information about\n    nodes and resources.\n  * Update ResourceSlices when resource capacity in the cluster changes.\n  * Optionally, create DeviceClasses that workload operators can use to\n    claim devices.\n\n* **Cluster admin**: responsible for configuring clusters and nodes,\n  attaching devices, installing drivers, and similar tasks. To use DRA,\n  cluster admins do the following:\n\n  * Attach devices to nodes.\n  * Install device drivers that support DRA.\n  * Optionally, create DeviceClasses that workload operators can use to claim\n    devices.\n\n* **Workload operator**: responsible for deploying and managing workloads in the\n  cluster. To use DRA to allocate devices to Pods, workload operators do the\n  following:\n\n  * Create ResourceClaims or ResourceClaimTemplates to request specific\n    configurations within DeviceClasses.\n  * Deploy workloads that use specific ResourceClaims or ResourceClaimTemplates.",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Core Kubernetes feature/API for Dynamic Resource Allocation, the main subject of this documentation."
        },
        {
          "term": "dynamic volume provisioning",
          "tier": 2,
          "reasoning": "Kubernetes concept for automatically provisioning storage volumes."
        },
        {
          "term": "PersistentVolumeClaims",
          "tier": 1,
          "reasoning": "Kubernetes API object for claiming persistent storage capacity."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the core Kubernetes workload resource."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Common Expression Language - a protocol/standard used for device filtering in DRA."
        },
        {
          "term": "common expression language",
          "tier": 2,
          "reasoning": "The full name of CEL, used for fine-grained filtering expressions."
        },
        {
          "term": "device filtering",
          "tier": 2,
          "reasoning": "Technical process for selecting devices based on attributes."
        },
        {
          "term": "device attributes",
          "tier": 2,
          "reasoning": "Technical concept describing properties of devices for filtering."
        },
        {
          "term": "resource claim",
          "tier": 2,
          "reasoning": "DRA concept for requesting device resources."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for isolated application runtime units."
        },
        {
          "term": "device classes",
          "tier": 1,
          "reasoning": "DRA API object for categorizing devices by use case."
        },
        {
          "term": "DeviceClasses",
          "tier": 1,
          "reasoning": "Kubernetes API object name for device categorization in DRA."
        },
        {
          "term": "device drivers",
          "tier": 2,
          "reasoning": "Software components that enable device communication with Kubernetes."
        },
        {
          "term": "cluster admins",
          "tier": 2,
          "reasoning": "Role/user type responsible for cluster configuration."
        },
        {
          "term": "app operators",
          "tier": 2,
          "reasoning": "Role/user type responsible for deploying applications."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes concept for applications running in the cluster."
        },
        {
          "term": "device plugins",
          "tier": 1,
          "reasoning": "Kubernetes extension mechanism for device allocation, compared to DRA."
        },
        {
          "term": "device allocation",
          "tier": 2,
          "reasoning": "Technical process of assigning devices to workloads."
        },
        {
          "term": "ResourceSlices",
          "tier": 1,
          "reasoning": "DRA API object providing Kubernetes with node and resource information."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Kubernetes concept for worker machines in a cluster."
        },
        {
          "term": "resource capacity",
          "tier": 2,
          "reasoning": "Technical concept describing available resources in the cluster."
        },
        {
          "term": "workload operators",
          "tier": 2,
          "reasoning": "Role/user type responsible for deploying and managing workloads."
        },
        {
          "term": "ResourceClaims",
          "tier": 1,
          "reasoning": "DRA API object for requesting specific device configurations."
        },
        {
          "term": "ResourceClaimTemplates",
          "tier": 1,
          "reasoning": "DRA API object template for creating ResourceClaims."
        },
        {
          "term": "device owner",
          "tier": 2,
          "reasoning": "DRA user role responsible for devices and drivers."
        },
        {
          "term": "drivers",
          "tier": 2,
          "reasoning": "Software components enabling device functionality in Kubernetes."
        },
        {
          "term": "device sharing",
          "tier": 2,
          "reasoning": "DRA capability allowing multiple containers to use the same device."
        },
        {
          "term": "Pod resource requests",
          "tier": 2,
          "reasoning": "Kubernetes concept for specifying resource requirements in Pods."
        },
        {
          "term": "device configuration",
          "tier": 2,
          "reasoning": "Technical concept for device settings applied to Pods."
        },
        {
          "term": "storage capacity",
          "tier": 2,
          "reasoning": "Technical concept for available storage resources."
        },
        {
          "term": "per-container device requests",
          "tier": 2,
          "reasoning": "Device plugin limitation requiring requests per container."
        },
        {
          "term": "expression-based device filtering",
          "tier": 2,
          "reasoning": "DRA capability for filtering devices using expressions."
        },
        {
          "term": "DRA-compatible drivers",
          "tier": 2,
          "reasoning": "Device drivers that support the DRA interface."
        }
      ],
      "term_count": 35,
      "generated_at": "2026-02-08T21:29:25.830638",
      "elapsed_time": 18.77550196647644
    },
    {
      "chunk_id": "tutorials_kubernetes-basics_explore_explore-intro_sec1",
      "doc_id": "tutorials_kubernetes-basics_explore_explore-intro",
      "heading": "Nodes",
      "source_file": "tutorials_kubernetes-basics_explore_explore-intro.md",
      "content": "A Pod always runs on a **Node**. A Node is a worker machine in Kubernetes and may\nbe either a virtual or a physical machine, depending on the cluster. Each Node is\nmanaged by the control plane. A Node can have multiple pods, and the Kubernetes\ncontrol plane automatically handles scheduling the pods across the Nodes in the\ncluster. The control plane's automatic scheduling takes into account the available\nresources on each Node.\n\nEvery Kubernetes Node runs at least:\n\n* Kubelet, a process responsible for communication between the Kubernetes control\nplane and the Node; it manages the Pods and the containers running on a machine.\n\n* A container runtime (like Docker) responsible for pulling the container image\nfrom a registry, unpacking the container, and running the application.\n\n### Nodes overview\n\n{{< figure src=\"/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg\" class=\"diagram-medium\" >}}",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Named Kubernetes resource representing a worker machine in the cluster."
        },
        {
          "term": "Kubelet",
          "tier": 1,
          "reasoning": "Named Kubernetes component process running on each Node."
        },
        {
          "term": "Docker",
          "tier": 1,
          "reasoning": "Named container runtime technology explicitly mentioned."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core platform/product name being documented."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core architectural concept referring to the cluster management layer."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Domain-specific term describing the role of a Node in the cluster."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept for a set of nodes."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, core Kubernetes API object referenced multiple times."
        },
        {
          "term": "Nodes",
          "tier": 1,
          "reasoning": "Plural form of Node, referenced in context of scheduling across the cluster."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Core Kubernetes process for assigning pods to nodes."
        },
        {
          "term": "automatic scheduling",
          "tier": 2,
          "reasoning": "Specific scheduling behavior performed by the control plane."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Technical term referring to compute capacity (CPU, memory) on nodes."
        },
        {
          "term": "container runtime",
          "tier": 2,
          "reasoning": "Infrastructure component category responsible for running containers."
        },
        {
          "term": "container image",
          "tier": 2,
          "reasoning": "Technical artifact that gets pulled and unpacked to run applications."
        },
        {
          "term": "registry",
          "tier": 2,
          "reasoning": "Infrastructure component where container images are stored and pulled from."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core virtualization concept for isolated application execution."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form of container, managed by kubelet on a machine."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Capitalized plural form as managed by kubelet."
        },
        {
          "term": "physical machine",
          "tier": 3,
          "reasoning": "Infrastructure concept - Node may be a physical machine."
        },
        {
          "term": "machine",
          "tier": 3,
          "reasoning": "General infrastructure term used to describe where containers run."
        },
        {
          "term": "application",
          "tier": 3,
          "reasoning": "Technical term for the software running inside containers."
        },
        {
          "term": "process",
          "tier": 3,
          "reasoning": "OS-level concept describing kubelet as a running process."
        },
        {
          "term": "communication",
          "tier": 3,
          "reasoning": "Technical term describing kubelet's role between control plane and Node."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:29:40.682948",
      "elapsed_time": 13.842349290847778
    },
    {
      "chunk_id": "reference_using-api_server-side-apply_sec4",
      "doc_id": "reference_using-api_server-side-apply",
      "heading": "Merge strategy",
      "source_file": "reference_using-api_server-side-apply.md",
      "content": "The merging strategy, implemented with Server-Side Apply, provides a generally\nmore stable object lifecycle. Server-Side Apply tries to merge fields based on\nthe actor who manages them instead of overruling based on values. This way\nmultiple actors can update the same object without causing unexpected interference.\n\nWhen a user sends a _fully-specified intent_ object to the Server-Side Apply\nendpoint, the server merges it with the live object favoring the value from the\nrequest body if it is specified in both places. If the set of items present in\nthe applied config is not a superset of the items applied by the same user last\ntime, each missing item not managed by any other appliers is removed. For\nmore information about how an object's schema is used to make decisions when\nmerging, see\n[sigs.k8s.io/structured-merge-diff](https://sigs.k8s.io/structured-merge-diff).\n\nThe Kubernetes API (and the Go code that implements that API for Kubernetes) allows\ndefining _merge strategy markers_. These markers describe the merge strategy supported\nfor fields within Kubernetes objects.\nFor a {{< glossary_tooltip term_id=\"CustomResourceDefinition\" text=\"CustomResourceDefinition\" >}},\nyou can set these markers when you define the custom resource.\n\n| Golang marker   | OpenAPI extension            | Possible values                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| --------------- | ---------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `//+listType`   | `x-kubernetes-list-type`     | `atomic`/`set`/`map`                             | Applicable to lists. `set` applies to lists that include only scalar elements. These elements must be unique. `map` applies to lists of nested types only. The key values (see `listMapKey`) must be unique in the list. `atomic` can apply to any list. If configured as `atomic`, the entire list is replaced during merge. At any point in time, a single manager owns the list. If `set` or `map`, different managers can manage entries separately. |\n| `//+listMapKey` | `x-kubernetes-list-map-keys` | List of field names, e.g. `[\"port\", \"protocol\"]` | Only applicable when `+listType=map`. A list of field names whose values uniquely identify entries in the list. While there can be multiple keys, `listMapKey` is singular because keys need to be specified individually in the Go type. The key fields must be scalars.                                                                                                                                                                                |\n| `//+mapType`    | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to maps. `atomic` means that the map can only be entirely replaced by a single manager. `granular` means that the map supports separate managers updating individual fields.                                                                                                                                                                                                                                                                  |\n| `//+structType` | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to structs; otherwise same usage and OpenAPI annotation as `//+mapType`.                                                                                                                                                                                                                                                                                                                                                                      |\n\nIf `listType` is missing, the API server interprets a\n`patchStrategy=merge` marker as a `listType=map` and the\ncorresponding `patchMergeKey` marker as a `listMapKey`.\n\nThe `atomic` list type is recursive.\n\n(In the [Go](https://go.dev/) code for Kubernetes, these markers are specified as\ncomments and code authors need not repeat them as field tags).",
      "terms": [
        {
          "term": "Server-Side Apply",
          "tier": 1,
          "reasoning": "Core Kubernetes API mechanism for applying configuration changes with field ownership tracking."
        },
        {
          "term": "merging strategy",
          "tier": 2,
          "reasoning": "Technical concept describing how object fields are combined during updates."
        },
        {
          "term": "object lifecycle",
          "tier": 2,
          "reasoning": "Domain concept referring to the stages and management of Kubernetes objects over time."
        },
        {
          "term": "actor",
          "tier": 2,
          "reasoning": "Technical term referring to an entity (user or controller) that manages fields in an object."
        },
        {
          "term": "fully-specified intent",
          "tier": 2,
          "reasoning": "Domain-specific concept describing a complete desired state object sent to the API."
        },
        {
          "term": "live object",
          "tier": 2,
          "reasoning": "Technical term for the current state of an object in the Kubernetes cluster."
        },
        {
          "term": "applied config",
          "tier": 2,
          "reasoning": "Technical term referring to the configuration that was previously applied by a user."
        },
        {
          "term": "appliers",
          "tier": 2,
          "reasoning": "Domain term for actors that apply configurations to objects."
        },
        {
          "term": "schema",
          "tier": 2,
          "reasoning": "Technical concept describing the structure definition used for merge decisions."
        },
        {
          "term": "structured-merge-diff",
          "tier": 1,
          "reasoning": "Specific library/project name for handling structured merging in Kubernetes."
        },
        {
          "term": "sigs.k8s.io/structured-merge-diff",
          "tier": 1,
          "reasoning": "Full reference path to the structured merge diff project."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core component name for the API that exposes Kubernetes functionality."
        },
        {
          "term": "merge strategy markers",
          "tier": 2,
          "reasoning": "Domain-specific concept for annotations that define how fields should be merged."
        },
        {
          "term": "Kubernetes objects",
          "tier": 2,
          "reasoning": "Core domain concept referring to persistent entities in the Kubernetes system."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for defining custom resources."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Domain concept for user-defined extensions to the Kubernetes API."
        },
        {
          "term": "Golang marker",
          "tier": 2,
          "reasoning": "Technical term for Go code annotations used to define merge behavior."
        },
        {
          "term": "OpenAPI extension",
          "tier": 2,
          "reasoning": "Technical concept for custom extensions to OpenAPI specifications."
        },
        {
          "term": "//+listType",
          "tier": 1,
          "reasoning": "Specific Golang marker syntax for defining list merge behavior."
        },
        {
          "term": "x-kubernetes-list-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for Kubernetes list type definitions."
        },
        {
          "term": "//+listMapKey",
          "tier": 1,
          "reasoning": "Specific Golang marker for defining map key fields in lists."
        },
        {
          "term": "x-kubernetes-list-map-keys",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for list map key definitions."
        },
        {
          "term": "//+mapType",
          "tier": 1,
          "reasoning": "Specific Golang marker for defining map merge behavior."
        },
        {
          "term": "x-kubernetes-map-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for Kubernetes map type definitions."
        },
        {
          "term": "//+structType",
          "tier": 1,
          "reasoning": "Specific Golang marker for defining struct merge behavior (truncated in text)."
        },
        {
          "term": "atomic",
          "tier": 2,
          "reasoning": "Technical value indicating entire field replacement during merge operations."
        },
        {
          "term": "set",
          "tier": 2,
          "reasoning": "Technical value for lists containing unique scalar elements."
        },
        {
          "term": "map",
          "tier": 2,
          "reasoning": "Technical value for lists of nested types with unique keys."
        },
        {
          "term": "granular",
          "tier": 2,
          "reasoning": "Technical value indicating individual field updates are supported."
        },
        {
          "term": "listMapKey",
          "tier": 2,
          "reasoning": "Technical concept for fields that uniquely identify list entries."
        },
        {
          "term": "scalar",
          "tier": 3,
          "reasoning": "Technical term for simple value types (strings, numbers) as opposed to complex types."
        },
        {
          "term": "manager",
          "tier": 2,
          "reasoning": "Domain term for an actor that owns and manages specific fields in an object."
        },
        {
          "term": "Go type",
          "tier": 3,
          "reasoning": "Technical reference to type definitions in the Go programming language."
        },
        {
          "term": "nested types",
          "tier": 2,
          "reasoning": "Technical term for complex types contained within other types."
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term for individual properties within Kubernetes objects."
        },
        {
          "term": "request body",
          "tier": 3,
          "reasoning": "Technical term for the payload sent in an API request."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "Technical term for an API URL that accepts requests."
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:30:03.053718",
      "elapsed_time": 21.359982013702393
    },
    {
      "chunk_id": "tasks_administer-cluster_kubelet-in-userns_sec6",
      "doc_id": "tasks_administer-cluster_kubelet-in-userns",
      "heading": "(unless you run another systemd in the namespace)",
      "source_file": "tasks_administer-cluster_kubelet-in-userns.md",
      "content": "SystemdCgroup = false\n```\n\nThe default path of the configuration file is `/etc/containerd/config.toml`.\nThe path can be specified with `containerd -c /path/to/containerd/config.toml`.\n\n{{% /tab %}}\n{{% tab name=\"CRI-O\" %}}\n\nRunning CRI-O in a user namespace is supported since CRI-O 1.22.\n\nCRI-O requires an environment variable `_CRIO_ROOTLESS=1` to be set.\n\nThe following configurations are also recommended:\n\n```toml\n[crio]\n  storage_driver = \"overlay\"",
      "terms": [
        {
          "term": "SystemdCgroup",
          "tier": 1,
          "reasoning": "Configuration parameter for container runtime cgroup management"
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Core container runtime component used in Kubernetes infrastructure"
        },
        {
          "term": "CRI-O",
          "tier": 1,
          "reasoning": "Container Runtime Interface implementation, a core Kubernetes container runtime"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Technical concept referring to system configuration storage"
        },
        {
          "term": "config.toml",
          "tier": 1,
          "reasoning": "Specific configuration file name for containerd runtime"
        },
        {
          "term": "/etc/containerd/config.toml",
          "tier": 1,
          "reasoning": "Specific filesystem path for containerd configuration"
        },
        {
          "term": "user namespace",
          "tier": 2,
          "reasoning": "Linux kernel isolation feature used for rootless container operation"
        },
        {
          "term": "environment variable",
          "tier": 2,
          "reasoning": "Technical concept for passing configuration to processes"
        },
        {
          "term": "_CRIO_ROOTLESS",
          "tier": 1,
          "reasoning": "Specific environment variable required for CRI-O rootless operation"
        },
        {
          "term": "storage_driver",
          "tier": 2,
          "reasoning": "Configuration parameter specifying container storage backend"
        },
        {
          "term": "overlay",
          "tier": 2,
          "reasoning": "Storage driver type using overlay filesystem for containers"
        },
        {
          "term": "rootless",
          "tier": 2,
          "reasoning": "Security concept for running containers without root privileges"
        },
        {
          "term": "toml",
          "tier": 3,
          "reasoning": "Configuration file format used by container runtimes"
        },
        {
          "term": "crio",
          "tier": 1,
          "reasoning": "Configuration section name for CRI-O settings"
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Filesystem path concept relevant to configuration location"
        },
        {
          "term": "containerd -c",
          "tier": 1,
          "reasoning": "CLI command with flag for specifying configuration file path"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:30:14.285902",
      "elapsed_time": 10.221590995788574
    },
    {
      "chunk_id": "reference_access-authn-authz_kubelet-authn-authz_sec0",
      "doc_id": "reference_access-authn-authz_kubelet-authn-authz",
      "heading": "Overview",
      "source_file": "reference_access-authn-authz_kubelet-authn-authz.md",
      "content": "A kubelet's HTTPS endpoint exposes APIs which give access to data of varying sensitivity,\nand allow you to perform operations with varying levels of power on the node and within containers.\n\nThis document describes how to authenticate and authorize access to the kubelet's HTTPS endpoint.",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages containers."
        },
        {
          "term": "HTTPS endpoint",
          "tier": 2,
          "reasoning": "Technical concept describing the secure API access point exposed by the kubelet."
        },
        {
          "term": "HTTPS",
          "tier": 3,
          "reasoning": "Protocol standard for secure HTTP communication used by the kubelet's endpoint."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "Technical networking term referring to an accessible API interface."
        },
        {
          "term": "APIs",
          "tier": 2,
          "reasoning": "Application Programming Interfaces exposed by the kubelet for programmatic access."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to a worker machine in the cluster."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core domain concept for isolated runtime environments managed by Kubernetes."
        },
        {
          "term": "authenticate",
          "tier": 2,
          "reasoning": "Security process concept for verifying identity when accessing the kubelet API."
        },
        {
          "term": "authorize",
          "tier": 2,
          "reasoning": "Security process concept for determining permissions for kubelet API operations."
        },
        {
          "term": "access",
          "tier": 3,
          "reasoning": "Technical term in security context referring to the ability to interact with the kubelet API."
        },
        {
          "term": "data",
          "tier": 3,
          "reasoning": "Technical term referring to information exposed through the kubelet's APIs."
        },
        {
          "term": "sensitivity",
          "tier": 3,
          "reasoning": "Security-related term describing the classification level of data exposed by APIs."
        },
        {
          "term": "operations",
          "tier": 3,
          "reasoning": "Technical term referring to actions that can be performed via the kubelet API."
        }
      ],
      "term_count": 13,
      "generated_at": "2026-02-08T21:30:25.172191",
      "elapsed_time": 9.876008033752441
    }
  ],
  "chunks": [
    {
      "chunk_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions_sec0",
      "doc_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions",
      "heading": "Introduction",
      "source_file": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions.md",
      "content": "---\ntitle: Extend the Kubernetes API with CustomResourceDefinitions\nreviewers:\n- deads2k\n- jpbetz\n- liggitt\n- roycaihw\n- sttts\ncontent_type: task\nmin-kubernetes-server-version: 1.16\nweight: 20\n---\n\n<!-- overview -->\nThis page shows how to install a\n[custom resource](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\ninto the Kubernetes API by creating a\n[CustomResourceDefinition](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#customresourcedefinition-v1-apiextensions-k8s-io).",
      "terms": [
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core Kubernetes component that serves as the primary interface for cluster operations and resource management."
        },
        {
          "term": "CustomResourceDefinitions",
          "tier": 1,
          "reasoning": "Named Kubernetes API object used to extend the API with custom resources."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Singular form of the API object for defining custom resources in Kubernetes."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Domain concept referring to user-defined extensions to the Kubernetes API."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually important for Kubernetes extension."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform that is the subject of this documentation."
        },
        {
          "term": "kubernetes-server-version",
          "tier": 2,
          "reasoning": "Technical metadata indicating minimum Kubernetes server version compatibility."
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Domain concept referring to the mechanism for extending Kubernetes API capabilities."
        },
        {
          "term": "apiextensions-k8s-io",
          "tier": 1,
          "reasoning": "Named API group in Kubernetes that handles API extension resources like CRDs."
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "API version indicator denoting stable API version in Kubernetes."
        },
        {
          "term": "1.16",
          "tier": 3,
          "reasoning": "Specific Kubernetes version number indicating minimum compatibility requirement."
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T21:18:44.587066",
      "elapsed_time": 7.229344844818115
    },
    {
      "chunk_id": "concepts_workloads_management_sec10",
      "doc_id": "concepts_workloads_management",
      "heading": "In-place updates of resources",
      "source_file": "concepts_workloads_management.md",
      "content": "Sometimes it's necessary to make narrow, non-disruptive updates to resources you've created.\n\n### kubectl apply\n\nIt is suggested to maintain a set of configuration files in source control\n(see [configuration as code](https://martinfowler.com/bliki/InfrastructureAsCode.html)),\nso that they can be maintained and versioned along with the code for the resources they configure.\nThen, you can use [`kubectl apply`](/docs/reference/kubectl/generated/kubectl_apply/)\nto push your configuration changes to the cluster.\n\nThis command will compare the version of the configuration that you're pushing with the previous\nversion and apply the changes you've made, without overwriting any automated changes to properties\nyou haven't specified.\n\n```shell\nkubectl apply -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml\n```\n\n```none\ndeployment.apps/my-nginx configured\n```\n\nTo learn more about the underlying mechanism, read [server-side apply](/docs/reference/using-api/server-side-apply/).\n\n### kubectl edit\n\nAlternatively, you may also update resources with [`kubectl edit`](/docs/reference/kubectl/generated/kubectl_edit/):\n\n```shell\nkubectl edit deployment/my-nginx\n```\n\nThis is equivalent to first `get` the resource, edit it in text editor, and then `apply` the\nresource with the updated version:\n\n```shell\nkubectl get deployment my-nginx -o yaml > /tmp/nginx.yaml\nvi /tmp/nginx.yaml",
      "terms": [
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for applying configuration changes to cluster resources."
        },
        {
          "term": "kubectl edit",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for editing resources directly."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line tool referenced throughout the documentation."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object/resource type shown in examples (deployment.apps/my-nginx, deployment/my-nginx)."
        },
        {
          "term": "my-nginx",
          "tier": 1,
          "reasoning": "Specific named deployment resource used in the examples."
        },
        {
          "term": "nginx-deployment.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file name referenced in the kubectl apply example."
        },
        {
          "term": "deployment.apps",
          "tier": 1,
          "reasoning": "Kubernetes API group and resource type shown in command output."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes objects that can be created and managed."
        },
        {
          "term": "configuration files",
          "tier": 2,
          "reasoning": "Technical concept for files containing resource definitions and settings."
        },
        {
          "term": "source control",
          "tier": 2,
          "reasoning": "Technical concept for version control systems used to manage configuration."
        },
        {
          "term": "configuration as code",
          "tier": 2,
          "reasoning": "Infrastructure/DevOps concept explicitly referenced with link to Martin Fowler's definition."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "configuration changes",
          "tier": 2,
          "reasoning": "Technical concept describing modifications to resource definitions."
        },
        {
          "term": "server-side apply",
          "tier": 2,
          "reasoning": "Kubernetes-specific mechanism for applying configuration changes mentioned as underlying mechanism."
        },
        {
          "term": "automated changes",
          "tier": 2,
          "reasoning": "Technical concept referring to system-generated modifications to resource properties."
        },
        {
          "term": "properties",
          "tier": 2,
          "reasoning": "Technical term for attributes/fields of Kubernetes resources."
        },
        {
          "term": "text editor",
          "tier": 3,
          "reasoning": "General technical tool referenced in the kubectl edit workflow."
        },
        {
          "term": "yaml",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes configuration files, shown in -o yaml flag."
        },
        {
          "term": "get",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for retrieving resource information."
        },
        {
          "term": "apply",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for applying configuration, used both as command and concept."
        },
        {
          "term": "-o yaml",
          "tier": 2,
          "reasoning": "kubectl output format flag for YAML serialization."
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Technical concept referring to configuration versions being compared during apply."
        },
        {
          "term": "versioned",
          "tier": 3,
          "reasoning": "Technical concept describing configuration files maintained with version history."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Technical context indicator for command-line examples."
        },
        {
          "term": "configured",
          "tier": 2,
          "reasoning": "Kubernetes command output status indicating successful configuration update."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:18:59.331028",
      "elapsed_time": 13.743110179901123
    },
    {
      "chunk_id": "concepts_extend-kubernetes_operator_sec7",
      "doc_id": "concepts_extend-kubernetes_operator",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "concepts_extend-kubernetes_operator.md",
      "content": "* Read the {{< glossary_tooltip text=\"CNCF\" term_id=\"cncf\" >}}\n  [Operator White Paper](https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md).\n* Learn more about [Custom Resources](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\n* Find ready-made operators on [OperatorHub.io](https://operatorhub.io/) to suit your use case\n* [Publish](https://operatorhub.io/) your operator for other people to use\n* Read [CoreOS' original article](https://web.archive.org/web/20170129131616/https://coreos.com/blog/introducing-operators.html)\n  that introduced the operator pattern (this is an archived version of the original article).\n* Read an [article](https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps)\n  from Google Cloud about best practices for building operators",
      "terms": [
        {
          "term": "CNCF",
          "tier": 1,
          "reasoning": "Cloud Native Computing Foundation - a specific organization and proper noun in the cloud-native ecosystem"
        },
        {
          "term": "Operator",
          "tier": 1,
          "reasoning": "A Kubernetes-specific pattern and resource type for managing applications"
        },
        {
          "term": "operator",
          "tier": 1,
          "reasoning": "Appears in lowercase form throughout the text referring to the Kubernetes operator pattern"
        },
        {
          "term": "operators",
          "tier": 1,
          "reasoning": "Plural form of the Kubernetes operator pattern, used multiple times in the chunk"
        },
        {
          "term": "Operator White Paper",
          "tier": 1,
          "reasoning": "A specific CNCF document about the operator pattern"
        },
        {
          "term": "Custom Resources",
          "tier": 1,
          "reasoning": "A Kubernetes API extension mechanism, capitalized as a proper concept"
        },
        {
          "term": "OperatorHub.io",
          "tier": 1,
          "reasoning": "A specific platform/registry for finding and publishing Kubernetes operators"
        },
        {
          "term": "CoreOS",
          "tier": 1,
          "reasoning": "A specific company/organization that introduced the operator pattern"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform, referenced in URLs and context"
        },
        {
          "term": "operator pattern",
          "tier": 2,
          "reasoning": "A specific architectural pattern in Kubernetes for application management"
        },
        {
          "term": "stateful apps",
          "tier": 2,
          "reasoning": "Applications that maintain state, a key concept in Kubernetes application management"
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Kubernetes API extension mechanism referenced in the URL path"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core concept in container orchestration, appears in Google Cloud URL"
        },
        {
          "term": "best practices",
          "tier": 3,
          "reasoning": "Technical guidance term used in the context of building operators"
        },
        {
          "term": "Google Cloud",
          "tier": 1,
          "reasoning": "A specific cloud provider mentioned as source of operator best practices"
        },
        {
          "term": "Publish",
          "tier": 3,
          "reasoning": "Action term in context of distributing operators to OperatorHub"
        },
        {
          "term": "tag-app-delivery",
          "tier": 2,
          "reasoning": "CNCF Technical Advisory Group for application delivery, referenced in path"
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:19:11.530532",
      "elapsed_time": 11.198503732681274
    },
    {
      "chunk_id": "reference_glossary_sysctl_sec0",
      "doc_id": "reference_glossary_sysctl",
      "heading": "Introduction",
      "source_file": "reference_glossary_sysctl.md",
      "content": "---\ntitle: sysctl\nid: sysctl\ndate: 2019-02-12\nfull_link: /docs/tasks/administer-cluster/sysctl-cluster/\nshort_description: >\n  An interface for getting and setting Unix kernel parameters\n\naka:\ntags:\n- tool\n---\n `sysctl` is a semi-standardized interface for reading or changing the\n attributes of the running Unix kernel.\n\n<!--more-->\n\nOn Unix-like systems, `sysctl` is both the name of the tool that administrators\nuse to view and modify these settings, and also the system call that the tool\nuses.\n\n{{< glossary_tooltip text=\"Container\" term_id=\"container\" >}} runtimes and\nnetwork plugins may rely on `sysctl` values being set a certain way.",
      "terms": [
        {
          "term": "sysctl",
          "tier": 1,
          "reasoning": "Named Unix tool and system call for kernel parameter management, the primary subject of this documentation."
        },
        {
          "term": "Unix kernel",
          "tier": 2,
          "reasoning": "Core operating system component whose parameters sysctl manages."
        },
        {
          "term": "kernel parameters",
          "tier": 2,
          "reasoning": "Technical concept referring to configurable settings of the Unix kernel."
        },
        {
          "term": "Unix kernel parameters",
          "tier": 2,
          "reasoning": "Compound term describing the specific settings that sysctl reads and modifies."
        },
        {
          "term": "Unix-like systems",
          "tier": 3,
          "reasoning": "Category of operating systems where sysctl operates."
        },
        {
          "term": "system call",
          "tier": 2,
          "reasoning": "Technical concept describing the programmatic interface sysctl uses to interact with the kernel."
        },
        {
          "term": "Container",
          "tier": 2,
          "reasoning": "Core Kubernetes/infrastructure concept; container runtimes depend on sysctl values."
        },
        {
          "term": "network plugins",
          "tier": 2,
          "reasoning": "Infrastructure components that may depend on specific sysctl configurations."
        },
        {
          "term": "interface",
          "tier": 3,
          "reasoning": "Technical term describing sysctl's role as a standardized access method."
        },
        {
          "term": "running",
          "tier": 3,
          "reasoning": "Technical context indicating the kernel is active/executing."
        },
        {
          "term": "attributes",
          "tier": 3,
          "reasoning": "Technical term for the kernel properties that can be read or modified."
        },
        {
          "term": "tool",
          "tier": 3,
          "reasoning": "Explicitly tagged as a tool in the metadata; describes sysctl's classification."
        },
        {
          "term": "administrators",
          "tier": 3,
          "reasoning": "Role-based term for users who manage sysctl settings."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Referenced in the documentation path; core Kubernetes infrastructure concept."
        },
        {
          "term": "administer-cluster",
          "tier": 2,
          "reasoning": "Task category indicating cluster administration context for sysctl usage."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:19:22.297958",
      "elapsed_time": 9.766122341156006
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec18",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`TCPTransport`     {#apiserver-k8s-io-v1beta1-TCPTransport}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [Transport](#apiserver-k8s-io-v1beta1-Transport)\n\n\n<p>TCPTransport provides the information to connect to konnectivity server via TCP</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>URL is the location of the konnectivity server to connect to.\nAs an example it might be &quot;https://127.0.0.1:8131&quot;</p>\n</td>\n</tr>\n<tr><td><code>tlsConfig</code><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-TLSConfig\"><code>TLSConfig</code></a>\n</td>\n<td>\n   <p>TLSConfig is the config needed to use TLS when connecting to konnectivity server</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Transport",
          "tier": 1,
          "reasoning": "Kubernetes API object type referenced in the documentation for network transport configuration."
        },
        {
          "term": "TCPTransport",
          "tier": 1,
          "reasoning": "Specific Kubernetes API resource type that provides TCP connection configuration to konnectivity server."
        },
        {
          "term": "konnectivity server",
          "tier": 1,
          "reasoning": "Named Kubernetes infrastructure component for network connectivity between control plane and nodes."
        },
        {
          "term": "TLSConfig",
          "tier": 1,
          "reasoning": "Kubernetes API object type for TLS configuration settings."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-Transport",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the Transport resource."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-TLSConfig",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the TLSConfig resource."
        },
        {
          "term": "TCP",
          "tier": 2,
          "reasoning": "Network protocol used for transport layer communication to konnectivity server."
        },
        {
          "term": "TLS",
          "tier": 2,
          "reasoning": "Transport Layer Security protocol for encrypted connections to konnectivity server."
        },
        {
          "term": "url",
          "tier": 2,
          "reasoning": "Configuration field specifying the location/address of the konnectivity server."
        },
        {
          "term": "tlsConfig",
          "tier": 2,
          "reasoning": "Configuration field name for TLS settings in TCPTransport."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "API version indicating beta maturity level of the Kubernetes API."
        },
        {
          "term": "apiserver",
          "tier": 2,
          "reasoning": "Part of the API group name, referring to the Kubernetes API server component."
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Protocol shown in the example URL for secure connection to konnectivity server."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing configuration parameters in the API object schema."
        },
        {
          "term": "connect",
          "tier": 3,
          "reasoning": "Technical action describing establishing network connection to konnectivity server."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:19:33.223246",
      "elapsed_time": 9.92405080795288
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec24",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`UserValidationRule`     {#apiserver-config-k8s-io-v1-UserValidationRule}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>UserValidationRule provides the configuration for a single user info validation rule.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>expression</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>expression represents the expression which will be evaluated by CEL.\nMust return true for the validation to pass.</p>\n<p>CEL expressions have access to the contents of UserInfo, organized into CEL variable:</p>\n<ul>\n<li>'user' - authentication.k8s.io/v1, Kind=UserInfo object\nRefer to https://github.com/kubernetes/api/blob/release-1.28/authentication/v1/types.go#L105-L122 for the definition.\nAPI documentation: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#userinfo-v1-authentication-k8s-io</li>\n</ul>\n<p>Documentation on CEL: https://kubernetes.io/docs/reference/using-api/cel/</p>\n</td>\n</tr>\n<tr><td><code>message</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>message customizes the returned error message when rule returns false.\nmessage is a literal string.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration."
        },
        {
          "term": "UserValidationRule",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration object for user info validation rules."
        },
        {
          "term": "UserInfo",
          "tier": 1,
          "reasoning": "Named Kubernetes API object representing authenticated user information."
        },
        {
          "term": "CEL",
          "tier": 2,
          "reasoning": "Common Expression Language - domain-specific language used for validation expressions in Kubernetes."
        },
        {
          "term": "expression",
          "tier": 2,
          "reasoning": "Technical field name representing the CEL expression to be evaluated for validation."
        },
        {
          "term": "validation",
          "tier": 2,
          "reasoning": "Domain concept referring to the process of verifying user information meets requirements."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Security concept for verifying identity, referenced in the API group path."
        },
        {
          "term": "authentication.k8s.io/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for authentication-related resources."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - general technical term used in context of Kubernetes API."
        },
        {
          "term": "CEL variable",
          "tier": 2,
          "reasoning": "Technical concept referring to variables accessible within CEL expressions."
        },
        {
          "term": "CEL expressions",
          "tier": 2,
          "reasoning": "Technical concept for expressions written in Common Expression Language."
        },
        {
          "term": "user",
          "tier": 2,
          "reasoning": "CEL variable name providing access to UserInfo object in validation context."
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Technical field name for customizing error messages when validation fails."
        },
        {
          "term": "error message",
          "tier": 3,
          "reasoning": "Technical concept for messages returned when validation rules fail."
        },
        {
          "term": "literal string",
          "tier": 3,
          "reasoning": "Technical term describing the type of value the message field accepts."
        },
        {
          "term": "rule",
          "tier": 2,
          "reasoning": "Domain concept referring to a single validation condition to be evaluated."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API configuration group reference for apiserver configuration."
        },
        {
          "term": "Kind",
          "tier": 2,
          "reasoning": "Kubernetes API concept identifying the type of resource object."
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API documentation and specification."
        },
        {
          "term": "release-1.28",
          "tier": 2,
          "reasoning": "Kubernetes version reference indicating specific API version compatibility."
        },
        {
          "term": "v1.28",
          "tier": 2,
          "reasoning": "Kubernetes version number referenced in documentation links."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T21:19:48.131367",
      "elapsed_time": 13.906741857528687
    },
    {
      "chunk_id": "reference_access-authn-authz_validating-admission-policy_sec0",
      "doc_id": "reference_access-authn-authz_validating-admission-policy",
      "heading": "Introduction",
      "source_file": "reference_access-authn-authz_validating-admission-policy.md",
      "content": "---\nreviewers:\n- liggitt\n- jpbetz\n- cici37\ntitle: Validating Admission Policy\ncontent_type: concept\n---\n\n<!-- overview -->\n\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.30\" >}}\n\nThis page provides an overview of Validating Admission Policy.\n\n\n<!-- body -->",
      "terms": [
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource and the primary subject of this documentation page."
        },
        {
          "term": "Admission Policy",
          "tier": 2,
          "reasoning": "Domain concept referring to policies that control admission of resources to the cluster."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating the feature has reached production-ready status in Kubernetes."
        },
        {
          "term": "v1.30",
          "tier": 3,
          "reasoning": "Specific Kubernetes version identifier indicating when the feature became stable."
        },
        {
          "term": "feature-state",
          "tier": 3,
          "reasoning": "Kubernetes documentation concept indicating the maturity level of a feature."
        }
      ],
      "term_count": 5,
      "generated_at": "2026-02-08T21:19:53.521722",
      "elapsed_time": 4.388874530792236
    },
    {
      "chunk_id": "concepts_workloads_management_sec0",
      "doc_id": "concepts_workloads_management",
      "heading": "Introduction",
      "source_file": "concepts_workloads_management.md",
      "content": "---\ntitle: Managing Workloads\ncontent_type: concept\nreviewers:\n- janetkuo\nweight: 40\n---\n\n<!-- overview -->\n\nYou've deployed your application and exposed it via a Service. Now what? Kubernetes provides a\nnumber of tools to help you manage your application deployment, including scaling and updating.\n\n<!-- body -->",
      "terms": [
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to applications running on the cluster, appears in title 'Managing Workloads'"
        },
        {
          "term": "Managing Workloads",
          "tier": 2,
          "reasoning": "Kubernetes operational concept describing the lifecycle management of applications"
        },
        {
          "term": "application",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context referring to containerized workloads deployed on the cluster"
        },
        {
          "term": "deployed",
          "tier": 2,
          "reasoning": "Technical process term describing the act of running applications on Kubernetes"
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource that exposes applications, capitalized indicating the specific K8s resource type"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary platform/proper noun this documentation is about"
        },
        {
          "term": "application deployment",
          "tier": 2,
          "reasoning": "Domain concept referring to the process and state of running applications on Kubernetes"
        },
        {
          "term": "scaling",
          "tier": 2,
          "reasoning": "Core Kubernetes operational concept for adjusting the number of replicas/resources"
        },
        {
          "term": "updating",
          "tier": 2,
          "reasoning": "Technical process term for modifying deployed applications, relates to rolling updates and deployments"
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Domain concept referring to the act of deploying or the state of deployed applications"
        },
        {
          "term": "exposed",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context meaning making an application accessible via networking/Service"
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T21:20:02.612850",
      "elapsed_time": 8.089533567428589
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "How apply calculates differences and merges changes",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "{{< caution >}}\nA *patch* is an update operation that is scoped to specific fields of an object\ninstead of the entire object. This enables updating only a specific set of fields\non an object without reading the object first.\n{{< /caution >}}\n\nWhen `kubectl apply` updates the live configuration for an object,\nit does so by sending a patch request to the API server. The\npatch defines updates scoped to specific fields of the live object\nconfiguration. The `kubectl apply` command calculates this patch request\nusing the configuration file, the live configuration, and the\n`last-applied-configuration` annotation stored in the live configuration.\n\n### Merge patch calculation\n\nThe `kubectl apply` command writes the contents of the configuration file to the\n`kubectl.kubernetes.io/last-applied-configuration` annotation. This\nis used to identify fields that have been removed from the configuration\nfile and need to be cleared from the live configuration. Here are the steps used\nto calculate which fields should be deleted or set:\n\n1. Calculate the fields to delete. These are the fields present in\n   `last-applied-configuration` and missing from the configuration file.\n2. Calculate the fields to add or set. These are the fields present in\n   the configuration file whose values don't match the live configuration.\n\nHere's an example. Suppose this is the configuration file for a Deployment object:\n\n{{% code_sample file=\"application/update_deployment.yaml\" %}}\n\nAlso, suppose this is the live configuration for the same Deployment object:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # note that the annotation does not contain replicas\n    # because it was not updated through apply\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"minReadySeconds\":5,\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.14.2\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n  # ...\nspec:\n  replicas: 2 # written by scale\n  # ...\n  minReadySeconds: 5\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n      # ...\n```\n\nHere are the merge calculations that would be performed by `kubectl apply`:\n\n1. Calculate the fields to delete by reading values from\n   `last-applied-configuration` and comparing them to values in the\n   configuration file.\n   Clear fields explicitly set to null in the local object configuration file\n   regardless of whether they appear in the `last-applied-configuration`.\n   In this example, `minReadySeconds` appears in the\n   `last-applied-configuration` annotation, but does not appear in the configuration file.\n   **Action:** Clear `minReadySeconds` from the live configuration.\n2. Calculate the fields to set by reading values from the configuration\n   file and comparing them to values in the live configuration. In this example,\n   the value of `image` in the configuration file does not match\n   the value in the live configuration. **Action:** Set the value of `image` in the live configuration.\n3. Set the `last-applied-configuration` annotation to match the value\n   of the configuration file.\n4. Merge the results from 1, 2, 3 into a single patch request to the API server.\n\nHere is the live configuration that is the result of the merge:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # The annotation contains the updated image to nginx 1.16.1,\n    # but does not contain the updated replicas to 2\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.16.1\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n    # ...\nspec:\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  replicas: 2 # Set by `kubectl scale`.  Ignored by `kubectl apply`.\n  # minReadySeconds cleared by `kubectl apply`\n  # ...\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.16.1 # Set by `kubectl apply`\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n        # ...\n      # ...\n    # ...\n  # ...\n```\n\n### How different types of fields are merged\n\nHow a particular field in a configuration file is merged with\nthe live configuration depends on the\ntype of the field. There are several types of fields:\n\n- *primitive*: A field of type string, integer, or boolean.\n  For example, `image` and `replicas` are primitive fields. **Action:** Replace.\n\n- *map*, also called *object*: A field of type map or a complex type that contains subfields. For example, `labels`,\n  `annotations`,`spec` and `metadata` are all maps. **Action:** Merge elements or subfields.\n\n- *list*: A field containing a list of items that can be either primitive types or maps.\n  For example, `containers`, `ports`, and `args` are lists. **Action:** Varies.\n\nWhen `kubectl apply` updates a map or list field, it typically does\nnot replace the entire field, but instead updates the individual subelements.\nFor instance, when merging the `spec` on a Deployment, the entire `spec` is\nnot replaced. Instead the subfields of `spec`, such as `replicas`, are compared\nand merged.\n\n### Merging changes to primitive fields\n\nPrimitive fields are replaced or cleared.\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Field in object configuration file  | Field in live object configuration | Field in last-applied-configuration | Action                                    |\n|-------------------------------------|------------------------------------|-------------------------------------|-------------------------------------------|\n| Yes                                 | Yes                                | -                                   | Set live to configuration file value.  |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.           |\n| No                                  | -                                  | Yes                                 | Clear from live configuration.            |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.             |\n\n### Merging changes to map fields\n\nFields that represent maps are merged by comparing each of the subfields or elements of the map:\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Key in object configuration file    | Key in live object configuration   | Field in last-applied-configuration | Action                           |\n|-------------------------------------|------------------------------------|-------------------------------------|----------------------------------|\n| Yes                                 | Yes                                | -                                   | Compare sub fields values.        |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.  |\n| No                                  | -                                  | Yes                                 | Delete from live configuration.   |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.     |\n\n### Merging changes for fields of type list\n\nMerging changes to a list uses one of three strategies:\n\n* Replace the list if all its elements are primitives.\n* Merge individual elements in a list of complex elements.\n* Merge a list of primitive elements.\n\nThe choice of strategy is made on a per-field basis.\n\n#### Replace the list if all its elements are primitives\n\nTreat the list the same as a primitive field. Replace or delete the\nentire list. This preserves ordering.\n\n**Example:** Use `kubectl apply` to update the `args` field of a Container in a Pod. This sets\nthe value of `args` in the live configuration to the value in the configuration file.\nAny `args` elements that had previously been added to the live configuration are lost.\nThe order of the `args` elements defined in the configuration file is\nretained in the live configuration.\n\n```yaml",
      "terms": [
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Core technical concept describing an update operation scoped to specific fields of an object"
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for applying configuration changes to Kubernetes objects"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool referenced throughout the documentation"
        },
        {
          "term": "live configuration",
          "tier": 2,
          "reasoning": "Domain concept referring to the current state of an object in the cluster"
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes component that receives patch requests"
        },
        {
          "term": "patch request",
          "tier": 2,
          "reasoning": "Technical concept describing the type of request sent to update specific fields"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Domain concept referring to the local YAML/JSON file defining desired state"
        },
        {
          "term": "last-applied-configuration",
          "tier": 1,
          "reasoning": "Specific Kubernetes annotation used to track previously applied configuration"
        },
        {
          "term": "kubectl.kubernetes.io/last-applied-configuration",
          "tier": 1,
          "reasoning": "Full annotation key used by kubectl apply to store configuration state"
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching arbitrary non-identifying metadata to objects"
        },
        {
          "term": "Merge patch calculation",
          "tier": 2,
          "reasoning": "Specific process/algorithm used by kubectl apply to determine changes"
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource type shown in the example"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Kubernetes domain term for API resources/entities"
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term referring to specific properties within a Kubernetes object specification"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployment resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the type of resource"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes object section containing identifying information and annotations"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes object section defining the desired state specification"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment field specifying the number of pod instances"
        },
        {
          "term": "minReadySeconds",
          "tier": 2,
          "reasoning": "Deployment spec field controlling minimum ready time before considering pod available"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field used to identify which pods belong to a resource"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Selector type that matches pods based on label equality"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within a Deployment"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata used for identifying and selecting objects"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod spec field defining the container specifications"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container spec field specifying the container image to run"
        },
        {
          "term": "nginx:1.14.2",
          "tier": 3,
          "reasoning": "Specific container image version used in the example"
        },
        {
          "term": "nginx:1.16.1",
          "tier": 3,
          "reasoning": "Updated container image version referenced in the merge result"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Container spec field defining exposed ports"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Port specification field for container network ports"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for logical resource isolation, referenced in metadata"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "Default Kubernetes namespace referenced in the example"
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes operation for adjusting replica count, mentioned as source of replicas value"
        },
        {
          "term": "null",
          "tier": 3,
          "reasoning": "Technical value used to explicitly clear fields in configuration"
        },
        {
          "term": "merge",
          "tier": 2,
          "reasoning": "Technical process of combining patch calculations into a single request"
        },
        {
          "term": "update operation",
          "tier": 2,
          "reasoning": "Technical concept describing the type of change being made to objects"
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:20:24.771097",
      "elapsed_time": 21.156017780303955
    },
    {
      "chunk_id": "tasks_administer-cluster_topology-manager_sec3",
      "doc_id": "tasks_administer-cluster_topology-manager",
      "heading": "Topology manager scopes and policies",
      "source_file": "tasks_administer-cluster_topology-manager.md",
      "content": "The Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
      "terms": [
        {
          "term": "Topology Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for resource alignment across NUMA nodes."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object and workload unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the fundamental Kubernetes workload unit, referenced in 'pod' scope."
        },
        {
          "term": "QoS classes",
          "tier": 2,
          "reasoning": "Quality of Service classification system for Pods in Kubernetes."
        },
        {
          "term": "Hint Provider",
          "tier": 1,
          "reasoning": "Named component that provides topology hints for resource alignment."
        },
        {
          "term": "topology hints",
          "tier": 2,
          "reasoning": "Domain concept describing hints used for NUMA-aware resource placement."
        },
        {
          "term": "scope",
          "tier": 2,
          "reasoning": "Configuration option defining granularity of resource alignment in Topology Manager."
        },
        {
          "term": "policy",
          "tier": 2,
          "reasoning": "Configuration option defining the alignment strategy used by Topology Manager."
        },
        {
          "term": "resource alignment",
          "tier": 2,
          "reasoning": "Technical process of aligning resources across topology domains."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing the unit of compute within a Pod."
        },
        {
          "term": "best-effort",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for resource alignment."
        },
        {
          "term": "restricted",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for stricter resource alignment."
        },
        {
          "term": "single-numa-node",
          "tier": 2,
          "reasoning": "Named Topology Manager policy requiring all resources from a single NUMA node."
        },
        {
          "term": "CPU resources",
          "tier": 2,
          "reasoning": "Domain concept for compute resources managed by CPU Manager."
        },
        {
          "term": "CPU Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for CPU resource management on nodes."
        },
        {
          "term": "CPU Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for CPU Manager behavior."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "System resource type managed by Memory Manager."
        },
        {
          "term": "hugepages",
          "tier": 2,
          "reasoning": "Linux memory feature for large memory pages, managed by Memory Manager."
        },
        {
          "term": "Memory Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for memory resource management."
        },
        {
          "term": "Memory Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for Memory Manager behavior."
        },
        {
          "term": "Pod spec",
          "tier": 2,
          "reasoning": "The specification section of a Pod definition containing resource requests."
        },
        {
          "term": "requested resources",
          "tier": 2,
          "reasoning": "Domain concept for resources explicitly requested in Pod specifications."
        },
        {
          "term": "CPU Management Policies",
          "tier": 2,
          "reasoning": "Named feature for controlling CPU allocation behavior on nodes."
        },
        {
          "term": "scopes",
          "tier": 2,
          "reasoning": "Plural form of scope configuration options for Topology Manager."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Plural form of policy configuration options for Topology Manager."
        },
        {
          "term": "resources",
          "tier": 3,
          "reasoning": "General term for compute resources (CPU, memory) in Kubernetes context."
        }
      ],
      "term_count": 27,
      "generated_at": "2026-02-08T21:20:39.745274",
      "elapsed_time": 13.97149658203125
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec1",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Terminology",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "For clarity, this guide defines the following terms:\n\n* Node: A worker machine in Kubernetes, part of a cluster.\n* Cluster: A set of Nodes that run containerized applications managed by Kubernetes.\n  For this example, and in most common Kubernetes deployments, nodes in the cluster\n  are not part of the public internet.\n* Edge router: A router that enforces the firewall policy for your cluster. This\n  could be a gateway managed by a cloud provider or a physical piece of hardware.\n* Cluster network: A set of links, logical or physical, that facilitate communication\n  within a cluster according to the Kubernetes [networking model](/docs/concepts/cluster-administration/networking/).\n* Service: A Kubernetes {{< glossary_tooltip term_id=\"service\" >}} that identifies\n  a set of Pods using {{< glossary_tooltip text=\"label\" term_id=\"label\" >}} selectors.\n  Unless mentioned otherwise, Services are assumed to have virtual IPs only routable within the cluster network.",
      "terms": [
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Core Kubernetes resource representing a worker machine in the cluster."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "containerized applications",
          "tier": 2,
          "reasoning": "Domain concept describing applications packaged in containers."
        },
        {
          "term": "Edge router",
          "tier": 2,
          "reasoning": "Network infrastructure component that enforces firewall policy at cluster boundary."
        },
        {
          "term": "router",
          "tier": 3,
          "reasoning": "General networking term with specific meaning in cluster context."
        },
        {
          "term": "firewall policy",
          "tier": 2,
          "reasoning": "Security concept governing network traffic rules for the cluster."
        },
        {
          "term": "gateway",
          "tier": 2,
          "reasoning": "Network component that can serve as edge router, managed by cloud provider."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Infrastructure concept referring to managed cloud services hosting Kubernetes."
        },
        {
          "term": "Cluster network",
          "tier": 2,
          "reasoning": "Kubernetes networking concept describing internal cluster communication links."
        },
        {
          "term": "networking model",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept defining how network communication works."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that identifies a set of Pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing the smallest deployable unit."
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes concept for key-value pairs used to organize and select resources."
        },
        {
          "term": "selectors",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for identifying resources based on labels."
        },
        {
          "term": "virtual IPs",
          "tier": 2,
          "reasoning": "Networking concept for IP addresses assigned to Services for internal routing."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Infrastructure term describing the role of a Node in the cluster."
        },
        {
          "term": "public internet",
          "tier": 3,
          "reasoning": "Networking context term distinguishing internal cluster network from external access."
        },
        {
          "term": "nodes in the cluster",
          "tier": 2,
          "reasoning": "Phrase describing the relationship between Nodes and Cluster architecture."
        },
        {
          "term": "Nodes",
          "tier": 1,
          "reasoning": "Plural form of the core Kubernetes Node resource."
        },
        {
          "term": "cluster network",
          "tier": 2,
          "reasoning": "Lowercase variant appearing in context of Service routing scope."
        },
        {
          "term": "hardware",
          "tier": 3,
          "reasoning": "Infrastructure term describing physical edge router implementation."
        },
        {
          "term": "communication",
          "tier": 3,
          "reasoning": "Technical term in context of cluster networking and inter-node connectivity."
        },
        {
          "term": "routable",
          "tier": 3,
          "reasoning": "Networking term describing accessibility of virtual IPs within cluster."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:20:54.878118",
      "elapsed_time": 14.129920721054077
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec19",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "You might already have removed the next set",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "kubectl delete configmaps/special-config configmaps/env-config\nkubectl delete configmap -l 'game-config in (config-4,config-5)'\n```\n\nRemove the `kustomization.yaml` file that you used to generate the ConfigMap:\n\n```bash\nrm kustomization.yaml\n```\n\nIf you created a directory `configure-pod-container` and no longer need it, you should remove that too,\nor move it into the trash can / deleted files location.\n\n```bash\nrm -r configure-pod-container\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used for cluster management and resource operations."
        },
        {
          "term": "configmaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing non-confidential configuration data as key-value pairs."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API resource referenced in the context of generation and deletion."
        },
        {
          "term": "special-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "env-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "config-4",
          "tier": 1,
          "reasoning": "Named configuration resource referenced in label selector."
        },
        {
          "term": "config-5",
          "tier": 1,
          "reasoning": "Named configuration resource referenced in label selector."
        },
        {
          "term": "game-config",
          "tier": 1,
          "reasoning": "Label key used for selecting ConfigMap resources."
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Kustomize configuration file used to generate Kubernetes resources."
        },
        {
          "term": "configure-pod-container",
          "tier": 2,
          "reasoning": "Directory name related to pod and container configuration workflow."
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation/command for removing resources from the cluster."
        },
        {
          "term": "kubectl delete",
          "tier": 2,
          "reasoning": "Compound command for deleting Kubernetes resources."
        },
        {
          "term": "-l",
          "tier": 3,
          "reasoning": "kubectl flag for label selector filtering of resources."
        },
        {
          "term": "rm",
          "tier": 3,
          "reasoning": "Unix/Linux command for removing files, used in cleanup operations."
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Unix shell environment in which the commands are executed."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "File system concept relevant to organizing Kubernetes configuration files."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource referenced in directory name 'configure-pod-container'."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept referenced in directory name 'configure-pod-container'."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T21:21:07.120881",
      "elapsed_time": 11.239883422851562
    },
    {
      "chunk_id": "reference_node_node-status_sec6",
      "doc_id": "reference_node_node-status",
      "heading": "Declared features {#declaredfeatures}",
      "source_file": "reference_node_node-status.md",
      "content": "{{< feature-state feature_gate_name=\"NodeDeclaredFeatures\" >}}\n\nThis field lists specific Kubernetes features that are currently enabled on the\nnode's kubelet via [feature gates](/docs/reference/command-line-tools-reference/feature-gates/).\nThe features are reported by the kubelet as a list of strings in the\n`.status.declaredFeatures` field of the Node object.\n\nThis field is intended for newer features under active development; features that\nhave graduated and no longer require a feature gate are considered baseline and\nare not declared in this field. This reflects the enablement of Kubernetes\nfeatures, not the underlying operating system or kernel capabilities of the node.\n\nSee [Node Declared Features](/docs/concepts/scheduling-eviction/node-declared-features/)\nfor more details.",
      "terms": [
        {
          "term": "NodeDeclaredFeatures",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature gate name that controls node feature declaration functionality."
        },
        {
          "term": "feature_gate_name",
          "tier": 2,
          "reasoning": "Technical parameter reference for specifying feature gate identifiers in Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform this documentation describes."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine in the cluster."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages pod lifecycle."
        },
        {
          "term": "feature gates",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": ".status.declaredFeatures",
          "tier": 1,
          "reasoning": "Specific API field path in the Node object for reporting enabled features."
        },
        {
          "term": "Node object",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a node in the cluster."
        },
        {
          "term": "features",
          "tier": 2,
          "reasoning": "Technical concept referring to specific Kubernetes capabilities that can be enabled or disabled."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type used to represent the feature list in the API field."
        },
        {
          "term": "active development",
          "tier": 2,
          "reasoning": "Technical lifecycle stage indicating features still being developed."
        },
        {
          "term": "graduated",
          "tier": 2,
          "reasoning": "Kubernetes feature lifecycle term indicating a feature has reached stable status."
        },
        {
          "term": "baseline",
          "tier": 2,
          "reasoning": "Technical term describing features that are standard and no longer require explicit enablement."
        },
        {
          "term": "enablement",
          "tier": 2,
          "reasoning": "Technical process of activating features in Kubernetes."
        },
        {
          "term": "operating system",
          "tier": 3,
          "reasoning": "Underlying system software context distinguished from Kubernetes features."
        },
        {
          "term": "kernel",
          "tier": 3,
          "reasoning": "Core OS component whose capabilities are distinguished from Kubernetes features."
        },
        {
          "term": "capabilities",
          "tier": 2,
          "reasoning": "Technical term for system or feature abilities in the context of nodes."
        },
        {
          "term": "Node Declared Features",
          "tier": 1,
          "reasoning": "Named Kubernetes concept/feature for declaring node capabilities."
        },
        {
          "term": "scheduling-eviction",
          "tier": 2,
          "reasoning": "Kubernetes domain area related to pod placement and removal decisions."
        },
        {
          "term": "field",
          "tier": 3,
          "reasoning": "API object attribute terminology used in Kubernetes resource specifications."
        },
        {
          "term": "list",
          "tier": 3,
          "reasoning": "Data structure type used to represent multiple features in the API."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API object section containing runtime state information."
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T21:21:21.004748",
      "elapsed_time": 12.881136417388916
    },
    {
      "chunk_id": "concepts_policy__index_sec3",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using ValidatingAdmissionPolicy",
      "source_file": "concepts_policy__index.md",
      "content": "Validating admission policies allow configurable validation checks to be executed in the API server using the Common Expression Language (CEL). For example, a `ValidatingAdmissionPolicy` can be used to disallow use of the `latest` image tag.\n\nA `ValidatingAdmissionPolicy` operates on an API request and can be used to block, audit, and warn users about non-compliant configurations.\n\nDetails on the `ValidatingAdmissionPolicy` API, with examples, are documented in a dedicated section:\n* [Validating Admission Policy](/docs/reference/access-authn-authz/validating-admission-policy/)",
      "terms": [
        {
          "term": "ValidatingAdmissionPolicy",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for configurable validation checks in the API server."
        },
        {
          "term": "Validating admission policies",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for admission control validation."
        },
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Proper noun reference to the Kubernetes API resource as it appears in documentation link."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that processes API requests."
        },
        {
          "term": "Common Expression Language",
          "tier": 2,
          "reasoning": "Domain-specific language used for writing validation expressions in Kubernetes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Acronym for Common Expression Language, a technical standard used in Kubernetes validation."
        },
        {
          "term": "API request",
          "tier": 2,
          "reasoning": "Technical concept referring to requests made to the Kubernetes API server."
        },
        {
          "term": "validation checks",
          "tier": 2,
          "reasoning": "Domain concept describing the verification process for admission policies."
        },
        {
          "term": "image tag",
          "tier": 2,
          "reasoning": "Container image concept referring to version identifiers for container images."
        },
        {
          "term": "latest",
          "tier": 2,
          "reasoning": "Specific image tag value with technical significance in container best practices."
        },
        {
          "term": "block",
          "tier": 2,
          "reasoning": "Admission control action that prevents non-compliant configurations."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Admission control action for logging policy violations without blocking."
        },
        {
          "term": "warn",
          "tier": 2,
          "reasoning": "Admission control action that alerts users about non-compliant configurations."
        },
        {
          "term": "non-compliant configurations",
          "tier": 2,
          "reasoning": "Domain concept describing configurations that violate defined policies."
        },
        {
          "term": "configurable validation",
          "tier": 2,
          "reasoning": "Technical concept describing customizable validation mechanisms."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually relevant to Kubernetes."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container concept referring to container images used in Kubernetes workloads."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:21:32.742429",
      "elapsed_time": 10.733844995498657
    },
    {
      "chunk_id": "concepts_policy__index_sec1",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using API objects",
      "source_file": "concepts_policy__index.md",
      "content": "Some API objects act as policies. Here are some examples:\n* [NetworkPolicies](/docs/concepts/services-networking/network-policies/) can be used to restrict ingress and egress traffic for a workload.\n* [LimitRanges](/docs/concepts/policy/limit-range/) manage resource allocation constraints across different object kinds.\n* [ResourceQuotas](/docs/concepts/policy/resource-quotas/) limit resource consumption for a {{< glossary_tooltip text=\"namespace\" term_id=\"namespace\" >}}.",
      "terms": [
        {
          "term": "API objects",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the persistent entities in the system that represent cluster state."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Domain concept describing API objects that enforce rules and constraints on cluster behavior."
        },
        {
          "term": "NetworkPolicies",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource for controlling network traffic flow."
        },
        {
          "term": "ingress",
          "tier": 2,
          "reasoning": "Networking concept referring to incoming traffic to a workload."
        },
        {
          "term": "egress",
          "tier": 2,
          "reasoning": "Networking concept referring to outgoing traffic from a workload."
        },
        {
          "term": "traffic",
          "tier": 3,
          "reasoning": "Networking term describing data flow in the context of network policies."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running on the cluster."
        },
        {
          "term": "LimitRanges",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource for managing resource allocation constraints."
        },
        {
          "term": "resource allocation",
          "tier": 2,
          "reasoning": "Domain concept describing how compute resources are distributed to objects."
        },
        {
          "term": "constraints",
          "tier": 2,
          "reasoning": "Technical term describing limitations or rules applied to resources."
        },
        {
          "term": "object kinds",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the types/categories of API objects."
        },
        {
          "term": "ResourceQuotas",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource for limiting resource consumption per namespace."
        },
        {
          "term": "resource consumption",
          "tier": 2,
          "reasoning": "Domain concept describing the usage of compute resources by workloads."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for logical partitioning of cluster resources."
        },
        {
          "term": "ingress and egress traffic",
          "tier": 2,
          "reasoning": "Compound networking concept describing bidirectional network flow control."
        },
        {
          "term": "restrict",
          "tier": 3,
          "reasoning": "Technical action term in the context of policy enforcement on traffic."
        },
        {
          "term": "limit",
          "tier": 3,
          "reasoning": "Technical action term describing resource consumption boundaries."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:21:43.099081",
      "elapsed_time": 9.353590726852417
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec7",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Types of Ingress",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "### Ingress backed by a single Service {#single-service-ingress}\n\nThere are existing Kubernetes concepts that allow you to expose a single Service\n(see [alternatives](#alternatives)). You can also do this with an Ingress by specifying a\n*default backend* with no rules.\n\n{{% code_sample file=\"service/networking/test-ingress.yaml\" %}}\n\nIf you create it using `kubectl apply -f` you should be able to view the state\nof the Ingress you added:\n\n```bash\nkubectl get ingress test-ingress\n```\n\n```\nNAME           CLASS         HOSTS   ADDRESS         PORTS   AGE\ntest-ingress   external-lb   *       203.0.113.123   80      59s\n```\n\nWhere `203.0.113.123` is the IP allocated by the Ingress controller to satisfy\nthis Ingress.\n\n{{< note >}}\nIngress controllers and load balancers may take a minute or two to allocate an IP address.\nUntil that time, you often see the address listed as `<pending>`.\n{{< /note >}}\n\n### Simple fanout\n\nA fanout configuration routes traffic from a single IP address to more than one Service,\nbased on the HTTP URI being requested. An Ingress allows you to keep the number of load balancers\ndown to a minimum. For example, a setup like:\n\n{{< figure src=\"/docs/images/ingressFanOut.svg\" alt=\"ingress-fanout-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Fan Out\" link=\"https://mermaid.live/edit#pako:eNqNUslOwzAQ_RXLvYCUhMQpUFzUUzkgcUBwbHpw4klr4diR7bCo8O8k2FFbFomLPZq3jP00O1xpDpjijWHtFt09zAuFUCUFKHey8vf6NE7QrdoYsDZumGIb4Oi6NAskNeOoZJKpCgxK4oXwrFVgRyi7nCVXWZKRPMlysv5yD6Q4Xryf1Vq_WzDPooJs9egLNDbolKTpT03JzKgh3zWEztJZ0Niu9L-qZGcdmAMfj4cxvWmreba613z9C0B-AMQD-V_AdA-A4j5QZu0SatRKJhSqhZR0wjmPrDP6CeikrutQxy-Cuy2dtq9RpaU2dJKm6fzI5Glmg0VOLio4_5dLjx27hFSC015KJ2VZHtuQvY2fuHcaE43G0MaCREOow_FV5cMxHZ5-oPX75UM5avuXhXuOI9yAaZjg_aLuBl6B3RYaKDDtSw4166QrcKE-emrXcubghgunDaY1kxYizDqnH99UhakzHYykpWD9hjS--fEJoIELqQ\" >}}\n\nIt would require an Ingress such as:\n\n{{% code_sample file=\"service/networking/simple-fanout-example.yaml\" %}}\n\nWhen you create the Ingress with `kubectl apply -f`:\n\n```shell\nkubectl describe ingress simple-fanout-example\n```\n\n```\nName:             simple-fanout-example\nNamespace:        default\nAddress:          178.91.123.132\nDefault backend:  default-http-backend:80 (10.8.2.3:8080)\nRules:\n  Host         Path  Backends\n  ----         ----  --------\n  foo.bar.com\n               /foo   service1:4200 (10.8.0.90:4200)\n               /bar   service2:8080 (10.8.0.91:8080)\nEvents:\n  Type     Reason  Age                From                     Message\n  ----     ------  ----               ----                     -------\n  Normal   ADD     22s                loadbalancer-controller  default/test\n```\n\nThe Ingress controller provisions an implementation-specific load balancer\nthat satisfies the Ingress, as long as the Services (`service1`, `service2`) exist.\nWhen it has done so, you can see the address of the load balancer at the\nAddress field.\n\n{{< note >}}\nDepending on the [Ingress controller](/docs/concepts/services-networking/ingress-controllers/)\nyou are using, you may need to create a default-http-backend\n[Service](/docs/concepts/services-networking/service/).\n{{< /note >}}\n\n### Name based virtual hosting\n\nName-based virtual hosts support routing HTTP traffic to multiple host names at the same IP address.\n\n{{< figure src=\"/docs/images/ingressNameBased.svg\" alt=\"ingress-namebase-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Name Based Virtual hosting\" link=\"https://mermaid.live/edit#pako:eNqNkl9PwyAUxb8KYS-atM1Kp05m9qSJJj4Y97jugcLtRqTQAPVPdN_dVlq3qUt8gZt7zvkBN7xjbgRgiteW1Rt0_zjLNUJcSdD-ZBn21WmcoDu9tuBcXDHN1iDQVWHnSBkmUMEU0xwsSuK5DK5l745QejFNLtMkJVmSZmT1Re9NcTz_uDXOU1QakxTMJtxUHw7ss-SQLhehQEODTsdH4l20Q-zFyc84-Y67pghv5apxHuweMuj9eS2_NiJdPhix-kMgvwQShOyYMNkJoEUYM3PuGkpUKyY1KqVSdCSEiJy35gnoqCzLvo5fpPAbOqlfI26UsXQ0Ho9nB5CnqesRGTnncPYvSqsdUvqp9KRdlI6KojjEkB0mnLgjDRONhqENBYm6oXbLV5V1y6S7-l42_LowlIN2uFm_twqOcAW2YlK0H_i9c-bYb6CCHNO2FFCyRvkc53rbWptaMA83QnpjMS2ZchBh1nizeNMcU28bGEzXkrV_pArN7Sc0rBTu\" >}}\n\nThe following Ingress tells the backing load balancer to route requests based on\nthe [Host header](https://tools.ietf.org/html/rfc7230#section-5.4).\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress.yaml\" %}}\n\nIf you create an Ingress resource without any hosts defined in the rules, then any\nweb traffic to the IP address of your Ingress controller can be matched without a name based\nvirtual host being required.\n\nFor example, the following Ingress routes traffic\nrequested for `first.bar.com` to `service1`, `second.bar.com` to `service2`,\nand any traffic whose request host header doesn't match `first.bar.com`\nand `second.bar.com` to `service3`.\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress-no-third-host.yaml\" %}}\n\n### TLS\n\nYou can secure an Ingress by specifying a {{< glossary_tooltip term_id=\"secret\" >}}\nthat contains a TLS private key and certificate. The Ingress resource only\nsupports a single TLS port, 443, and assumes TLS termination at the ingress point\n(traffic to the Service and its Pods is in plaintext).\nIf the TLS configuration section in an Ingress specifies different hosts, they are\nmultiplexed on the same port according to the hostname specified through the\nSNI TLS extension (provided the Ingress controller supports SNI). The TLS secret\nmust contain keys named `tls.crt` and `tls.key` that contain the certificate\nand private key to use for TLS. For example:\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: testsecret-tls\n  namespace: default\ndata:\n  tls.crt: base64 encoded cert\n  tls.key: base64 encoded key\ntype: kubernetes.io/tls\n```\n\nReferencing this secret in an Ingress tells the Ingress controller to\nsecure the channel from the client to the load balancer using TLS. You need to make\nsure the TLS secret you created came from a certificate that contains a Common\nName (CN), also known as a Fully Qualified Domain Name (FQDN) for `https-example.foo.com`.\n\n{{< note >}}\nKeep in mind that TLS will not work on the default rule because the\ncertificates would have to be issued for all the possible sub-domains. Therefore,\n`hosts` in the `tls` section need to explicitly match the `host` in the `rules`\nsection.\n{{< /note >}}\n\n{{% code_sample file=\"service/networking/tls-example-ingress.yaml\" %}}\n\n{{< note >}}\nThere is a gap between TLS features supported by various ingress controllers.\nYou should refer to the documentation for the ingress controller(s) you've chosen to\nunderstand how TLS works in your environment.\n{{< /note >}}\n\n### Load balancing {#load-balancing}\n\nAn Ingress controller is bootstrapped with some load balancing policy settings\nthat it applies to all Ingress, such as the load balancing algorithm, backend\nweight scheme, and others. More advanced load balancing concepts\n(e.g. persistent sessions, dynamic weights) are not yet exposed through the\nIngress. You can instead get these features through the load balancer used for\na Service.\n\nIt's also worth noting that even though health checks are not exposed directly\nthrough the Ingress, there exist parallel concepts in Kubernetes such as\n[readiness probes](/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)\nthat allow you to achieve the same end result. Please review the controller\nspecific documentation to see how they handle health checks.",
      "terms": [
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing external access to services in a cluster."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object that exposes applications running on pods."
        },
        {
          "term": "default backend",
          "tier": 2,
          "reasoning": "Ingress configuration concept specifying where traffic goes when no rules match."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used for cluster management."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for applying configuration to resources."
        },
        {
          "term": "kubectl get ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for retrieving Ingress resources."
        },
        {
          "term": "kubectl describe ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for detailed Ingress information."
        },
        {
          "term": "Ingress controller",
          "tier": 1,
          "reasoning": "Kubernetes component that implements Ingress resources and manages load balancing."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Infrastructure component that distributes network traffic across services."
        },
        {
          "term": "IP address",
          "tier": 3,
          "reasoning": "Network addressing concept essential for Ingress routing."
        },
        {
          "term": "fanout",
          "tier": 2,
          "reasoning": "Ingress routing pattern that distributes traffic from single IP to multiple services."
        },
        {
          "term": "HTTP URI",
          "tier": 3,
          "reasoning": "Protocol-specific identifier used for routing decisions in Ingress."
        },
        {
          "term": "Name based virtual hosting",
          "tier": 2,
          "reasoning": "Ingress routing technique supporting multiple hostnames at same IP address."
        },
        {
          "term": "HTTP traffic",
          "tier": 3,
          "reasoning": "Network protocol traffic type that Ingress manages."
        },
        {
          "term": "host names",
          "tier": 3,
          "reasoning": "DNS names used for virtual host routing in Ingress."
        },
        {
          "term": "Namespace",
          "tier": 1,
          "reasoning": "Kubernetes resource for organizing and isolating cluster resources."
        },
        {
          "term": "Address",
          "tier": 2,
          "reasoning": "Ingress field showing the allocated external IP or hostname."
        },
        {
          "term": "default-http-backend",
          "tier": 1,
          "reasoning": "Specific Service name required by some Ingress controllers for fallback routing."
        },
        {
          "term": "Rules",
          "tier": 2,
          "reasoning": "Ingress configuration element defining routing paths and backends."
        },
        {
          "term": "Host",
          "tier": 2,
          "reasoning": "Ingress rule field specifying the hostname for routing."
        },
        {
          "term": "Path",
          "tier": 2,
          "reasoning": "Ingress rule field specifying URL path for routing decisions."
        },
        {
          "term": "Backends",
          "tier": 2,
          "reasoning": "Ingress configuration specifying target Services for routed traffic."
        },
        {
          "term": "PORTS",
          "tier": 2,
          "reasoning": "Network ports exposed by the Ingress resource."
        },
        {
          "term": "CLASS",
          "tier": 2,
          "reasoning": "Ingress field specifying which Ingress controller should handle the resource."
        },
        {
          "term": "external-lb",
          "tier": 1,
          "reasoning": "Specific Ingress class name shown in the example output."
        },
        {
          "term": "test-ingress",
          "tier": 1,
          "reasoning": "Specific Ingress resource name used in the documentation example."
        },
        {
          "term": "simple-fanout-example",
          "tier": 1,
          "reasoning": "Specific Ingress resource name demonstrating fanout configuration."
        },
        {
          "term": "foo.bar.com",
          "tier": 3,
          "reasoning": "Example hostname used in Ingress routing rules."
        },
        {
          "term": "service1",
          "tier": 1,
          "reasoning": "Example Service name used as Ingress backend target."
        },
        {
          "term": "service2",
          "tier": 1,
          "reasoning": "Example Service name used as Ingress backend target."
        },
        {
          "term": "loadbalancer-controller",
          "tier": 1,
          "reasoning": "Component name shown in Events that manages load balancer provisioning."
        },
        {
          "term": "Events",
          "tier": 2,
          "reasoning": "Kubernetes resource field showing cluster events related to the resource."
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "Default Kubernetes namespace where resources are created."
        }
      ],
      "term_count": 33,
      "generated_at": "2026-02-08T21:22:02.817691",
      "elapsed_time": 18.714346170425415
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec19",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Key`     {#apiserver-config-k8s-io-v1-Key}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [AESConfiguration](#apiserver-config-k8s-io-v1-AESConfiguration)\n\n- [SecretboxConfiguration](#apiserver-config-k8s-io-v1-SecretboxConfiguration)\n\n\n<p>Key contains name and secret of the provided key for a transformer.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>name</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>name is the name of the key to be used while storing data to disk.</p>\n</td>\n</tr>\n<tr><td><code>secret</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>secret is the actual key, encoded in base64.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for AES encryption settings."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for Secretbox encryption settings."
        },
        {
          "term": "Key",
          "tier": 1,
          "reasoning": "Named API object/struct that contains name and secret for a transformer."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept referring to a component that transforms/encrypts data in Kubernetes."
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Required field identifier used for storing data to disk in the Key configuration."
        },
        {
          "term": "secret",
          "tier": 2,
          "reasoning": "Technical term referring to the actual encryption key value in Kubernetes context."
        },
        {
          "term": "base64",
          "tier": 3,
          "reasoning": "Encoding standard used for representing the secret key data."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the configuration fields."
        },
        {
          "term": "apiserver-config-k8s-io-v1-AESConfiguration",
          "tier": 1,
          "reasoning": "Full API group/version/kind reference for AESConfiguration resource."
        },
        {
          "term": "apiserver-config-k8s-io-v1-SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Full API group/version/kind reference for SecretboxConfiguration resource."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing configuration structure elements in API documentation."
        },
        {
          "term": "disk",
          "tier": 3,
          "reasoning": "Storage medium referenced in context of data persistence."
        },
        {
          "term": "key",
          "tier": 2,
          "reasoning": "Cryptographic concept referring to the encryption key used for data protection."
        },
        {
          "term": "encoded",
          "tier": 3,
          "reasoning": "Technical process term describing how the secret is represented."
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T21:22:12.605177",
      "elapsed_time": 8.783101320266724
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec6",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`AnonymousAuthCondition`     {#apiserver-k8s-io-v1beta1-AnonymousAuthCondition}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [AnonymousAuthConfig](#apiserver-k8s-io-v1beta1-AnonymousAuthConfig)\n\n\n<p>AnonymousAuthCondition describes the condition under which anonymous auth\nshould be enabled.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>path</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>Path for which anonymous auth is enabled.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for anonymous authentication settings."
        },
        {
          "term": "AnonymousAuthCondition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type that describes conditions for anonymous authentication."
        },
        {
          "term": "apiserver-k8s-io-v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version identifier for the apiserver configuration."
        },
        {
          "term": "anonymous auth",
          "tier": 2,
          "reasoning": "Domain concept referring to authentication mechanism allowing unauthenticated access."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Technical field specifying the URL path for which anonymous authentication applies."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing a configuration property in the API object schema."
        },
        {
          "term": "condition",
          "tier": 2,
          "reasoning": "Domain concept describing a state or requirement that must be met for a feature to be enabled."
        },
        {
          "term": "enabled",
          "tier": 3,
          "reasoning": "Technical state indicating a feature or configuration is active."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the path field in the API schema."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "API version indicating beta maturity level in Kubernetes API versioning scheme."
        }
      ],
      "term_count": 10,
      "generated_at": "2026-02-08T21:22:21.730841",
      "elapsed_time": 8.122105598449707
    },
    {
      "chunk_id": "tasks_administer-cluster_coredns_sec3",
      "doc_id": "tasks_administer-cluster_coredns",
      "heading": "Upgrading CoreDNS",
      "source_file": "tasks_administer-cluster_coredns.md",
      "content": "You can check the version of CoreDNS that kubeadm installs for each version of\nKubernetes in the page\n[CoreDNS version in Kubernetes](https://github.com/coredns/deployment/blob/master/kubernetes/CoreDNS-k8s_version.md).\n\nCoreDNS can be upgraded manually in case you want to only upgrade CoreDNS\nor use your own custom image.\nThere is a helpful [guideline and walkthrough](https://github.com/coredns/deployment/blob/master/kubernetes/Upgrading_CoreDNS.md)\navailable to ensure a smooth upgrade.\nMake sure the existing CoreDNS configuration (\"Corefile\") is retained when\nupgrading your cluster.\n\nIf you are upgrading your cluster using the `kubeadm` tool, `kubeadm`\ncan take care of retaining the existing CoreDNS configuration automatically.",
      "terms": [
        {
          "term": "CoreDNS",
          "tier": 1,
          "reasoning": "Core Kubernetes DNS component and proper noun, a specific infrastructure component for cluster DNS resolution."
        },
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster bootstrapping and management."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform this documentation describes."
        },
        {
          "term": "Corefile",
          "tier": 1,
          "reasoning": "CoreDNS-specific configuration file name, a proper noun for the configuration resource."
        },
        {
          "term": "CoreDNS configuration",
          "tier": 2,
          "reasoning": "Domain concept referring to the settings and rules that define CoreDNS behavior."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process for updating Kubernetes components to newer versions."
        },
        {
          "term": "upgrading",
          "tier": 2,
          "reasoning": "Technical process term as used in context of cluster and component version management."
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Technical concept for software release identification, critical for compatibility management."
        },
        {
          "term": "custom image",
          "tier": 2,
          "reasoning": "Container/Kubernetes concept referring to user-provided container images rather than defaults."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept, fundamental to Kubernetes workload deployment."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical concept for system settings and parameters that control component behavior."
        },
        {
          "term": "manually",
          "tier": 3,
          "reasoning": "Operational term indicating human-driven intervention versus automated processes."
        },
        {
          "term": "retained",
          "tier": 3,
          "reasoning": "Technical term in context of preserving configuration during upgrade operations."
        },
        {
          "term": "automatically",
          "tier": 3,
          "reasoning": "Operational term indicating tool-driven automation versus manual intervention."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:22:33.343978",
      "elapsed_time": 10.607872724533081
    },
    {
      "chunk_id": "tasks_debug_debug-application_debug-statefulset_sec1",
      "doc_id": "tasks_debug_debug-application_debug-statefulset",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_debug_debug-application_debug-statefulset.md",
      "content": "* You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with your cluster.\n* You should have a StatefulSet running that you want to investigate.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes cluster",
          "tier": 1,
          "reasoning": "Core infrastructure resource - a complete Kubernetes deployment environment"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster communication and management"
        },
        {
          "term": "command-line tool",
          "tier": 2,
          "reasoning": "Technical term describing the type of interface kubectl provides"
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/workload resource for managing stateful applications"
        },
        {
          "term": "configured",
          "tier": 3,
          "reasoning": "Technical term in context referring to proper setup of kubectl to communicate with cluster"
        }
      ],
      "term_count": 7,
      "generated_at": "2026-02-08T21:22:41.272685",
      "elapsed_time": 6.924311876296997
    },
    {
      "chunk_id": "concepts_overview_working-with-objects_annotations_sec1",
      "doc_id": "concepts_overview_working-with-objects_annotations",
      "heading": "Attaching metadata to objects",
      "source_file": "concepts_overview_working-with-objects_annotations.md",
      "content": "You can use either labels or annotations to attach metadata to Kubernetes\nobjects. Labels can be used to select objects and to find\ncollections of objects that satisfy certain conditions. In contrast, annotations\nare not used to identify and select objects. The metadata\nin an annotation can be small or large, structured or unstructured, and can\ninclude characters not permitted by labels. It is possible to use labels as \nwell as annotations in the metadata of the same object.\n\nAnnotations, like labels, are key/value maps:\n\n```json\n\"metadata\": {\n  \"annotations\": {\n    \"key1\" : \"value1\",\n    \"key2\" : \"value2\"\n  }\n}\n```\n\n{{<note>}}\nThe keys and the values in the map must be strings. In other words, you cannot use\nnumeric, boolean, list or other types for either the keys or the values.\n{{</note>}}\n\nHere are some examples of information that could be recorded in annotations:\n\n* Fields managed by a declarative configuration layer. Attaching these fields\n  as annotations distinguishes them from default values set by clients or\n  servers, and from auto-generated fields and fields set by\n  auto-sizing or auto-scaling systems.\n\n* Build, release, or image information like timestamps, release IDs, git branch,\n  PR numbers, image hashes, and registry address.\n\n* Pointers to logging, monitoring, analytics, or audit repositories.\n\n* Client library or tool information that can be used for debugging purposes:\n  for example, name, version, and build information.\n\n* User or tool/system provenance information, such as URLs of related objects\n  from other ecosystem components.\n\n* Lightweight rollout tool metadata: for example, config or checkpoints.\n\n* Phone or pager numbers of persons responsible, or directory entries that\n  specify where that information can be found, such as a team web site.\n\n* Directives from the end-user to the implementations to modify behavior or\n  engage non-standard features.\n\nInstead of using annotations, you could store this type of information in an\nexternal database or directory, but that would make it much harder to produce\nshared client libraries and tools for deployment, management, introspection,\nand the like.",
      "terms": [
        {
          "term": "labels",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for object selection and identification."
        },
        {
          "term": "annotations",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for attaching non-identifying information to objects."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform this documentation describes."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Technical concept referring to data about Kubernetes objects."
        },
        {
          "term": "objects",
          "tier": 2,
          "reasoning": "Kubernetes domain term for persistent entities in the system (Pods, Services, etc.)."
        },
        {
          "term": "key/value maps",
          "tier": 2,
          "reasoning": "Data structure concept describing how annotations and labels are stored."
        },
        {
          "term": "key/value",
          "tier": 2,
          "reasoning": "Technical data structure pattern used for metadata storage."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type constraint for annotation and label keys/values."
        },
        {
          "term": "declarative configuration layer",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept for managing desired state through configuration."
        },
        {
          "term": "clients",
          "tier": 2,
          "reasoning": "Technical term for systems or tools that interact with Kubernetes API."
        },
        {
          "term": "servers",
          "tier": 2,
          "reasoning": "Technical term for systems that serve the Kubernetes API."
        },
        {
          "term": "auto-generated fields",
          "tier": 2,
          "reasoning": "Kubernetes concept for fields automatically populated by the system."
        },
        {
          "term": "auto-sizing",
          "tier": 2,
          "reasoning": "Kubernetes operational concept for automatic resource adjustment."
        },
        {
          "term": "auto-scaling systems",
          "tier": 2,
          "reasoning": "Kubernetes systems that automatically adjust workload replicas or resources."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept central to Kubernetes workloads."
        },
        {
          "term": "release IDs",
          "tier": 3,
          "reasoning": "Deployment metadata concept for tracking software versions."
        },
        {
          "term": "git branch",
          "tier": 3,
          "reasoning": "Version control concept used in build/release metadata."
        },
        {
          "term": "PR numbers",
          "tier": 3,
          "reasoning": "Pull request identifiers used in build metadata tracking."
        },
        {
          "term": "image hashes",
          "tier": 2,
          "reasoning": "Container image identification mechanism for integrity verification."
        },
        {
          "term": "registry address",
          "tier": 2,
          "reasoning": "Container registry location for image storage and retrieval."
        },
        {
          "term": "logging",
          "tier": 2,
          "reasoning": "Observability concept for recording system events."
        },
        {
          "term": "monitoring",
          "tier": 2,
          "reasoning": "Observability concept for tracking system health and metrics."
        },
        {
          "term": "analytics",
          "tier": 2,
          "reasoning": "Data analysis concept for understanding system behavior."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Security and compliance concept for tracking system access and changes."
        },
        {
          "term": "repositories",
          "tier": 3,
          "reasoning": "Storage locations for code, logs, or other artifacts."
        },
        {
          "term": "client library",
          "tier": 2,
          "reasoning": "SDK or library for programmatic Kubernetes API interaction."
        },
        {
          "term": "debugging",
          "tier": 3,
          "reasoning": "Technical process for troubleshooting system issues."
        },
        {
          "term": "provenance information",
          "tier": 2,
          "reasoning": "Metadata concept tracking origin and history of objects."
        },
        {
          "term": "ecosystem components",
          "tier": 2,
          "reasoning": "Related tools and systems in the Kubernetes ecosystem."
        },
        {
          "term": "rollout tool",
          "tier": 2,
          "reasoning": "Deployment tooling for managing application updates."
        },
        {
          "term": "config",
          "tier": 2,
          "reasoning": "Configuration data for applications or systems."
        },
        {
          "term": "checkpoints",
          "tier": 2,
          "reasoning": "State snapshots used in rollout and recovery processes."
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Process of releasing applications to Kubernetes (also a resource type)."
        },
        {
          "term": "management",
          "tier": 2,
          "reasoning": "Operational concept for administering Kubernetes resources."
        },
        {
          "term": "introspection",
          "tier": 2,
          "reasoning": "Technical capability to examine object state and metadata."
        },
        {
          "term": "external database",
          "tier": 3,
          "reasoning": "Storage system outside Kubernetes for persistent data."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "Storage or lookup system for organizational information."
        },
        {
          "term": "shared client libraries",
          "tier": 2,
          "reasoning": "Reusable code libraries for Kubernetes API interaction."
        },
        {
          "term": "tools",
          "tier": 3,
          "reasoning": "Software utilities for Kubernetes operations and management."
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T21:23:01.485844",
      "elapsed_time": 19.20917797088623
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster_sec7",
      "doc_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster.md",
      "content": "* [Learn more about DRA](/docs/concepts/scheduling-eviction/dynamic-resource-allocation)\n* [Allocate Devices to Workloads with DRA](/docs/tasks/configure-pod-container/assign-resources/allocate-devices-dra)",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Abbreviation for Dynamic Resource Allocation, a specific Kubernetes feature/API for resource management."
        },
        {
          "term": "Dynamic Resource Allocation",
          "tier": 1,
          "reasoning": "Full name of DRA, a core Kubernetes scheduling feature for allocating resources dynamically."
        },
        {
          "term": "Devices",
          "tier": 2,
          "reasoning": "Technical term referring to hardware resources (GPUs, FPGAs, etc.) that can be allocated to workloads in Kubernetes."
        },
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Domain concept referring to applications or jobs running in a Kubernetes cluster that consume resources."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the process of assigning pods to nodes based on resource requirements."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the process of terminating pods, often due to resource constraints."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Implied by 'configure-pod-container' in the URL path; fundamental Kubernetes API object and workload unit."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Appears in 'configure-pod-container' path; core concept for isolated application runtime environments."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Appears in 'assign-resources' and 'Dynamic Resource Allocation'; refers to compute resources like CPU, memory, devices."
        },
        {
          "term": "Allocate",
          "tier": 2,
          "reasoning": "Technical process term describing the assignment of resources to workloads in the scheduling context."
        }
      ],
      "term_count": 10,
      "generated_at": "2026-02-08T21:23:11.300937",
      "elapsed_time": 8.810391187667847
    },
    {
      "chunk_id": "reference_config-api_apiserver-admission.v1_sec2",
      "doc_id": "reference_config-api_apiserver-admission.v1",
      "heading": "`AdmissionResponse`     {#admission-k8s-io-v1-AdmissionResponse}",
      "source_file": "reference_config-api_apiserver-admission.v1.md",
      "content": "**Appears in:**\n\n- [AdmissionReview](#admission-k8s-io-v1-AdmissionReview)\n\n\n<p>AdmissionResponse describes an admission response.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>uid</code> <B>[Required]</B><br/>\n<a href=\"https://pkg.go.dev/k8s.io/apimachinery/pkg/types#UID\"><code>k8s.io/apimachinery/pkg/types.UID</code></a>\n</td>\n<td>\n   <p>uid is an identifier for the individual request/response.\nThis must be copied over from the corresponding AdmissionRequest.</p>\n</td>\n</tr>\n<tr><td><code>allowed</code> <B>[Required]</B><br/>\n<code>bool</code>\n</td>\n<td>\n   <p>allowed indicates whether or not the admission request was permitted.</p>\n</td>\n</tr>\n<tr><td><code>status</code><br/>\n<a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.35/#status-v1-meta\"><code>meta/v1.Status</code></a>\n</td>\n<td>\n   <p>status is the result contains extra details into why an admission request was denied.\nThis field IS NOT consulted in any way if &quot;Allowed&quot; is &quot;true&quot;.</p>\n</td>\n</tr>\n<tr><td><code>patch</code><br/>\n<code>[]byte</code>\n</td>\n<td>\n   <p>patch is the patch body. Currently we only support &quot;JSONPatch&quot; which implements RFC 6902.</p>\n</td>\n</tr>\n<tr><td><code>patchType</code><br/>\n<a href=\"#admission-k8s-io-v1-PatchType\"><code>PatchType</code></a>\n</td>\n<td>\n   <p>patchType is the type of Patch. Currently we only allow &quot;JSONPatch&quot;.</p>\n</td>\n</tr>\n<tr><td><code>auditAnnotations</code><br/>\n<code>map[string]string</code>\n</td>\n<td>\n   <p>auditAnnotations is an unstructured key value map set by remote admission controller (e.g. error=image-blacklisted).\nMutatingAdmissionWebhook and ValidatingAdmissionWebhook admission controller will prefix the keys with\nadmission webhook name (e.g. imagepolicy.example.com/error=image-blacklisted). AuditAnnotations will be provided by\nthe admission webhook to add additional context to the audit log for this request.</p>\n</td>\n</tr>\n<tr><td><code>warnings</code><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>warnings is a list of warning messages to return to the requesting API client.\nWarning messages describe a problem the client making the API request should correct or be aware of.\nLimit warnings to 120 characters if possible.\nWarnings over 256 characters and large numbers of warnings may be truncated.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AdmissionReview",
          "tier": 1,
          "reasoning": "Kubernetes API object for admission control review requests and responses."
        },
        {
          "term": "AdmissionResponse",
          "tier": 1,
          "reasoning": "Kubernetes API object that describes an admission response structure."
        },
        {
          "term": "AdmissionRequest",
          "tier": 1,
          "reasoning": "Kubernetes API object representing an admission request that AdmissionResponse corresponds to."
        },
        {
          "term": "uid",
          "tier": 2,
          "reasoning": "Field identifier for individual request/response tracking in admission control."
        },
        {
          "term": "UID",
          "tier": 2,
          "reasoning": "Type reference from k8s.io/apimachinery for unique identifiers."
        },
        {
          "term": "k8s.io/apimachinery/pkg/types.UID",
          "tier": 1,
          "reasoning": "Full package path reference to the UID type in Kubernetes apimachinery."
        },
        {
          "term": "allowed",
          "tier": 2,
          "reasoning": "Boolean field indicating whether an admission request was permitted."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Field containing extra details about why an admission request was denied."
        },
        {
          "term": "meta/v1.Status",
          "tier": 1,
          "reasoning": "Kubernetes meta API type for status information."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Field containing the patch body for mutating admission responses."
        },
        {
          "term": "JSONPatch",
          "tier": 2,
          "reasoning": "Patch format implementing RFC 6902 for JSON document modifications."
        },
        {
          "term": "RFC 6902",
          "tier": 3,
          "reasoning": "Internet standard specification for JSON Patch operations."
        },
        {
          "term": "patchType",
          "tier": 2,
          "reasoning": "Field specifying the type of patch being applied."
        },
        {
          "term": "PatchType",
          "tier": 1,
          "reasoning": "Kubernetes admission API type for specifying patch formats."
        },
        {
          "term": "auditAnnotations",
          "tier": 2,
          "reasoning": "Field for key-value annotations added by admission controllers for audit logging."
        },
        {
          "term": "admission controller",
          "tier": 2,
          "reasoning": "Kubernetes component that intercepts requests to the API server for validation or mutation."
        },
        {
          "term": "remote admission controller",
          "tier": 2,
          "reasoning": "External admission controller that processes admission requests via webhooks."
        },
        {
          "term": "MutatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Kubernetes admission controller type that can modify objects during admission."
        },
        {
          "term": "ValidatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Kubernetes admission controller type that validates objects during admission."
        },
        {
          "term": "admission webhook",
          "tier": 2,
          "reasoning": "Webhook-based mechanism for implementing custom admission control logic."
        },
        {
          "term": "audit log",
          "tier": 2,
          "reasoning": "Kubernetes logging mechanism for recording API server requests and responses."
        },
        {
          "term": "warnings",
          "tier": 2,
          "reasoning": "Field containing warning messages returned to API clients about potential issues."
        },
        {
          "term": "API client",
          "tier": 2,
          "reasoning": "Client making requests to the Kubernetes API server."
        },
        {
          "term": "API request",
          "tier": 2,
          "reasoning": "Request made to the Kubernetes API server."
        },
        {
          "term": "admission request",
          "tier": 2,
          "reasoning": "Request processed by admission controllers before persistence."
        },
        {
          "term": "map[string]string",
          "tier": 3,
          "reasoning": "Go type representing a string-to-string map data structure."
        },
        {
          "term": "[]byte",
          "tier": 3,
          "reasoning": "Go type representing a byte slice for binary data."
        },
        {
          "term": "[]string",
          "tier": 3,
          "reasoning": "Go type representing a slice of strings."
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "Boolean data type used for the allowed field."
        },
        {
          "term": "admission-k8s-io-v1-AdmissionReview",
          "tier": 1,
          "reasoning": "API reference anchor for AdmissionReview in admission.k8s.io/v1."
        },
        {
          "term": "admission-k8s-io-v1-PatchType",
          "tier": 1,
          "reasoning": "API reference anchor for PatchType in admission.k8s.io/v1."
        }
      ],
      "term_count": 31,
      "generated_at": "2026-02-08T21:23:30.290429",
      "elapsed_time": 17.98514199256897
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec1",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "{{< version-check >}}\n\n- You are the owner of an application running on a Kubernetes cluster that requires\n  high availability.\n- You should know how to deploy [Replicated Stateless Applications](/docs/tasks/run-application/run-stateless-application-deployment/)\n  and/or [Replicated Stateful Applications](/docs/tasks/run-application/run-replicated-stateful-application/).\n- You should have read about [Pod Disruptions](/docs/concepts/workloads/pods/disruptions/).\n- You should confirm with your cluster owner or service provider that they respect\n  Pod Disruption Budgets.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes cluster",
          "tier": 1,
          "reasoning": "Core infrastructure resource - the primary container orchestration platform being discussed."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the central subject of this documentation."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental architectural concept referring to a set of nodes running containerized applications."
        },
        {
          "term": "high availability",
          "tier": 2,
          "reasoning": "Critical architectural concept describing system design for continuous operation."
        },
        {
          "term": "application",
          "tier": 2,
          "reasoning": "Domain concept referring to workloads running on the cluster."
        },
        {
          "term": "Replicated Stateless Applications",
          "tier": 1,
          "reasoning": "Specific Kubernetes workload pattern and documentation reference for applications without persistent state."
        },
        {
          "term": "Replicated Stateful Applications",
          "tier": 1,
          "reasoning": "Specific Kubernetes workload pattern for applications requiring persistent state management."
        },
        {
          "term": "Pod Disruptions",
          "tier": 1,
          "reasoning": "Core Kubernetes concept describing voluntary and involuntary interruptions to Pod availability."
        },
        {
          "term": "Pod Disruption Budgets",
          "tier": 1,
          "reasoning": "Specific Kubernetes API object (PDB) that limits disruptions to Pods during voluntary operations."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object - the smallest deployable unit in Kubernetes."
        },
        {
          "term": "owner",
          "tier": 2,
          "reasoning": "Domain concept referring to the entity responsible for managing an application or resource."
        },
        {
          "term": "cluster owner",
          "tier": 2,
          "reasoning": "Role-based concept describing the administrator responsible for cluster operations."
        },
        {
          "term": "service provider",
          "tier": 2,
          "reasoning": "Domain concept referring to managed Kubernetes service operators."
        },
        {
          "term": "deploy",
          "tier": 2,
          "reasoning": "Technical process of releasing and running applications on the cluster."
        },
        {
          "term": "Stateless Applications",
          "tier": 2,
          "reasoning": "Application architecture pattern where instances don't maintain persistent state."
        },
        {
          "term": "Stateful Applications",
          "tier": 2,
          "reasoning": "Application architecture pattern where instances maintain persistent state across restarts."
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:23:41.336265",
      "elapsed_time": 10.041298627853394
    },
    {
      "chunk_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information_sec2",
      "doc_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information",
      "heading": "Store container fields",
      "source_file": "tasks_inject-data-application_downward-api-volume-expose-pod-information.md",
      "content": "The preceding exercise, you made Pod-level fields accessible using the\ndownward API.\nIn this next exercise, you are going to pass fields that are part of the Pod\ndefinition, but taken from the specific\n[container](/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container)\nrather than from the Pod overall. Here is a manifest for a Pod that again has\njust one container:\n\n{{% code_sample file=\"pods/inject/dapi-volume-resources.yaml\" %}}\n\nIn the manifest, you can see that the Pod has a\n[`downwardAPI` volume](/docs/concepts/storage/volumes/#downwardapi),\nand that the single container in that Pod mounts the volume at `/etc/podinfo`.\n\nLook at the `items` array under `downwardAPI`. Each element of the array\ndefines a file in the downward API volume.\n\nThe first element specifies that in the container named `client-container`,\nthe value of the `limits.cpu` field in the format specified by `1m` should be\npublished as a file named `cpu_limit`. The `divisor` field is optional and has the\ndefault value of `1`. A divisor of 1 means cores for `cpu` resources, or\nbytes for `memory` resources.\n\nCreate the Pod:\n\n```shell\nkubectl apply -f https://k8s.io/examples/pods/inject/dapi-volume-resources.yaml\n```\n\nGet a shell into the container that is running in your Pod:\n\n```shell\nkubectl exec -it kubernetes-downwardapi-volume-example-2 -- sh\n```\n\nIn your shell, view the `cpu_limit` file:\n\n```shell",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and workload resource explicitly discussed throughout the chunk."
        },
        {
          "term": "downward API",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature for exposing Pod and container information to containers."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing the runtime unit within a Pod."
        },
        {
          "term": "Pod-level fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata and spec fields defined at the Pod scope."
        },
        {
          "term": "manifest",
          "tier": 2,
          "reasoning": "Technical term for the YAML/JSON file that declares Kubernetes resources."
        },
        {
          "term": "downwardAPI volume",
          "tier": 1,
          "reasoning": "Specific Kubernetes volume type that exposes Pod/container information as files."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Core Kubernetes storage concept for providing persistent or ephemeral storage to containers."
        },
        {
          "term": "client-container",
          "tier": 1,
          "reasoning": "Specific container name referenced in the example manifest."
        },
        {
          "term": "limits.cpu",
          "tier": 2,
          "reasoning": "Kubernetes resource field specifying CPU resource limits for a container."
        },
        {
          "term": "divisor",
          "tier": 2,
          "reasoning": "Technical field in downward API configuration that specifies unit conversion."
        },
        {
          "term": "cpu",
          "tier": 3,
          "reasoning": "Computing resource type managed by Kubernetes resource limits and requests."
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "Computing resource type managed by Kubernetes resource limits and requests."
        },
        {
          "term": "cores",
          "tier": 3,
          "reasoning": "Unit of CPU measurement referenced in the context of resource divisors."
        },
        {
          "term": "bytes",
          "tier": 3,
          "reasoning": "Unit of memory measurement referenced in the context of resource divisors."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for creating or updating resources declaratively."
        },
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for executing commands inside a container."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes command-line interface tool."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for interacting with containers."
        },
        {
          "term": "cpu_limit",
          "tier": 2,
          "reasoning": "Specific file name created by the downward API to expose CPU limit information."
        },
        {
          "term": "kubernetes-downwardapi-volume-example-2",
          "tier": 1,
          "reasoning": "Specific Pod name used in the example commands."
        },
        {
          "term": "1m",
          "tier": 2,
          "reasoning": "Kubernetes resource quantity format representing millicores for CPU."
        },
        {
          "term": "/etc/podinfo",
          "tier": 2,
          "reasoning": "Mount path where the downward API volume is mounted in the container."
        },
        {
          "term": "mounts",
          "tier": 2,
          "reasoning": "Technical operation of attaching a volume to a container filesystem."
        },
        {
          "term": "file",
          "tier": 3,
          "reasoning": "Filesystem object created by downward API to expose container/Pod information."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kubernetes concept for CPU and memory allocations to containers."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:23:56.619507",
      "elapsed_time": 14.2784583568573
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec10",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a deployment.yaml file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF > deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx\n        ports:\n        - containerPort: 80\nEOF",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource for managing replicated applications."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource."
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployment resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field that specifies the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section containing resource identification information."
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Kubernetes metadata field used to identify resources within a namespace."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section defining the desired state specification of a resource."
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching and selecting resources based on labels."
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector field for exact label matching to identify target pods."
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes Deployment field specifying the desired number of pod instances."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Kubernetes pod template specification embedded within a Deployment."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes pod spec field defining the container workloads to run."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core virtualization concept for isolated application runtime environments."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image reference specifying the packaged application to deploy."
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container image name referring to the NGINX web server software."
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Kubernetes container spec field for defining network port configurations."
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes field specifying the port number exposed by a container."
        },
        {
          "term": "deployment.yaml",
          "tier": 3,
          "reasoning": "Kubernetes manifest file naming convention for Deployment resources."
        },
        {
          "term": "my-nginx",
          "tier": 3,
          "reasoning": "Resource name and label value used to identify this specific Deployment and its pods."
        },
        {
          "term": "run",
          "tier": 3,
          "reasoning": "Label key used in this manifest for pod selection and identification."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T21:24:09.261500",
      "elapsed_time": 11.637039184570312
    },
    {
      "chunk_id": "reference_node_node-status_sec3",
      "doc_id": "reference_node_node-status",
      "heading": "Conditions {#condition}",
      "source_file": "reference_node_node-status.md",
      "content": "The `conditions` field describes the status of all `Running` nodes. Examples of conditions include:\n\n{{< table caption = \"Node conditions, and a description of when each condition applies.\" >}}\n| Node Condition       | Description |\n|----------------------|-------------|\n| `Ready`              | `True` if the node is healthy and ready to accept pods, `False` if the node is not healthy and is not accepting pods, and `Unknown` if the node controller has not heard from the node in the last `node-monitor-grace-period` (default is 50 seconds) |\n| `DiskPressure`       | `True` if pressure exists on the disk size\u2014that is, if the disk capacity is low; otherwise `False` |\n| `MemoryPressure`     | `True` if pressure exists on the node memory\u2014that is, if the node memory is low; otherwise `False` |\n| `PIDPressure`        | `True` if pressure exists on the processes\u2014that is, if there are too many processes on the node; otherwise `False` |\n| `NetworkUnavailable` | `True` if the network for the node is not correctly configured, otherwise `False` |\n{{< /table >}}\n\n{{< note >}}\nIf you use command-line tools to print details of a cordoned Node, the Condition includes\n`SchedulingDisabled`. `SchedulingDisabled` is not a Condition in the Kubernetes API; instead,\ncordoned nodes are marked Unschedulable in their spec.\n{{< /note >}}\n\nIn the Kubernetes API, a node's condition is represented as part of the `.status`\nof the Node resource. For example, the following JSON structure describes a healthy node:\n\n```json\n\"conditions\": [\n  {\n    \"type\": \"Ready\",\n    \"status\": \"True\",\n    \"reason\": \"KubeletReady\",\n    \"message\": \"kubelet is posting ready status\",\n    \"lastHeartbeatTime\": \"2019-06-05T18:38:35Z\",\n    \"lastTransitionTime\": \"2019-06-05T11:41:27Z\"\n  }\n]\n```\n\nWhen problems occur on nodes, the Kubernetes control plane automatically creates\n[taints](/docs/concepts/scheduling-eviction/taint-and-toleration/) that match the conditions\naffecting the node. An example of this is when the `status` of the Ready condition\nremains `Unknown` or `False` for longer than the kube-controller-manager's `NodeMonitorGracePeriod`,\nwhich defaults to 50 seconds. This will cause either an `node.kubernetes.io/unreachable` taint, for an `Unknown` status,\nor a `node.kubernetes.io/not-ready` taint, for a `False` status, to be added to the Node.\n\nThese taints affect pending pods as the scheduler takes the Node's taints into consideration when\nassigning a pod to a Node. Existing pods scheduled to the node may be evicted due to the application\nof `NoExecute` taints. Pods may also have {{< glossary_tooltip text=\"tolerations\" term_id=\"toleration\" >}} that let\nthem schedule to and continue running on a Node even though it has a specific taint.\n\nSee [Taint Based Evictions](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-based-evictions) and\n[Taint Nodes by Condition](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-nodes-by-condition)\nfor more details.",
      "terms": [
        {
          "term": "conditions",
          "tier": 2,
          "reasoning": "Domain concept describing the status field of node resources in Kubernetes API"
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "Node status state indicating operational nodes"
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing worker machines in a cluster"
        },
        {
          "term": "Node Condition",
          "tier": 2,
          "reasoning": "Specific Kubernetes concept for describing node health states"
        },
        {
          "term": "Ready",
          "tier": 1,
          "reasoning": "Named node condition type in Kubernetes API"
        },
        {
          "term": "DiskPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low disk capacity"
        },
        {
          "term": "MemoryPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low node memory"
        },
        {
          "term": "PIDPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating too many processes"
        },
        {
          "term": "NetworkUnavailable",
          "tier": 1,
          "reasoning": "Named node condition type indicating network misconfiguration"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing deployable units"
        },
        {
          "term": "node controller",
          "tier": 1,
          "reasoning": "Kubernetes control plane component managing node lifecycle"
        },
        {
          "term": "node-monitor-grace-period",
          "tier": 1,
          "reasoning": "Specific configuration parameter for node monitoring timeout"
        },
        {
          "term": "disk capacity",
          "tier": 3,
          "reasoning": "Technical term for storage space relevant to DiskPressure condition"
        },
        {
          "term": "node memory",
          "tier": 2,
          "reasoning": "Technical concept for memory resources on a node"
        },
        {
          "term": "processes",
          "tier": 3,
          "reasoning": "OS-level concept relevant to PIDPressure condition"
        },
        {
          "term": "network",
          "tier": 3,
          "reasoning": "Infrastructure concept relevant to NetworkUnavailable condition"
        },
        {
          "term": "cordoned Node",
          "tier": 2,
          "reasoning": "Kubernetes operational concept for nodes marked to prevent new pod scheduling"
        },
        {
          "term": "SchedulingDisabled",
          "tier": 1,
          "reasoning": "Condition label shown in CLI for cordoned nodes"
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for interacting with Kubernetes resources"
        },
        {
          "term": "Unschedulable",
          "tier": 2,
          "reasoning": "Node spec field marking nodes as not accepting new pods"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes resource specification field"
        },
        {
          "term": ".status",
          "tier": 2,
          "reasoning": "Kubernetes resource status field containing runtime state"
        },
        {
          "term": "Node resource",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a cluster node"
        },
        {
          "term": "type",
          "tier": 2,
          "reasoning": "Field in condition structure identifying the condition kind"
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Field in condition structure indicating True/False/Unknown state"
        },
        {
          "term": "reason",
          "tier": 2,
          "reasoning": "Field in condition structure providing machine-readable cause"
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Field in condition structure providing human-readable description"
        },
        {
          "term": "lastHeartbeatTime",
          "tier": 2,
          "reasoning": "Condition field tracking last node heartbeat timestamp"
        },
        {
          "term": "lastTransitionTime",
          "tier": 2,
          "reasoning": "Condition field tracking when condition last changed"
        },
        {
          "term": "KubeletReady",
          "tier": 1,
          "reasoning": "Specific reason value indicating kubelet is operational"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component"
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept for cluster management components"
        },
        {
          "term": "taints",
          "tier": 2,
          "reasoning": "Kubernetes scheduling mechanism to repel pods from nodes"
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component running controllers"
        },
        {
          "term": "NodeMonitorGracePeriod",
          "tier": 1,
          "reasoning": "Specific kube-controller-manager configuration parameter"
        },
        {
          "term": "node.kubernetes.io/unreachable",
          "tier": 1,
          "reasoning": "Specific taint key applied when node status is Unknown"
        },
        {
          "term": "node.kubernetes.io/not-ready",
          "tier": 1,
          "reasoning": "Specific taint key applied when node status is False"
        },
        {
          "term": "Unknown",
          "tier": 2,
          "reasoning": "Condition status value indicating uncertain node state"
        },
        {
          "term": "False",
          "tier": 2,
          "reasoning": "Condition status value indicating negative/unhealthy state"
        },
        {
          "term": "True",
          "tier": 2,
          "reasoning": "Condition status value indicating positive/healthy state"
        },
        {
          "term": "pending pods",
          "tier": 2,
          "reasoning": "Pods waiting to be scheduled to a node"
        },
        {
          "term": "scheduler",
          "tier": 1,
          "reasoning": "Kubernetes control plane component assigning pods to nodes"
        },
        {
          "term": "evicted",
          "tier": 2,
          "reasoning": "Process of removing pods from nodes"
        },
        {
          "term": "NoExecute",
          "tier": 1,
          "reasoning": "Taint effect that evicts existing pods and prevents new scheduling"
        },
        {
          "term": "tolerations",
          "tier": 2,
          "reasoning": "Pod specification allowing scheduling despite node taints"
        },
        {
          "term": "Taint Based Evictions",
          "tier": 2,
          "reasoning": "Kubernetes concept for evicting pods based on node taints"
        },
        {
          "term": "Taint Nodes by Condition",
          "tier": 2,
          "reasoning": "Kubernetes feature automatically tainting nodes based on conditions"
        }
      ],
      "term_count": 47,
      "generated_at": "2026-02-08T21:24:33.478951",
      "elapsed_time": 23.211890935897827
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec21",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`ProviderConfiguration`     {#apiserver-config-k8s-io-v1-ProviderConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [ResourceConfiguration](#apiserver-config-k8s-io-v1-ResourceConfiguration)\n\n\n<p>ProviderConfiguration stores the provided configuration for an encryption provider.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>aesgcm</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aesgcm is the configuration for the AES-GCM transformer.</p>\n</td>\n</tr>\n<tr><td><code>aescbc</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aescbc is the configuration for the AES-CBC transformer.</p>\n</td>\n</tr>\n<tr><td><code>secretbox</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-SecretboxConfiguration\"><code>SecretboxConfiguration</code></a>\n</td>\n<td>\n   <p>secretbox is the configuration for the Secretbox based transformer.</p>\n</td>\n</tr>\n<tr><td><code>identity</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-IdentityConfiguration\"><code>IdentityConfiguration</code></a>\n</td>\n<td>\n   <p>identity is the (empty) configuration for the identity transformer.</p>\n</td>\n</tr>\n<tr><td><code>kms</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-KMSConfiguration\"><code>KMSConfiguration</code></a>\n</td>\n<td>\n   <p>kms contains the name, cache size and path to configuration file for a KMS based envelope transformer.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "ResourceConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for resource encryption settings."
        },
        {
          "term": "ProviderConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration structure that stores encryption provider settings."
        },
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for AES encryption transformers."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for Secretbox-based encryption."
        },
        {
          "term": "IdentityConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for the identity transformer."
        },
        {
          "term": "KMSConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration type for KMS-based envelope encryption."
        },
        {
          "term": "encryption provider",
          "tier": 2,
          "reasoning": "Domain concept referring to a pluggable encryption mechanism for Kubernetes secrets at rest."
        },
        {
          "term": "aesgcm",
          "tier": 2,
          "reasoning": "Configuration field name for AES-GCM encryption transformer in Kubernetes."
        },
        {
          "term": "AES-GCM transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using AES in Galois/Counter Mode for data encryption."
        },
        {
          "term": "aescbc",
          "tier": 2,
          "reasoning": "Configuration field name for AES-CBC encryption transformer in Kubernetes."
        },
        {
          "term": "AES-CBC transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using AES in Cipher Block Chaining mode."
        },
        {
          "term": "secretbox",
          "tier": 2,
          "reasoning": "Configuration field for Secretbox-based encryption transformer."
        },
        {
          "term": "Secretbox based transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using NaCl Secretbox authenticated encryption."
        },
        {
          "term": "identity",
          "tier": 2,
          "reasoning": "Configuration field for the identity transformer that performs no encryption."
        },
        {
          "term": "identity transformer",
          "tier": 2,
          "reasoning": "A transformer that passes data through unchanged without encryption."
        },
        {
          "term": "kms",
          "tier": 2,
          "reasoning": "Configuration field for Key Management Service based encryption."
        },
        {
          "term": "KMS based envelope transformer",
          "tier": 2,
          "reasoning": "Encryption transformer using external KMS for envelope encryption of data."
        },
        {
          "term": "envelope transformer",
          "tier": 2,
          "reasoning": "Encryption pattern where data encryption keys are wrapped by a master key."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept for a component that transforms data during encryption/decryption."
        },
        {
          "term": "cache size",
          "tier": 3,
          "reasoning": "Technical parameter for KMS configuration affecting key caching behavior."
        },
        {
          "term": "configuration file",
          "tier": 3,
          "reasoning": "Technical term for the file containing KMS transformer settings."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version identifier for apiserver configuration resources."
        },
        {
          "term": "AES-GCM",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Galois/Counter Mode, a cryptographic algorithm."
        },
        {
          "term": "AES-CBC",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Cipher Block Chaining mode, a cryptographic algorithm."
        },
        {
          "term": "KMS",
          "tier": 3,
          "reasoning": "Key Management Service, external service for managing encryption keys."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:24:46.574551",
      "elapsed_time": 12.087833404541016
    },
    {
      "chunk_id": "reference_setup-tools_kubeadm_kubeadm-upgrade_sec1",
      "doc_id": "reference_setup-tools_kubeadm_kubeadm-upgrade",
      "heading": "kubeadm upgrade guidance",
      "source_file": "reference_setup-tools_kubeadm_kubeadm-upgrade.md",
      "content": "The steps for performing an upgrade using kubeadm are outlined in [this document](/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/).\nFor older versions of kubeadm, please refer to older documentation sets of the Kubernetes website.\n\nYou can use `kubeadm upgrade diff` to see the changes that would be applied to static pod manifests.\n\nIn Kubernetes v1.15.0 and later, `kubeadm upgrade apply` and `kubeadm upgrade node` will also\nautomatically renew the kubeadm managed certificates on this node, including those stored in kubeconfig files.\nTo opt-out, it is possible to pass the flag `--certificate-renewal=false`. For more details about certificate\nrenewal see the [certificate management documentation](/docs/tasks/administer-cluster/kubeadm/kubeadm-certs).\n\n{{< note >}}\nThe commands `kubeadm upgrade apply` and `kubeadm upgrade plan` have a legacy `--config`\nflag which makes it possible to reconfigure the cluster, while performing planning or upgrade of that particular\ncontrol-plane node. Please be aware that the upgrade workflow was not designed for this scenario and there are\nreports of unexpected results.\n{{</ note >}}",
      "terms": [
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI tool for cluster bootstrapping and management"
        },
        {
          "term": "kubeadm upgrade",
          "tier": 1,
          "reasoning": "Specific kubeadm subcommand for performing cluster upgrades"
        },
        {
          "term": "kubeadm upgrade diff",
          "tier": 1,
          "reasoning": "Specific kubeadm command to preview changes to static pod manifests"
        },
        {
          "term": "kubeadm upgrade apply",
          "tier": 1,
          "reasoning": "Specific kubeadm command to apply cluster upgrades"
        },
        {
          "term": "kubeadm upgrade node",
          "tier": 1,
          "reasoning": "Specific kubeadm command to upgrade a node"
        },
        {
          "term": "kubeadm upgrade plan",
          "tier": 1,
          "reasoning": "Specific kubeadm command for planning cluster upgrades"
        },
        {
          "term": "static pod manifests",
          "tier": 2,
          "reasoning": "Domain concept referring to pod definitions managed directly by kubelet"
        },
        {
          "term": "static pod",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for pods managed directly by kubelet without API server"
        },
        {
          "term": "manifests",
          "tier": 2,
          "reasoning": "Technical term for Kubernetes resource definition files"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented"
        },
        {
          "term": "certificates",
          "tier": 2,
          "reasoning": "Security concept for TLS/PKI certificates used in cluster authentication"
        },
        {
          "term": "certificate renewal",
          "tier": 2,
          "reasoning": "Process of renewing expiring certificates in the cluster"
        },
        {
          "term": "kubeconfig files",
          "tier": 1,
          "reasoning": "Configuration files containing cluster access credentials and settings"
        },
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Core Kubernetes configuration file format for cluster access"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine in the cluster"
        },
        {
          "term": "--certificate-renewal=false",
          "tier": 1,
          "reasoning": "Specific CLI flag to disable automatic certificate renewal"
        },
        {
          "term": "--config",
          "tier": 1,
          "reasoning": "CLI flag for specifying configuration during upgrade operations"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core architectural concept representing a set of Kubernetes nodes"
        },
        {
          "term": "control-plane node",
          "tier": 2,
          "reasoning": "Node running control plane components that manage the cluster"
        },
        {
          "term": "control-plane",
          "tier": 2,
          "reasoning": "Architectural concept for the components that manage cluster state"
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process of updating Kubernetes version or components"
        },
        {
          "term": "upgrade workflow",
          "tier": 2,
          "reasoning": "The defined process and steps for performing cluster upgrades"
        },
        {
          "term": "certificate management",
          "tier": 2,
          "reasoning": "Domain concept for handling PKI certificates in the cluster"
        },
        {
          "term": "reconfigure",
          "tier": 2,
          "reasoning": "Technical process of changing cluster configuration"
        },
        {
          "term": "v1.15.0",
          "tier": 3,
          "reasoning": "Specific Kubernetes version reference indicating feature availability"
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:25:01.014628",
      "elapsed_time": 13.434211730957031
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec18",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "{{% heading \"cleanup\" %}}",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "Delete the ConfigMaps and Pods that you made:\n\n```bash\nkubectl delete configmaps/game-config configmaps/game-config-2 configmaps/game-config-3 \\\n               configmaps/game-config-env-file\nkubectl delete pod dapi-test-pod --now",
      "terms": [
        {
          "term": "ConfigMaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data as key-value pairs"
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Kubernetes API object representing the smallest deployable unit"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used to interact with the cluster"
        },
        {
          "term": "kubectl delete",
          "tier": 1,
          "reasoning": "Specific kubectl command for removing Kubernetes resources"
        },
        {
          "term": "game-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance being deleted"
        },
        {
          "term": "game-config-2",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance being deleted"
        },
        {
          "term": "game-config-3",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance being deleted"
        },
        {
          "term": "game-config-env-file",
          "tier": 1,
          "reasoning": "Named ConfigMap resource instance created from environment file"
        },
        {
          "term": "dapi-test-pod",
          "tier": 1,
          "reasoning": "Named Pod resource instance being deleted, likely for Downward API testing"
        },
        {
          "term": "configmaps",
          "tier": 1,
          "reasoning": "Resource type specifier used in kubectl command syntax"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Resource type specifier used in kubectl delete command"
        },
        {
          "term": "--now",
          "tier": 2,
          "reasoning": "kubectl flag that forces immediate deletion without waiting for graceful termination"
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation to remove resources from the cluster"
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Unix shell environment in which the kubectl commands are executed"
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T21:25:10.441721",
      "elapsed_time": 8.421381711959839
    },
    {
      "chunk_id": "reference_instrumentation_node-metrics_sec0",
      "doc_id": "reference_instrumentation_node-metrics",
      "heading": "Introduction",
      "source_file": "reference_instrumentation_node-metrics.md",
      "content": "---\ntitle: Node metrics data\ncontent_type: reference\nweight: 50\ndescription: >-\n  Mechanisms for accessing metrics at node, volume, pod and container level,\n  as seen by the kubelet.\n---\n\nThe [kubelet](/docs/reference/command-line-tools-reference/kubelet/)\ngathers metric statistics at the node, volume, pod and container level,\nand emits this information in the\n[Summary API](/docs/reference/config-api/kubelet-stats.v1alpha1/).\n\nYou can send a proxied request to the stats summary API via the\nKubernetes API server.\n\nHere is an example of a Summary API request for a node named `minikube`:\n\n```shell\nkubectl get --raw \"/api/v1/nodes/minikube/proxy/stats/summary\"\n```\n\nHere is the same API call using `curl`:\n\n```shell",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for node-level operations, explicitly referenced and linked in the documentation."
        },
        {
          "term": "Summary API",
          "tier": 1,
          "reasoning": "Specific Kubernetes API for accessing kubelet statistics, a named API endpoint."
        },
        {
          "term": "Kubernetes API server",
          "tier": 1,
          "reasoning": "Core control plane component that proxies requests to the stats summary API."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used in the example command."
        },
        {
          "term": "minikube",
          "tier": 1,
          "reasoning": "Named Kubernetes distribution/tool used as an example node name."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine where pods run."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Kubernetes storage abstraction, one of the levels at which metrics are gathered."
        },
        {
          "term": "pod",
          "tier": 2,
          "reasoning": "Core Kubernetes workload unit, one of the levels at which metrics are gathered."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental unit of deployment in Kubernetes, one of the levels at which metrics are gathered."
        },
        {
          "term": "metric statistics",
          "tier": 2,
          "reasoning": "Domain concept referring to the quantitative data collected by the kubelet."
        },
        {
          "term": "metrics",
          "tier": 2,
          "reasoning": "Core observability concept central to the document's purpose."
        },
        {
          "term": "Node metrics data",
          "tier": 2,
          "reasoning": "The main topic of the document, referring to metrics collected at the node level."
        },
        {
          "term": "stats summary API",
          "tier": 2,
          "reasoning": "Alternative reference to the Summary API for kubelet statistics."
        },
        {
          "term": "proxied request",
          "tier": 2,
          "reasoning": "Technical concept describing how requests are forwarded through the API server."
        },
        {
          "term": "container level",
          "tier": 2,
          "reasoning": "Hierarchical scope at which metrics are collected."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface, used in context of Kubernetes APIs."
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool for making HTTP requests, shown as alternative to kubectl."
        },
        {
          "term": "kubectl get",
          "tier": 3,
          "reasoning": "Specific kubectl subcommand used to retrieve resources or make raw API calls."
        },
        {
          "term": "--raw",
          "tier": 3,
          "reasoning": "kubectl flag that allows making raw API requests to the Kubernetes API server."
        },
        {
          "term": "proxy",
          "tier": 3,
          "reasoning": "Technical concept for forwarding requests, used in the API path structure."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T21:25:25.155939",
      "elapsed_time": 13.707784175872803
    },
    {
      "chunk_id": "concepts_cluster-administration_system-logs_sec1",
      "doc_id": "concepts_cluster-administration_system-logs",
      "heading": "Klog",
      "source_file": "concepts_cluster-administration_system-logs.md",
      "content": "klog is the Kubernetes logging library. [klog](https://github.com/kubernetes/klog)\ngenerates log messages for the Kubernetes system components.\n\nKubernetes is in the process of simplifying logging in its components.\nThe following klog command line flags\n[are deprecated](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/2845-deprecate-klog-specific-flags-in-k8s-components)\nstarting with Kubernetes v1.23 and removed in Kubernetes v1.26:\n\n- `--add-dir-header`\n- `--alsologtostderr`\n- `--log-backtrace-at`\n- `--log-dir`\n- `--log-file`\n- `--log-file-max-size`\n- `--logtostderr`\n- `--one-output`\n- `--skip-headers`\n- `--skip-log-headers`\n- `--stderrthreshold`\n\nOutput will always be written to stderr, regardless of the output format. Output redirection is\nexpected to be handled by the component which invokes a Kubernetes component. This can be a POSIX\nshell or a tool like systemd.\n\nIn some cases, for example a distroless container or a Windows system service, those options are\nnot available. Then the\n[`kube-log-runner`](https://github.com/kubernetes/kubernetes/blob/d2a8a81639fcff8d1221b900f66d28361a170654/staging/src/k8s.io/component-base/logs/kube-log-runner/README.md)\nbinary can be used as wrapper around a Kubernetes component to redirect\noutput. A prebuilt binary is included in several Kubernetes base images under\nits traditional name as `/go-runner` and as `kube-log-runner` in server and\nnode release archives.\n\nThis table shows how `kube-log-runner` invocations correspond to shell redirection:\n\n| Usage                                    | POSIX shell (such as bash) | `kube-log-runner <options> <cmd>`                           |\n| -----------------------------------------|----------------------------|-------------------------------------------------------------|\n| Merge stderr and stdout, write to stdout | `2>&1`                     | `kube-log-runner` (default behavior)                        |\n| Redirect both into log file              | `1>>/tmp/log 2>&1`         | `kube-log-runner -log-file=/tmp/log`                        |\n| Copy into log file and to stdout         | `2>&1 \\| tee -a /tmp/log`  | `kube-log-runner -log-file=/tmp/log -also-stdout`           |\n| Redirect only stdout into log file       | `>/tmp/log`                | `kube-log-runner -log-file=/tmp/log -redirect-stderr=false` |\n\n### Klog output\n\nAn example of the traditional klog native format:\n\n```\nI1025 00:15:15.525108       1 httplog.go:79] GET /api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-57c75779f-9p8wg: (1.512ms) 200 [pod_nanny/v0.0.0 (linux/amd64) kubernetes/$Format 10.56.1.19:51756]\n```\n\nThe message string may contain line breaks:\n\n```\nI1025 00:15:15.525108       1 example.go:79] This is a message\nwhich has a line break.\n```\n\n### Structured Logging\n\n{{< feature-state for_k8s_version=\"v1.23\" state=\"beta\" >}}\n\n{{< warning >}}\nMigration to structured log messages is an ongoing process. Not all log messages are structured in\nthis version. When parsing log files, you must also handle unstructured log messages.\n\nLog formatting and value serialization are subject to change.\n{{< /warning>}}\n\nStructured logging introduces a uniform structure in log messages allowing for programmatic\nextraction of information. You can store and process structured logs with less effort and cost.\nThe code which generates a log message determines whether it uses the traditional unstructured\nklog output or structured logging.\n\nThe default formatting of structured log messages is as text, with a format that is backward\ncompatible with traditional klog:\n\n```\n<klog header> \"<message>\" <key1>=\"<value1>\" <key2>=\"<value2>\" ...\n```\n\nExample:\n\n```\nI1025 00:15:15.525108       1 controller_utils.go:116] \"Pod status updated\" pod=\"kube-system/kubedns\" status=\"ready\"\n```\n\nStrings are quoted. Other values are formatted with\n[`%+v`](https://pkg.go.dev/fmt#hdr-Printing), which may cause log messages to\ncontinue on the next line [depending on the data](https://github.com/kubernetes/kubernetes/issues/106428).\n\n```\nI1025 00:15:15.525108       1 example.go:116] \"Example\" data=\"This is text with a line break\\nand \\\"quotation marks\\\".\" someInt=1 someFloat=0.1 someStruct={StringField: First line,\nsecond line.}\n```\n\n### Contextual Logging\n\n{{< feature-state for_k8s_version=\"v1.30\" state=\"beta\" >}}\n\nContextual logging builds on top of structured logging. It is primarily about\nhow developers use logging calls: code based on that concept is more flexible\nand supports additional use cases as described in the [Contextual Logging\nKEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/3077-contextual-logging).\n\nIf developers use additional functions like `WithValues` or `WithName` in\ntheir components, then log entries contain additional information that gets\npassed into functions by their caller.\n\nFor Kubernetes {{< skew currentVersion >}}, this is gated behind the `ContextualLogging`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) and is\nenabled by default. The infrastructure for this was added in 1.24 without\nmodifying components. The\n[`component-base/logs/example`](https://github.com/kubernetes/kubernetes/blob/v1.24.0-beta.0/staging/src/k8s.io/component-base/logs/example/cmd/logger.go)\ncommand demonstrates how to use the new logging calls and how a component\nbehaves that supports contextual logging.\n\n```console\n$ cd $GOPATH/src/k8s.io/kubernetes/staging/src/k8s.io/component-base/logs/example/cmd/\n$ go run . --help\n...\n      --feature-gates mapStringBool  A set of key=value pairs that describe feature gates for alpha/experimental features. Options are:\n                                     AllAlpha=true|false (ALPHA - default=false)\n                                     AllBeta=true|false (BETA - default=false)\n                                     ContextualLogging=true|false (BETA - default=true)\n$ go run . --feature-gates ContextualLogging=true\n...\nI0222 15:13:31.645988  197901 example.go:54] \"runtime\" logger=\"example.myname\" foo=\"bar\" duration=\"1m0s\"\nI0222 15:13:31.646007  197901 example.go:55] \"another runtime\" logger=\"example\" foo=\"bar\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\nThe `logger` key and `foo=\"bar\"` were added by the caller of the function\nwhich logs the `runtime` message and `duration=\"1m0s\"` value, without having to\nmodify that function.\n\nWith contextual logging disable, `WithValues` and `WithName` do nothing and log\ncalls go through the global klog logger. Therefore this additional information\nis not in the log output anymore:\n\n```console\n$ go run . --feature-gates ContextualLogging=false\n...\nI0222 15:14:40.497333  198174 example.go:54] \"runtime\" duration=\"1m0s\"\nI0222 15:14:40.497346  198174 example.go:55] \"another runtime\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\n### JSON log format\n\n{{< feature-state for_k8s_version=\"v1.19\" state=\"alpha\" >}}\n\n{{<warning >}}\nJSON output does not support many standard klog flags. For list of unsupported klog flags, see the\n[Command line tool reference](/docs/reference/command-line-tools-reference/).\n\nNot all logs are guaranteed to be written in JSON format (for example, during process start).\nIf you intend to parse logs, make sure you can handle log lines that are not JSON as well.\n\nField names and JSON serialization are subject to change.\n{{< /warning >}}\n\nThe `--logging-format=json` flag changes the format of logs from klog native format to JSON format.\nExample of JSON log format (pretty printed):\n\n```json\n{\n   \"ts\": 1580306777.04728,\n   \"v\": 4,\n   \"msg\": \"Pod status updated\",\n   \"pod\":{\n      \"name\": \"nginx-1\",\n      \"namespace\": \"default\"\n   },\n   \"status\": \"ready\"\n}\n```\n\nKeys with special meaning:\n\n* `ts` - timestamp as Unix time (required, float)\n* `v` - verbosity (only for info and not for error messages, int)\n* `err` - error string (optional, string)\n* `msg` - message (required, string)\n\nList of components currently supporting JSON format:\n\n* {{< glossary_tooltip term_id=\"kube-controller-manager\" text=\"kube-controller-manager\" >}}\n* {{< glossary_tooltip term_id=\"kube-apiserver\" text=\"kube-apiserver\" >}}\n* {{< glossary_tooltip term_id=\"kube-scheduler\" text=\"kube-scheduler\" >}}\n* {{< glossary_tooltip term_id=\"kubelet\" text=\"kubelet\" >}}\n\n### Log verbosity level\n\nThe `-v` flag controls log verbosity. Increasing the value increases the number of logged events.\nDecreasing the value decreases the number of logged events.  Increasing verbosity settings logs\nincreasingly less severe events. A verbosity setting of 0 logs only critical events.\n\n### Log location\n\nThere are two types of system components: those that run in a container and those\nthat do not run in a container. For example:\n\n* The Kubernetes scheduler and kube-proxy run in a container.\n* The kubelet and {{<glossary_tooltip term_id=\"container-runtime\" text=\"container runtime\">}}\n  do not run in containers.\n\nOn machines with systemd, the kubelet and container runtime write to journald.\nOtherwise, they write to `.log` files in the `/var/log` directory.\nSystem components inside containers always write to `.log` files in the `/var/log` directory,\nbypassing the default logging mechanism.\nSimilar to the container logs, you should rotate system component logs in the `/var/log` directory.\nIn Kubernetes clusters created by the `kube-up.sh` script, log rotation is configured by the `logrotate` tool.\nThe `logrotate` tool rotates logs daily, or once the log size is greater than 100MB.",
      "terms": [
        {
          "term": "klog",
          "tier": 1,
          "reasoning": "Named Kubernetes logging library, a specific component for system logging."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core domain proper noun, the container orchestration platform being documented."
        },
        {
          "term": "logging library",
          "tier": 2,
          "reasoning": "Technical concept describing the type of component klog is."
        },
        {
          "term": "log messages",
          "tier": 2,
          "reasoning": "Domain concept referring to the output generated by logging systems."
        },
        {
          "term": "system components",
          "tier": 2,
          "reasoning": "Technical term referring to the various parts of the Kubernetes system."
        },
        {
          "term": "klog command line flags",
          "tier": 2,
          "reasoning": "Technical concept referring to CLI configuration options for klog."
        },
        {
          "term": "--add-dir-header",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--alsologtostderr",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-backtrace-at",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-dir",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-file",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--log-file-max-size",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--logtostderr",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--one-output",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--skip-headers",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--skip-log-headers",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "--stderrthreshold",
          "tier": 1,
          "reasoning": "Specific deprecated CLI flag for klog configuration."
        },
        {
          "term": "stderr",
          "tier": 3,
          "reasoning": "Standard error stream, OS-level concept relevant to log output handling."
        },
        {
          "term": "stdout",
          "tier": 3,
          "reasoning": "Standard output stream, OS-level concept relevant to log output handling."
        },
        {
          "term": "output format",
          "tier": 2,
          "reasoning": "Technical concept describing how log data is structured."
        },
        {
          "term": "output redirection",
          "tier": 2,
          "reasoning": "Technical process for directing output streams to different destinations."
        },
        {
          "term": "Kubernetes component",
          "tier": 2,
          "reasoning": "Domain term referring to individual parts of the Kubernetes system."
        },
        {
          "term": "POSIX shell",
          "tier": 3,
          "reasoning": "Technical standard for shell environments, used for comparison with kube-log-runner."
        },
        {
          "term": "systemd",
          "tier": 3,
          "reasoning": "Linux system and service manager, mentioned as a tool for handling output."
        },
        {
          "term": "distroless container",
          "tier": 2,
          "reasoning": "Container concept referring to minimal containers without shell utilities."
        },
        {
          "term": "Windows system service",
          "tier": 3,
          "reasoning": "OS-specific concept for background services on Windows."
        },
        {
          "term": "kube-log-runner",
          "tier": 1,
          "reasoning": "Named Kubernetes binary tool for log output redirection."
        },
        {
          "term": "/go-runner",
          "tier": 1,
          "reasoning": "Traditional name for the kube-log-runner binary in base images."
        },
        {
          "term": "Kubernetes base images",
          "tier": 2,
          "reasoning": "Domain concept referring to foundational container images for Kubernetes."
        },
        {
          "term": "-log-file",
          "tier": 1,
          "reasoning": "CLI option for kube-log-runner to specify log file destination."
        },
        {
          "term": "-also-stdout",
          "tier": 1,
          "reasoning": "CLI option for kube-log-runner to copy output to stdout."
        },
        {
          "term": "-redirect-stderr",
          "tier": 1,
          "reasoning": "CLI option for kube-log-runner to control stderr redirection."
        },
        {
          "term": "klog native format",
          "tier": 2,
          "reasoning": "Technical term for the traditional log message format used by klog."
        },
        {
          "term": "klog header",
          "tier": 2,
          "reasoning": "Component of structured log format containing metadata."
        },
        {
          "term": "Structured Logging",
          "tier": 2,
          "reasoning": "Core logging concept introducing uniform structure to log messages."
        },
        {
          "term": "structured log messages",
          "tier": 2,
          "reasoning": "Log messages with programmatically parseable format."
        },
        {
          "term": "unstructured log messages",
          "tier": 2,
          "reasoning": "Traditional log messages without uniform structure."
        },
        {
          "term": "log formatting",
          "tier": 2,
          "reasoning": "Technical concept for how log data is presented."
        },
        {
          "term": "value serialization",
          "tier": 2,
          "reasoning": "Technical process of converting values to string representation in logs."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object, referenced in log message examples."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Lowercase reference to Pod resource in structured log key-value pairs."
        },
        {
          "term": "namespaces",
          "tier": 2,
          "reasoning": "Kubernetes concept for resource isolation, appears in API path."
        },
        {
          "term": "kube-system",
          "tier": 1,
          "reasoning": "Named Kubernetes namespace for system components."
        },
        {
          "term": "metrics-server",
          "tier": 1,
          "reasoning": "Named Kubernetes component for resource metrics."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Technical term for application programming interface, used in API paths."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating pre-stable functionality."
        },
        {
          "term": "log file",
          "tier": 2,
          "reasoning": "Technical concept for persistent storage of log output."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept for isolated runtime environments."
        },
        {
          "term": "linux/amd64",
          "tier": 3,
          "reasoning": "Platform identifier indicating operating system and architecture."
        }
      ],
      "term_count": 49,
      "generated_at": "2026-02-08T21:25:52.003442",
      "elapsed_time": 25.840669870376587
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates.md",
      "content": "---\ntitle: DefaultHostNetworkHostPortsInPodTemplates\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: deprecated\n    defaultValue: false\n    fromVersion: \"1.28\"\n    toVersion: \"1.30\"\n\nremoved: true\n---\nThis feature gate controls the point at which a default value for\n`.spec.containers[*].ports[*].hostPort`\nis assigned, for Pods using `hostNetwork: true`. The default since Kubernetes v1.28 is to only set a default\nvalue in Pods.\n\nEnabling this means a default will be assigned even to the `.spec` of an embedded\n[PodTemplate](/docs/concepts/workloads/pods/#pod-templates) (for example, in a Deployment),\nwhich is the way that older releases of Kubernetes worked.\nYou should migrate your code so that it does not rely on the legacy behavior.",
      "terms": [
        {
          "term": "DefaultHostNetworkHostPortsInPodTemplates",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": "feature gate",
          "tier": 1,
          "reasoning": "Alternative form of feature_gate, a core Kubernetes configuration mechanism."
        },
        {
          "term": ".spec.containers[*].ports[*].hostPort",
          "tier": 1,
          "reasoning": "A specific API field path in the Pod specification for container port configuration."
        },
        {
          "term": "hostPort",
          "tier": 1,
          "reasoning": "A specific Kubernetes Pod container port configuration field."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "hostNetwork",
          "tier": 1,
          "reasoning": "A specific Pod spec field that controls network namespace sharing with the host."
        },
        {
          "term": "PodTemplate",
          "tier": 1,
          "reasoning": "A Kubernetes API object that defines a template for creating Pods."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "A core Kubernetes workload API object for managing replicated applications."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": ".spec",
          "tier": 2,
          "reasoning": "The specification section of a Kubernetes API object, a key structural concept."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Technical term referring to container definitions within a Pod spec."
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Network port configuration concept within container specifications."
        },
        {
          "term": "deprecated",
          "tier": 2,
          "reasoning": "A feature lifecycle stage indicating the feature is being phased out."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Configuration concept for the default state of a feature gate."
        },
        {
          "term": "default value",
          "tier": 2,
          "reasoning": "Technical concept referring to automatically assigned configuration values."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running on the cluster."
        },
        {
          "term": "embedded",
          "tier": 2,
          "reasoning": "Technical concept describing nested object specifications within parent resources."
        },
        {
          "term": "stages",
          "tier": 2,
          "reasoning": "Feature gate lifecycle concept describing the progression of a feature."
        },
        {
          "term": "removed",
          "tier": 2,
          "reasoning": "Feature lifecycle state indicating the feature gate has been eliminated."
        },
        {
          "term": "legacy behavior",
          "tier": 2,
          "reasoning": "Technical concept referring to older, deprecated functionality patterns."
        },
        {
          "term": "migrate",
          "tier": 2,
          "reasoning": "Technical process of updating code or configurations to newer patterns."
        },
        {
          "term": "v1.28",
          "tier": 3,
          "reasoning": "Specific Kubernetes version reference indicating when behavior changed."
        },
        {
          "term": "1.28",
          "tier": 3,
          "reasoning": "Version number marking the introduction of the new default behavior."
        },
        {
          "term": "1.30",
          "tier": 3,
          "reasoning": "Version number marking the end of this feature gate's availability."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Configuration metadata indicating the starting version for a feature stage."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Configuration metadata indicating the ending version for a feature stage."
        },
        {
          "term": "code",
          "tier": 3,
          "reasoning": "Technical term referring to application source code that may depend on this behavior."
        }
      ],
      "term_count": 28,
      "generated_at": "2026-02-08T21:26:08.541023",
      "elapsed_time": 15.52647066116333
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a password.txt file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF >./password.txt\nusername=admin\npassword=secret\nEOF\n\ncat <<EOF >deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  labels:\n    app: my-app\nspec:\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: app\n        image: my-app\n        volumeMounts:\n        - name: password\n          mountPath: /secrets\n      volumes:\n      - name: password\n        secret:\n          secretName: example-secret-1\nEOF\n\ncat <<EOF >./kustomization.yaml\nresources:\n- deployment.yaml\nsecretGenerator:\n- name: example-secret-1\n  files:\n  - password.txt\nEOF\n```\n\n#### generatorOptions\n\nThe generated ConfigMaps and Secrets have a content hash suffix appended. This ensures that\na new ConfigMap or Secret is generated when the contents are changed. To disable the behavior\nof appending a suffix, one can use `generatorOptions`. Besides that, it is also possible to\nspecify cross-cutting options for generated ConfigMaps and Secrets.\n\n```shell\ncat <<EOF >./kustomization.yaml\nconfigMapGenerator:\n- name: example-configmap-3\n  literals:\n  - FOO=Bar\ngeneratorOptions:\n  disableNameSuffixHash: true\n  labels:\n    type: generated\n  annotations:\n    note: generated\nEOF\n```\n\nRun`kubectl kustomize ./` to view the generated ConfigMap:\n\n```yaml\napiVersion: v1\ndata:\n  FOO: Bar\nkind: ConfigMap\nmetadata:\n  annotations:\n    note: generated\n  labels:\n    type: generated\n  name: example-configmap-3\n```\n\n### Setting cross-cutting fields\n\nIt is quite common to set cross-cutting fields for all Kubernetes resources in a project.\nSome use cases for setting cross-cutting fields:\n\n* setting the same namespace for all resources\n* adding the same name prefix or suffix\n* adding the same set of labels\n* adding the same set of annotations\n\nHere is an example:\n\n```shell",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing application deployments"
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data"
        },
        {
          "term": "Secret",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing sensitive data like passwords"
        },
        {
          "term": "secretGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating Secret resources"
        },
        {
          "term": "configMapGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating ConfigMap resources"
        },
        {
          "term": "generatorOptions",
          "tier": 1,
          "reasoning": "Kustomize configuration block for controlling generator behavior"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "kustomize",
          "tier": 1,
          "reasoning": "Kubernetes configuration management tool referenced via kubectl kustomize"
        },
        {
          "term": "kubectl kustomize",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for running kustomize"
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Configuration file for Kustomize tool"
        },
        {
          "term": "deployment.yaml",
          "tier": 1,
          "reasoning": "YAML file defining a Kubernetes Deployment resource"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying API version"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API version for apps resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying resource type"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource metadata"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource specification"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for matching resources by labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector mechanism for label matching"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within Deployment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes spec field defining container configurations"
        },
        {
          "term": "volumeMounts",
          "tier": 2,
          "reasoning": "Kubernetes field for mounting volumes into containers"
        },
        {
          "term": "volumes",
          "tier": 2,
          "reasoning": "Kubernetes field for defining volume sources"
        },
        {
          "term": "mountPath",
          "tier": 2,
          "reasoning": "Path where volume is mounted inside container"
        },
        {
          "term": "secretName",
          "tier": 2,
          "reasoning": "Reference to a Secret resource by name"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for organizing and selecting resources"
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata for attaching non-identifying information"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for resource isolation and organization"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kustomize field listing Kubernetes resource files"
        },
        {
          "term": "name prefix",
          "tier": 2,
          "reasoning": "Kustomize feature for adding prefix to resource names"
        },
        {
          "term": "content hash suffix",
          "tier": 2,
          "reasoning": "Auto-generated suffix based on content hash for ConfigMaps/Secrets"
        },
        {
          "term": "disableNameSuffixHash",
          "tier": 2,
          "reasoning": "Kustomize option to disable automatic hash suffix generation"
        },
        {
          "term": "cross-cutting fields",
          "tier": 2,
          "reasoning": "Configuration fields applied across all resources in a project"
        },
        {
          "term": "literals",
          "tier": 2,
          "reasoning": "Kustomize field for defining key-value pairs inline"
        },
        {
          "term": "files",
          "tier": 2,
          "reasoning": "Kustomize field for referencing external files"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image specification in Kubernetes"
        },
        {
          "term": "Kubernetes resources",
          "tier": 2,
          "reasoning": "General term for objects managed by Kubernetes API"
        },
        {
          "term": "password.txt",
          "tier": 3,
          "reasoning": "Example file containing credentials for Secret generation"
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "Kubernetes core API version shown in ConfigMap output"
        },
        {
          "term": "data",
          "tier": 3,
          "reasoning": "Field in ConfigMap/Secret containing stored data"
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T21:26:25.199129",
      "elapsed_time": 15.65053939819336
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_options__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_options__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_options__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for options</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "-h",
          "tier": 1,
          "reasoning": "CLI flag shorthand for help option, a specific command-line interface element."
        },
        {
          "term": "--help",
          "tier": 1,
          "reasoning": "CLI flag for displaying help information, a standard command-line option."
        },
        {
          "term": "help",
          "tier": 3,
          "reasoning": "In CLI context, 'help' refers to the built-in documentation/usage information system."
        },
        {
          "term": "options",
          "tier": 3,
          "reasoning": "In CLI context, 'options' refers to command-line flags and parameters that modify command behavior."
        }
      ],
      "term_count": 4,
      "generated_at": "2026-02-08T21:26:29.962553",
      "elapsed_time": 3.7550439834594727
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation.md",
      "content": "---\ntitle: CronJobsScheduledAnnotation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.28\"\n    toVersion: \"1.31\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.32\"\n\n---\nSet the scheduled job time as an\n{{< glossary_tooltip text=\"annotation\" term_id=\"annotation\" >}} on Jobs that were created\non behalf of a CronJob.",
      "terms": [
        {
          "term": "CronJobsScheduledAnnotation",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling optional features, appearing as the content_type."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "A Kubernetes concept for attaching non-identifying metadata to objects."
        },
        {
          "term": "Jobs",
          "tier": 1,
          "reasoning": "A Kubernetes API object/resource that runs tasks to completion."
        },
        {
          "term": "CronJob",
          "tier": 1,
          "reasoning": "A Kubernetes API object that creates Jobs on a time-based schedule."
        },
        {
          "term": "scheduled job time",
          "tier": 2,
          "reasoning": "A domain concept referring to the time when a job is scheduled to run."
        },
        {
          "term": "beta",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is well-tested but not yet stable."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is production-ready and enabled by default."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "A configuration concept indicating the default state of a feature gate."
        },
        {
          "term": "stage",
          "tier": 3,
          "reasoning": "Technical term describing the maturity phase of a feature in Kubernetes feature gate lifecycle."
        },
        {
          "term": "fromVersion",
          "tier": 2,
          "reasoning": "A versioning concept indicating the starting Kubernetes version for a feature stage."
        },
        {
          "term": "toVersion",
          "tier": 2,
          "reasoning": "A versioning concept indicating the ending Kubernetes version for a feature stage."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:26:38.780345",
      "elapsed_time": 7.810666084289551
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec16",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Issuer`     {#apiserver-config-k8s-io-v1-Issuer}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>Issuer provides the configuration for an external provider's specific settings.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>url points to the issuer URL in a format https://url or https://url/path.\nThis must match the &quot;iss&quot; claim in the presented JWT, and the issuer returned from discovery.\nSame value as the --oidc-issuer-url flag.\nDiscovery information is fetched from &quot;{url}/.well-known/openid-configuration&quot; unless overridden by discoveryURL.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>discoveryURL</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>discoveryURL, if specified, overrides the URL used to fetch discovery\ninformation instead of using &quot;{url}/.well-known/openid-configuration&quot;.\nThe exact value specified is used, so &quot;/.well-known/openid-configuration&quot;\nmust be included in discoveryURL if needed.</p>\n<p>The &quot;issuer&quot; field in the fetched discovery information must match the &quot;issuer.url&quot; field\nin the AuthenticationConfiguration and will be used to validate the &quot;iss&quot; claim in the presented JWT.\nThis is for scenarios where the well-known and jwks endpoints are hosted at a different\nlocation than the issuer (such as locally in the cluster).</p>\n<p>Example:\nA discovery url that is exposed using kubernetes service 'oidc' in namespace 'oidc-namespace'\nand discovery information is available at '/.well-known/openid-configuration'.\ndiscoveryURL: &quot;https://oidc.oidc-namespace/.well-known/openid-configuration&quot;\ncertificateAuthority is used to verify the TLS connection and the hostname on the leaf certificate\nmust be set to 'oidc.oidc-namespace'.</p>\n<p>curl https://oidc.oidc-namespace/.well-known/openid-configuration (.discoveryURL field)\n{\nissuer: &quot;https://oidc.example.com&quot; (.url field)\n}</p>\n<p>discoveryURL must be different from url.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>certificateAuthority</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>certificateAuthority contains PEM-encoded certificate authority certificates\nused to validate the connection when fetching discovery information.\nIf unset, the system verifier is used.\nSame value as the content of the file referenced by the --oidc-ca-file flag.</p>\n</td>\n</tr>\n<tr><td><code>audiences</code> <B>[Required]</B><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>audiences is the set of acceptable audiences the JWT must be issued to.\nAt least one of the entries must match the &quot;aud&quot; claim in presented JWTs.\nSame value as the --oidc-client-id flag (though this field supports an array).\nRequired to be non-empty.</p>\n</td>\n</tr>\n<tr><td><code>audienceMatchPolicy</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AudienceMatchPolicyType\"><code>AudienceMatchPolicyType</code></a>\n</td>\n<td>\n   <p>audienceMatchPolicy defines how the &quot;audiences&quot; field is used to match the &quot;aud&quot; claim in the presented JWT.\nAllowed values are:</p>\n<ol>\n<li>&quot;MatchAny&quot; when multiple audiences are specified and</li>\n<li>empty (or unset) or &quot;MatchAny&quot; when a single audience is specified.</li>\n</ol>\n<ul>\n<li>\n<p>MatchAny: the &quot;aud&quot; claim in the presented JWT must match at least one of the entries in the &quot;audiences&quot; field.\nFor example, if &quot;audiences&quot; is [&quot;foo&quot;, &quot;bar&quot;], the &quot;aud&quot; claim in the presented JWT must contain either &quot;foo&quot; or &quot;bar&quot; (and may contain both).</p>\n</li>\n<li>\n<p>&quot;&quot;: The match policy can be empty (or unset) when a single audience is specified in the &quot;audiences&quot; field. The &quot;aud&quot; claim in the presented JWT must contain the single audience (and may contain others).</p>\n</li>\n</ul>\n<p>For more nuanced audience validation, use claimValidationRules.\nexample: claimValidationRule[].expression: 'sets.equivalent(claims.aud, [&quot;bar&quot;, &quot;foo&quot;, &quot;baz&quot;])' to require an exact match.</p>\n</td>\n</tr>\n<tr><td><code>egressSelectorType</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-EgressSelectorType\"><code>EgressSelectorType</code></a>\n</td>\n<td>\n   <p>egressSelectorType is an indicator of which egress selection should be used for sending all traffic related\nto this issuer (discovery, JWKS, distributed claims, etc).  If unspecified, no custom dialer is used.\nWhen specified, the valid choices are &quot;controlplane&quot; and &quot;cluster&quot;.  These correspond to the associated\nvalues in the --egress-selector-config-file.</p>\n<ul>\n<li>\n<p>controlplane: for traffic intended to go to the control plane.</p>\n</li>\n<li>\n<p>cluster: for traffic intended to go to the system being managed by Kubernetes.</p>\n</li>\n</ul>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration"
        },
        {
          "term": "Issuer",
          "tier": 1,
          "reasoning": "Named configuration component for external provider settings in JWT authentication"
        },
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for authentication settings"
        },
        {
          "term": "AudienceMatchPolicyType",
          "tier": 1,
          "reasoning": "Named Kubernetes API type for defining audience matching behavior"
        },
        {
          "term": "url",
          "tier": 2,
          "reasoning": "Configuration field pointing to the issuer URL for JWT validation"
        },
        {
          "term": "discoveryURL",
          "tier": 2,
          "reasoning": "Configuration field that overrides the default OIDC discovery endpoint"
        },
        {
          "term": "certificateAuthority",
          "tier": 2,
          "reasoning": "Configuration field containing PEM-encoded CA certificates for TLS validation"
        },
        {
          "term": "audiences",
          "tier": 2,
          "reasoning": "Configuration field defining acceptable JWT audience values"
        },
        {
          "term": "audienceMatchPolicy",
          "tier": 2,
          "reasoning": "Configuration field defining how audience claims are matched"
        },
        {
          "term": "JWT",
          "tier": 2,
          "reasoning": "JSON Web Token - core authentication token format being configured"
        },
        {
          "term": "iss",
          "tier": 2,
          "reasoning": "Standard JWT claim identifying the token issuer"
        },
        {
          "term": "aud",
          "tier": 2,
          "reasoning": "Standard JWT claim identifying the intended audience"
        },
        {
          "term": "OIDC",
          "tier": 2,
          "reasoning": "OpenID Connect protocol referenced for discovery and authentication"
        },
        {
          "term": "discovery",
          "tier": 2,
          "reasoning": "OIDC discovery mechanism for fetching provider configuration"
        },
        {
          "term": "discovery information",
          "tier": 2,
          "reasoning": "Metadata fetched from OIDC discovery endpoint"
        },
        {
          "term": "openid-configuration",
          "tier": 2,
          "reasoning": "Standard OIDC discovery endpoint path"
        },
        {
          "term": ".well-known/openid-configuration",
          "tier": 2,
          "reasoning": "Full well-known path for OIDC discovery endpoint"
        },
        {
          "term": "--oidc-issuer-url",
          "tier": 1,
          "reasoning": "CLI flag for configuring OIDC issuer URL"
        },
        {
          "term": "--oidc-ca-file",
          "tier": 1,
          "reasoning": "CLI flag for configuring OIDC CA certificate file"
        },
        {
          "term": "--oidc-client-id",
          "tier": 1,
          "reasoning": "CLI flag for configuring OIDC client ID"
        },
        {
          "term": "JWT authenticators",
          "tier": 2,
          "reasoning": "Authentication components that validate JWT tokens"
        },
        {
          "term": "PEM-encoded",
          "tier": 3,
          "reasoning": "Certificate encoding format used for certificate authority configuration"
        },
        {
          "term": "certificate authority certificates",
          "tier": 2,
          "reasoning": "CA certificates used for validating TLS connections"
        },
        {
          "term": "TLS connection",
          "tier": 3,
          "reasoning": "Secure transport layer connection being validated"
        },
        {
          "term": "leaf certificate",
          "tier": 3,
          "reasoning": "End-entity certificate in TLS certificate chain"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Network hostname validated on leaf certificate"
        },
        {
          "term": "egress selection configuration",
          "tier": 2,
          "reasoning": "Kubernetes network egress configuration mechanism"
        },
        {
          "term": "kubernetes service",
          "tier": 2,
          "reasoning": "Kubernetes Service resource for network access"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes namespace for resource isolation"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster where services are hosted"
        },
        {
          "term": "jwks",
          "tier": 2,
          "reasoning": "JSON Web Key Set endpoint for JWT signature verification"
        },
        {
          "term": "MatchAny",
          "tier": 2,
          "reasoning": "Audience match policy value requiring any audience to match"
        },
        {
          "term": "issuer",
          "tier": 2,
          "reasoning": "Entity that issues and signs JWT tokens"
        },
        {
          "term": "system verifier",
          "tier": 2,
          "reasoning": "Default system-level certificate verification mechanism"
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Secure HTTP protocol required for issuer URLs"
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool shown in example for fetching discovery information"
        },
        {
          "term": "external provider",
          "tier": 2,
          "reasoning": "Third-party identity provider for authentication"
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:26:57.525597",
      "elapsed_time": 17.738083839416504
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_logs__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_logs__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_logs__index.md",
      "content": "```\n  # Return snapshot logs from pod nginx with only one container\n  kubectl logs nginx\n  \n  # Return snapshot logs from pod nginx, prefixing each line with the source pod and container name\n  kubectl logs nginx --prefix\n  \n  # Return snapshot logs from pod nginx, limiting output to 500 bytes\n  kubectl logs nginx --limit-bytes=500\n  \n  # Return snapshot logs from pod nginx, waiting up to 20 seconds for it to start running.\n  kubectl logs nginx --pod-running-timeout=20s\n  \n  # Return snapshot logs from pod nginx with multi containers\n  kubectl logs nginx --all-containers=true\n  \n  # Return snapshot logs from all pods in the deployment nginx\n  kubectl logs deployment/nginx --all-pods=true\n  \n  # Return snapshot logs from all containers in pods defined by label app=nginx\n  kubectl logs -l app=nginx --all-containers=true\n  \n  # Return snapshot logs from all pods defined by label app=nginx, limiting concurrent log requests to 10 pods\n  kubectl logs -l app=nginx --max-log-requests=10\n  \n  # Return snapshot of previous terminated ruby container logs from pod web-1\n  kubectl logs -p -c ruby web-1\n  \n  # Begin streaming the logs from pod nginx, continuing even if errors occur\n  kubectl logs nginx -f --ignore-errors=true\n  \n  # Begin streaming the logs of the ruby container in pod web-1\n  kubectl logs -f -c ruby web-1\n  \n  # Begin streaming the logs from all containers in pods defined by label app=nginx\n  kubectl logs -f -l app=nginx --all-containers=true\n  \n  # Display only the most recent 20 lines of output in pod nginx\n  kubectl logs --tail=20 nginx\n  \n  # Show all logs from pod nginx written in the last hour\n  kubectl logs --since=1h nginx\n  \n  # Show all logs with timestamps from pod nginx starting from August 30, 2024, at 06:00:00 UTC\n  kubectl logs nginx --since-time=2024-08-30T06:00:00Z --timestamps=true\n  \n  # Show logs from a kubelet with an expired serving certificate\n  kubectl logs --insecure-skip-tls-verify-backend nginx\n  \n  # Return snapshot logs from first container of a job named hello\n  kubectl logs job/hello\n  \n  # Return snapshot logs from container nginx-1 of a deployment named nginx\n  kubectl logs deployment/nginx -c nginx-1\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout all examples"
        },
        {
          "term": "logs",
          "tier": 2,
          "reasoning": "Kubectl subcommand for retrieving container/pod log output"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental deployment unit referenced throughout"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container/pod name used as example throughout the documentation"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing isolated runtime environment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form used in --all-containers flag context"
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing pod replicas, referenced as deployment/nginx"
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept used for selecting pods with -l flag"
        },
        {
          "term": "ruby",
          "tier": 1,
          "reasoning": "Specific container name used in examples"
        },
        {
          "term": "web-1",
          "tier": 1,
          "reasoning": "Specific pod name used in examples"
        },
        {
          "term": "job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running batch workloads, referenced as job/hello"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component explicitly mentioned"
        },
        {
          "term": "--prefix",
          "tier": 3,
          "reasoning": "CLI flag for prefixing log lines with source pod and container name"
        },
        {
          "term": "--limit-bytes",
          "tier": 3,
          "reasoning": "CLI flag for limiting log output size"
        },
        {
          "term": "--pod-running-timeout",
          "tier": 3,
          "reasoning": "CLI flag for setting pod startup wait time"
        },
        {
          "term": "--all-containers",
          "tier": 3,
          "reasoning": "CLI flag for retrieving logs from all containers in a pod"
        },
        {
          "term": "--all-pods",
          "tier": 3,
          "reasoning": "CLI flag for retrieving logs from all pods in a deployment"
        },
        {
          "term": "--max-log-requests",
          "tier": 3,
          "reasoning": "CLI flag for limiting concurrent log requests"
        },
        {
          "term": "-p",
          "tier": 3,
          "reasoning": "CLI flag shorthand for previous terminated container logs"
        },
        {
          "term": "-c",
          "tier": 3,
          "reasoning": "CLI flag shorthand for specifying container name"
        },
        {
          "term": "-f",
          "tier": 3,
          "reasoning": "CLI flag shorthand for following/streaming logs"
        },
        {
          "term": "--ignore-errors",
          "tier": 3,
          "reasoning": "CLI flag for continuing log streaming despite errors"
        },
        {
          "term": "--tail",
          "tier": 3,
          "reasoning": "CLI flag for limiting output to most recent lines"
        },
        {
          "term": "--since",
          "tier": 3,
          "reasoning": "CLI flag for filtering logs by relative time duration"
        },
        {
          "term": "--since-time",
          "tier": 3,
          "reasoning": "CLI flag for filtering logs by absolute timestamp"
        },
        {
          "term": "--timestamps",
          "tier": 3,
          "reasoning": "CLI flag for including timestamps in log output"
        },
        {
          "term": "--insecure-skip-tls-verify-backend",
          "tier": 3,
          "reasoning": "CLI flag for bypassing TLS verification for backend connections"
        },
        {
          "term": "-l",
          "tier": 3,
          "reasoning": "CLI flag shorthand for label selector"
        },
        {
          "term": "snapshot logs",
          "tier": 2,
          "reasoning": "Technical concept describing point-in-time log retrieval vs streaming"
        },
        {
          "term": "streaming",
          "tier": 2,
          "reasoning": "Technical concept for continuous real-time log following"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol referenced in --insecure-skip-tls-verify-backend"
        },
        {
          "term": "serving certificate",
          "tier": 2,
          "reasoning": "TLS certificate concept used for kubelet authentication"
        },
        {
          "term": "terminated",
          "tier": 2,
          "reasoning": "Container lifecycle state for retrieving previous container logs"
        },
        {
          "term": "app=nginx",
          "tier": 2,
          "reasoning": "Label selector syntax example for filtering pods"
        },
        {
          "term": "multi containers",
          "tier": 2,
          "reasoning": "Concept of pods containing multiple containers"
        },
        {
          "term": "nginx-1",
          "tier": 1,
          "reasoning": "Specific container name used in deployment example"
        },
        {
          "term": "hello",
          "tier": 1,
          "reasoning": "Specific job name used in example"
        },
        {
          "term": "UTC",
          "tier": 3,
          "reasoning": "Timezone standard used in timestamp specification"
        }
      ],
      "term_count": 38,
      "generated_at": "2026-02-08T21:27:16.470359",
      "elapsed_time": 17.93152356147766
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec6",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Ingress class",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "Ingresses can be implemented by different controllers, often with different\nconfiguration. Each Ingress should specify a class, a reference to an\nIngressClass resource that contains additional configuration including the name\nof the controller that should implement the class.\n\n{{% code_sample file=\"service/networking/external-lb.yaml\" %}}\n\nThe `.spec.parameters` field of an IngressClass lets you reference another\nresource that provides configuration related to that IngressClass.\n\nThe specific type of parameters to use depends on the ingress controller\nthat you specify in the `.spec.controller` field of the IngressClass.\n\n### IngressClass scope\n\nDepending on your ingress controller, you may be able to use parameters\nthat you set cluster-wide, or just for one namespace.\n\n{{< tabs name=\"tabs_ingressclass_parameter_scope\" >}}\n{{% tab name=\"Cluster\" %}}\nThe default scope for IngressClass parameters is cluster-wide.\n\nIf you set the `.spec.parameters` field and don't set\n`.spec.parameters.scope`, or if you set `.spec.parameters.scope` to\n`Cluster`, then the IngressClass refers to a cluster-scoped resource.\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a cluster-scoped API (possibly a custom resource), and\nthe `name` of the parameters identifies a specific cluster scoped\nresource for that API.\n\nFor example:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-1\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in a\n    # ClusterIngressParameter (API group k8s.example.net) named\n    # \"external-config-1\". This definition tells Kubernetes to\n    # look for a cluster-scoped parameter resource.\n    scope: Cluster\n    apiGroup: k8s.example.net\n    kind: ClusterIngressParameter\n    name: external-config-1\n```\n\n{{% /tab %}}\n{{% tab name=\"Namespaced\" %}}\n{{< feature-state for_k8s_version=\"v1.23\" state=\"stable\" >}}\n\nIf you set the `.spec.parameters` field and set\n`.spec.parameters.scope` to `Namespace`, then the IngressClass refers\nto a namespaced-scoped resource. You must also set the `namespace`\nfield within `.spec.parameters` to the namespace that contains\nthe parameters you want to use.\n\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a namespaced API (for example: ConfigMap), and\nthe `name` of the parameters identifies a specific resource\nin the namespace you specified in `namespace`.\n\nNamespace-scoped parameters help the cluster operator delegate control over the\nconfiguration (for example: load balancer settings, API gateway definition)\nthat is used for a workload. If you used a cluster-scoped parameter then either:\n\n- the cluster operator team needs to approve a different team's changes every\n  time there's a new configuration change being applied.\n- the cluster operator must define specific access controls, such as\n  [RBAC](/docs/reference/access-authn-authz/rbac/) roles and bindings, that let\n  the application team make changes to the cluster-scoped parameters resource.\n\nThe IngressClass API itself is always cluster-scoped.\n\nHere is an example of an IngressClass that refers to parameters that are\nnamespaced:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-2\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in an\n    # IngressParameter (API group k8s.example.com) named \"external-config\",\n    # that's in the \"external-configuration\" namespace.\n    scope: Namespace\n    apiGroup: k8s.example.com\n    kind: IngressParameter\n    namespace: external-configuration\n    name: external-config\n```\n\n{{% /tab %}}\n{{< /tabs >}}\n\n### Deprecated annotation\n\nBefore the IngressClass resource and `ingressClassName` field were added in\nKubernetes 1.18, Ingress classes were specified with a\n`kubernetes.io/ingress.class` annotation on the Ingress. This annotation was\nnever formally defined, but was widely supported by Ingress controllers.\n\nThe newer `ingressClassName` field on Ingresses is a replacement for that\nannotation, but is not a direct equivalent. While the annotation was generally\nused to reference the name of the Ingress controller that should implement the\nIngress, the field is a reference to an IngressClass resource that contains\nadditional Ingress configuration, including the name of the Ingress controller.\n\n### Default IngressClass {#default-ingress-class}\n\nYou can mark a particular IngressClass as default for your cluster. Setting the\n`ingressclass.kubernetes.io/is-default-class` annotation to `true` on an\nIngressClass resource will ensure that new Ingresses without an\n`ingressClassName` field specified will be assigned this default IngressClass.\n\n{{< caution >}}\nIf you have more than one IngressClass marked as the default for your cluster,\nthe admission controller prevents creating new Ingress objects that don't have\nan `ingressClassName` specified. You can resolve this by ensuring that at most 1\nIngressClass is marked as default in your cluster.\n{{< /caution >}}\n\nStart by defining a\ndefault IngressClass. It is recommended though, to specify the default\nIngressClass:\n\n{{% code_sample file=\"service/networking/default-ingressclass.yaml\" %}}",
      "terms": [
        {
          "term": "Ingresses",
          "tier": 1,
          "reasoning": "Kubernetes API resource for managing external access to services in a cluster."
        },
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Kubernetes API object that manages external access to services, typically HTTP."
        },
        {
          "term": "controllers",
          "tier": 2,
          "reasoning": "Components that implement the control loop pattern to manage Kubernetes resources."
        },
        {
          "term": "IngressClass",
          "tier": 1,
          "reasoning": "Kubernetes API resource that contains configuration for Ingress controllers."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "A component that watches the state of the cluster and makes changes to move toward desired state."
        },
        {
          "term": ".spec.parameters",
          "tier": 1,
          "reasoning": "Specific field path in IngressClass resource for referencing configuration parameters."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "A Kubernetes API object that represents cluster state."
        },
        {
          "term": "ingress controller",
          "tier": 1,
          "reasoning": "Controller that fulfills Ingress resources, typically with a load balancer."
        },
        {
          "term": ".spec.controller",
          "tier": 1,
          "reasoning": "Field in IngressClass that specifies which controller should implement the class."
        },
        {
          "term": "IngressClass scope",
          "tier": 2,
          "reasoning": "Concept describing whether IngressClass parameters are cluster-wide or namespace-scoped."
        },
        {
          "term": "cluster-wide",
          "tier": 2,
          "reasoning": "Scope indicating a resource or configuration applies across the entire cluster."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for isolating groups of resources within a cluster."
        },
        {
          "term": "cluster-scoped",
          "tier": 2,
          "reasoning": "Resources that exist at the cluster level rather than within a namespace."
        },
        {
          "term": ".spec.parameters.scope",
          "tier": 1,
          "reasoning": "Field that determines whether IngressClass parameters are cluster or namespace scoped."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Scope value indicating cluster-wide parameter reference."
        },
        {
          "term": "cluster-scoped resource",
          "tier": 2,
          "reasoning": "A Kubernetes resource that is not namespaced and exists at cluster level."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource."
        },
        {
          "term": "apiGroup",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the API group a resource belongs to."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Extension of the Kubernetes API that allows users to define their own resource types."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for networking resources."
        },
        {
          "term": "ClusterIngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for cluster-scoped Ingress parameters."
        },
        {
          "term": "Namespaced",
          "tier": 2,
          "reasoning": "Scope value indicating namespace-level parameter reference."
        },
        {
          "term": "namespaced-scoped resource",
          "tier": 2,
          "reasoning": "A Kubernetes resource that exists within a specific namespace."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object used to store non-confidential configuration data."
        },
        {
          "term": "cluster operator",
          "tier": 2,
          "reasoning": "Role responsible for managing and operating a Kubernetes cluster."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Component that distributes network traffic across multiple servers."
        },
        {
          "term": "API gateway",
          "tier": 2,
          "reasoning": "Service that manages API traffic and provides features like routing and authentication."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "An application running on Kubernetes, typically as pods."
        },
        {
          "term": "RBAC",
          "tier": 1,
          "reasoning": "Role-Based Access Control - Kubernetes authorization mechanism."
        },
        {
          "term": "roles",
          "tier": 2,
          "reasoning": "RBAC resources that define permissions within a namespace."
        },
        {
          "term": "bindings",
          "tier": 2,
          "reasoning": "RBAC resources that associate roles with users or service accounts."
        },
        {
          "term": "IngressClass API",
          "tier": 1,
          "reasoning": "The Kubernetes API for IngressClass resources."
        },
        {
          "term": "IngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for namespaced Ingress parameters."
        },
        {
          "term": "ingressClassName",
          "tier": 1,
          "reasoning": "Field in Ingress spec that references an IngressClass."
        },
        {
          "term": "kubernetes.io/ingress.class",
          "tier": 1,
          "reasoning": "Deprecated annotation used to specify Ingress class before IngressClass resource existed."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata attached to objects for non-identifying information."
        },
        {
          "term": "Kubernetes 1.18",
          "tier": 2,
          "reasoning": "Specific Kubernetes version when IngressClass resource was introduced."
        },
        {
          "term": "v1.23",
          "tier": 2,
          "reasoning": "Kubernetes version when namespaced IngressClass parameters became stable."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready functionality."
        },
        {
          "term": "access controls",
          "tier": 2,
          "reasoning": "Mechanisms for controlling who can access or modify resources."
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T21:27:37.702942",
      "elapsed_time": 20.223953008651733
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec3",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "JSONSchemaProps {#JSONSchemaProps}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "JSONSchemaProps is a JSON-Schema following Specification Draft 4 (http://json-schema.org/).\n\n<hr>\n\n- **$ref** (string)\n\n\n- **$schema** (string)\n\n\n- **additionalItems** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **additionalProperties** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **allOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **anyOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **default** (JSON)\n\n  default is a default value for undefined object fields. Defaulting is a beta feature under the CustomResourceDefaulting feature gate. Defaulting requires spec.preserveUnknownFields to be false.\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **definitions** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **dependencies** (map[string]JSONSchemaPropsOrStringArray)\n\n\n  <a name=\"JSONSchemaPropsOrStringArray\"></a>\n  *JSONSchemaPropsOrStringArray represents a JSONSchemaProps or a string array.*\n\n- **description** (string)\n\n\n- **enum** ([]JSON)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **example** (JSON)\n\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **exclusiveMaximum** (boolean)\n\n\n- **exclusiveMinimum** (boolean)\n\n\n- **externalDocs** (ExternalDocumentation)\n\n\n  <a name=\"ExternalDocumentation\"></a>\n  *ExternalDocumentation allows referencing an external resource for extended documentation.*\n\n  - **externalDocs.description** (string)\n\n\n  - **externalDocs.url** (string)\n\n\n- **format** (string)\n\n  format is an OpenAPI v3 format string. Unknown formats are ignored. The following formats are validated:\n  \n  - bsonobjectid: a bson object ID, i.e. a 24 characters hex string - uri: an URI as parsed by Golang net/url.ParseRequestURI - email: an email address as parsed by Golang net/mail.ParseAddress - hostname: a valid representation for an Internet host name, as defined by RFC 1034, section 3.1 [RFC1034]. - ipv4: an IPv4 IP as parsed by Golang net.ParseIP - ipv6: an IPv6 IP as parsed by Golang net.ParseIP - cidr: a CIDR as parsed by Golang net.ParseCIDR - mac: a MAC address as parsed by Golang net.ParseMAC - uuid: an UUID that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid3: an UUID3 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?3[0-9a-f]{3}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid4: an UUID4 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?4[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - uuid5: an UUID5 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?5[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - isbn: an ISBN10 or ISBN13 number string like \"0321751043\" or \"978-0321751041\" - isbn10: an ISBN10 number string like \"0321751043\" - isbn13: an ISBN13 number string like \"978-0321751041\" - creditcard: a credit card number defined by the regex ^(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|6(?:011|5[0-9][0-9])[0-9]{12}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|(?:2131|1800|35\\\\d{3})\\\\d{11})$ with any non digit characters mixed in - ssn: a U.S. social security number following the regex ^\\\\d{3}[- ]?\\\\d{2}[- ]?\\\\d{4}$ - hexcolor: an hexadecimal color code like \"#FFFFFF: following the regex ^#?([0-9a-fA-F]{3}|[0-9a-fA-F]{6})$ - rgbcolor: an RGB color code like rgb like \"rgb(255,255,2559\" - byte: base64 encoded binary data - password: any kind of string - date: a date string like \"2006-01-02\" as defined by full-date in RFC3339 - duration: a duration string like \"22 ns\" as parsed by Golang time.ParseDuration or compatible with Scala duration format - datetime: a date time string like \"2014-12-15T19:30:20.000Z\" as defined by date-time in RFC3339.\n\n- **id** (string)\n\n\n- **items** (JSONSchemaPropsOrArray)\n\n\n  <a name=\"JSONSchemaPropsOrArray\"></a>\n  *JSONSchemaPropsOrArray represents a value that can either be a JSONSchemaProps or an array of JSONSchemaProps. Mainly here for serialization purposes.*\n\n- **maxItems** (int64)\n\n\n- **maxLength** (int64)\n\n\n- **maxProperties** (int64)\n\n\n- **maximum** (double)\n\n\n- **minItems** (int64)\n\n\n- **minLength** (int64)\n\n\n- **minProperties** (int64)\n\n\n- **minimum** (double)\n\n\n- **multipleOf** (double)\n\n\n- **not** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **nullable** (boolean)\n\n\n- **oneOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **pattern** (string)\n\n\n- **patternProperties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **properties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **required** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **title** (string)\n\n\n- **type** (string)\n\n\n- **uniqueItems** (boolean)\n\n\n- **x-kubernetes-embedded-resource** (boolean)\n\n  x-kubernetes-embedded-resource defines that the value is an embedded Kubernetes runtime.Object, with TypeMeta and ObjectMeta. The type must be object. It is allowed to further restrict the embedded object. kind, apiVersion and metadata are validated automatically. x-kubernetes-preserve-unknown-fields is allowed to be true, but does not have to be if the object is fully specified (up to kind, apiVersion, metadata).\n\n- **x-kubernetes-int-or-string** (boolean)\n\n  x-kubernetes-int-or-string specifies that this value is either an integer or a string. If this is true, an empty type is allowed and type as child of anyOf is permitted if following one of the following patterns:\n  \n  1) anyOf:\n     - type: integer\n     - type: string\n  2) allOf:\n     - anyOf:\n       - type: integer\n       - type: string\n     - ... zero or more\n\n- **x-kubernetes-list-map-keys** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  x-kubernetes-list-map-keys annotates an array with the x-kubernetes-list-type `map` by specifying the keys used as the index of the map.\n  \n  This tag MUST only be used on lists that have the \"x-kubernetes-list-type\" extension set to \"map\". Also, the values specified for this attribute must be a scalar typed field of the child structure (no nesting is supported).\n  \n  The properties specified must either be required or have a default value, to ensure those properties are present for all list items.\n\n- **x-kubernetes-list-type** (string)\n\n  x-kubernetes-list-type annotates an array to further describe its topology. This extension must only be used on lists and may have 3 possible values:\n  \n  1) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic lists will be entirely replaced when updated. This extension\n       may be used on any type of list (struct, scalar, ...).\n  2) `set`:\n       Sets are lists that must not have multiple items with the same value. Each\n       value must be a scalar, an object with x-kubernetes-map-type `atomic` or an\n       array with x-kubernetes-list-type `atomic`.\n  3) `map`:\n       These lists are like maps in that their elements have a non-index key\n       used to identify them. Order is preserved upon merge. The map tag\n       must only be used on a list with elements of type object.\n  Defaults to atomic for arrays.\n\n- **x-kubernetes-map-type** (string)\n\n  x-kubernetes-map-type annotates an object to further describe its topology. This extension must only be used when type is object and may have 2 possible values:\n  \n  1) `granular`:\n       These maps are actual maps (key-value pairs) and each fields are independent\n       from each other (they can each be manipulated by separate actors). This is\n       the default behaviour for all maps.\n  2) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic maps will be entirely replaced when updated.\n\n- **x-kubernetes-preserve-unknown-fields** (boolean)\n\n  x-kubernetes-preserve-unknown-fields stops the API server decoding step from pruning fields which are not specified in the validation schema. This affects fields recursively, but switches back to normal pruning behaviour if nested properties or additionalProperties are specified in the schema. This can either be true or undefined. False is forbidden.\n\n- **x-kubernetes-validations** ([]ValidationRule)\n\n  *Patch strategy: merge on key `rule`*\n  \n  *Map: unique values on key rule will be kept during a merge*\n  \n  x-kubernetes-validations describes a list of validation rules written in the CEL expression language.\n\n  <a name=\"ValidationRule\"></a>\n  *ValidationRule describes a validation rule written in the CEL expression language.*\n\n  - **x-kubernetes-validations.rule** (string), required\n\n    Rule represents the expression which will be evaluated by CEL. ref: https://github.com/google/cel-spec The Rule is scoped to the location of the x-kubernetes-validations extension in the schema. The `self` variable in the CEL expression is bound to the scoped value. Example: - Rule scoped to the root of a resource with a status subresource: {\"rule\": \"self.status.actual \\<= self.spec.maxDesired\"}\n    \n    If the Rule is scoped to an object with properties, the accessible properties of the object are field selectable via `self.field` and field presence can be checked via `has(self.field)`. Null valued fields are treated as absent fields in CEL expressions. If the Rule is scoped to an object with additionalProperties (i.e. a map) the value of the map are accessible via `self[mapKey]`, map containment can be checked via `mapKey in self` and all entries of the map are accessible via CEL macros and functions such as `self.all(...)`. If the Rule is scoped to an array, the elements of the array are accessible via `self[i]` and also by macros and functions. If the Rule is scoped to a scalar, `self` is bound to the scalar value. Examples: - Rule scoped to a map of objects: {\"rule\": \"self.components['Widget'].priority \\< 10\"} - Rule scoped to a list of integers: {\"rule\": \"self.values.all(value, value >= 0 && value \\< 100)\"} - Rule scoped to a string value: {\"rule\": \"self.startsWith('kube')\"}\n    \n    The `apiVersion`, `kind`, `metadata.name` and `metadata.generateName` are always accessible from the root of the object and from any x-kubernetes-embedded-resource annotated objects. No other metadata properties are accessible.\n    \n    Unknown data preserved in custom resources via x-kubernetes-preserve-unknown-fields is not accessible in CEL expressions. This includes: - Unknown field values that are preserved by object schemas with x-kubernetes-preserve-unknown-fields. - Object properties where the property schema is of an \"unknown type\". An \"unknown type\" is recursively defined as:\n      - A schema with no type and x-kubernetes-preserve-unknown-fields set to true\n      - An array where the items schema is of an \"unknown type\"\n      - An object where the additionalProperties schema is of an \"unknown type\"\n    \n    Only property names of the form `[a-zA-Z_.-/][a-zA-Z0-9_.-/]*` are accessible. Accessible property names are escaped according to the following rules when accessed in the expression: - '__' escapes to '__underscores__' - '.' escapes to '__dot__' - '-' escapes to '__dash__' - '/' escapes to '__slash__' - Property names that exactly match a CEL RESERVED keyword escape to '__{keyword}__'. The keywords are:\n    \t  \"true\", \"false\", \"null\", \"in\", \"as\", \"break\", \"const\", \"continue\", \"else\", \"for\", \"function\", \"if\",\n    \t  \"import\", \"let\", \"loop\", \"package\", \"namespace\", \"return\".\n    Examples:\n      - Rule accessing a property named \"namespace\": {\"rule\": \"self.__namespace__ > 0\"}\n      - Rule accessing a property named \"x-prop\": {\"rule\": \"self.x__dash__prop > 0\"}\n      - Rule accessing a property named \"redact__d\": {\"rule\": \"self.redact__underscores__d > 0\"}\n    \n    Equality on arrays with x-kubernetes-list-type of 'set' or 'map' ignores element order, i.e. [1, 2] == [2, 1]. Concatenation on arrays with x-kubernetes-list-type use the semantics of the list type:\n      - 'set': `X + Y` performs a union where the array positions of all elements in `X` are preserved and\n        non-intersecting elements in `Y` are appended, retaining their partial order.\n      - 'map': `X + Y` performs a merge where the array positions of all keys in `X` are preserved but the values\n        are overwritten by values in `Y` when the key sets of `X` and `Y` intersect. Elements in `Y` with\n        non-intersecting keys are appended, retaining their partial order.\n    \n    If `rule` makes use of the `oldSelf` variable it is implicitly a `transition rule`.\n    \n    By default, the `oldSelf` variable is the same type as `self`. When `optionalOldSelf` is true, the `oldSelf` variable is a CEL optional\n     variable whose value() is the same type as `self`.\n    See the documentation for the `optionalOldSelf` field for details.\n    \n    Transition rules by default are applied only on UPDATE requests and are skipped if an old value could not be found. You can opt a transition rule into unconditional evaluation by setting `optionalOldSelf` to true.\n\n  - **x-kubernetes-validations.fieldPath** (string)\n\n    fieldPath represents the field path returned when the validation fails. It must be a relative JSON path (i.e. with array notation) scoped to the location of this x-kubernetes-validations extension in the schema and refer to an existing field. e.g. when validation checks if a specific attribute `foo` under a map `testMap`, the fieldPath could be set to `.testMap.foo` If the validation checks two lists must have unique attributes, the fieldPath could be set to either of the list: e.g. `.testList` It does not support list numeric index. It supports child operation to refer to an existing field currently. Refer to [JSONPath support in Kubernetes](https://kubernetes.io/docs/reference/kubectl/jsonpath/) for more info. Numeric index of array is not supported. For field name which contains special characters, use `['specialName']` to refer the field name. e.g. for attribute `foo.34$` appears in a list `testList`, the fieldPath could be set to `.testList['foo.34$']`\n\n  - **x-kubernetes-validations.message** (string)\n\n    Message represents the message displayed when validation fails. The message is required if the Rule contains line breaks. The message must not contain line breaks. If unset, the message is \"failed rule: {Rule}\". e.g. \"must be a URL with the host matching spec.host\"\n\n  - **x-kubernetes-validations.messageExpression** (string)\n\n    MessageExpression declares a CEL expression that evaluates to the validation failure message that is returned when this rule fails. Since messageExpression is used as a failure message, it must evaluate to a string. If both message and messageExpression are present on a rule, then messageExpression will be used if validation fails. If messageExpression results in a runtime error, the runtime error is logged, and the validation failure message is produced as if the messageExpression field were unset. If messageExpression evaluates to an empty string, a string with only spaces, or a string that contains line breaks, then the validation failure message will also be produced as if the messageExpression field were unset, and the fact that messageExpression produced an empty string/string with only spaces/string with line breaks will be logged. messageExpression has access to all the same variables as the rule; the only difference is the return type. Example: \"x must be less than max (\"+string(self.max)+\")\"\n\n  - **x-kubernetes-validations.optionalOldSelf** (boolean)\n\n    optionalOldSelf is used to opt a transition rule into evaluation even when the object is first created, or if the old object is missing the value.\n    \n    When enabled `oldSelf` will be a CEL optional whose value will be `None` if there is no old value, or when the object is initially created.\n    \n    You may check for presence of oldSelf using `oldSelf.hasValue()` and unwrap it after checking using `oldSelf.value()`. Check the CEL documentation for Optional types for more information: https://pkg.go.dev/github.com/google/cel-go/cel#OptionalTypes\n    \n    May not be set unless `oldSelf` is used in `rule`.\n\n  - **x-kubernetes-validations.reason** (string)\n\n    reason provides a machine-readable validation failure reason that is returned to the caller when a request fails this validation rule. The HTTP status code returned to the caller will match the reason of the reason of the first failed validation rule. The currently supported reasons are: \"FieldValueInvalid\", \"FieldValueForbidden\", \"FieldValueRequired\", \"FieldValueDuplicate\". If not set, default to use \"FieldValueInvalid\". All future added reasons must be accepted by clients when reading this value and unknown reasons should be treated as FieldValueInvalid.\n    \n    Possible enum values:\n     - `\"FieldValueDuplicate\"` is used to report collisions of values that must be unique (e.g. unique IDs).\n     - `\"FieldValueForbidden\"` is used to report valid (as per formatting rules) values which would be accepted under some conditions, but which are not permitted by the current conditions (such as security policy).\n     - `\"FieldValueInvalid\"` is used to report malformed values (e.g. failed regex match, too long, out of bounds).\n     - `\"FieldValueRequired\"` is used to report required values that are not provided (e.g. empty strings, null values, or empty arrays).",
      "terms": [
        {
          "term": "JSONSchemaProps",
          "tier": 1,
          "reasoning": "Core API object type for defining JSON Schema properties in Kubernetes CRDs"
        },
        {
          "term": "JSON-Schema",
          "tier": 2,
          "reasoning": "Domain standard specification that JSONSchemaProps follows"
        },
        {
          "term": "Specification Draft 4",
          "tier": 2,
          "reasoning": "Specific version of JSON Schema specification referenced"
        },
        {
          "term": "$ref",
          "tier": 3,
          "reasoning": "JSON Schema keyword for referencing other schemas"
        },
        {
          "term": "$schema",
          "tier": 3,
          "reasoning": "JSON Schema keyword for declaring schema version"
        },
        {
          "term": "additionalItems",
          "tier": 2,
          "reasoning": "JSON Schema property for controlling additional array items validation"
        },
        {
          "term": "JSONSchemaPropsOrBool",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or boolean value"
        },
        {
          "term": "additionalProperties",
          "tier": 2,
          "reasoning": "JSON Schema property for controlling additional object properties validation"
        },
        {
          "term": "allOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical AND"
        },
        {
          "term": "Atomic",
          "tier": 2,
          "reasoning": "Kubernetes merge strategy annotation indicating replacement during merge"
        },
        {
          "term": "anyOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical OR"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "JSON Schema property for specifying default values for undefined fields"
        },
        {
          "term": "JSON",
          "tier": 2,
          "reasoning": "Data format type representing valid JSON values in the schema"
        },
        {
          "term": "CustomResourceDefaulting",
          "tier": 1,
          "reasoning": "Kubernetes feature gate controlling defaulting behavior for custom resources"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling features"
        },
        {
          "term": "spec.preserveUnknownFields",
          "tier": 1,
          "reasoning": "Kubernetes CRD spec field controlling unknown field preservation"
        },
        {
          "term": "definitions",
          "tier": 2,
          "reasoning": "JSON Schema keyword for reusable schema definitions"
        },
        {
          "term": "dependencies",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining property dependencies"
        },
        {
          "term": "JSONSchemaPropsOrStringArray",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or string array"
        },
        {
          "term": "description",
          "tier": 3,
          "reasoning": "JSON Schema property for human-readable descriptions"
        },
        {
          "term": "enum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining allowed values"
        },
        {
          "term": "example",
          "tier": 3,
          "reasoning": "JSON Schema property for providing example values"
        },
        {
          "term": "exclusiveMaximum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive upper bound validation"
        },
        {
          "term": "exclusiveMinimum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive lower bound validation"
        },
        {
          "term": "externalDocs",
          "tier": 2,
          "reasoning": "OpenAPI/JSON Schema property for external documentation references"
        },
        {
          "term": "ExternalDocumentation",
          "tier": 1,
          "reasoning": "Kubernetes type for referencing external documentation resources"
        },
        {
          "term": "format",
          "tier": 2,
          "reasoning": "JSON Schema/OpenAPI property for string format validation"
        },
        {
          "term": "OpenAPI v3",
          "tier": 2,
          "reasoning": "API specification standard that defines format strings"
        },
        {
          "term": "bsonobjectid",
          "tier": 3,
          "reasoning": "Format string for BSON object ID validation"
        },
        {
          "term": "uri",
          "tier": 3,
          "reasoning": "Format string for URI validation"
        },
        {
          "term": "email",
          "tier": 3,
          "reasoning": "Format string for email address validation"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Format string for Internet host name validation"
        },
        {
          "term": "RFC 1034",
          "tier": 3,
          "reasoning": "Internet standard defining hostname format"
        },
        {
          "term": "ipv4",
          "tier": 3,
          "reasoning": "Format string for IPv4 address validation"
        },
        {
          "term": "ipv6",
          "tier": 3,
          "reasoning": "Format string for IPv6 address validation"
        },
        {
          "term": "cidr",
          "tier": 3,
          "reasoning": "Format string for CIDR notation validation"
        },
        {
          "term": "mac",
          "tier": 3,
          "reasoning": "Format string for MAC address validation"
        },
        {
          "term": "uuid",
          "tier": 3,
          "reasoning": "Format string for UUID validation"
        },
        {
          "term": "uuid3",
          "tier": 3,
          "reasoning": "Format string for UUID version 3 validation"
        },
        {
          "term": "uuid4",
          "tier": 3,
          "reasoning": "Format string for UUID version 4 validation"
        },
        {
          "term": "uuid5",
          "tier": 3,
          "reasoning": "Format string for UUID version 5 validation"
        },
        {
          "term": "isbn",
          "tier": 3,
          "reasoning": "Format string for ISBN number validation"
        },
        {
          "term": "isbn10",
          "tier": 3,
          "reasoning": "Format string for ISBN-10 number validation"
        },
        {
          "term": "isbn13",
          "tier": 3,
          "reasoning": "Format string for ISBN-13 number validation"
        },
        {
          "term": "creditcard",
          "tier": 3,
          "reasoning": "Format string for credit card number validation"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating defaulting is a beta feature"
        },
        {
          "term": "custom-resource-definition-v1",
          "tier": 1,
          "reasoning": "Reference to CustomResourceDefinition API version"
        },
        {
          "term": "extend-resources",
          "tier": 2,
          "reasoning": "Kubernetes documentation category for resource extension mechanisms"
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "int64",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "float64",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "JSON data type supported in JSON representation"
        },
        {
          "term": "regex",
          "tier": 3,
          "reasoning": "Regular expression pattern used for format validation"
        }
      ],
      "term_count": 53,
      "generated_at": "2026-02-08T21:28:00.199041",
      "elapsed_time": 21.482445240020752
    },
    {
      "chunk_id": "concepts_storage_volume-pvc-datasource_sec0",
      "doc_id": "concepts_storage_volume-pvc-datasource",
      "heading": "Introduction",
      "source_file": "concepts_storage_volume-pvc-datasource.md",
      "content": "---\nreviewers:\n- jsafrane\n- saad-ali\n- thockin\n- msau42\ntitle: CSI Volume Cloning\ncontent_type: concept\nweight: 70\n---\n\n<!-- overview -->\n\nThis document describes the concept of cloning existing CSI Volumes in Kubernetes.\nFamiliarity with [Volumes](/docs/concepts/storage/volumes) is suggested.\n\n<!-- body -->",
      "terms": [
        {
          "term": "CSI",
          "tier": 1,
          "reasoning": "Container Storage Interface - a core Kubernetes storage standard/protocol for volume plugins."
        },
        {
          "term": "CSI Volumes",
          "tier": 1,
          "reasoning": "Specific Kubernetes storage resource type using the Container Storage Interface."
        },
        {
          "term": "CSI Volume Cloning",
          "tier": 2,
          "reasoning": "A specific Kubernetes storage feature/process for duplicating CSI-based volumes."
        },
        {
          "term": "Volumes",
          "tier": 1,
          "reasoning": "Core Kubernetes storage API object/resource for persistent data."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "cloning",
          "tier": 2,
          "reasoning": "Technical process of duplicating storage volumes in the Kubernetes context."
        }
      ],
      "term_count": 6,
      "generated_at": "2026-02-08T21:28:08.506096",
      "elapsed_time": 7.297876834869385
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_run__index_sec3",
      "doc_id": "reference_kubectl_generated_kubectl_run__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_run__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--allow-missing-template-keys&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--annotations strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Annotations to apply to the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--attach</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for the Pod to start running, and then attach to the Pod as if 'kubectl attach ...' were called.  Default false, unless '-i/--stdin' is set, in which case the default is true. With '--restart=Never' the exit code of the container process is returned.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cascade string[=\"background\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"background\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;background&quot;, &quot;orphan&quot;, or &quot;foreground&quot;. Selects the deletion cascading strategy for the dependents (e.g. Pods created by a ReplicationController). Defaults to background.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--command</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true and extra arguments are present, use them as the 'command' field in the container, rather than the 'args' field which is the default.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--dry-run string[=\"unchanged\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;none&quot;, &quot;server&quot;, or &quot;client&quot;. If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--env strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Environment variables to set in the container.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--expose --port</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, create a ClusterIP service associated with the pod.  Requires --port.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--field-manager string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"kubectl-run\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the manager used to track field ownership.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-f, --filename strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>to use to replace the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--force</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, immediately remove resources from API and bypass graceful deletion. Note that immediate deletion of some resources may result in inconsistency or data loss and requires confirmation.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--grace-period int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: -1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Period of time in seconds given to the resource to terminate gracefully. Ignored if negative. Set to 1 for immediate shutdown. Can only be set to 0 when --force is true (force deletion).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for run</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image for the container to run.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image-pull-policy string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image pull policy for the container.  If left empty, this value will not be specified by the client and defaulted by the server.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-k, --kustomize string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process a kustomization directory. This flag can't be used together with -f or -R.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-l, --labels string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Comma separated labels to apply to the pod. Will override previous values.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--leave-stdin-open</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If the pod is started in interactive mode or with stdin, leave stdin open after the first attach completes. By default, stdin will be closed after the first attach completes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-o, --output string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Output format. One of: (json, yaml, kyaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--override-type string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"merge\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The method used to override the generated object: json, merge, or strategic.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--overrides string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>An inline JSON override for the generated object. If this is non-empty, it is used to override the generated object. Requires that the object supply a valid apiVersion field.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--pod-running-timeout duration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1m0s</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time (like 5s, 2m, or 3h, higher than zero) to wait until at least one pod is running</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--port string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The port that this container exposes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--privileged</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, run the container in privileged mode.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-q, --quiet</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, suppress prompt messages.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-R, --recursive</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--restart string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"Always\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The restart policy for this Pod.  Legal values [Always, OnFailure, Never].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--rm</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, delete the pod after it exits.  Only valid when attaching to the container, e.g. with '--attach' or with '-i/--stdin'.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--save-config</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the configuration of current object will be saved in its annotation. Otherwise, the annotation will be unchanged. This flag is useful when you want to perform kubectl apply on this object in the future.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--show-managed-fields</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, keep the managedFields when printing objects in JSON or YAML format.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-i, --stdin</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Keep stdin open on the container in the pod, even if nothing is attached.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--template string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--timeout duration</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time to wait before giving up on a delete, zero means determine a timeout from the size of the object</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-t, --tty</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Allocate a TTY for the container in the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--wait</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for resources to be gone before returning. This waits for finalizers.</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Kubernetes API object that ensures a specified number of pod replicas are running."
        },
        {
          "term": "ClusterIP service",
          "tier": 1,
          "reasoning": "Specific Kubernetes Service type that exposes the service on a cluster-internal IP."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool, referenced as 'kubectl attach' and 'kubectl-run'."
        },
        {
          "term": "kubectl attach",
          "tier": 1,
          "reasoning": "Specific kubectl command for attaching to a running container."
        },
        {
          "term": "kubectl-run",
          "tier": 1,
          "reasoning": "Field manager name for the kubectl run command."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing an isolated runtime environment for applications."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Technical concept for output formatting in golang and jsonpath contexts."
        },
        {
          "term": "golang",
          "tier": 3,
          "reasoning": "Programming language referenced as an output format type."
        },
        {
          "term": "jsonpath",
          "tier": 2,
          "reasoning": "Query language for JSON used as an output format in kubectl."
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching arbitrary non-identifying metadata to objects."
        },
        {
          "term": "cascade",
          "tier": 2,
          "reasoning": "Deletion strategy concept controlling how dependent resources are handled."
        },
        {
          "term": "deletion cascading strategy",
          "tier": 2,
          "reasoning": "Technical concept describing how dependents are deleted when a parent resource is removed."
        },
        {
          "term": "dependents",
          "tier": 2,
          "reasoning": "Technical term for resources that depend on a parent resource."
        },
        {
          "term": "dry-run",
          "tier": 2,
          "reasoning": "Operational mode that simulates an action without persisting changes."
        },
        {
          "term": "server-side request",
          "tier": 2,
          "reasoning": "Technical concept for requests processed by the API server."
        },
        {
          "term": "client strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where operations are simulated client-side only."
        },
        {
          "term": "server strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where requests are submitted to server without persisting."
        },
        {
          "term": "environment variables",
          "tier": 2,
          "reasoning": "Configuration mechanism for passing runtime settings to containers."
        },
        {
          "term": "field-manager",
          "tier": 2,
          "reasoning": "Server-side apply concept for tracking which manager owns which fields."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Concept in server-side apply for tracking who manages specific fields."
        },
        {
          "term": "graceful deletion",
          "tier": 2,
          "reasoning": "Kubernetes concept for allowing resources time to terminate cleanly."
        },
        {
          "term": "grace-period",
          "tier": 2,
          "reasoning": "Time period given to resources to terminate gracefully before forced deletion."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image that defines what runs inside a container."
        },
        {
          "term": "image-pull-policy",
          "tier": 2,
          "reasoning": "Policy controlling when container images are pulled from registries."
        },
        {
          "term": "stdin",
          "tier": 3,
          "reasoning": "Standard input stream, referenced as -i/--stdin flag for interactive mode."
        },
        {
          "term": "attach",
          "tier": 2,
          "reasoning": "Operation to connect to a running container's input/output streams."
        },
        {
          "term": "exit code",
          "tier": 3,
          "reasoning": "Process termination status returned by container processes."
        },
        {
          "term": "container process",
          "tier": 2,
          "reasoning": "The main process running inside a container."
        },
        {
          "term": "command",
          "tier": 2,
          "reasoning": "Container specification field defining the entrypoint command."
        },
        {
          "term": "args",
          "tier": 2,
          "reasoning": "Container specification field for arguments passed to the command."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Generic term for Kubernetes API objects that can be created and managed."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in context of removing resources from API."
        },
        {
          "term": "--port",
          "tier": 2,
          "reasoning": "CLI flag for specifying port configuration, required for expose functionality."
        },
        {
          "term": "force deletion",
          "tier": 2,
          "reasoning": "Immediate removal of resources bypassing graceful termination."
        },
        {
          "term": "output formats",
          "tier": 2,
          "reasoning": "Different ways kubectl can format command output (golang, jsonpath)."
        },
        {
          "term": "--restart=Never",
          "tier": 2,
          "reasoning": "Pod restart policy option that prevents automatic restarts."
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:28:32.448183",
      "elapsed_time": 22.93202257156372
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_patch__index_sec2",
      "doc_id": "reference_kubectl_generated_kubectl_patch__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_patch__index.md",
      "content": "```\n  # Partially update a node using a strategic merge patch, specifying the patch as JSON\n  kubectl patch node k8s-node-1 -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Partially update a node using a strategic merge patch, specifying the patch as YAML\n  kubectl patch node k8s-node-1 -p $'spec:\\n unschedulable: true'\n  \n  # Partially update a node identified by the type and name specified in \"node.json\" using strategic merge patch\n  kubectl patch -f node.json -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Update a container's image; spec.containers[*].name is required because it's a merge key\n  kubectl patch pod valid-pod -p '{\"spec\":{\"containers\":[{\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"}]}}'\n  \n  # Update a container's image using a JSON patch with positional arrays\n  kubectl patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"}]'\n  \n  # Update a deployment's replicas through the 'scale' subresource using a merge patch\n  kubectl patch deployment nginx-deployment --subresource='scale' --type='merge' -p '{\"spec\":{\"replicas\":2}}'\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout the documentation chunk."
        },
        {
          "term": "node",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing replicated applications."
        },
        {
          "term": "k8s-node-1",
          "tier": 1,
          "reasoning": "Specific node name used as an example in the commands."
        },
        {
          "term": "valid-pod",
          "tier": 1,
          "reasoning": "Specific pod name used as an example in the commands."
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific deployment name used as an example in the commands."
        },
        {
          "term": "kubernetes-serve-hostname",
          "tier": 1,
          "reasoning": "Specific container name used as an example in the patch command."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Kubernetes operation for partially updating resources without replacing them entirely."
        },
        {
          "term": "strategic merge patch",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch strategy that understands the schema of Kubernetes objects."
        },
        {
          "term": "JSON patch",
          "tier": 2,
          "reasoning": "RFC 6902 standard patch format supported by Kubernetes for precise updates."
        },
        {
          "term": "merge patch",
          "tier": 2,
          "reasoning": "Patch type that merges the provided fields with existing object fields."
        },
        {
          "term": "subresource",
          "tier": 2,
          "reasoning": "Kubernetes concept for accessing specific aspects of a resource like scale or status."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes subresource used to adjust the number of replicas."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Standard Kubernetes object field containing the desired state specification."
        },
        {
          "term": "unschedulable",
          "tier": 2,
          "reasoning": "Node spec field that prevents new pods from being scheduled on the node."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Spec field containing the list of containers in a pod."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container specification field defining the container image to run."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment/scale spec field defining the desired number of pod instances."
        },
        {
          "term": "merge key",
          "tier": 2,
          "reasoning": "Field used by strategic merge patch to identify list items for merging."
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Metadata field used as merge key for containers in strategic merge patch."
        },
        {
          "term": "positional arrays",
          "tier": 2,
          "reasoning": "JSON patch technique using array indices to target specific elements."
        },
        {
          "term": "JSON",
          "tier": 3,
          "reasoning": "Data format used for specifying patch content in kubectl commands."
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data format alternative to JSON for specifying patch content."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core concept in Kubernetes representing an isolated runtime environment."
        },
        {
          "term": "-p",
          "tier": 3,
          "reasoning": "kubectl patch flag for specifying the patch content."
        },
        {
          "term": "-f",
          "tier": 3,
          "reasoning": "kubectl flag for specifying a file containing resource definition."
        },
        {
          "term": "--type",
          "tier": 3,
          "reasoning": "kubectl patch flag for specifying the patch type (json, merge, strategic)."
        },
        {
          "term": "--subresource",
          "tier": 3,
          "reasoning": "kubectl flag for targeting a specific subresource of an object."
        },
        {
          "term": "node.json",
          "tier": 3,
          "reasoning": "Example file name containing node resource definition."
        },
        {
          "term": "op",
          "tier": 3,
          "reasoning": "JSON patch operation field specifying the action (replace, add, remove)."
        },
        {
          "term": "replace",
          "tier": 3,
          "reasoning": "JSON patch operation that replaces a value at a specified path."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "JSON patch field specifying the location in the object to modify."
        },
        {
          "term": "value",
          "tier": 3,
          "reasoning": "JSON patch field containing the new value to set."
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T21:28:50.369698",
      "elapsed_time": 16.91165852546692
    },
    {
      "chunk_id": "tasks_debug_debug-application_get-shell-running-container_sec0",
      "doc_id": "tasks_debug_debug-application_get-shell-running-container",
      "heading": "Introduction",
      "source_file": "tasks_debug_debug-application_get-shell-running-container.md",
      "content": "---\nreviewers:\n- caesarxuchao\n- mikedanese\ntitle: Get a Shell to a Running Container\ncontent_type: task\n---\n\n<!-- overview -->\n\nThis page shows how to use `kubectl exec` to get a shell to a\nrunning container.",
      "terms": [
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for executing commands in containers, a core Kubernetes CLI operation."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool, a core CLI component."
        },
        {
          "term": "exec",
          "tier": 2,
          "reasoning": "A specific kubectl command/operation for executing commands inside containers."
        },
        {
          "term": "shell",
          "tier": 2,
          "reasoning": "Technical term referring to command-line interface access to a container's environment."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes/containerization concept representing an isolated runtime environment."
        },
        {
          "term": "running container",
          "tier": 2,
          "reasoning": "Domain-specific phrase describing a container in active execution state."
        },
        {
          "term": "task",
          "tier": 3,
          "reasoning": "Content type classification indicating procedural documentation in Kubernetes docs."
        }
      ],
      "term_count": 7,
      "generated_at": "2026-02-08T21:28:57.468186",
      "elapsed_time": 6.08925724029541
    },
    {
      "chunk_id": "reference_glossary_host-aliases_sec0",
      "doc_id": "reference_glossary_host-aliases",
      "heading": "Introduction",
      "source_file": "reference_glossary_host-aliases.md",
      "content": "---\ntitle: HostAliases\nid: HostAliases\ndate: 2019-01-31\nfull_link: /docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core\nshort_description: >\n  A HostAliases is a mapping between the IP address and hostname to be injected into a Pod's hosts file.\n\naka:\ntags:\n- operation\n---\n A HostAliases is a mapping between the IP address and hostname to be injected into a {{< glossary_tooltip text=\"Pod\" term_id=\"pod\" >}}'s hosts file.\n\n<!--more-->\n\n[HostAliases](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core) is an optional list of hostnames and IP addresses that will be injected into the Pod's hosts file if specified. This is only valid for non-hostNetwork Pods.",
      "terms": [
        {
          "term": "HostAliases",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for mapping IP addresses to hostnames in Pod hosts files"
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that HostAliases is injected into"
        },
        {
          "term": "IP address",
          "tier": 2,
          "reasoning": "Network addressing concept that is mapped to hostnames in HostAliases"
        },
        {
          "term": "hostname",
          "tier": 2,
          "reasoning": "Network identity concept that IP addresses are mapped to in HostAliases"
        },
        {
          "term": "hosts file",
          "tier": 3,
          "reasoning": "Operating system file that HostAliases entries are injected into"
        },
        {
          "term": "hostNetwork",
          "tier": 2,
          "reasoning": "Kubernetes Pod networking mode that affects HostAliases validity"
        },
        {
          "term": "non-hostNetwork Pods",
          "tier": 2,
          "reasoning": "Specific Pod configuration context where HostAliases is valid"
        },
        {
          "term": "mapping",
          "tier": 3,
          "reasoning": "Technical concept describing the relationship between IP and hostname"
        },
        {
          "term": "injected",
          "tier": 3,
          "reasoning": "Technical process term describing how HostAliases entries are added to hosts file"
        },
        {
          "term": "v1-core",
          "tier": 2,
          "reasoning": "Kubernetes API version and group identifier for the HostAlias resource"
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API documentation and specification"
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T21:29:06.044698",
      "elapsed_time": 7.559743881225586
    },
    {
      "chunk_id": "concepts_scheduling-eviction_dynamic-resource-allocation_sec1",
      "doc_id": "concepts_scheduling-eviction_dynamic-resource-allocation",
      "heading": "About DRA {#about-dra}",
      "source_file": "concepts_scheduling-eviction_dynamic-resource-allocation.md",
      "content": "{{< glossary_definition prepend=\"DRA is\" term_id=\"dra\" length=\"all\" >}}\n\nAllocating resources with DRA is a similar experience to\n[dynamic volume provisioning](/docs/concepts/storage/dynamic-provisioning/), in\nwhich you use PersistentVolumeClaims to claim storage capacity from storage\nclasses and request the claimed capacity in your Pods.\n\n### Benefits of DRA {#dra-benefits}\n\nDRA provides a flexible way to categorize, request, and use devices in your\ncluster. Using DRA provides benefits like the following:\n\n* **Flexible device filtering**: use common expression language (CEL) to perform\n  fine-grained filtering for specific device attributes.\n* **Device sharing**: share the same resource with multiple containers or Pods\n  by referencing the corresponding resource claim.\n* **Centralized device categorization**: device drivers and cluster admins can\n  use device classes to provide app operators with hardware categories that are\n  optimized for various use cases. For example, you can create a cost-optimized\n  device class for general-purpose workloads, and a high-performance device\n  class for critical jobs.\n* **Simplified Pod requests**: with DRA, app operators don't need to specify\n  device quantities in Pod resource requests. Instead, the Pod references a\n  resource claim, and the device configuration in that claim applies to the Pod.\n\nThese benefits provide significant improvements in the device allocation\nworkflow when compared to\n[device plugins](/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/),\nwhich require per-container device requests, don't support device sharing, and\ndon't support expression-based device filtering.\n\n### Types of DRA users {#dra-user-types}\n\nThe workflow of using DRA to allocate devices involves the following types of\nusers:\n\n* **Device owner**: responsible for devices. Device owners might be commercial\n  vendors, the cluster operator, or another entity. To use DRA, devices must\n  have DRA-compatible drivers that do the following:\n\n  * Create ResourceSlices that provide Kubernetes with information about\n    nodes and resources.\n  * Update ResourceSlices when resource capacity in the cluster changes.\n  * Optionally, create DeviceClasses that workload operators can use to\n    claim devices.\n\n* **Cluster admin**: responsible for configuring clusters and nodes,\n  attaching devices, installing drivers, and similar tasks. To use DRA,\n  cluster admins do the following:\n\n  * Attach devices to nodes.\n  * Install device drivers that support DRA.\n  * Optionally, create DeviceClasses that workload operators can use to claim\n    devices.\n\n* **Workload operator**: responsible for deploying and managing workloads in the\n  cluster. To use DRA to allocate devices to Pods, workload operators do the\n  following:\n\n  * Create ResourceClaims or ResourceClaimTemplates to request specific\n    configurations within DeviceClasses.\n  * Deploy workloads that use specific ResourceClaims or ResourceClaimTemplates.",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Core Kubernetes feature/API for Dynamic Resource Allocation, the main subject of this documentation."
        },
        {
          "term": "dynamic volume provisioning",
          "tier": 2,
          "reasoning": "Kubernetes concept for automatically provisioning storage volumes."
        },
        {
          "term": "PersistentVolumeClaims",
          "tier": 1,
          "reasoning": "Kubernetes API object for claiming persistent storage capacity."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the core Kubernetes workload resource."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Common Expression Language - a protocol/standard used for device filtering in DRA."
        },
        {
          "term": "common expression language",
          "tier": 2,
          "reasoning": "The full name of CEL, used for fine-grained filtering expressions."
        },
        {
          "term": "device filtering",
          "tier": 2,
          "reasoning": "Technical process for selecting devices based on attributes."
        },
        {
          "term": "device attributes",
          "tier": 2,
          "reasoning": "Technical concept describing properties of devices for filtering."
        },
        {
          "term": "resource claim",
          "tier": 2,
          "reasoning": "DRA concept for requesting device resources."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for isolated application runtime units."
        },
        {
          "term": "device classes",
          "tier": 1,
          "reasoning": "DRA API object for categorizing devices by use case."
        },
        {
          "term": "DeviceClasses",
          "tier": 1,
          "reasoning": "Kubernetes API object name for device categorization in DRA."
        },
        {
          "term": "device drivers",
          "tier": 2,
          "reasoning": "Software components that enable device communication with Kubernetes."
        },
        {
          "term": "cluster admins",
          "tier": 2,
          "reasoning": "Role/user type responsible for cluster configuration."
        },
        {
          "term": "app operators",
          "tier": 2,
          "reasoning": "Role/user type responsible for deploying applications."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes concept for applications running in the cluster."
        },
        {
          "term": "device plugins",
          "tier": 1,
          "reasoning": "Kubernetes extension mechanism for device allocation, compared to DRA."
        },
        {
          "term": "device allocation",
          "tier": 2,
          "reasoning": "Technical process of assigning devices to workloads."
        },
        {
          "term": "ResourceSlices",
          "tier": 1,
          "reasoning": "DRA API object providing Kubernetes with node and resource information."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Kubernetes concept for worker machines in a cluster."
        },
        {
          "term": "resource capacity",
          "tier": 2,
          "reasoning": "Technical concept describing available resources in the cluster."
        },
        {
          "term": "workload operators",
          "tier": 2,
          "reasoning": "Role/user type responsible for deploying and managing workloads."
        },
        {
          "term": "ResourceClaims",
          "tier": 1,
          "reasoning": "DRA API object for requesting specific device configurations."
        },
        {
          "term": "ResourceClaimTemplates",
          "tier": 1,
          "reasoning": "DRA API object template for creating ResourceClaims."
        },
        {
          "term": "device owner",
          "tier": 2,
          "reasoning": "DRA user role responsible for devices and drivers."
        },
        {
          "term": "drivers",
          "tier": 2,
          "reasoning": "Software components enabling device functionality in Kubernetes."
        },
        {
          "term": "device sharing",
          "tier": 2,
          "reasoning": "DRA capability allowing multiple containers to use the same device."
        },
        {
          "term": "Pod resource requests",
          "tier": 2,
          "reasoning": "Kubernetes concept for specifying resource requirements in Pods."
        },
        {
          "term": "device configuration",
          "tier": 2,
          "reasoning": "Technical concept for device settings applied to Pods."
        },
        {
          "term": "storage capacity",
          "tier": 2,
          "reasoning": "Technical concept for available storage resources."
        },
        {
          "term": "per-container device requests",
          "tier": 2,
          "reasoning": "Device plugin limitation requiring requests per container."
        },
        {
          "term": "expression-based device filtering",
          "tier": 2,
          "reasoning": "DRA capability for filtering devices using expressions."
        },
        {
          "term": "DRA-compatible drivers",
          "tier": 2,
          "reasoning": "Device drivers that support the DRA interface."
        }
      ],
      "term_count": 35,
      "generated_at": "2026-02-08T21:29:25.830638",
      "elapsed_time": 18.77550196647644
    },
    {
      "chunk_id": "tutorials_kubernetes-basics_explore_explore-intro_sec1",
      "doc_id": "tutorials_kubernetes-basics_explore_explore-intro",
      "heading": "Nodes",
      "source_file": "tutorials_kubernetes-basics_explore_explore-intro.md",
      "content": "A Pod always runs on a **Node**. A Node is a worker machine in Kubernetes and may\nbe either a virtual or a physical machine, depending on the cluster. Each Node is\nmanaged by the control plane. A Node can have multiple pods, and the Kubernetes\ncontrol plane automatically handles scheduling the pods across the Nodes in the\ncluster. The control plane's automatic scheduling takes into account the available\nresources on each Node.\n\nEvery Kubernetes Node runs at least:\n\n* Kubelet, a process responsible for communication between the Kubernetes control\nplane and the Node; it manages the Pods and the containers running on a machine.\n\n* A container runtime (like Docker) responsible for pulling the container image\nfrom a registry, unpacking the container, and running the application.\n\n### Nodes overview\n\n{{< figure src=\"/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg\" class=\"diagram-medium\" >}}",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Named Kubernetes resource representing a worker machine in the cluster."
        },
        {
          "term": "Kubelet",
          "tier": 1,
          "reasoning": "Named Kubernetes component process running on each Node."
        },
        {
          "term": "Docker",
          "tier": 1,
          "reasoning": "Named container runtime technology explicitly mentioned."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core platform/product name being documented."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core architectural concept referring to the cluster management layer."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Domain-specific term describing the role of a Node in the cluster."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept for a set of nodes."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, core Kubernetes API object referenced multiple times."
        },
        {
          "term": "Nodes",
          "tier": 1,
          "reasoning": "Plural form of Node, referenced in context of scheduling across the cluster."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Core Kubernetes process for assigning pods to nodes."
        },
        {
          "term": "automatic scheduling",
          "tier": 2,
          "reasoning": "Specific scheduling behavior performed by the control plane."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Technical term referring to compute capacity (CPU, memory) on nodes."
        },
        {
          "term": "container runtime",
          "tier": 2,
          "reasoning": "Infrastructure component category responsible for running containers."
        },
        {
          "term": "container image",
          "tier": 2,
          "reasoning": "Technical artifact that gets pulled and unpacked to run applications."
        },
        {
          "term": "registry",
          "tier": 2,
          "reasoning": "Infrastructure component where container images are stored and pulled from."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core virtualization concept for isolated application execution."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form of container, managed by kubelet on a machine."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Capitalized plural form as managed by kubelet."
        },
        {
          "term": "physical machine",
          "tier": 3,
          "reasoning": "Infrastructure concept - Node may be a physical machine."
        },
        {
          "term": "machine",
          "tier": 3,
          "reasoning": "General infrastructure term used to describe where containers run."
        },
        {
          "term": "application",
          "tier": 3,
          "reasoning": "Technical term for the software running inside containers."
        },
        {
          "term": "process",
          "tier": 3,
          "reasoning": "OS-level concept describing kubelet as a running process."
        },
        {
          "term": "communication",
          "tier": 3,
          "reasoning": "Technical term describing kubelet's role between control plane and Node."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:29:40.682948",
      "elapsed_time": 13.842349290847778
    },
    {
      "chunk_id": "reference_using-api_server-side-apply_sec4",
      "doc_id": "reference_using-api_server-side-apply",
      "heading": "Merge strategy",
      "source_file": "reference_using-api_server-side-apply.md",
      "content": "The merging strategy, implemented with Server-Side Apply, provides a generally\nmore stable object lifecycle. Server-Side Apply tries to merge fields based on\nthe actor who manages them instead of overruling based on values. This way\nmultiple actors can update the same object without causing unexpected interference.\n\nWhen a user sends a _fully-specified intent_ object to the Server-Side Apply\nendpoint, the server merges it with the live object favoring the value from the\nrequest body if it is specified in both places. If the set of items present in\nthe applied config is not a superset of the items applied by the same user last\ntime, each missing item not managed by any other appliers is removed. For\nmore information about how an object's schema is used to make decisions when\nmerging, see\n[sigs.k8s.io/structured-merge-diff](https://sigs.k8s.io/structured-merge-diff).\n\nThe Kubernetes API (and the Go code that implements that API for Kubernetes) allows\ndefining _merge strategy markers_. These markers describe the merge strategy supported\nfor fields within Kubernetes objects.\nFor a {{< glossary_tooltip term_id=\"CustomResourceDefinition\" text=\"CustomResourceDefinition\" >}},\nyou can set these markers when you define the custom resource.\n\n| Golang marker   | OpenAPI extension            | Possible values                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| --------------- | ---------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `//+listType`   | `x-kubernetes-list-type`     | `atomic`/`set`/`map`                             | Applicable to lists. `set` applies to lists that include only scalar elements. These elements must be unique. `map` applies to lists of nested types only. The key values (see `listMapKey`) must be unique in the list. `atomic` can apply to any list. If configured as `atomic`, the entire list is replaced during merge. At any point in time, a single manager owns the list. If `set` or `map`, different managers can manage entries separately. |\n| `//+listMapKey` | `x-kubernetes-list-map-keys` | List of field names, e.g. `[\"port\", \"protocol\"]` | Only applicable when `+listType=map`. A list of field names whose values uniquely identify entries in the list. While there can be multiple keys, `listMapKey` is singular because keys need to be specified individually in the Go type. The key fields must be scalars.                                                                                                                                                                                |\n| `//+mapType`    | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to maps. `atomic` means that the map can only be entirely replaced by a single manager. `granular` means that the map supports separate managers updating individual fields.                                                                                                                                                                                                                                                                  |\n| `//+structType` | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to structs; otherwise same usage and OpenAPI annotation as `//+mapType`.                                                                                                                                                                                                                                                                                                                                                                      |\n\nIf `listType` is missing, the API server interprets a\n`patchStrategy=merge` marker as a `listType=map` and the\ncorresponding `patchMergeKey` marker as a `listMapKey`.\n\nThe `atomic` list type is recursive.\n\n(In the [Go](https://go.dev/) code for Kubernetes, these markers are specified as\ncomments and code authors need not repeat them as field tags).",
      "terms": [
        {
          "term": "Server-Side Apply",
          "tier": 1,
          "reasoning": "Core Kubernetes API mechanism for applying configuration changes with field ownership tracking."
        },
        {
          "term": "merging strategy",
          "tier": 2,
          "reasoning": "Technical concept describing how object fields are combined during updates."
        },
        {
          "term": "object lifecycle",
          "tier": 2,
          "reasoning": "Domain concept referring to the stages and management of Kubernetes objects over time."
        },
        {
          "term": "actor",
          "tier": 2,
          "reasoning": "Technical term referring to an entity (user or controller) that manages fields in an object."
        },
        {
          "term": "fully-specified intent",
          "tier": 2,
          "reasoning": "Domain-specific concept describing a complete desired state object sent to the API."
        },
        {
          "term": "live object",
          "tier": 2,
          "reasoning": "Technical term for the current state of an object in the Kubernetes cluster."
        },
        {
          "term": "applied config",
          "tier": 2,
          "reasoning": "Technical term referring to the configuration that was previously applied by a user."
        },
        {
          "term": "appliers",
          "tier": 2,
          "reasoning": "Domain term for actors that apply configurations to objects."
        },
        {
          "term": "schema",
          "tier": 2,
          "reasoning": "Technical concept describing the structure definition used for merge decisions."
        },
        {
          "term": "structured-merge-diff",
          "tier": 1,
          "reasoning": "Specific library/project name for handling structured merging in Kubernetes."
        },
        {
          "term": "sigs.k8s.io/structured-merge-diff",
          "tier": 1,
          "reasoning": "Full reference path to the structured merge diff project."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core component name for the API that exposes Kubernetes functionality."
        },
        {
          "term": "merge strategy markers",
          "tier": 2,
          "reasoning": "Domain-specific concept for annotations that define how fields should be merged."
        },
        {
          "term": "Kubernetes objects",
          "tier": 2,
          "reasoning": "Core domain concept referring to persistent entities in the Kubernetes system."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for defining custom resources."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Domain concept for user-defined extensions to the Kubernetes API."
        },
        {
          "term": "Golang marker",
          "tier": 2,
          "reasoning": "Technical term for Go code annotations used to define merge behavior."
        },
        {
          "term": "OpenAPI extension",
          "tier": 2,
          "reasoning": "Technical concept for custom extensions to OpenAPI specifications."
        },
        {
          "term": "//+listType",
          "tier": 1,
          "reasoning": "Specific Golang marker syntax for defining list merge behavior."
        },
        {
          "term": "x-kubernetes-list-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for Kubernetes list type definitions."
        },
        {
          "term": "//+listMapKey",
          "tier": 1,
          "reasoning": "Specific Golang marker for defining map key fields in lists."
        },
        {
          "term": "x-kubernetes-list-map-keys",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for list map key definitions."
        },
        {
          "term": "//+mapType",
          "tier": 1,
          "reasoning": "Specific Golang marker for defining map merge behavior."
        },
        {
          "term": "x-kubernetes-map-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for Kubernetes map type definitions."
        },
        {
          "term": "//+structType",
          "tier": 1,
          "reasoning": "Specific Golang marker for defining struct merge behavior (truncated in text)."
        },
        {
          "term": "atomic",
          "tier": 2,
          "reasoning": "Technical value indicating entire field replacement during merge operations."
        },
        {
          "term": "set",
          "tier": 2,
          "reasoning": "Technical value for lists containing unique scalar elements."
        },
        {
          "term": "map",
          "tier": 2,
          "reasoning": "Technical value for lists of nested types with unique keys."
        },
        {
          "term": "granular",
          "tier": 2,
          "reasoning": "Technical value indicating individual field updates are supported."
        },
        {
          "term": "listMapKey",
          "tier": 2,
          "reasoning": "Technical concept for fields that uniquely identify list entries."
        },
        {
          "term": "scalar",
          "tier": 3,
          "reasoning": "Technical term for simple value types (strings, numbers) as opposed to complex types."
        },
        {
          "term": "manager",
          "tier": 2,
          "reasoning": "Domain term for an actor that owns and manages specific fields in an object."
        },
        {
          "term": "Go type",
          "tier": 3,
          "reasoning": "Technical reference to type definitions in the Go programming language."
        },
        {
          "term": "nested types",
          "tier": 2,
          "reasoning": "Technical term for complex types contained within other types."
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term for individual properties within Kubernetes objects."
        },
        {
          "term": "request body",
          "tier": 3,
          "reasoning": "Technical term for the payload sent in an API request."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "Technical term for an API URL that accepts requests."
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:30:03.053718",
      "elapsed_time": 21.359982013702393
    },
    {
      "chunk_id": "tasks_administer-cluster_kubelet-in-userns_sec6",
      "doc_id": "tasks_administer-cluster_kubelet-in-userns",
      "heading": "(unless you run another systemd in the namespace)",
      "source_file": "tasks_administer-cluster_kubelet-in-userns.md",
      "content": "SystemdCgroup = false\n```\n\nThe default path of the configuration file is `/etc/containerd/config.toml`.\nThe path can be specified with `containerd -c /path/to/containerd/config.toml`.\n\n{{% /tab %}}\n{{% tab name=\"CRI-O\" %}}\n\nRunning CRI-O in a user namespace is supported since CRI-O 1.22.\n\nCRI-O requires an environment variable `_CRIO_ROOTLESS=1` to be set.\n\nThe following configurations are also recommended:\n\n```toml\n[crio]\n  storage_driver = \"overlay\"",
      "terms": [
        {
          "term": "SystemdCgroup",
          "tier": 1,
          "reasoning": "Configuration parameter for container runtime cgroup management"
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Core container runtime component used in Kubernetes infrastructure"
        },
        {
          "term": "CRI-O",
          "tier": 1,
          "reasoning": "Container Runtime Interface implementation, a core Kubernetes container runtime"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Technical concept referring to system configuration storage"
        },
        {
          "term": "config.toml",
          "tier": 1,
          "reasoning": "Specific configuration file name for containerd runtime"
        },
        {
          "term": "/etc/containerd/config.toml",
          "tier": 1,
          "reasoning": "Specific filesystem path for containerd configuration"
        },
        {
          "term": "user namespace",
          "tier": 2,
          "reasoning": "Linux kernel isolation feature used for rootless container operation"
        },
        {
          "term": "environment variable",
          "tier": 2,
          "reasoning": "Technical concept for passing configuration to processes"
        },
        {
          "term": "_CRIO_ROOTLESS",
          "tier": 1,
          "reasoning": "Specific environment variable required for CRI-O rootless operation"
        },
        {
          "term": "storage_driver",
          "tier": 2,
          "reasoning": "Configuration parameter specifying container storage backend"
        },
        {
          "term": "overlay",
          "tier": 2,
          "reasoning": "Storage driver type using overlay filesystem for containers"
        },
        {
          "term": "rootless",
          "tier": 2,
          "reasoning": "Security concept for running containers without root privileges"
        },
        {
          "term": "toml",
          "tier": 3,
          "reasoning": "Configuration file format used by container runtimes"
        },
        {
          "term": "crio",
          "tier": 1,
          "reasoning": "Configuration section name for CRI-O settings"
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Filesystem path concept relevant to configuration location"
        },
        {
          "term": "containerd -c",
          "tier": 1,
          "reasoning": "CLI command with flag for specifying configuration file path"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:30:14.285902",
      "elapsed_time": 10.221590995788574
    },
    {
      "chunk_id": "reference_access-authn-authz_kubelet-authn-authz_sec0",
      "doc_id": "reference_access-authn-authz_kubelet-authn-authz",
      "heading": "Overview",
      "source_file": "reference_access-authn-authz_kubelet-authn-authz.md",
      "content": "A kubelet's HTTPS endpoint exposes APIs which give access to data of varying sensitivity,\nand allow you to perform operations with varying levels of power on the node and within containers.\n\nThis document describes how to authenticate and authorize access to the kubelet's HTTPS endpoint.",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages containers."
        },
        {
          "term": "HTTPS endpoint",
          "tier": 2,
          "reasoning": "Technical concept describing the secure API access point exposed by the kubelet."
        },
        {
          "term": "HTTPS",
          "tier": 3,
          "reasoning": "Protocol standard for secure HTTP communication used by the kubelet's endpoint."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "Technical networking term referring to an accessible API interface."
        },
        {
          "term": "APIs",
          "tier": 2,
          "reasoning": "Application Programming Interfaces exposed by the kubelet for programmatic access."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to a worker machine in the cluster."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core domain concept for isolated runtime environments managed by Kubernetes."
        },
        {
          "term": "authenticate",
          "tier": 2,
          "reasoning": "Security process concept for verifying identity when accessing the kubelet API."
        },
        {
          "term": "authorize",
          "tier": 2,
          "reasoning": "Security process concept for determining permissions for kubelet API operations."
        },
        {
          "term": "access",
          "tier": 3,
          "reasoning": "Technical term in security context referring to the ability to interact with the kubelet API."
        },
        {
          "term": "data",
          "tier": 3,
          "reasoning": "Technical term referring to information exposed through the kubelet's APIs."
        },
        {
          "term": "sensitivity",
          "tier": 3,
          "reasoning": "Security-related term describing the classification level of data exposed by APIs."
        },
        {
          "term": "operations",
          "tier": 3,
          "reasoning": "Technical term referring to actions that can be performed via the kubelet API."
        }
      ],
      "term_count": 13,
      "generated_at": "2026-02-08T21:30:25.172191",
      "elapsed_time": 9.876008033752441
    }
  ]
}