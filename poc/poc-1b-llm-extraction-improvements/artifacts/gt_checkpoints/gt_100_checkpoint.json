{
  "metadata": {
    "started_at": "2026-02-08T21:52:09.097981",
    "random_seed": 42,
    "target_chunks": 100,
    "model": "claude-opus-4-5-20251101",
    "total_cost_usd": 7.335315,
    "last_saved": "2026-02-08T22:15:26.757121"
  },
  "completed_chunks": [
    {
      "chunk_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions_sec0",
      "doc_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions",
      "heading": "Introduction",
      "source_file": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions.md",
      "content": "---\ntitle: Extend the Kubernetes API with CustomResourceDefinitions\nreviewers:\n- deads2k\n- jpbetz\n- liggitt\n- roycaihw\n- sttts\ncontent_type: task\nmin-kubernetes-server-version: 1.16\nweight: 20\n---\n\n<!-- overview -->\nThis page shows how to install a\n[custom resource](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\ninto the Kubernetes API by creating a\n[CustomResourceDefinition](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#customresourcedefinition-v1-apiextensions-k8s-io).",
      "terms": [
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core Kubernetes component that serves as the primary interface for cluster operations and resource management."
        },
        {
          "term": "CustomResourceDefinitions",
          "tier": 1,
          "reasoning": "Named Kubernetes API object used to extend the API with custom resources."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Singular form of the API object for defining custom resources in Kubernetes."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Domain concept referring to user-defined extensions to the Kubernetes API."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually important for Kubernetes extension."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform that is the subject of this documentation."
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Domain concept referring to the mechanism for extending Kubernetes API capabilities."
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the generated Kubernetes API documentation and specification."
        },
        {
          "term": "apiextensions-k8s-io",
          "tier": 1,
          "reasoning": "API group name for Kubernetes API extensions, specifically for CustomResourceDefinitions."
        },
        {
          "term": "v1",
          "tier": 2,
          "reasoning": "API version indicator representing a stable/GA API version in Kubernetes."
        },
        {
          "term": "kubernetes-server-version",
          "tier": 2,
          "reasoning": "Technical concept referring to the minimum required Kubernetes server version for compatibility."
        },
        {
          "term": "1.16",
          "tier": 3,
          "reasoning": "Specific Kubernetes version number indicating minimum compatibility requirement."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:52:17.770996",
      "elapsed_time": 8.672800064086914
    },
    {
      "chunk_id": "concepts_workloads_management_sec10",
      "doc_id": "concepts_workloads_management",
      "heading": "In-place updates of resources",
      "source_file": "concepts_workloads_management.md",
      "content": "Sometimes it's necessary to make narrow, non-disruptive updates to resources you've created.\n\n### kubectl apply\n\nIt is suggested to maintain a set of configuration files in source control\n(see [configuration as code](https://martinfowler.com/bliki/InfrastructureAsCode.html)),\nso that they can be maintained and versioned along with the code for the resources they configure.\nThen, you can use [`kubectl apply`](/docs/reference/kubectl/generated/kubectl_apply/)\nto push your configuration changes to the cluster.\n\nThis command will compare the version of the configuration that you're pushing with the previous\nversion and apply the changes you've made, without overwriting any automated changes to properties\nyou haven't specified.\n\n```shell\nkubectl apply -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml\n```\n\n```none\ndeployment.apps/my-nginx configured\n```\n\nTo learn more about the underlying mechanism, read [server-side apply](/docs/reference/using-api/server-side-apply/).\n\n### kubectl edit\n\nAlternatively, you may also update resources with [`kubectl edit`](/docs/reference/kubectl/generated/kubectl_edit/):\n\n```shell\nkubectl edit deployment/my-nginx\n```\n\nThis is equivalent to first `get` the resource, edit it in text editor, and then `apply` the\nresource with the updated version:\n\n```shell\nkubectl get deployment my-nginx -o yaml > /tmp/nginx.yaml\nvi /tmp/nginx.yaml",
      "terms": [
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for applying configuration changes to cluster resources."
        },
        {
          "term": "kubectl edit",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for editing resources directly."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line tool referenced throughout the documentation."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object/resource type shown in examples (deployment.apps/my-nginx, deployment/my-nginx)."
        },
        {
          "term": "my-nginx",
          "tier": 1,
          "reasoning": "Specific named deployment resource used in the examples."
        },
        {
          "term": "nginx-deployment.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file name referenced in the kubectl apply example."
        },
        {
          "term": "deployment.apps",
          "tier": 1,
          "reasoning": "Kubernetes API group and resource type shown in command output."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes objects that can be created and managed."
        },
        {
          "term": "configuration files",
          "tier": 2,
          "reasoning": "Technical concept for files containing resource definitions and settings."
        },
        {
          "term": "source control",
          "tier": 2,
          "reasoning": "Technical concept for version control systems used to manage configuration."
        },
        {
          "term": "configuration as code",
          "tier": 2,
          "reasoning": "Infrastructure/DevOps concept explicitly referenced with link to Martin Fowler's definition."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "configuration changes",
          "tier": 2,
          "reasoning": "Technical concept describing modifications to resource definitions."
        },
        {
          "term": "server-side apply",
          "tier": 2,
          "reasoning": "Kubernetes-specific mechanism for applying configuration changes mentioned as underlying mechanism."
        },
        {
          "term": "automated changes",
          "tier": 2,
          "reasoning": "Technical concept referring to system-generated modifications to resource properties."
        },
        {
          "term": "properties",
          "tier": 2,
          "reasoning": "Technical term for attributes/fields of Kubernetes resources."
        },
        {
          "term": "text editor",
          "tier": 3,
          "reasoning": "General technical tool referenced in the kubectl edit workflow."
        },
        {
          "term": "yaml",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes configuration files, shown in -o yaml flag."
        },
        {
          "term": "get",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for retrieving resource information."
        },
        {
          "term": "apply",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for applying configuration, used both as command and concept."
        },
        {
          "term": "-o yaml",
          "tier": 2,
          "reasoning": "kubectl output format flag for YAML serialization."
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Technical concept referring to configuration versions being compared during apply."
        },
        {
          "term": "versioned",
          "tier": 3,
          "reasoning": "Technical concept about maintaining version history of configurations."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Technical context indicator for command-line examples."
        },
        {
          "term": "configured",
          "tier": 2,
          "reasoning": "Kubernetes command output status indicating successful configuration update."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:52:32.539071",
      "elapsed_time": 13.76734185218811
    },
    {
      "chunk_id": "concepts_extend-kubernetes_operator_sec7",
      "doc_id": "concepts_extend-kubernetes_operator",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "concepts_extend-kubernetes_operator.md",
      "content": "* Read the {{< glossary_tooltip text=\"CNCF\" term_id=\"cncf\" >}}\n  [Operator White Paper](https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md).\n* Learn more about [Custom Resources](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\n* Find ready-made operators on [OperatorHub.io](https://operatorhub.io/) to suit your use case\n* [Publish](https://operatorhub.io/) your operator for other people to use\n* Read [CoreOS' original article](https://web.archive.org/web/20170129131616/https://coreos.com/blog/introducing-operators.html)\n  that introduced the operator pattern (this is an archived version of the original article).\n* Read an [article](https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps)\n  from Google Cloud about best practices for building operators",
      "terms": [
        {
          "term": "CNCF",
          "tier": 1,
          "reasoning": "Cloud Native Computing Foundation - a specific organization and proper noun in the cloud-native ecosystem"
        },
        {
          "term": "Operator",
          "tier": 1,
          "reasoning": "A Kubernetes-specific pattern and resource type for managing applications"
        },
        {
          "term": "operator",
          "tier": 1,
          "reasoning": "Appears in lowercase form throughout the text referring to the Kubernetes operator pattern"
        },
        {
          "term": "operators",
          "tier": 1,
          "reasoning": "Plural form of operator, referring to multiple Kubernetes operator implementations"
        },
        {
          "term": "Custom Resources",
          "tier": 1,
          "reasoning": "A specific Kubernetes API extension mechanism for defining custom API objects"
        },
        {
          "term": "OperatorHub.io",
          "tier": 1,
          "reasoning": "A specific platform/registry for discovering and publishing Kubernetes operators"
        },
        {
          "term": "Operator White Paper",
          "tier": 2,
          "reasoning": "A specific technical document defining the operator pattern standards"
        },
        {
          "term": "operator pattern",
          "tier": 2,
          "reasoning": "A Kubernetes architectural pattern for automating application management"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the core subject of this documentation"
        },
        {
          "term": "stateful apps",
          "tier": 2,
          "reasoning": "Applications that maintain persistent state, a key concept in Kubernetes application management"
        },
        {
          "term": "CoreOS",
          "tier": 1,
          "reasoning": "The company that originally introduced the operator pattern, a proper noun"
        },
        {
          "term": "Google Cloud",
          "tier": 1,
          "reasoning": "A specific cloud provider mentioned as source of best practices"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Fundamental virtualization technology that Kubernetes orchestrates"
        },
        {
          "term": "best practices",
          "tier": 3,
          "reasoning": "Technical guidance term used in the context of building operators"
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in the context of extending Kubernetes APIs"
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Kubernetes concept for extending the API server with custom resources"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:52:42.960362",
      "elapsed_time": 9.420279741287231
    },
    {
      "chunk_id": "reference_glossary_sysctl_sec0",
      "doc_id": "reference_glossary_sysctl",
      "heading": "Introduction",
      "source_file": "reference_glossary_sysctl.md",
      "content": "---\ntitle: sysctl\nid: sysctl\ndate: 2019-02-12\nfull_link: /docs/tasks/administer-cluster/sysctl-cluster/\nshort_description: >\n  An interface for getting and setting Unix kernel parameters\n\naka:\ntags:\n- tool\n---\n `sysctl` is a semi-standardized interface for reading or changing the\n attributes of the running Unix kernel.\n\n<!--more-->\n\nOn Unix-like systems, `sysctl` is both the name of the tool that administrators\nuse to view and modify these settings, and also the system call that the tool\nuses.\n\n{{< glossary_tooltip text=\"Container\" term_id=\"container\" >}} runtimes and\nnetwork plugins may rely on `sysctl` values being set a certain way.",
      "terms": [
        {
          "term": "sysctl",
          "tier": 1,
          "reasoning": "Named Unix tool and system call for kernel parameter management, the primary subject of this documentation."
        },
        {
          "term": "Unix kernel",
          "tier": 2,
          "reasoning": "Core operating system component whose parameters sysctl manages."
        },
        {
          "term": "kernel parameters",
          "tier": 2,
          "reasoning": "Technical concept referring to configurable settings of the Unix kernel."
        },
        {
          "term": "Unix kernel parameters",
          "tier": 2,
          "reasoning": "Compound term describing the specific settings that sysctl reads and modifies."
        },
        {
          "term": "Unix-like systems",
          "tier": 3,
          "reasoning": "Category of operating systems where sysctl operates."
        },
        {
          "term": "system call",
          "tier": 2,
          "reasoning": "Technical concept describing the programmatic interface sysctl uses to interact with the kernel."
        },
        {
          "term": "Container",
          "tier": 2,
          "reasoning": "Core Kubernetes/infrastructure concept; container runtimes depend on sysctl values."
        },
        {
          "term": "network plugins",
          "tier": 2,
          "reasoning": "Infrastructure components that handle networking and may depend on sysctl values."
        },
        {
          "term": "interface",
          "tier": 3,
          "reasoning": "Technical term describing sysctl's role as a standardized access method."
        },
        {
          "term": "attributes",
          "tier": 3,
          "reasoning": "Technical term referring to the kernel properties that can be viewed or modified."
        },
        {
          "term": "running",
          "tier": 3,
          "reasoning": "Technical context indicating the kernel is active/executing when sysctl operates on it."
        },
        {
          "term": "tool",
          "tier": 3,
          "reasoning": "Explicitly tagged as a tool in the metadata; describes sysctl's classification."
        },
        {
          "term": "administrators",
          "tier": 3,
          "reasoning": "Role term describing users who interact with sysctl to manage systems."
        }
      ],
      "term_count": 13,
      "generated_at": "2026-02-08T21:52:54.236888",
      "elapsed_time": 10.275332927703857
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec18",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`TCPTransport`     {#apiserver-k8s-io-v1beta1-TCPTransport}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [Transport](#apiserver-k8s-io-v1beta1-Transport)\n\n\n<p>TCPTransport provides the information to connect to konnectivity server via TCP</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>URL is the location of the konnectivity server to connect to.\nAs an example it might be &quot;https://127.0.0.1:8131&quot;</p>\n</td>\n</tr>\n<tr><td><code>tlsConfig</code><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-TLSConfig\"><code>TLSConfig</code></a>\n</td>\n<td>\n   <p>TLSConfig is the config needed to use TLS when connecting to konnectivity server</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Transport",
          "tier": 1,
          "reasoning": "Kubernetes API object type referenced in the documentation for network transport configuration."
        },
        {
          "term": "TCPTransport",
          "tier": 1,
          "reasoning": "Specific Kubernetes API resource type that provides TCP connection configuration to konnectivity server."
        },
        {
          "term": "konnectivity server",
          "tier": 1,
          "reasoning": "Named Kubernetes infrastructure component for network connectivity between control plane and nodes."
        },
        {
          "term": "TLSConfig",
          "tier": 1,
          "reasoning": "Kubernetes API object type for TLS configuration settings."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-Transport",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the Transport resource."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-TLSConfig",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the TLSConfig resource."
        },
        {
          "term": "TCP",
          "tier": 2,
          "reasoning": "Network protocol used for transport layer communication to konnectivity server."
        },
        {
          "term": "TLS",
          "tier": 2,
          "reasoning": "Transport Layer Security protocol for encrypted connections to konnectivity server."
        },
        {
          "term": "url",
          "tier": 3,
          "reasoning": "Configuration field specifying the location/address of the konnectivity server."
        },
        {
          "term": "tlsConfig",
          "tier": 2,
          "reasoning": "Configuration field name for TLS settings in the TCPTransport specification."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "API version indicating beta maturity level of the Kubernetes API."
        },
        {
          "term": "apiserver",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API server component in the API group naming."
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Protocol shown in the example URL for secure connection to konnectivity server."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing configuration parameters in the API object specification."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the url field in the API object."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:53:03.889797",
      "elapsed_time": 8.651746273040771
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec24",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`UserValidationRule`     {#apiserver-config-k8s-io-v1-UserValidationRule}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>UserValidationRule provides the configuration for a single user info validation rule.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>expression</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>expression represents the expression which will be evaluated by CEL.\nMust return true for the validation to pass.</p>\n<p>CEL expressions have access to the contents of UserInfo, organized into CEL variable:</p>\n<ul>\n<li>'user' - authentication.k8s.io/v1, Kind=UserInfo object\nRefer to https://github.com/kubernetes/api/blob/release-1.28/authentication/v1/types.go#L105-L122 for the definition.\nAPI documentation: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#userinfo-v1-authentication-k8s-io</li>\n</ul>\n<p>Documentation on CEL: https://kubernetes.io/docs/reference/using-api/cel/</p>\n</td>\n</tr>\n<tr><td><code>message</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>message customizes the returned error message when rule returns false.\nmessage is a literal string.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration."
        },
        {
          "term": "UserValidationRule",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration object for user info validation rules."
        },
        {
          "term": "UserInfo",
          "tier": 1,
          "reasoning": "Named Kubernetes API object (authentication.k8s.io/v1, Kind=UserInfo) containing user information."
        },
        {
          "term": "CEL",
          "tier": 2,
          "reasoning": "Common Expression Language - a domain-specific expression language used for validation in Kubernetes."
        },
        {
          "term": "expression",
          "tier": 2,
          "reasoning": "Technical field name representing the CEL expression to be evaluated for validation."
        },
        {
          "term": "validation",
          "tier": 2,
          "reasoning": "Domain concept referring to the process of verifying user information meets specified rules."
        },
        {
          "term": "CEL variable",
          "tier": 2,
          "reasoning": "Technical concept referring to variables accessible within CEL expressions."
        },
        {
          "term": "CEL expressions",
          "tier": 2,
          "reasoning": "Technical term for expressions written in Common Expression Language for evaluation."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Core security concept for verifying user identity in Kubernetes."
        },
        {
          "term": "authentication.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for authentication-related resources."
        },
        {
          "term": "user",
          "tier": 2,
          "reasoning": "CEL variable name providing access to UserInfo object in validation expressions."
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Technical field name for customizing error messages when validation fails."
        },
        {
          "term": "error message",
          "tier": 3,
          "reasoning": "Technical term for the message returned when validation rule returns false."
        },
        {
          "term": "literal string",
          "tier": 3,
          "reasoning": "Technical term describing the type of value the message field accepts."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - referenced in context of Kubernetes API documentation."
        },
        {
          "term": "kubernetes-api",
          "tier": 2,
          "reasoning": "Referenced as part of documentation URL for Kubernetes API specifications."
        },
        {
          "term": "v1.28",
          "tier": 2,
          "reasoning": "Specific Kubernetes version referenced for API definitions."
        },
        {
          "term": "release-1.28",
          "tier": 2,
          "reasoning": "Specific Kubernetes release version referenced for source code."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the expression and message fields."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term referring to configuration fields in the API object specification."
        },
        {
          "term": "rule",
          "tier": 2,
          "reasoning": "Domain concept referring to a single validation condition to be evaluated."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical term for the settings and parameters of the validation rule."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API group reference for API server configuration objects."
        }
      ],
      "term_count": 23,
      "generated_at": "2026-02-08T21:53:19.982247",
      "elapsed_time": 15.091115951538086
    },
    {
      "chunk_id": "reference_access-authn-authz_validating-admission-policy_sec0",
      "doc_id": "reference_access-authn-authz_validating-admission-policy",
      "heading": "Introduction",
      "source_file": "reference_access-authn-authz_validating-admission-policy.md",
      "content": "---\nreviewers:\n- liggitt\n- jpbetz\n- cici37\ntitle: Validating Admission Policy\ncontent_type: concept\n---\n\n<!-- overview -->\n\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.30\" >}}\n\nThis page provides an overview of Validating Admission Policy.\n\n\n<!-- body -->",
      "terms": [
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource and the primary subject of this documentation page."
        },
        {
          "term": "Admission Policy",
          "tier": 2,
          "reasoning": "Domain concept referring to policies that control admission of resources to the cluster."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating the feature has reached production-ready status in Kubernetes."
        },
        {
          "term": "v1.30",
          "tier": 3,
          "reasoning": "Specific Kubernetes version identifier indicating when the feature became stable."
        },
        {
          "term": "feature-state",
          "tier": 3,
          "reasoning": "Kubernetes documentation concept indicating the maturity level of a feature."
        }
      ],
      "term_count": 5,
      "generated_at": "2026-02-08T21:53:25.410278",
      "elapsed_time": 4.42641282081604
    },
    {
      "chunk_id": "concepts_workloads_management_sec0",
      "doc_id": "concepts_workloads_management",
      "heading": "Introduction",
      "source_file": "concepts_workloads_management.md",
      "content": "---\ntitle: Managing Workloads\ncontent_type: concept\nreviewers:\n- janetkuo\nweight: 40\n---\n\n<!-- overview -->\n\nYou've deployed your application and exposed it via a Service. Now what? Kubernetes provides a\nnumber of tools to help you manage your application deployment, including scaling and updating.\n\n<!-- body -->",
      "terms": [
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to applications running on the cluster, appears in title."
        },
        {
          "term": "application",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context referring to deployed software workloads."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource for exposing applications, capitalized indicating the K8s resource type."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary platform/system being documented, proper noun."
        },
        {
          "term": "application deployment",
          "tier": 2,
          "reasoning": "Domain concept describing the process of deploying applications to Kubernetes."
        },
        {
          "term": "scaling",
          "tier": 2,
          "reasoning": "Core Kubernetes operational concept for adjusting application capacity."
        },
        {
          "term": "updating",
          "tier": 2,
          "reasoning": "Technical process in Kubernetes for modifying deployed applications."
        },
        {
          "term": "deployed",
          "tier": 2,
          "reasoning": "Technical term describing the state of an application running in Kubernetes."
        },
        {
          "term": "exposed",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context meaning making a service accessible via networking."
        },
        {
          "term": "Managing Workloads",
          "tier": 2,
          "reasoning": "Compound concept representing the operational practice of administering Kubernetes workloads."
        }
      ],
      "term_count": 10,
      "generated_at": "2026-02-08T21:53:33.539238",
      "elapsed_time": 7.126946926116943
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "How apply calculates differences and merges changes",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "{{< caution >}}\nA *patch* is an update operation that is scoped to specific fields of an object\ninstead of the entire object. This enables updating only a specific set of fields\non an object without reading the object first.\n{{< /caution >}}\n\nWhen `kubectl apply` updates the live configuration for an object,\nit does so by sending a patch request to the API server. The\npatch defines updates scoped to specific fields of the live object\nconfiguration. The `kubectl apply` command calculates this patch request\nusing the configuration file, the live configuration, and the\n`last-applied-configuration` annotation stored in the live configuration.\n\n### Merge patch calculation\n\nThe `kubectl apply` command writes the contents of the configuration file to the\n`kubectl.kubernetes.io/last-applied-configuration` annotation. This\nis used to identify fields that have been removed from the configuration\nfile and need to be cleared from the live configuration. Here are the steps used\nto calculate which fields should be deleted or set:\n\n1. Calculate the fields to delete. These are the fields present in\n   `last-applied-configuration` and missing from the configuration file.\n2. Calculate the fields to add or set. These are the fields present in\n   the configuration file whose values don't match the live configuration.\n\nHere's an example. Suppose this is the configuration file for a Deployment object:\n\n{{% code_sample file=\"application/update_deployment.yaml\" %}}\n\nAlso, suppose this is the live configuration for the same Deployment object:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # note that the annotation does not contain replicas\n    # because it was not updated through apply\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"minReadySeconds\":5,\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.14.2\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n  # ...\nspec:\n  replicas: 2 # written by scale\n  # ...\n  minReadySeconds: 5\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n      # ...\n```\n\nHere are the merge calculations that would be performed by `kubectl apply`:\n\n1. Calculate the fields to delete by reading values from\n   `last-applied-configuration` and comparing them to values in the\n   configuration file.\n   Clear fields explicitly set to null in the local object configuration file\n   regardless of whether they appear in the `last-applied-configuration`.\n   In this example, `minReadySeconds` appears in the\n   `last-applied-configuration` annotation, but does not appear in the configuration file.\n   **Action:** Clear `minReadySeconds` from the live configuration.\n2. Calculate the fields to set by reading values from the configuration\n   file and comparing them to values in the live configuration. In this example,\n   the value of `image` in the configuration file does not match\n   the value in the live configuration. **Action:** Set the value of `image` in the live configuration.\n3. Set the `last-applied-configuration` annotation to match the value\n   of the configuration file.\n4. Merge the results from 1, 2, 3 into a single patch request to the API server.\n\nHere is the live configuration that is the result of the merge:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # The annotation contains the updated image to nginx 1.16.1,\n    # but does not contain the updated replicas to 2\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.16.1\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n    # ...\nspec:\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  replicas: 2 # Set by `kubectl scale`.  Ignored by `kubectl apply`.\n  # minReadySeconds cleared by `kubectl apply`\n  # ...\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.16.1 # Set by `kubectl apply`\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n        # ...\n      # ...\n    # ...\n  # ...\n```\n\n### How different types of fields are merged\n\nHow a particular field in a configuration file is merged with\nthe live configuration depends on the\ntype of the field. There are several types of fields:\n\n- *primitive*: A field of type string, integer, or boolean.\n  For example, `image` and `replicas` are primitive fields. **Action:** Replace.\n\n- *map*, also called *object*: A field of type map or a complex type that contains subfields. For example, `labels`,\n  `annotations`,`spec` and `metadata` are all maps. **Action:** Merge elements or subfields.\n\n- *list*: A field containing a list of items that can be either primitive types or maps.\n  For example, `containers`, `ports`, and `args` are lists. **Action:** Varies.\n\nWhen `kubectl apply` updates a map or list field, it typically does\nnot replace the entire field, but instead updates the individual subelements.\nFor instance, when merging the `spec` on a Deployment, the entire `spec` is\nnot replaced. Instead the subfields of `spec`, such as `replicas`, are compared\nand merged.\n\n### Merging changes to primitive fields\n\nPrimitive fields are replaced or cleared.\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Field in object configuration file  | Field in live object configuration | Field in last-applied-configuration | Action                                    |\n|-------------------------------------|------------------------------------|-------------------------------------|-------------------------------------------|\n| Yes                                 | Yes                                | -                                   | Set live to configuration file value.  |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.           |\n| No                                  | -                                  | Yes                                 | Clear from live configuration.            |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.             |\n\n### Merging changes to map fields\n\nFields that represent maps are merged by comparing each of the subfields or elements of the map:\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Key in object configuration file    | Key in live object configuration   | Field in last-applied-configuration | Action                           |\n|-------------------------------------|------------------------------------|-------------------------------------|----------------------------------|\n| Yes                                 | Yes                                | -                                   | Compare sub fields values.        |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.  |\n| No                                  | -                                  | Yes                                 | Delete from live configuration.   |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.     |\n\n### Merging changes for fields of type list\n\nMerging changes to a list uses one of three strategies:\n\n* Replace the list if all its elements are primitives.\n* Merge individual elements in a list of complex elements.\n* Merge a list of primitive elements.\n\nThe choice of strategy is made on a per-field basis.\n\n#### Replace the list if all its elements are primitives\n\nTreat the list the same as a primitive field. Replace or delete the\nentire list. This preserves ordering.\n\n**Example:** Use `kubectl apply` to update the `args` field of a Container in a Pod. This sets\nthe value of `args` in the live configuration to the value in the configuration file.\nAny `args` elements that had previously been added to the live configuration are lost.\nThe order of the `args` elements defined in the configuration file is\nretained in the live configuration.\n\n```yaml",
      "terms": [
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Core technical concept describing an update operation scoped to specific fields of an object"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes API objects that can be created and managed"
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for declarative configuration management"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters"
        },
        {
          "term": "live configuration",
          "tier": 2,
          "reasoning": "Domain concept referring to the current state of an object in the cluster"
        },
        {
          "term": "patch request",
          "tier": 2,
          "reasoning": "Technical process describing the API request type sent to update objects"
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes component that exposes the Kubernetes API"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Domain concept for the declarative specification file used with kubectl apply"
        },
        {
          "term": "last-applied-configuration",
          "tier": 1,
          "reasoning": "Specific annotation name used to track previous configuration state"
        },
        {
          "term": "kubectl.kubernetes.io/last-applied-configuration",
          "tier": 1,
          "reasoning": "Full annotation key used by kubectl apply to store configuration history"
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching arbitrary non-identifying metadata to objects"
        },
        {
          "term": "Merge patch calculation",
          "tier": 2,
          "reasoning": "Specific technical process for calculating differences between configurations"
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing stateless applications"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the object"
        },
        {
          "term": "apps/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for apps resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the type of resource"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes object section containing identifying information"
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata field for non-identifying key-value pairs"
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Kubernetes metadata field for the unique identifier within a namespace"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for logical partitioning of cluster resources"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "The default Kubernetes namespace used when none is specified"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes object section defining the desired state"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment spec field controlling the number of pod instances"
        },
        {
          "term": "minReadySeconds",
          "tier": 2,
          "reasoning": "Deployment spec field for minimum seconds a pod must be ready"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for selecting pods based on labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Selector field for exact label matching"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within a Deployment"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for identifying and selecting objects"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod spec field listing container specifications"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container spec field specifying the container image to run"
        },
        {
          "term": "nginx:1.14.2",
          "tier": 3,
          "reasoning": "Specific container image version used in the example"
        },
        {
          "term": "nginx:1.16.1",
          "tier": 3,
          "reasoning": "Updated container image version shown in the merge result"
        },
        {
          "term": "nginx",
          "tier": 3,
          "reasoning": "Container name and application used in the example"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Container spec field for exposing container ports"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Port specification field for container network ports"
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes operation for adjusting replica count"
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific Deployment resource name used in the example"
        },
        {
          "term": "app",
          "tier": 2,
          "reasoning": "Common label key used for application identification"
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term for specific properties within Kubernetes objects"
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T21:53:54.876026",
      "elapsed_time": 20.334879875183105
    },
    {
      "chunk_id": "tasks_administer-cluster_topology-manager_sec3",
      "doc_id": "tasks_administer-cluster_topology-manager",
      "heading": "Topology manager scopes and policies",
      "source_file": "tasks_administer-cluster_topology-manager.md",
      "content": "The Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
      "terms": [
        {
          "term": "Topology Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for resource alignment across NUMA nodes."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object and workload unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the fundamental Kubernetes workload unit, referenced in 'pod' scope."
        },
        {
          "term": "QoS classes",
          "tier": 2,
          "reasoning": "Quality of Service classification system for Pods in Kubernetes."
        },
        {
          "term": "Hint Provider",
          "tier": 1,
          "reasoning": "Named component that provides topology hints for resource alignment."
        },
        {
          "term": "topology hints",
          "tier": 2,
          "reasoning": "Domain concept describing hints used for NUMA-aware resource placement."
        },
        {
          "term": "scope",
          "tier": 2,
          "reasoning": "Configuration option defining granularity of resource alignment in Topology Manager."
        },
        {
          "term": "policy",
          "tier": 2,
          "reasoning": "Configuration option defining the alignment strategy used by Topology Manager."
        },
        {
          "term": "resource alignment",
          "tier": 2,
          "reasoning": "Technical process of aligning resources across topology domains."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing the unit of compute within a Pod."
        },
        {
          "term": "best-effort",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for resource alignment."
        },
        {
          "term": "restricted",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for stricter resource alignment."
        },
        {
          "term": "single-numa-node",
          "tier": 2,
          "reasoning": "Named Topology Manager policy requiring all resources on a single NUMA node."
        },
        {
          "term": "CPU resources",
          "tier": 2,
          "reasoning": "Technical term for compute resources managed by CPU Manager."
        },
        {
          "term": "CPU Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for CPU resource management on nodes."
        },
        {
          "term": "CPU Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for CPU Manager behavior."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "CPU Management Policies",
          "tier": 2,
          "reasoning": "Domain concept for policies controlling CPU allocation on nodes."
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "System resource type managed by Memory Manager."
        },
        {
          "term": "hugepages",
          "tier": 2,
          "reasoning": "Linux memory feature for large memory pages, managed by Memory Manager."
        },
        {
          "term": "Memory Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for memory resource management on nodes."
        },
        {
          "term": "Memory Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for Memory Manager behavior."
        },
        {
          "term": "Pod spec",
          "tier": 2,
          "reasoning": "Technical term for the specification section of a Pod definition."
        },
        {
          "term": "requested resources",
          "tier": 2,
          "reasoning": "Domain concept for resources explicitly requested in Pod specifications."
        },
        {
          "term": "scopes",
          "tier": 2,
          "reasoning": "Plural form referring to available Topology Manager scope options."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Plural form referring to available Topology Manager policy options."
        },
        {
          "term": "Control CPU Management Policies on the Node",
          "tier": 2,
          "reasoning": "Referenced documentation topic for CPU management configuration."
        },
        {
          "term": "administer-cluster",
          "tier": 3,
          "reasoning": "Documentation path segment indicating cluster administration tasks."
        }
      ],
      "term_count": 28,
      "generated_at": "2026-02-08T21:54:09.885159",
      "elapsed_time": 14.007121801376343
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec1",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Terminology",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "For clarity, this guide defines the following terms:\n\n* Node: A worker machine in Kubernetes, part of a cluster.\n* Cluster: A set of Nodes that run containerized applications managed by Kubernetes.\n  For this example, and in most common Kubernetes deployments, nodes in the cluster\n  are not part of the public internet.\n* Edge router: A router that enforces the firewall policy for your cluster. This\n  could be a gateway managed by a cloud provider or a physical piece of hardware.\n* Cluster network: A set of links, logical or physical, that facilitate communication\n  within a cluster according to the Kubernetes [networking model](/docs/concepts/cluster-administration/networking/).\n* Service: A Kubernetes {{< glossary_tooltip term_id=\"service\" >}} that identifies\n  a set of Pods using {{< glossary_tooltip text=\"label\" term_id=\"label\" >}} selectors.\n  Unless mentioned otherwise, Services are assumed to have virtual IPs only routable within the cluster network.",
      "terms": [
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Core Kubernetes resource representing a worker machine in the cluster."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "containerized applications",
          "tier": 2,
          "reasoning": "Domain concept describing applications packaged in containers."
        },
        {
          "term": "Edge router",
          "tier": 2,
          "reasoning": "Network infrastructure component that enforces firewall policy at cluster boundary."
        },
        {
          "term": "router",
          "tier": 3,
          "reasoning": "General networking term with specific meaning in cluster context."
        },
        {
          "term": "firewall policy",
          "tier": 2,
          "reasoning": "Security concept governing network traffic rules for the cluster."
        },
        {
          "term": "gateway",
          "tier": 2,
          "reasoning": "Network component that can serve as edge router in cloud deployments."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Infrastructure concept referring to managed cloud services hosting Kubernetes."
        },
        {
          "term": "Cluster network",
          "tier": 2,
          "reasoning": "Kubernetes networking concept describing internal cluster communication infrastructure."
        },
        {
          "term": "networking model",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept defining how network communication works."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that identifies and exposes a set of Pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing the smallest deployable unit."
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes concept for key-value pairs used to organize and select resources."
        },
        {
          "term": "virtual IPs",
          "tier": 2,
          "reasoning": "Networking concept for IP addresses assigned to Services for internal routing."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Infrastructure term describing the compute resources that run workloads."
        },
        {
          "term": "public internet",
          "tier": 3,
          "reasoning": "Networking context term distinguishing external from internal cluster access."
        },
        {
          "term": "hardware",
          "tier": 3,
          "reasoning": "Infrastructure term referring to physical networking equipment."
        },
        {
          "term": "links",
          "tier": 3,
          "reasoning": "Networking term describing connections within cluster network."
        },
        {
          "term": "communication",
          "tier": 3,
          "reasoning": "Technical term describing data exchange within the cluster network context."
        },
        {
          "term": "routable",
          "tier": 3,
          "reasoning": "Networking term describing whether traffic can reach a destination."
        },
        {
          "term": "selectors",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching resources based on criteria."
        },
        {
          "term": "nodes",
          "tier": 1,
          "reasoning": "Plural form of Node, core Kubernetes worker machine resource."
        },
        {
          "term": "cluster network",
          "tier": 2,
          "reasoning": "Lowercase variant appearing in context of Service routing scope."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:54:23.729709",
      "elapsed_time": 12.8415048122406
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec19",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "You might already have removed the next set",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "kubectl delete configmaps/special-config configmaps/env-config\nkubectl delete configmap -l 'game-config in (config-4,config-5)'\n```\n\nRemove the `kustomization.yaml` file that you used to generate the ConfigMap:\n\n```bash\nrm kustomization.yaml\n```\n\nIf you created a directory `configure-pod-container` and no longer need it, you should remove that too,\nor move it into the trash can / deleted files location.\n\n```bash\nrm -r configure-pod-container\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used for cluster management and resource operations."
        },
        {
          "term": "configmaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing non-confidential configuration data as key-value pairs."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API resource referenced in the context of generation and deletion."
        },
        {
          "term": "special-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "env-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "game-config",
          "tier": 1,
          "reasoning": "Named label value used for ConfigMap selection in the delete command."
        },
        {
          "term": "config-4",
          "tier": 1,
          "reasoning": "Specific ConfigMap configuration name used in label selector."
        },
        {
          "term": "config-5",
          "tier": 1,
          "reasoning": "Specific ConfigMap configuration name used in label selector."
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Kustomize configuration file used to generate Kubernetes resources including ConfigMaps."
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation/command for removing resources from the cluster."
        },
        {
          "term": "configure-pod-container",
          "tier": 2,
          "reasoning": "Directory name related to pod and container configuration documentation/examples."
        },
        {
          "term": "-l",
          "tier": 3,
          "reasoning": "kubectl flag for label selector, used to filter resources by labels."
        },
        {
          "term": "rm",
          "tier": 3,
          "reasoning": "Unix/Linux command for removing files, used in cleanup operations."
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Shell environment indicated for executing the cleanup commands."
        },
        {
          "term": "pod",
          "tier": 2,
          "reasoning": "Referenced in directory name 'configure-pod-container', fundamental Kubernetes workload unit."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Referenced in directory name 'configure-pod-container', core concept in Kubernetes."
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:54:33.771879",
      "elapsed_time": 9.039495944976807
    },
    {
      "chunk_id": "reference_node_node-status_sec6",
      "doc_id": "reference_node_node-status",
      "heading": "Declared features {#declaredfeatures}",
      "source_file": "reference_node_node-status.md",
      "content": "{{< feature-state feature_gate_name=\"NodeDeclaredFeatures\" >}}\n\nThis field lists specific Kubernetes features that are currently enabled on the\nnode's kubelet via [feature gates](/docs/reference/command-line-tools-reference/feature-gates/).\nThe features are reported by the kubelet as a list of strings in the\n`.status.declaredFeatures` field of the Node object.\n\nThis field is intended for newer features under active development; features that\nhave graduated and no longer require a feature gate are considered baseline and\nare not declared in this field. This reflects the enablement of Kubernetes\nfeatures, not the underlying operating system or kernel capabilities of the node.\n\nSee [Node Declared Features](/docs/concepts/scheduling-eviction/node-declared-features/)\nfor more details.",
      "terms": [
        {
          "term": "NodeDeclaredFeatures",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature gate name that controls node feature declaration functionality."
        },
        {
          "term": "feature_gate_name",
          "tier": 2,
          "reasoning": "Technical parameter reference for specifying feature gate identifiers in Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform this documentation describes."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine in the cluster."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages pod lifecycle."
        },
        {
          "term": "feature gates",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": "features",
          "tier": 2,
          "reasoning": "Technical term referring to specific Kubernetes capabilities that can be enabled or disabled."
        },
        {
          "term": ".status.declaredFeatures",
          "tier": 1,
          "reasoning": "Specific API field path in the Node object where declared features are reported."
        },
        {
          "term": "Node object",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a node resource in the cluster."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type used to represent the feature list in the API field."
        },
        {
          "term": "field",
          "tier": 3,
          "reasoning": "Technical term for a property within a Kubernetes API object structure."
        },
        {
          "term": "graduated",
          "tier": 2,
          "reasoning": "Kubernetes feature lifecycle term indicating a feature has moved to stable/GA status."
        },
        {
          "term": "baseline",
          "tier": 2,
          "reasoning": "Technical term describing features that are standard and no longer require explicit enablement."
        },
        {
          "term": "operating system",
          "tier": 3,
          "reasoning": "System software concept distinguished from Kubernetes feature enablement."
        },
        {
          "term": "kernel",
          "tier": 3,
          "reasoning": "Core OS component whose capabilities are distinguished from Kubernetes features."
        },
        {
          "term": "Node Declared Features",
          "tier": 1,
          "reasoning": "Named Kubernetes concept/feature for reporting enabled features on nodes."
        },
        {
          "term": "scheduling-eviction",
          "tier": 2,
          "reasoning": "Kubernetes documentation category related to pod scheduling and eviction processes."
        },
        {
          "term": "enablement",
          "tier": 2,
          "reasoning": "Technical process term describing the activation state of Kubernetes features."
        },
        {
          "term": "capabilities",
          "tier": 2,
          "reasoning": "Technical term for functional abilities of a system or component."
        },
        {
          "term": "active development",
          "tier": 2,
          "reasoning": "Feature lifecycle term indicating features still being developed and refined."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T21:54:46.556410",
      "elapsed_time": 11.781420946121216
    },
    {
      "chunk_id": "concepts_policy__index_sec3",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using ValidatingAdmissionPolicy",
      "source_file": "concepts_policy__index.md",
      "content": "Validating admission policies allow configurable validation checks to be executed in the API server using the Common Expression Language (CEL). For example, a `ValidatingAdmissionPolicy` can be used to disallow use of the `latest` image tag.\n\nA `ValidatingAdmissionPolicy` operates on an API request and can be used to block, audit, and warn users about non-compliant configurations.\n\nDetails on the `ValidatingAdmissionPolicy` API, with examples, are documented in a dedicated section:\n* [Validating Admission Policy](/docs/reference/access-authn-authz/validating-admission-policy/)",
      "terms": [
        {
          "term": "ValidatingAdmissionPolicy",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for configurable validation checks in the API server."
        },
        {
          "term": "Validating admission policies",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for admission control validation."
        },
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Proper noun reference to the Kubernetes API resource as it appears in documentation link."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that processes API requests."
        },
        {
          "term": "Common Expression Language",
          "tier": 2,
          "reasoning": "Domain-specific language used for writing validation expressions in Kubernetes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Acronym for Common Expression Language, a technical standard used in validation policies."
        },
        {
          "term": "API request",
          "tier": 2,
          "reasoning": "Technical concept referring to requests made to the Kubernetes API server."
        },
        {
          "term": "validation checks",
          "tier": 2,
          "reasoning": "Domain concept describing the verification process performed by admission policies."
        },
        {
          "term": "configurable validation",
          "tier": 2,
          "reasoning": "Technical concept describing customizable validation behavior."
        },
        {
          "term": "image tag",
          "tier": 2,
          "reasoning": "Container domain concept referring to version identifiers for container images."
        },
        {
          "term": "latest",
          "tier": 2,
          "reasoning": "Specific image tag value with special meaning in container ecosystems, used as example of what to disallow."
        },
        {
          "term": "block",
          "tier": 2,
          "reasoning": "Admission control action that prevents non-compliant configurations."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Admission control action for logging policy violations without blocking."
        },
        {
          "term": "warn",
          "tier": 2,
          "reasoning": "Admission control action that alerts users about non-compliant configurations."
        },
        {
          "term": "non-compliant configurations",
          "tier": 2,
          "reasoning": "Domain concept describing configurations that violate defined policies."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually relevant to Kubernetes."
        },
        {
          "term": "admission",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to the admission control phase of API request processing."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:54:59.104958",
      "elapsed_time": 11.545385837554932
    },
    {
      "chunk_id": "concepts_policy__index_sec1",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using API objects",
      "source_file": "concepts_policy__index.md",
      "content": "Some API objects act as policies. Here are some examples:\n* [NetworkPolicies](/docs/concepts/services-networking/network-policies/) can be used to restrict ingress and egress traffic for a workload.\n* [LimitRanges](/docs/concepts/policy/limit-range/) manage resource allocation constraints across different object kinds.\n* [ResourceQuotas](/docs/concepts/policy/resource-quotas/) limit resource consumption for a {{< glossary_tooltip text=\"namespace\" term_id=\"namespace\" >}}.",
      "terms": [
        {
          "term": "API objects",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the persistent entities in the system that represent cluster state."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Domain concept describing API objects that enforce rules and constraints on cluster behavior."
        },
        {
          "term": "NetworkPolicies",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource that controls network traffic flow for workloads."
        },
        {
          "term": "ingress",
          "tier": 2,
          "reasoning": "Networking concept referring to incoming traffic to a workload or cluster."
        },
        {
          "term": "egress",
          "tier": 2,
          "reasoning": "Networking concept referring to outgoing traffic from a workload or cluster."
        },
        {
          "term": "traffic",
          "tier": 3,
          "reasoning": "Technical networking term describing data flow in the context of network policies."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running on the cluster."
        },
        {
          "term": "LimitRanges",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource that manages resource allocation constraints."
        },
        {
          "term": "resource allocation",
          "tier": 2,
          "reasoning": "Domain concept describing how compute resources are distributed to objects."
        },
        {
          "term": "constraints",
          "tier": 2,
          "reasoning": "Technical term describing limitations or rules applied to resource usage."
        },
        {
          "term": "object kinds",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the types/categories of API objects."
        },
        {
          "term": "ResourceQuotas",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource that limits resource consumption per namespace."
        },
        {
          "term": "resource consumption",
          "tier": 2,
          "reasoning": "Domain concept describing the usage of compute resources by workloads."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for logical partitioning and isolation of cluster resources."
        },
        {
          "term": "ingress and egress traffic",
          "tier": 2,
          "reasoning": "Compound networking concept describing bidirectional network flow control."
        },
        {
          "term": "restrict",
          "tier": 3,
          "reasoning": "Technical action term in the context of policy enforcement on network traffic."
        },
        {
          "term": "limit",
          "tier": 3,
          "reasoning": "Technical action term describing resource consumption boundaries."
        },
        {
          "term": "manage",
          "tier": 3,
          "reasoning": "Technical action term describing administrative control over resource allocation."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T21:55:10.283284",
      "elapsed_time": 10.175119400024414
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec7",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Types of Ingress",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "### Ingress backed by a single Service {#single-service-ingress}\n\nThere are existing Kubernetes concepts that allow you to expose a single Service\n(see [alternatives](#alternatives)). You can also do this with an Ingress by specifying a\n*default backend* with no rules.\n\n{{% code_sample file=\"service/networking/test-ingress.yaml\" %}}\n\nIf you create it using `kubectl apply -f` you should be able to view the state\nof the Ingress you added:\n\n```bash\nkubectl get ingress test-ingress\n```\n\n```\nNAME           CLASS         HOSTS   ADDRESS         PORTS   AGE\ntest-ingress   external-lb   *       203.0.113.123   80      59s\n```\n\nWhere `203.0.113.123` is the IP allocated by the Ingress controller to satisfy\nthis Ingress.\n\n{{< note >}}\nIngress controllers and load balancers may take a minute or two to allocate an IP address.\nUntil that time, you often see the address listed as `<pending>`.\n{{< /note >}}\n\n### Simple fanout\n\nA fanout configuration routes traffic from a single IP address to more than one Service,\nbased on the HTTP URI being requested. An Ingress allows you to keep the number of load balancers\ndown to a minimum. For example, a setup like:\n\n{{< figure src=\"/docs/images/ingressFanOut.svg\" alt=\"ingress-fanout-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Fan Out\" link=\"https://mermaid.live/edit#pako:eNqNUslOwzAQ_RXLvYCUhMQpUFzUUzkgcUBwbHpw4klr4diR7bCo8O8k2FFbFomLPZq3jP00O1xpDpjijWHtFt09zAuFUCUFKHey8vf6NE7QrdoYsDZumGIb4Oi6NAskNeOoZJKpCgxK4oXwrFVgRyi7nCVXWZKRPMlysv5yD6Q4Xryf1Vq_WzDPooJs9egLNDbolKTpT03JzKgh3zWEztJZ0Niu9L-qZGcdmAMfj4cxvWmreba613z9C0B-AMQD-V_AdA-A4j5QZu0SatRKJhSqhZR0wjmPrDP6CeikrutQxy-Cuy2dtq9RpaU2dJKm6fzI5Glmg0VOLio4_5dLjx27hFSC015KJ2VZHtuQvY2fuHcaE43G0MaCREOow_FV5cMxHZ5-oPX75UM5avuXhXuOI9yAaZjg_aLuBl6B3RYaKDDtSw4166QrcKE-emrXcubghgunDaY1kxYizDqnH99UhakzHYykpWD9hjS--fEJoIELqQ\" >}}\n\nIt would require an Ingress such as:\n\n{{% code_sample file=\"service/networking/simple-fanout-example.yaml\" %}}\n\nWhen you create the Ingress with `kubectl apply -f`:\n\n```shell\nkubectl describe ingress simple-fanout-example\n```\n\n```\nName:             simple-fanout-example\nNamespace:        default\nAddress:          178.91.123.132\nDefault backend:  default-http-backend:80 (10.8.2.3:8080)\nRules:\n  Host         Path  Backends\n  ----         ----  --------\n  foo.bar.com\n               /foo   service1:4200 (10.8.0.90:4200)\n               /bar   service2:8080 (10.8.0.91:8080)\nEvents:\n  Type     Reason  Age                From                     Message\n  ----     ------  ----               ----                     -------\n  Normal   ADD     22s                loadbalancer-controller  default/test\n```\n\nThe Ingress controller provisions an implementation-specific load balancer\nthat satisfies the Ingress, as long as the Services (`service1`, `service2`) exist.\nWhen it has done so, you can see the address of the load balancer at the\nAddress field.\n\n{{< note >}}\nDepending on the [Ingress controller](/docs/concepts/services-networking/ingress-controllers/)\nyou are using, you may need to create a default-http-backend\n[Service](/docs/concepts/services-networking/service/).\n{{< /note >}}\n\n### Name based virtual hosting\n\nName-based virtual hosts support routing HTTP traffic to multiple host names at the same IP address.\n\n{{< figure src=\"/docs/images/ingressNameBased.svg\" alt=\"ingress-namebase-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Name Based Virtual hosting\" link=\"https://mermaid.live/edit#pako:eNqNkl9PwyAUxb8KYS-atM1Kp05m9qSJJj4Y97jugcLtRqTQAPVPdN_dVlq3qUt8gZt7zvkBN7xjbgRgiteW1Rt0_zjLNUJcSdD-ZBn21WmcoDu9tuBcXDHN1iDQVWHnSBkmUMEU0xwsSuK5DK5l745QejFNLtMkJVmSZmT1Re9NcTz_uDXOU1QakxTMJtxUHw7ss-SQLhehQEODTsdH4l20Q-zFyc84-Y67pghv5apxHuweMuj9eS2_NiJdPhix-kMgvwQShOyYMNkJoEUYM3PuGkpUKyY1KqVSdCSEiJy35gnoqCzLvo5fpPAbOqlfI26UsXQ0Ho9nB5CnqesRGTnncPYvSqsdUvqp9KRdlI6KojjEkB0mnLgjDRONhqENBYm6oXbLV5V1y6S7-l42_LowlIN2uFm_twqOcAW2YlK0H_i9c-bYb6CCHNO2FFCyRvkc53rbWptaMA83QnpjMS2ZchBh1nizeNMcU28bGEzXkrV_pArN7Sc0rBTu\" >}}\n\nThe following Ingress tells the backing load balancer to route requests based on\nthe [Host header](https://tools.ietf.org/html/rfc7230#section-5.4).\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress.yaml\" %}}\n\nIf you create an Ingress resource without any hosts defined in the rules, then any\nweb traffic to the IP address of your Ingress controller can be matched without a name based\nvirtual host being required.\n\nFor example, the following Ingress routes traffic\nrequested for `first.bar.com` to `service1`, `second.bar.com` to `service2`,\nand any traffic whose request host header doesn't match `first.bar.com`\nand `second.bar.com` to `service3`.\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress-no-third-host.yaml\" %}}\n\n### TLS\n\nYou can secure an Ingress by specifying a {{< glossary_tooltip term_id=\"secret\" >}}\nthat contains a TLS private key and certificate. The Ingress resource only\nsupports a single TLS port, 443, and assumes TLS termination at the ingress point\n(traffic to the Service and its Pods is in plaintext).\nIf the TLS configuration section in an Ingress specifies different hosts, they are\nmultiplexed on the same port according to the hostname specified through the\nSNI TLS extension (provided the Ingress controller supports SNI). The TLS secret\nmust contain keys named `tls.crt` and `tls.key` that contain the certificate\nand private key to use for TLS. For example:\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: testsecret-tls\n  namespace: default\ndata:\n  tls.crt: base64 encoded cert\n  tls.key: base64 encoded key\ntype: kubernetes.io/tls\n```\n\nReferencing this secret in an Ingress tells the Ingress controller to\nsecure the channel from the client to the load balancer using TLS. You need to make\nsure the TLS secret you created came from a certificate that contains a Common\nName (CN), also known as a Fully Qualified Domain Name (FQDN) for `https-example.foo.com`.\n\n{{< note >}}\nKeep in mind that TLS will not work on the default rule because the\ncertificates would have to be issued for all the possible sub-domains. Therefore,\n`hosts` in the `tls` section need to explicitly match the `host` in the `rules`\nsection.\n{{< /note >}}\n\n{{% code_sample file=\"service/networking/tls-example-ingress.yaml\" %}}\n\n{{< note >}}\nThere is a gap between TLS features supported by various ingress controllers.\nYou should refer to the documentation for the ingress controller(s) you've chosen to\nunderstand how TLS works in your environment.\n{{< /note >}}\n\n### Load balancing {#load-balancing}\n\nAn Ingress controller is bootstrapped with some load balancing policy settings\nthat it applies to all Ingress, such as the load balancing algorithm, backend\nweight scheme, and others. More advanced load balancing concepts\n(e.g. persistent sessions, dynamic weights) are not yet exposed through the\nIngress. You can instead get these features through the load balancer used for\na Service.\n\nIt's also worth noting that even though health checks are not exposed directly\nthrough the Ingress, there exist parallel concepts in Kubernetes such as\n[readiness probes](/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)\nthat allow you to achieve the same end result. Please review the controller\nspecific documentation to see how they handle health checks.",
      "terms": [
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing external access to services in a cluster."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object that exposes applications running on pods."
        },
        {
          "term": "default backend",
          "tier": 2,
          "reasoning": "Ingress configuration concept specifying where traffic goes when no rules match."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used for cluster management."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for applying configuration to resources."
        },
        {
          "term": "kubectl get ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for retrieving Ingress resources."
        },
        {
          "term": "kubectl describe ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for detailed Ingress information."
        },
        {
          "term": "Ingress controller",
          "tier": 1,
          "reasoning": "Kubernetes component that implements Ingress resources and manages load balancing."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Infrastructure component that distributes network traffic across services."
        },
        {
          "term": "IP address",
          "tier": 3,
          "reasoning": "Network addressing concept essential for Ingress routing."
        },
        {
          "term": "fanout",
          "tier": 2,
          "reasoning": "Ingress configuration pattern routing traffic from single IP to multiple services."
        },
        {
          "term": "HTTP URI",
          "tier": 3,
          "reasoning": "Protocol-specific identifier used for routing decisions in Ingress."
        },
        {
          "term": "Address",
          "tier": 2,
          "reasoning": "Ingress field showing the allocated IP for the load balancer."
        },
        {
          "term": "Name based virtual hosting",
          "tier": 2,
          "reasoning": "Ingress routing pattern supporting multiple hostnames at same IP."
        },
        {
          "term": "virtual hosting",
          "tier": 2,
          "reasoning": "Networking concept for hosting multiple domains on single IP."
        },
        {
          "term": "HTTP traffic",
          "tier": 3,
          "reasoning": "Protocol-specific network traffic that Ingress routes."
        },
        {
          "term": "host names",
          "tier": 2,
          "reasoning": "DNS names used for name-based virtual hosting routing."
        },
        {
          "term": "Namespace",
          "tier": 1,
          "reasoning": "Kubernetes resource for organizing and isolating cluster resources."
        },
        {
          "term": "default-http-backend",
          "tier": 1,
          "reasoning": "Specific Service name required by some Ingress controllers."
        },
        {
          "term": "Backends",
          "tier": 2,
          "reasoning": "Ingress concept referring to target Services for routing."
        },
        {
          "term": "Rules",
          "tier": 2,
          "reasoning": "Ingress configuration element defining routing logic."
        },
        {
          "term": "Host",
          "tier": 2,
          "reasoning": "Ingress rule field specifying hostname for routing."
        },
        {
          "term": "Path",
          "tier": 2,
          "reasoning": "Ingress rule field specifying URL path for routing."
        },
        {
          "term": "PORTS",
          "tier": 2,
          "reasoning": "Network ports exposed by the Ingress resource."
        },
        {
          "term": "CLASS",
          "tier": 2,
          "reasoning": "Ingress field specifying which controller should implement it."
        },
        {
          "term": "external-lb",
          "tier": 1,
          "reasoning": "Specific Ingress class name shown in the example."
        },
        {
          "term": "service1",
          "tier": 1,
          "reasoning": "Named Service resource in the fanout example."
        },
        {
          "term": "service2",
          "tier": 1,
          "reasoning": "Named Service resource in the fanout example."
        },
        {
          "term": "test-ingress",
          "tier": 1,
          "reasoning": "Named Ingress resource in the single-service example."
        },
        {
          "term": "simple-fanout-example",
          "tier": 1,
          "reasoning": "Named Ingress resource demonstrating fanout configuration."
        },
        {
          "term": "foo.bar.com",
          "tier": 2,
          "reasoning": "Example hostname used in Ingress routing rules."
        },
        {
          "term": "Events",
          "tier": 2,
          "reasoning": "Kubernetes resource field showing cluster events related to the resource."
        },
        {
          "term": "loadbalancer-controller",
          "tier": 1,
          "reasoning": "Component name shown in Events generating Ingress-related messages."
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "Kubernetes namespace name where resources are created."
        },
        {
          "term": "-f",
          "tier": 3,
          "reasoning": "kubectl flag for specifying file input."
        }
      ],
      "term_count": 35,
      "generated_at": "2026-02-08T21:55:30.425499",
      "elapsed_time": 19.13832187652588
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec19",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Key`     {#apiserver-config-k8s-io-v1-Key}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [AESConfiguration](#apiserver-config-k8s-io-v1-AESConfiguration)\n\n- [SecretboxConfiguration](#apiserver-config-k8s-io-v1-SecretboxConfiguration)\n\n\n<p>Key contains name and secret of the provided key for a transformer.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>name</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>name is the name of the key to be used while storing data to disk.</p>\n</td>\n</tr>\n<tr><td><code>secret</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>secret is the actual key, encoded in base64.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for AES encryption settings."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for Secretbox encryption settings."
        },
        {
          "term": "Key",
          "tier": 1,
          "reasoning": "Named API object/struct that contains name and secret for a transformer."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept referring to a component that transforms/encrypts data in Kubernetes."
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Required field identifier used for storing data to disk, carries technical meaning in this API context."
        },
        {
          "term": "secret",
          "tier": 2,
          "reasoning": "Technical term referring to the actual encryption key value, core security concept."
        },
        {
          "term": "base64",
          "tier": 3,
          "reasoning": "Encoding standard used for representing the secret key data."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the field values in the API object."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "API group and version identifier for Kubernetes API server configuration."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing a property/attribute in the API object schema."
        },
        {
          "term": "disk",
          "tier": 3,
          "reasoning": "Storage medium referenced in context of data persistence."
        },
        {
          "term": "encoded",
          "tier": 3,
          "reasoning": "Technical process term describing how the secret key is represented."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:55:39.744741",
      "elapsed_time": 8.31572151184082
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec6",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`AnonymousAuthCondition`     {#apiserver-k8s-io-v1beta1-AnonymousAuthCondition}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [AnonymousAuthConfig](#apiserver-k8s-io-v1beta1-AnonymousAuthConfig)\n\n\n<p>AnonymousAuthCondition describes the condition under which anonymous auth\nshould be enabled.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>path</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>Path for which anonymous auth is enabled.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for anonymous authentication settings."
        },
        {
          "term": "AnonymousAuthCondition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type that describes conditions for anonymous authentication."
        },
        {
          "term": "apiserver-k8s-io-v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version identifier for the apiserver configuration."
        },
        {
          "term": "anonymous auth",
          "tier": 2,
          "reasoning": "Domain concept referring to authentication mechanism allowing unauthenticated access."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Technical field specifying the URL path for which anonymous authentication applies."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing a configuration property in the API object schema."
        },
        {
          "term": "condition",
          "tier": 2,
          "reasoning": "Domain concept describing a state or requirement that must be met for a feature to be enabled."
        },
        {
          "term": "enabled",
          "tier": 3,
          "reasoning": "Technical state indicating a feature or configuration is active."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the path field in the API schema."
        }
      ],
      "term_count": 9,
      "generated_at": "2026-02-08T21:55:46.876831",
      "elapsed_time": 6.128656387329102
    },
    {
      "chunk_id": "tasks_administer-cluster_coredns_sec3",
      "doc_id": "tasks_administer-cluster_coredns",
      "heading": "Upgrading CoreDNS",
      "source_file": "tasks_administer-cluster_coredns.md",
      "content": "You can check the version of CoreDNS that kubeadm installs for each version of\nKubernetes in the page\n[CoreDNS version in Kubernetes](https://github.com/coredns/deployment/blob/master/kubernetes/CoreDNS-k8s_version.md).\n\nCoreDNS can be upgraded manually in case you want to only upgrade CoreDNS\nor use your own custom image.\nThere is a helpful [guideline and walkthrough](https://github.com/coredns/deployment/blob/master/kubernetes/Upgrading_CoreDNS.md)\navailable to ensure a smooth upgrade.\nMake sure the existing CoreDNS configuration (\"Corefile\") is retained when\nupgrading your cluster.\n\nIf you are upgrading your cluster using the `kubeadm` tool, `kubeadm`\ncan take care of retaining the existing CoreDNS configuration automatically.",
      "terms": [
        {
          "term": "CoreDNS",
          "tier": 1,
          "reasoning": "Core Kubernetes DNS component and proper noun, a specific infrastructure component"
        },
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster bootstrapping and management"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform this documentation describes"
        },
        {
          "term": "Corefile",
          "tier": 1,
          "reasoning": "CoreDNS-specific configuration file name, a proper noun for the configuration resource"
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Technical term referring to software versioning in the context of CoreDNS and Kubernetes releases"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process term for updating software components to newer versions"
        },
        {
          "term": "upgraded",
          "tier": 2,
          "reasoning": "Past tense form of upgrade process appearing in the text"
        },
        {
          "term": "upgrading",
          "tier": 2,
          "reasoning": "Gerund form of the upgrade process, used multiple times in context"
        },
        {
          "term": "custom image",
          "tier": 2,
          "reasoning": "Container/Kubernetes concept referring to user-defined container images"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept, fundamental to Kubernetes workloads"
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical term for system settings and parameters, specifically CoreDNS configuration"
        },
        {
          "term": "CoreDNS configuration",
          "tier": 2,
          "reasoning": "Compound term referring to the specific configuration of the CoreDNS component"
        },
        {
          "term": "CoreDNS version",
          "tier": 2,
          "reasoning": "Compound term referring to specific releases of the CoreDNS component"
        },
        {
          "term": "installs",
          "tier": 3,
          "reasoning": "Technical action term for deploying software components"
        },
        {
          "term": "manually",
          "tier": 3,
          "reasoning": "Operational term contrasting with automated processes in cluster management"
        },
        {
          "term": "tool",
          "tier": 3,
          "reasoning": "Technical term referring to CLI utilities like kubeadm"
        },
        {
          "term": "retained",
          "tier": 3,
          "reasoning": "Technical term for preserving configuration during upgrade processes"
        },
        {
          "term": "automatically",
          "tier": 3,
          "reasoning": "Operational term describing kubeadm's behavior in managing configurations"
        }
      ],
      "term_count": 19,
      "generated_at": "2026-02-08T21:55:59.593692",
      "elapsed_time": 11.71185302734375
    },
    {
      "chunk_id": "tasks_debug_debug-application_debug-statefulset_sec1",
      "doc_id": "tasks_debug_debug-application_debug-statefulset",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_debug_debug-application_debug-statefulset.md",
      "content": "* You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with your cluster.\n* You should have a StatefulSet running that you want to investigate.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes cluster",
          "tier": 1,
          "reasoning": "Core infrastructure resource - a complete Kubernetes deployment environment"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster management and communication"
        },
        {
          "term": "command-line tool",
          "tier": 2,
          "reasoning": "Technical term describing the type of interface kubectl provides"
        },
        {
          "term": "configured",
          "tier": 3,
          "reasoning": "Technical process term referring to setting up tool parameters for cluster communication"
        },
        {
          "term": "communicate",
          "tier": 3,
          "reasoning": "Technical term in context referring to API communication between kubectl and cluster"
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/workload resource for managing stateful applications"
        },
        {
          "term": "running",
          "tier": 3,
          "reasoning": "Technical state term describing an active workload in Kubernetes context"
        }
      ],
      "term_count": 9,
      "generated_at": "2026-02-08T21:56:07.693260",
      "elapsed_time": 7.0959837436676025
    },
    {
      "chunk_id": "concepts_overview_working-with-objects_annotations_sec1",
      "doc_id": "concepts_overview_working-with-objects_annotations",
      "heading": "Attaching metadata to objects",
      "source_file": "concepts_overview_working-with-objects_annotations.md",
      "content": "You can use either labels or annotations to attach metadata to Kubernetes\nobjects. Labels can be used to select objects and to find\ncollections of objects that satisfy certain conditions. In contrast, annotations\nare not used to identify and select objects. The metadata\nin an annotation can be small or large, structured or unstructured, and can\ninclude characters not permitted by labels. It is possible to use labels as \nwell as annotations in the metadata of the same object.\n\nAnnotations, like labels, are key/value maps:\n\n```json\n\"metadata\": {\n  \"annotations\": {\n    \"key1\" : \"value1\",\n    \"key2\" : \"value2\"\n  }\n}\n```\n\n{{<note>}}\nThe keys and the values in the map must be strings. In other words, you cannot use\nnumeric, boolean, list or other types for either the keys or the values.\n{{</note>}}\n\nHere are some examples of information that could be recorded in annotations:\n\n* Fields managed by a declarative configuration layer. Attaching these fields\n  as annotations distinguishes them from default values set by clients or\n  servers, and from auto-generated fields and fields set by\n  auto-sizing or auto-scaling systems.\n\n* Build, release, or image information like timestamps, release IDs, git branch,\n  PR numbers, image hashes, and registry address.\n\n* Pointers to logging, monitoring, analytics, or audit repositories.\n\n* Client library or tool information that can be used for debugging purposes:\n  for example, name, version, and build information.\n\n* User or tool/system provenance information, such as URLs of related objects\n  from other ecosystem components.\n\n* Lightweight rollout tool metadata: for example, config or checkpoints.\n\n* Phone or pager numbers of persons responsible, or directory entries that\n  specify where that information can be found, such as a team web site.\n\n* Directives from the end-user to the implementations to modify behavior or\n  engage non-standard features.\n\nInstead of using annotations, you could store this type of information in an\nexternal database or directory, but that would make it much harder to produce\nshared client libraries and tools for deployment, management, introspection,\nand the like.",
      "terms": [
        {
          "term": "labels",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for selecting and identifying objects."
        },
        {
          "term": "annotations",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for attaching non-identifying information to objects."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Technical concept referring to data attached to Kubernetes objects for identification and description."
        },
        {
          "term": "objects",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes API resources and entities."
        },
        {
          "term": "key/value maps",
          "tier": 2,
          "reasoning": "Data structure concept describing how annotations and labels store information."
        },
        {
          "term": "keys",
          "tier": 3,
          "reasoning": "Technical term for the identifier portion of key/value pairs in metadata."
        },
        {
          "term": "values",
          "tier": 3,
          "reasoning": "Technical term for the data portion of key/value pairs in metadata."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type constraint for annotation and label keys and values."
        },
        {
          "term": "declarative configuration layer",
          "tier": 2,
          "reasoning": "Architectural concept describing configuration management approach in Kubernetes."
        },
        {
          "term": "clients",
          "tier": 2,
          "reasoning": "Technical term for applications or tools that interact with Kubernetes API."
        },
        {
          "term": "servers",
          "tier": 2,
          "reasoning": "Technical term for Kubernetes API server components that process requests."
        },
        {
          "term": "auto-generated fields",
          "tier": 2,
          "reasoning": "Domain concept for fields automatically populated by Kubernetes systems."
        },
        {
          "term": "auto-sizing",
          "tier": 2,
          "reasoning": "Technical process for automatic resource adjustment in Kubernetes."
        },
        {
          "term": "auto-scaling systems",
          "tier": 2,
          "reasoning": "Domain concept for systems that automatically scale workloads."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept used in build and release metadata context."
        },
        {
          "term": "timestamps",
          "tier": 3,
          "reasoning": "Technical metadata element for recording time information."
        },
        {
          "term": "release IDs",
          "tier": 3,
          "reasoning": "Technical metadata for identifying software releases."
        },
        {
          "term": "git branch",
          "tier": 3,
          "reasoning": "Version control concept used in build metadata."
        },
        {
          "term": "PR numbers",
          "tier": 3,
          "reasoning": "Pull request identifiers used in build metadata tracking."
        },
        {
          "term": "image hashes",
          "tier": 2,
          "reasoning": "Container image identification mechanism using cryptographic hashes."
        },
        {
          "term": "registry address",
          "tier": 2,
          "reasoning": "Container registry location information for image storage."
        },
        {
          "term": "logging",
          "tier": 2,
          "reasoning": "Observability concept for recording system events and data."
        },
        {
          "term": "monitoring",
          "tier": 2,
          "reasoning": "Observability concept for tracking system health and metrics."
        },
        {
          "term": "analytics",
          "tier": 2,
          "reasoning": "Technical concept for data analysis and insights."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Security and compliance concept for tracking system actions."
        },
        {
          "term": "repositories",
          "tier": 3,
          "reasoning": "Storage locations for code, logs, or other data."
        },
        {
          "term": "client library",
          "tier": 2,
          "reasoning": "Software development concept for API interaction libraries."
        },
        {
          "term": "debugging",
          "tier": 3,
          "reasoning": "Technical process for troubleshooting and fixing issues."
        },
        {
          "term": "provenance information",
          "tier": 2,
          "reasoning": "Technical concept for tracking origin and history of resources."
        },
        {
          "term": "ecosystem components",
          "tier": 2,
          "reasoning": "Architectural term for related tools and systems in Kubernetes ecosystem."
        },
        {
          "term": "rollout tool",
          "tier": 2,
          "reasoning": "Deployment tooling concept for managing application updates."
        },
        {
          "term": "config",
          "tier": 2,
          "reasoning": "Configuration data used in deployment and management."
        },
        {
          "term": "checkpoints",
          "tier": 2,
          "reasoning": "Technical concept for saving state during rollout processes."
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Domain concept for releasing and managing applications."
        },
        {
          "term": "management",
          "tier": 2,
          "reasoning": "Operational concept for administering Kubernetes resources."
        },
        {
          "term": "introspection",
          "tier": 2,
          "reasoning": "Technical capability for examining system state and configuration."
        },
        {
          "term": "external database",
          "tier": 3,
          "reasoning": "Alternative storage mechanism mentioned for metadata."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "Storage or organizational structure for information."
        },
        {
          "term": "shared client libraries",
          "tier": 2,
          "reasoning": "Reusable software components for Kubernetes API interaction."
        },
        {
          "term": "tools",
          "tier": 3,
          "reasoning": "Software utilities for Kubernetes operations and management."
        }
      ],
      "term_count": 41,
      "generated_at": "2026-02-08T21:56:27.995248",
      "elapsed_time": 19.2979154586792
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster_sec7",
      "doc_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster.md",
      "content": "* [Learn more about DRA](/docs/concepts/scheduling-eviction/dynamic-resource-allocation)\n* [Allocate Devices to Workloads with DRA](/docs/tasks/configure-pod-container/assign-resources/allocate-devices-dra)",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Abbreviation for Dynamic Resource Allocation, a specific Kubernetes feature/API for resource management."
        },
        {
          "term": "Dynamic Resource Allocation",
          "tier": 1,
          "reasoning": "Implied by the DRA abbreviation in the URL path, this is a core Kubernetes scheduling feature."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Domain concept appearing in the URL path 'scheduling-eviction', referring to the Kubernetes scheduling process."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Domain concept appearing in the URL path 'scheduling-eviction', referring to the process of removing pods from nodes."
        },
        {
          "term": "Devices",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context referring to hardware resources that can be allocated to workloads."
        },
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running in the cluster (Pods, Deployments, etc.)."
        },
        {
          "term": "Allocate",
          "tier": 2,
          "reasoning": "Technical process term describing the assignment of resources to workloads in Kubernetes."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to compute resources (CPU, memory, devices) that can be requested and allocated."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Implied by 'configure-pod-container' in the URL path, Pod is a core Kubernetes API object."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Appears in URL path 'configure-pod-container', fundamental Kubernetes concept for running applications."
        },
        {
          "term": "assign-resources",
          "tier": 2,
          "reasoning": "Technical process appearing in URL path describing the action of assigning resources to pods/containers."
        },
        {
          "term": "allocate-devices-dra",
          "tier": 2,
          "reasoning": "Task/process name appearing in URL describing the specific operation of allocating devices using DRA."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:56:39.190401",
      "elapsed_time": 10.190244674682617
    },
    {
      "chunk_id": "reference_config-api_apiserver-admission.v1_sec2",
      "doc_id": "reference_config-api_apiserver-admission.v1",
      "heading": "`AdmissionResponse`     {#admission-k8s-io-v1-AdmissionResponse}",
      "source_file": "reference_config-api_apiserver-admission.v1.md",
      "content": "**Appears in:**\n\n- [AdmissionReview](#admission-k8s-io-v1-AdmissionReview)\n\n\n<p>AdmissionResponse describes an admission response.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>uid</code> <B>[Required]</B><br/>\n<a href=\"https://pkg.go.dev/k8s.io/apimachinery/pkg/types#UID\"><code>k8s.io/apimachinery/pkg/types.UID</code></a>\n</td>\n<td>\n   <p>uid is an identifier for the individual request/response.\nThis must be copied over from the corresponding AdmissionRequest.</p>\n</td>\n</tr>\n<tr><td><code>allowed</code> <B>[Required]</B><br/>\n<code>bool</code>\n</td>\n<td>\n   <p>allowed indicates whether or not the admission request was permitted.</p>\n</td>\n</tr>\n<tr><td><code>status</code><br/>\n<a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.35/#status-v1-meta\"><code>meta/v1.Status</code></a>\n</td>\n<td>\n   <p>status is the result contains extra details into why an admission request was denied.\nThis field IS NOT consulted in any way if &quot;Allowed&quot; is &quot;true&quot;.</p>\n</td>\n</tr>\n<tr><td><code>patch</code><br/>\n<code>[]byte</code>\n</td>\n<td>\n   <p>patch is the patch body. Currently we only support &quot;JSONPatch&quot; which implements RFC 6902.</p>\n</td>\n</tr>\n<tr><td><code>patchType</code><br/>\n<a href=\"#admission-k8s-io-v1-PatchType\"><code>PatchType</code></a>\n</td>\n<td>\n   <p>patchType is the type of Patch. Currently we only allow &quot;JSONPatch&quot;.</p>\n</td>\n</tr>\n<tr><td><code>auditAnnotations</code><br/>\n<code>map[string]string</code>\n</td>\n<td>\n   <p>auditAnnotations is an unstructured key value map set by remote admission controller (e.g. error=image-blacklisted).\nMutatingAdmissionWebhook and ValidatingAdmissionWebhook admission controller will prefix the keys with\nadmission webhook name (e.g. imagepolicy.example.com/error=image-blacklisted). AuditAnnotations will be provided by\nthe admission webhook to add additional context to the audit log for this request.</p>\n</td>\n</tr>\n<tr><td><code>warnings</code><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>warnings is a list of warning messages to return to the requesting API client.\nWarning messages describe a problem the client making the API request should correct or be aware of.\nLimit warnings to 120 characters if possible.\nWarnings over 256 characters and large numbers of warnings may be truncated.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AdmissionReview",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for admission control review requests and responses."
        },
        {
          "term": "AdmissionResponse",
          "tier": 1,
          "reasoning": "Core Kubernetes API object that describes an admission response structure."
        },
        {
          "term": "AdmissionRequest",
          "tier": 1,
          "reasoning": "Core Kubernetes API object referenced as the source for copying uid field."
        },
        {
          "term": "uid",
          "tier": 2,
          "reasoning": "Technical field identifier for individual request/response tracking in admission control."
        },
        {
          "term": "UID",
          "tier": 2,
          "reasoning": "Kubernetes type from apimachinery package for unique identifiers."
        },
        {
          "term": "k8s.io/apimachinery/pkg/types.UID",
          "tier": 1,
          "reasoning": "Specific Kubernetes Go package type reference for unique identifiers."
        },
        {
          "term": "allowed",
          "tier": 2,
          "reasoning": "Technical field indicating whether an admission request was permitted."
        },
        {
          "term": "admission request",
          "tier": 2,
          "reasoning": "Domain concept describing a request to the admission control system."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Technical field containing result details for denied admission requests."
        },
        {
          "term": "meta/v1.Status",
          "tier": 1,
          "reasoning": "Kubernetes API type reference for status information in meta/v1 API group."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Technical field containing the patch body for mutating admission responses."
        },
        {
          "term": "JSONPatch",
          "tier": 2,
          "reasoning": "Specific patch format implementing RFC 6902 for JSON document modifications."
        },
        {
          "term": "RFC 6902",
          "tier": 3,
          "reasoning": "Technical standard specification for JSON Patch operations."
        },
        {
          "term": "patchType",
          "tier": 2,
          "reasoning": "Technical field specifying the type of patch being applied."
        },
        {
          "term": "PatchType",
          "tier": 1,
          "reasoning": "Kubernetes API type for specifying patch format in admission responses."
        },
        {
          "term": "auditAnnotations",
          "tier": 2,
          "reasoning": "Technical field for key-value annotations added by admission controllers for audit logging."
        },
        {
          "term": "remote admission controller",
          "tier": 2,
          "reasoning": "Domain concept describing external admission control webhooks."
        },
        {
          "term": "MutatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Core Kubernetes admission controller type that can modify resources."
        },
        {
          "term": "ValidatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Core Kubernetes admission controller type that validates resources."
        },
        {
          "term": "admission webhook",
          "tier": 2,
          "reasoning": "Domain concept for webhook-based admission control mechanisms."
        },
        {
          "term": "audit log",
          "tier": 2,
          "reasoning": "Technical concept for logging system recording admission decisions and context."
        },
        {
          "term": "warnings",
          "tier": 2,
          "reasoning": "Technical field containing warning messages returned to API clients."
        },
        {
          "term": "API client",
          "tier": 2,
          "reasoning": "Technical term for clients making requests to the Kubernetes API."
        },
        {
          "term": "admission controller",
          "tier": 2,
          "reasoning": "Domain concept for components that intercept and process admission requests."
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "Go programming language boolean type used in field definitions."
        },
        {
          "term": "[]byte",
          "tier": 3,
          "reasoning": "Go programming language byte slice type for patch body data."
        },
        {
          "term": "map[string]string",
          "tier": 3,
          "reasoning": "Go programming language map type for key-value audit annotations."
        },
        {
          "term": "[]string",
          "tier": 3,
          "reasoning": "Go programming language string slice type for warnings list."
        },
        {
          "term": "request/response",
          "tier": 2,
          "reasoning": "Technical pattern describing the admission control communication model."
        }
      ],
      "term_count": 29,
      "generated_at": "2026-02-08T21:56:56.765033",
      "elapsed_time": 16.5705885887146
    },
    {
      "chunk_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information_sec2",
      "doc_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information",
      "heading": "Store container fields",
      "source_file": "tasks_inject-data-application_downward-api-volume-expose-pod-information.md",
      "content": "The preceding exercise, you made Pod-level fields accessible using the\ndownward API.\nIn this next exercise, you are going to pass fields that are part of the Pod\ndefinition, but taken from the specific\n[container](/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container)\nrather than from the Pod overall. Here is a manifest for a Pod that again has\njust one container:\n\n{{% code_sample file=\"pods/inject/dapi-volume-resources.yaml\" %}}\n\nIn the manifest, you can see that the Pod has a\n[`downwardAPI` volume](/docs/concepts/storage/volumes/#downwardapi),\nand that the single container in that Pod mounts the volume at `/etc/podinfo`.\n\nLook at the `items` array under `downwardAPI`. Each element of the array\ndefines a file in the downward API volume.\n\nThe first element specifies that in the container named `client-container`,\nthe value of the `limits.cpu` field in the format specified by `1m` should be\npublished as a file named `cpu_limit`. The `divisor` field is optional and has the\ndefault value of `1`. A divisor of 1 means cores for `cpu` resources, or\nbytes for `memory` resources.\n\nCreate the Pod:\n\n```shell\nkubectl apply -f https://k8s.io/examples/pods/inject/dapi-volume-resources.yaml\n```\n\nGet a shell into the container that is running in your Pod:\n\n```shell\nkubectl exec -it kubernetes-downwardapi-volume-example-2 -- sh\n```\n\nIn your shell, view the `cpu_limit` file:\n\n```shell",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and workload resource explicitly discussed throughout the chunk."
        },
        {
          "term": "downward API",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature for exposing Pod and container information to containers."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing the runtime unit within a Pod."
        },
        {
          "term": "Pod-level fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata and spec fields defined at the Pod scope."
        },
        {
          "term": "manifest",
          "tier": 2,
          "reasoning": "Technical term for the YAML/JSON file defining Kubernetes resources."
        },
        {
          "term": "downwardAPI volume",
          "tier": 1,
          "reasoning": "Specific Kubernetes volume type for exposing downward API data as files."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Core Kubernetes storage concept for providing data to containers."
        },
        {
          "term": "mounts",
          "tier": 2,
          "reasoning": "Technical process of attaching a volume to a container filesystem path."
        },
        {
          "term": "client-container",
          "tier": 1,
          "reasoning": "Specific named container referenced in the example manifest."
        },
        {
          "term": "limits.cpu",
          "tier": 2,
          "reasoning": "Kubernetes resource field specifying CPU resource limits for a container."
        },
        {
          "term": "divisor",
          "tier": 2,
          "reasoning": "Configuration field in downward API that controls unit formatting of resource values."
        },
        {
          "term": "cores",
          "tier": 3,
          "reasoning": "Unit of measurement for CPU resources in Kubernetes."
        },
        {
          "term": "bytes",
          "tier": 3,
          "reasoning": "Unit of measurement for memory resources in Kubernetes."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for creating or updating resources declaratively."
        },
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for executing commands inside a container."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes command-line interface tool."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface environment used to interact with containers."
        },
        {
          "term": "sh",
          "tier": 3,
          "reasoning": "Shell executable used when accessing container command line."
        },
        {
          "term": "cpu_limit",
          "tier": 2,
          "reasoning": "File name in the downward API volume containing CPU limit value."
        },
        {
          "term": "kubernetes-downwardapi-volume-example-2",
          "tier": 1,
          "reasoning": "Specific Pod name used in the example commands."
        },
        {
          "term": "dapi-volume-resources.yaml",
          "tier": 1,
          "reasoning": "Specific manifest filename referenced for the example Pod definition."
        },
        {
          "term": "/etc/podinfo",
          "tier": 2,
          "reasoning": "Mount path where the downward API volume is attached in the container."
        },
        {
          "term": "1m",
          "tier": 2,
          "reasoning": "Format specifier for CPU resource values (millicores notation)."
        },
        {
          "term": "file",
          "tier": 3,
          "reasoning": "Technical concept for how downward API data is exposed within the volume."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:57:12.905436",
      "elapsed_time": 15.136048793792725
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec10",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a deployment.yaml file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF > deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx\n        ports:\n        - containerPort: 80\nEOF",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource for managing replicated applications"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployment resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field that specifies the type of resource being defined"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section containing resource identification information"
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Kubernetes metadata field for resource identification"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section defining the desired state specification"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching and selecting resources based on labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector field for exact label matching"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes Deployment field specifying the number of Pod instances to run"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Kubernetes Pod template specification within a Deployment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes spec field defining container configurations within a Pod"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core virtualization concept - isolated runtime environment for applications"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image reference specifying the container runtime artifact"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container image name - popular web server/reverse proxy software"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Kubernetes container spec field for network port configuration"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes field specifying the port exposed by a container"
        },
        {
          "term": "EOF",
          "tier": 3,
          "reasoning": "Shell heredoc delimiter used in command-line operations"
        },
        {
          "term": "cat",
          "tier": 3,
          "reasoning": "Unix/Linux command used here for file creation via heredoc"
        },
        {
          "term": "deployment.yaml",
          "tier": 3,
          "reasoning": "YAML manifest filename for Kubernetes Deployment configuration"
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes manifests (implied by .yaml extension)"
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T21:57:24.855511",
      "elapsed_time": 10.94538950920105
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec8",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Arbitrary workloads and arbitrary selectors {#arbitrary-controllers-and-selectors}",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "You can skip this section if you only use PDBs with the built-in\nworkload resources (Deployment, ReplicaSet, StatefulSet and ReplicationController)\nor with {{< glossary_tooltip term_id=\"CustomResourceDefinition\" text=\"custom resources\" >}}\nthat implement a `scale` [subresource](/docs/concepts/extend-kubernetes/api-extension/custom-resources/#advanced-features-and-flexibility),\nand where the PDB selector exactly matches the selector of the Pod's owning resource.\n\nYou can use a PDB with pods controlled by another resource, by an\n\"operator\", or bare pods, but with these restrictions:\n\n- only `.spec.minAvailable` can be used, not `.spec.maxUnavailable`.\n- only an integer value can be used with `.spec.minAvailable`, not a percentage.\n\nIt is not possible to use other availability configurations,\nbecause Kubernetes cannot derive a total number of pods without a supported owning resource.\n\nYou can use a selector which selects a subset or superset of the pods belonging to a\nworkload resource. The eviction API will disallow eviction of any pod covered by multiple PDBs,\nso most users will want to avoid overlapping selectors. One reasonable use of overlapping\nPDBs is when pods are being transitioned from one PDB to another.",
      "terms": [
        {
          "term": "PDBs",
          "tier": 1,
          "reasoning": "Abbreviation for PodDisruptionBudget, a core Kubernetes API resource for managing pod availability during disruptions."
        },
        {
          "term": "PDB",
          "tier": 1,
          "reasoning": "Singular form of PodDisruptionBudget, a named Kubernetes API object."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource for managing stateless applications."
        },
        {
          "term": "ReplicaSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource that maintains a stable set of replica pods."
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource for managing stateful applications."
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Legacy Kubernetes workload resource for maintaining pod replicas."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Kubernetes API extension mechanism for defining custom resources."
        },
        {
          "term": "custom resources",
          "tier": 1,
          "reasoning": "User-defined Kubernetes API objects extending the platform's capabilities."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes workload unit representing one or more containers."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, the basic schedulable unit in Kubernetes."
        },
        {
          "term": "eviction API",
          "tier": 1,
          "reasoning": "Specific Kubernetes API for gracefully removing pods from nodes."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes subresource enabling scaling operations on workload resources."
        },
        {
          "term": "subresource",
          "tier": 2,
          "reasoning": "Technical concept referring to a secondary API endpoint on a Kubernetes resource."
        },
        {
          "term": "workload resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources that manage pod lifecycles."
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for matching and selecting resources based on labels."
        },
        {
          "term": "owning resource",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the parent resource that controls child objects."
        },
        {
          "term": "operator",
          "tier": 2,
          "reasoning": "Kubernetes pattern for extending cluster behavior with custom controllers."
        },
        {
          "term": "bare pods",
          "tier": 2,
          "reasoning": "Pods created directly without a controlling workload resource."
        },
        {
          "term": ".spec.minAvailable",
          "tier": 2,
          "reasoning": "PDB specification field defining minimum available pods during disruption."
        },
        {
          "term": ".spec.maxUnavailable",
          "tier": 2,
          "reasoning": "PDB specification field defining maximum unavailable pods during disruption."
        },
        {
          "term": "integer value",
          "tier": 3,
          "reasoning": "Technical constraint on PDB configuration for bare pods."
        },
        {
          "term": "percentage",
          "tier": 3,
          "reasoning": "Alternative value type for PDB configuration not available for bare pods."
        },
        {
          "term": "availability configurations",
          "tier": 2,
          "reasoning": "Settings controlling pod availability guarantees during disruptions."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Kubernetes process of gracefully terminating pods from nodes."
        },
        {
          "term": "overlapping selectors",
          "tier": 2,
          "reasoning": "Configuration where multiple PDBs select the same pods."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in context of Kubernetes eviction API."
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Kubernetes concept for extending the API with custom resources."
        }
      ],
      "term_count": 27,
      "generated_at": "2026-02-08T21:57:40.524005",
      "elapsed_time": 14.663658380508423
    },
    {
      "chunk_id": "reference_node_node-status_sec3",
      "doc_id": "reference_node_node-status",
      "heading": "Conditions {#condition}",
      "source_file": "reference_node_node-status.md",
      "content": "The `conditions` field describes the status of all `Running` nodes. Examples of conditions include:\n\n{{< table caption = \"Node conditions, and a description of when each condition applies.\" >}}\n| Node Condition       | Description |\n|----------------------|-------------|\n| `Ready`              | `True` if the node is healthy and ready to accept pods, `False` if the node is not healthy and is not accepting pods, and `Unknown` if the node controller has not heard from the node in the last `node-monitor-grace-period` (default is 50 seconds) |\n| `DiskPressure`       | `True` if pressure exists on the disk size\u2014that is, if the disk capacity is low; otherwise `False` |\n| `MemoryPressure`     | `True` if pressure exists on the node memory\u2014that is, if the node memory is low; otherwise `False` |\n| `PIDPressure`        | `True` if pressure exists on the processes\u2014that is, if there are too many processes on the node; otherwise `False` |\n| `NetworkUnavailable` | `True` if the network for the node is not correctly configured, otherwise `False` |\n{{< /table >}}\n\n{{< note >}}\nIf you use command-line tools to print details of a cordoned Node, the Condition includes\n`SchedulingDisabled`. `SchedulingDisabled` is not a Condition in the Kubernetes API; instead,\ncordoned nodes are marked Unschedulable in their spec.\n{{< /note >}}\n\nIn the Kubernetes API, a node's condition is represented as part of the `.status`\nof the Node resource. For example, the following JSON structure describes a healthy node:\n\n```json\n\"conditions\": [\n  {\n    \"type\": \"Ready\",\n    \"status\": \"True\",\n    \"reason\": \"KubeletReady\",\n    \"message\": \"kubelet is posting ready status\",\n    \"lastHeartbeatTime\": \"2019-06-05T18:38:35Z\",\n    \"lastTransitionTime\": \"2019-06-05T11:41:27Z\"\n  }\n]\n```\n\nWhen problems occur on nodes, the Kubernetes control plane automatically creates\n[taints](/docs/concepts/scheduling-eviction/taint-and-toleration/) that match the conditions\naffecting the node. An example of this is when the `status` of the Ready condition\nremains `Unknown` or `False` for longer than the kube-controller-manager's `NodeMonitorGracePeriod`,\nwhich defaults to 50 seconds. This will cause either an `node.kubernetes.io/unreachable` taint, for an `Unknown` status,\nor a `node.kubernetes.io/not-ready` taint, for a `False` status, to be added to the Node.\n\nThese taints affect pending pods as the scheduler takes the Node's taints into consideration when\nassigning a pod to a Node. Existing pods scheduled to the node may be evicted due to the application\nof `NoExecute` taints. Pods may also have {{< glossary_tooltip text=\"tolerations\" term_id=\"toleration\" >}} that let\nthem schedule to and continue running on a Node even though it has a specific taint.\n\nSee [Taint Based Evictions](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-based-evictions) and\n[Taint Nodes by Condition](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-nodes-by-condition)\nfor more details.",
      "terms": [
        {
          "term": "conditions",
          "tier": 2,
          "reasoning": "Domain concept describing the status field of node resources in Kubernetes API"
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "Node status state indicating operational nodes"
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing worker machines in a cluster"
        },
        {
          "term": "Node Condition",
          "tier": 2,
          "reasoning": "Specific Kubernetes concept for describing node health states"
        },
        {
          "term": "Ready",
          "tier": 1,
          "reasoning": "Named node condition type in Kubernetes API"
        },
        {
          "term": "DiskPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low disk capacity"
        },
        {
          "term": "MemoryPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low node memory"
        },
        {
          "term": "PIDPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating too many processes"
        },
        {
          "term": "NetworkUnavailable",
          "tier": 1,
          "reasoning": "Named node condition type indicating network misconfiguration"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing deployable units"
        },
        {
          "term": "node controller",
          "tier": 1,
          "reasoning": "Kubernetes control plane component managing node lifecycle"
        },
        {
          "term": "node-monitor-grace-period",
          "tier": 1,
          "reasoning": "Specific configuration parameter for node monitoring timeout"
        },
        {
          "term": "disk capacity",
          "tier": 3,
          "reasoning": "Technical term for storage space relevant to DiskPressure condition"
        },
        {
          "term": "node memory",
          "tier": 2,
          "reasoning": "Technical concept for memory resources on a node"
        },
        {
          "term": "processes",
          "tier": 3,
          "reasoning": "OS-level concept relevant to PIDPressure condition"
        },
        {
          "term": "network",
          "tier": 3,
          "reasoning": "Infrastructure concept relevant to NetworkUnavailable condition"
        },
        {
          "term": "cordoned Node",
          "tier": 2,
          "reasoning": "Kubernetes operational concept for nodes marked to prevent new pod scheduling"
        },
        {
          "term": "SchedulingDisabled",
          "tier": 1,
          "reasoning": "Condition label shown in CLI for cordoned nodes"
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for interacting with Kubernetes resources"
        },
        {
          "term": "Unschedulable",
          "tier": 2,
          "reasoning": "Node spec field indicating scheduling is disabled"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes resource specification field"
        },
        {
          "term": ".status",
          "tier": 2,
          "reasoning": "Kubernetes resource status field path notation"
        },
        {
          "term": "Node resource",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a node"
        },
        {
          "term": "type",
          "tier": 2,
          "reasoning": "Field in condition structure specifying condition type"
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Field in condition structure indicating True/False/Unknown"
        },
        {
          "term": "reason",
          "tier": 2,
          "reasoning": "Field in condition structure providing machine-readable reason"
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Field in condition structure providing human-readable description"
        },
        {
          "term": "lastHeartbeatTime",
          "tier": 2,
          "reasoning": "Condition field tracking last heartbeat timestamp"
        },
        {
          "term": "lastTransitionTime",
          "tier": 2,
          "reasoning": "Condition field tracking last state change timestamp"
        },
        {
          "term": "KubeletReady",
          "tier": 1,
          "reasoning": "Specific reason value indicating kubelet is ready"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component"
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept for management components"
        },
        {
          "term": "taints",
          "tier": 2,
          "reasoning": "Kubernetes scheduling mechanism to repel pods from nodes"
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component"
        },
        {
          "term": "NodeMonitorGracePeriod",
          "tier": 1,
          "reasoning": "Specific configuration parameter for node monitoring"
        },
        {
          "term": "node.kubernetes.io/unreachable",
          "tier": 1,
          "reasoning": "Specific taint key applied to unreachable nodes"
        },
        {
          "term": "node.kubernetes.io/not-ready",
          "tier": 1,
          "reasoning": "Specific taint key applied to not-ready nodes"
        },
        {
          "term": "scheduler",
          "tier": 1,
          "reasoning": "Kubernetes control plane component for pod placement"
        },
        {
          "term": "pending pods",
          "tier": 2,
          "reasoning": "Pods waiting to be scheduled to a node"
        },
        {
          "term": "evicted",
          "tier": 2,
          "reasoning": "Process of removing pods from nodes"
        },
        {
          "term": "NoExecute",
          "tier": 1,
          "reasoning": "Specific taint effect that evicts existing pods"
        },
        {
          "term": "tolerations",
          "tier": 2,
          "reasoning": "Kubernetes mechanism allowing pods to schedule on tainted nodes"
        },
        {
          "term": "Taint Based Evictions",
          "tier": 2,
          "reasoning": "Kubernetes concept for evicting pods based on taints"
        },
        {
          "term": "Taint Nodes by Condition",
          "tier": 2,
          "reasoning": "Kubernetes feature for automatically tainting nodes based on conditions"
        },
        {
          "term": "Unknown",
          "tier": 2,
          "reasoning": "Condition status value indicating uncertain state"
        },
        {
          "term": "True",
          "tier": 3,
          "reasoning": "Condition status value indicating positive state"
        },
        {
          "term": "False",
          "tier": 3,
          "reasoning": "Condition status value indicating negative state"
        }
      ],
      "term_count": 47,
      "generated_at": "2026-02-08T21:58:01.907161",
      "elapsed_time": 20.37715244293213
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec21",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`ProviderConfiguration`     {#apiserver-config-k8s-io-v1-ProviderConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [ResourceConfiguration](#apiserver-config-k8s-io-v1-ResourceConfiguration)\n\n\n<p>ProviderConfiguration stores the provided configuration for an encryption provider.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>aesgcm</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aesgcm is the configuration for the AES-GCM transformer.</p>\n</td>\n</tr>\n<tr><td><code>aescbc</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aescbc is the configuration for the AES-CBC transformer.</p>\n</td>\n</tr>\n<tr><td><code>secretbox</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-SecretboxConfiguration\"><code>SecretboxConfiguration</code></a>\n</td>\n<td>\n   <p>secretbox is the configuration for the Secretbox based transformer.</p>\n</td>\n</tr>\n<tr><td><code>identity</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-IdentityConfiguration\"><code>IdentityConfiguration</code></a>\n</td>\n<td>\n   <p>identity is the (empty) configuration for the identity transformer.</p>\n</td>\n</tr>\n<tr><td><code>kms</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-KMSConfiguration\"><code>KMSConfiguration</code></a>\n</td>\n<td>\n   <p>kms contains the name, cache size and path to configuration file for a KMS based envelope transformer.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "ResourceConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for resource settings."
        },
        {
          "term": "ProviderConfiguration",
          "tier": 1,
          "reasoning": "Named configuration structure that stores encryption provider settings."
        },
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for AES-based encryption transformers."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for Secretbox-based encryption transformer."
        },
        {
          "term": "IdentityConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for the identity transformer."
        },
        {
          "term": "KMSConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for KMS-based envelope transformer."
        },
        {
          "term": "encryption provider",
          "tier": 2,
          "reasoning": "Domain concept referring to a component that provides encryption capabilities."
        },
        {
          "term": "aesgcm",
          "tier": 2,
          "reasoning": "Configuration field name for AES-GCM transformer, a specific encryption mode."
        },
        {
          "term": "AES-GCM transformer",
          "tier": 2,
          "reasoning": "Encryption component using AES in Galois/Counter Mode for data transformation."
        },
        {
          "term": "aescbc",
          "tier": 2,
          "reasoning": "Configuration field name for AES-CBC transformer, a specific encryption mode."
        },
        {
          "term": "AES-CBC transformer",
          "tier": 2,
          "reasoning": "Encryption component using AES in Cipher Block Chaining mode for data transformation."
        },
        {
          "term": "secretbox",
          "tier": 2,
          "reasoning": "Configuration field for Secretbox-based encryption transformer."
        },
        {
          "term": "Secretbox based transformer",
          "tier": 2,
          "reasoning": "Encryption component using NaCl Secretbox for authenticated encryption."
        },
        {
          "term": "identity",
          "tier": 2,
          "reasoning": "Configuration field for identity transformer that performs no encryption."
        },
        {
          "term": "identity transformer",
          "tier": 2,
          "reasoning": "A transformer that passes data through unchanged without encryption."
        },
        {
          "term": "kms",
          "tier": 2,
          "reasoning": "Configuration field for Key Management Service based encryption."
        },
        {
          "term": "KMS based envelope transformer",
          "tier": 2,
          "reasoning": "Encryption component using external KMS for envelope encryption."
        },
        {
          "term": "envelope transformer",
          "tier": 2,
          "reasoning": "Encryption pattern where data encryption keys are wrapped by a master key."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept for components that transform/encrypt data at rest."
        },
        {
          "term": "cache size",
          "tier": 3,
          "reasoning": "Technical parameter for KMS configuration affecting performance."
        },
        {
          "term": "configuration file",
          "tier": 3,
          "reasoning": "Technical term for file containing KMS transformer settings."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "API group and version identifier for Kubernetes API server configuration."
        },
        {
          "term": "AES-GCM",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Galois/Counter Mode, a cryptographic algorithm."
        },
        {
          "term": "AES-CBC",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Cipher Block Chaining mode, a cryptographic algorithm."
        },
        {
          "term": "KMS",
          "tier": 2,
          "reasoning": "Key Management Service, external service for managing encryption keys."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:58:14.624220",
      "elapsed_time": 11.71132779121399
    },
    {
      "chunk_id": "reference_setup-tools_kubeadm_kubeadm-upgrade_sec1",
      "doc_id": "reference_setup-tools_kubeadm_kubeadm-upgrade",
      "heading": "kubeadm upgrade guidance",
      "source_file": "reference_setup-tools_kubeadm_kubeadm-upgrade.md",
      "content": "The steps for performing an upgrade using kubeadm are outlined in [this document](/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/).\nFor older versions of kubeadm, please refer to older documentation sets of the Kubernetes website.\n\nYou can use `kubeadm upgrade diff` to see the changes that would be applied to static pod manifests.\n\nIn Kubernetes v1.15.0 and later, `kubeadm upgrade apply` and `kubeadm upgrade node` will also\nautomatically renew the kubeadm managed certificates on this node, including those stored in kubeconfig files.\nTo opt-out, it is possible to pass the flag `--certificate-renewal=false`. For more details about certificate\nrenewal see the [certificate management documentation](/docs/tasks/administer-cluster/kubeadm/kubeadm-certs).\n\n{{< note >}}\nThe commands `kubeadm upgrade apply` and `kubeadm upgrade plan` have a legacy `--config`\nflag which makes it possible to reconfigure the cluster, while performing planning or upgrade of that particular\ncontrol-plane node. Please be aware that the upgrade workflow was not designed for this scenario and there are\nreports of unexpected results.\n{{</ note >}}",
      "terms": [
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI tool for cluster bootstrapping and management"
        },
        {
          "term": "kubeadm upgrade",
          "tier": 1,
          "reasoning": "Specific kubeadm subcommand for performing cluster upgrades"
        },
        {
          "term": "kubeadm upgrade diff",
          "tier": 1,
          "reasoning": "Specific kubeadm command to preview changes to static pod manifests"
        },
        {
          "term": "kubeadm upgrade apply",
          "tier": 1,
          "reasoning": "Specific kubeadm command to apply cluster upgrades"
        },
        {
          "term": "kubeadm upgrade node",
          "tier": 1,
          "reasoning": "Specific kubeadm command to upgrade a node"
        },
        {
          "term": "kubeadm upgrade plan",
          "tier": 1,
          "reasoning": "Specific kubeadm command for planning upgrades"
        },
        {
          "term": "static pod manifests",
          "tier": 2,
          "reasoning": "Domain concept referring to pod definitions managed directly by kubelet"
        },
        {
          "term": "static pod",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for pods managed directly by kubelet without API server"
        },
        {
          "term": "manifests",
          "tier": 2,
          "reasoning": "Technical term for Kubernetes resource definition files"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented"
        },
        {
          "term": "certificates",
          "tier": 2,
          "reasoning": "Security concept for TLS/PKI certificates used in cluster authentication"
        },
        {
          "term": "certificate renewal",
          "tier": 2,
          "reasoning": "Process of renewing expiring certificates in the cluster"
        },
        {
          "term": "kubeconfig files",
          "tier": 1,
          "reasoning": "Configuration files containing cluster access credentials and settings"
        },
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Core Kubernetes configuration file format for cluster access"
        },
        {
          "term": "--certificate-renewal=false",
          "tier": 1,
          "reasoning": "CLI flag to disable automatic certificate renewal"
        },
        {
          "term": "--config",
          "tier": 1,
          "reasoning": "CLI flag for specifying configuration during upgrade operations"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept referring to the set of nodes running workloads"
        },
        {
          "term": "control-plane node",
          "tier": 2,
          "reasoning": "Node running control plane components that manage the cluster"
        },
        {
          "term": "control-plane",
          "tier": 2,
          "reasoning": "Architectural component containing cluster management services"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for a worker machine in the cluster"
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process of updating Kubernetes version or components"
        },
        {
          "term": "upgrade workflow",
          "tier": 2,
          "reasoning": "The defined process and steps for performing cluster upgrades"
        },
        {
          "term": "certificate management",
          "tier": 2,
          "reasoning": "Domain concept for handling PKI certificates in the cluster"
        },
        {
          "term": "reconfigure",
          "tier": 2,
          "reasoning": "Technical operation of changing cluster configuration"
        },
        {
          "term": "v1.15.0",
          "tier": 3,
          "reasoning": "Specific Kubernetes version reference indicating feature availability"
        },
        {
          "term": "flag",
          "tier": 3,
          "reasoning": "CLI concept for command-line options passed to tools"
        }
      ],
      "term_count": 26,
      "generated_at": "2026-02-08T21:58:29.512782",
      "elapsed_time": 13.881198167800903
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec18",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "{{% heading \"cleanup\" %}}",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "Delete the ConfigMaps and Pods that you made:\n\n```bash\nkubectl delete configmaps/game-config configmaps/game-config-2 configmaps/game-config-3 \\\n               configmaps/game-config-env-file\nkubectl delete pod dapi-test-pod --now",
      "terms": [
        {
          "term": "ConfigMaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data as key-value pairs, explicitly named in the delete command."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit, explicitly mentioned in the section header."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used to interact with the cluster, shown executing delete commands."
        },
        {
          "term": "kubectl delete",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for removing Kubernetes resources from the cluster."
        },
        {
          "term": "configmaps/game-config",
          "tier": 1,
          "reasoning": "Specific ConfigMap resource reference using type/name notation in kubectl command."
        },
        {
          "term": "configmaps/game-config-2",
          "tier": 1,
          "reasoning": "Specific ConfigMap resource reference demonstrating multiple resource deletion."
        },
        {
          "term": "configmaps/game-config-3",
          "tier": 1,
          "reasoning": "Specific ConfigMap resource reference in the batch delete operation."
        },
        {
          "term": "configmaps/game-config-env-file",
          "tier": 1,
          "reasoning": "ConfigMap resource created from environment file, indicated by naming convention."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Kubernetes resource type specified in the delete command for dapi-test-pod."
        },
        {
          "term": "dapi-test-pod",
          "tier": 1,
          "reasoning": "Specific named Pod resource being deleted, likely used for Downward API testing based on naming."
        },
        {
          "term": "game-config",
          "tier": 2,
          "reasoning": "ConfigMap name representing a configuration resource for a game application example."
        },
        {
          "term": "game-config-2",
          "tier": 2,
          "reasoning": "Second ConfigMap variant in the tutorial example series."
        },
        {
          "term": "game-config-3",
          "tier": 2,
          "reasoning": "Third ConfigMap variant in the tutorial example series."
        },
        {
          "term": "game-config-env-file",
          "tier": 2,
          "reasoning": "ConfigMap created from an environment file, demonstrating env-file creation pattern."
        },
        {
          "term": "--now",
          "tier": 2,
          "reasoning": "kubectl flag that forces immediate deletion without waiting for graceful termination."
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation for removing resources from the cluster."
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Shell environment indicated for executing the kubectl commands."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:58:41.518149",
      "elapsed_time": 10.999773502349854
    },
    {
      "chunk_id": "reference_instrumentation_node-metrics_sec0",
      "doc_id": "reference_instrumentation_node-metrics",
      "heading": "Introduction",
      "source_file": "reference_instrumentation_node-metrics.md",
      "content": "---\ntitle: Node metrics data\ncontent_type: reference\nweight: 50\ndescription: >-\n  Mechanisms for accessing metrics at node, volume, pod and container level,\n  as seen by the kubelet.\n---\n\nThe [kubelet](/docs/reference/command-line-tools-reference/kubelet/)\ngathers metric statistics at the node, volume, pod and container level,\nand emits this information in the\n[Summary API](/docs/reference/config-api/kubelet-stats.v1alpha1/).\n\nYou can send a proxied request to the stats summary API via the\nKubernetes API server.\n\nHere is an example of a Summary API request for a node named `minikube`:\n\n```shell\nkubectl get --raw \"/api/v1/nodes/minikube/proxy/stats/summary\"\n```\n\nHere is the same API call using `curl`:\n\n```shell",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for node-level operations, explicitly referenced and linked in the documentation."
        },
        {
          "term": "Summary API",
          "tier": 1,
          "reasoning": "Specific Kubernetes API for accessing kubelet statistics, a named API endpoint."
        },
        {
          "term": "Kubernetes API server",
          "tier": 1,
          "reasoning": "Core control plane component that proxies requests to the stats summary API."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used in the example command."
        },
        {
          "term": "minikube",
          "tier": 1,
          "reasoning": "Named Kubernetes distribution/tool used as the example node name."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine where pods run."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Kubernetes storage abstraction, one of the levels at which metrics are gathered."
        },
        {
          "term": "pod",
          "tier": 2,
          "reasoning": "Core Kubernetes workload unit, one of the levels at which metrics are gathered."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental unit of containerized applications, one of the levels at which metrics are gathered."
        },
        {
          "term": "metric statistics",
          "tier": 2,
          "reasoning": "Domain concept referring to the performance and resource usage data collected by kubelet."
        },
        {
          "term": "Node metrics data",
          "tier": 2,
          "reasoning": "The main topic of this documentation, referring to metrics collected at the node level."
        },
        {
          "term": "stats summary API",
          "tier": 2,
          "reasoning": "Alternative reference to the Summary API endpoint for statistics."
        },
        {
          "term": "proxied request",
          "tier": 2,
          "reasoning": "Technical concept describing how requests are forwarded through the API server."
        },
        {
          "term": "container level",
          "tier": 2,
          "reasoning": "Architectural concept indicating the granularity of metrics collection."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface, used in context of Kubernetes APIs."
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool for making HTTP requests, shown as alternative to kubectl."
        },
        {
          "term": "kubectl get",
          "tier": 2,
          "reasoning": "Specific kubectl subcommand used to retrieve resources and API data."
        },
        {
          "term": "--raw",
          "tier": 2,
          "reasoning": "kubectl flag that allows raw API requests to be made directly."
        },
        {
          "term": "proxy",
          "tier": 2,
          "reasoning": "Technical concept for forwarding requests, used in the API path structure."
        }
      ],
      "term_count": 19,
      "generated_at": "2026-02-08T21:58:54.633688",
      "elapsed_time": 12.109588146209717
    },
    {
      "chunk_id": "concepts_cluster-administration_system-logs_sec1",
      "doc_id": "concepts_cluster-administration_system-logs",
      "heading": "Klog",
      "source_file": "concepts_cluster-administration_system-logs.md",
      "content": "klog is the Kubernetes logging library. [klog](https://github.com/kubernetes/klog)\ngenerates log messages for the Kubernetes system components.\n\nKubernetes is in the process of simplifying logging in its components.\nThe following klog command line flags\n[are deprecated](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/2845-deprecate-klog-specific-flags-in-k8s-components)\nstarting with Kubernetes v1.23 and removed in Kubernetes v1.26:\n\n- `--add-dir-header`\n- `--alsologtostderr`\n- `--log-backtrace-at`\n- `--log-dir`\n- `--log-file`\n- `--log-file-max-size`\n- `--logtostderr`\n- `--one-output`\n- `--skip-headers`\n- `--skip-log-headers`\n- `--stderrthreshold`\n\nOutput will always be written to stderr, regardless of the output format. Output redirection is\nexpected to be handled by the component which invokes a Kubernetes component. This can be a POSIX\nshell or a tool like systemd.\n\nIn some cases, for example a distroless container or a Windows system service, those options are\nnot available. Then the\n[`kube-log-runner`](https://github.com/kubernetes/kubernetes/blob/d2a8a81639fcff8d1221b900f66d28361a170654/staging/src/k8s.io/component-base/logs/kube-log-runner/README.md)\nbinary can be used as wrapper around a Kubernetes component to redirect\noutput. A prebuilt binary is included in several Kubernetes base images under\nits traditional name as `/go-runner` and as `kube-log-runner` in server and\nnode release archives.\n\nThis table shows how `kube-log-runner` invocations correspond to shell redirection:\n\n| Usage                                    | POSIX shell (such as bash) | `kube-log-runner <options> <cmd>`                           |\n| -----------------------------------------|----------------------------|-------------------------------------------------------------|\n| Merge stderr and stdout, write to stdout | `2>&1`                     | `kube-log-runner` (default behavior)                        |\n| Redirect both into log file              | `1>>/tmp/log 2>&1`         | `kube-log-runner -log-file=/tmp/log`                        |\n| Copy into log file and to stdout         | `2>&1 \\| tee -a /tmp/log`  | `kube-log-runner -log-file=/tmp/log -also-stdout`           |\n| Redirect only stdout into log file       | `>/tmp/log`                | `kube-log-runner -log-file=/tmp/log -redirect-stderr=false` |\n\n### Klog output\n\nAn example of the traditional klog native format:\n\n```\nI1025 00:15:15.525108       1 httplog.go:79] GET /api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-57c75779f-9p8wg: (1.512ms) 200 [pod_nanny/v0.0.0 (linux/amd64) kubernetes/$Format 10.56.1.19:51756]\n```\n\nThe message string may contain line breaks:\n\n```\nI1025 00:15:15.525108       1 example.go:79] This is a message\nwhich has a line break.\n```\n\n### Structured Logging\n\n{{< feature-state for_k8s_version=\"v1.23\" state=\"beta\" >}}\n\n{{< warning >}}\nMigration to structured log messages is an ongoing process. Not all log messages are structured in\nthis version. When parsing log files, you must also handle unstructured log messages.\n\nLog formatting and value serialization are subject to change.\n{{< /warning>}}\n\nStructured logging introduces a uniform structure in log messages allowing for programmatic\nextraction of information. You can store and process structured logs with less effort and cost.\nThe code which generates a log message determines whether it uses the traditional unstructured\nklog output or structured logging.\n\nThe default formatting of structured log messages is as text, with a format that is backward\ncompatible with traditional klog:\n\n```\n<klog header> \"<message>\" <key1>=\"<value1>\" <key2>=\"<value2>\" ...\n```\n\nExample:\n\n```\nI1025 00:15:15.525108       1 controller_utils.go:116] \"Pod status updated\" pod=\"kube-system/kubedns\" status=\"ready\"\n```\n\nStrings are quoted. Other values are formatted with\n[`%+v`](https://pkg.go.dev/fmt#hdr-Printing), which may cause log messages to\ncontinue on the next line [depending on the data](https://github.com/kubernetes/kubernetes/issues/106428).\n\n```\nI1025 00:15:15.525108       1 example.go:116] \"Example\" data=\"This is text with a line break\\nand \\\"quotation marks\\\".\" someInt=1 someFloat=0.1 someStruct={StringField: First line,\nsecond line.}\n```\n\n### Contextual Logging\n\n{{< feature-state for_k8s_version=\"v1.30\" state=\"beta\" >}}\n\nContextual logging builds on top of structured logging. It is primarily about\nhow developers use logging calls: code based on that concept is more flexible\nand supports additional use cases as described in the [Contextual Logging\nKEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/3077-contextual-logging).\n\nIf developers use additional functions like `WithValues` or `WithName` in\ntheir components, then log entries contain additional information that gets\npassed into functions by their caller.\n\nFor Kubernetes {{< skew currentVersion >}}, this is gated behind the `ContextualLogging`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) and is\nenabled by default. The infrastructure for this was added in 1.24 without\nmodifying components. The\n[`component-base/logs/example`](https://github.com/kubernetes/kubernetes/blob/v1.24.0-beta.0/staging/src/k8s.io/component-base/logs/example/cmd/logger.go)\ncommand demonstrates how to use the new logging calls and how a component\nbehaves that supports contextual logging.\n\n```console\n$ cd $GOPATH/src/k8s.io/kubernetes/staging/src/k8s.io/component-base/logs/example/cmd/\n$ go run . --help\n...\n      --feature-gates mapStringBool  A set of key=value pairs that describe feature gates for alpha/experimental features. Options are:\n                                     AllAlpha=true|false (ALPHA - default=false)\n                                     AllBeta=true|false (BETA - default=false)\n                                     ContextualLogging=true|false (BETA - default=true)\n$ go run . --feature-gates ContextualLogging=true\n...\nI0222 15:13:31.645988  197901 example.go:54] \"runtime\" logger=\"example.myname\" foo=\"bar\" duration=\"1m0s\"\nI0222 15:13:31.646007  197901 example.go:55] \"another runtime\" logger=\"example\" foo=\"bar\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\nThe `logger` key and `foo=\"bar\"` were added by the caller of the function\nwhich logs the `runtime` message and `duration=\"1m0s\"` value, without having to\nmodify that function.\n\nWith contextual logging disable, `WithValues` and `WithName` do nothing and log\ncalls go through the global klog logger. Therefore this additional information\nis not in the log output anymore:\n\n```console\n$ go run . --feature-gates ContextualLogging=false\n...\nI0222 15:14:40.497333  198174 example.go:54] \"runtime\" duration=\"1m0s\"\nI0222 15:14:40.497346  198174 example.go:55] \"another runtime\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\n### JSON log format\n\n{{< feature-state for_k8s_version=\"v1.19\" state=\"alpha\" >}}\n\n{{<warning >}}\nJSON output does not support many standard klog flags. For list of unsupported klog flags, see the\n[Command line tool reference](/docs/reference/command-line-tools-reference/).\n\nNot all logs are guaranteed to be written in JSON format (for example, during process start).\nIf you intend to parse logs, make sure you can handle log lines that are not JSON as well.\n\nField names and JSON serialization are subject to change.\n{{< /warning >}}\n\nThe `--logging-format=json` flag changes the format of logs from klog native format to JSON format.\nExample of JSON log format (pretty printed):\n\n```json\n{\n   \"ts\": 1580306777.04728,\n   \"v\": 4,\n   \"msg\": \"Pod status updated\",\n   \"pod\":{\n      \"name\": \"nginx-1\",\n      \"namespace\": \"default\"\n   },\n   \"status\": \"ready\"\n}\n```\n\nKeys with special meaning:\n\n* `ts` - timestamp as Unix time (required, float)\n* `v` - verbosity (only for info and not for error messages, int)\n* `err` - error string (optional, string)\n* `msg` - message (required, string)\n\nList of components currently supporting JSON format:\n\n* {{< glossary_tooltip term_id=\"kube-controller-manager\" text=\"kube-controller-manager\" >}}\n* {{< glossary_tooltip term_id=\"kube-apiserver\" text=\"kube-apiserver\" >}}\n* {{< glossary_tooltip term_id=\"kube-scheduler\" text=\"kube-scheduler\" >}}\n* {{< glossary_tooltip term_id=\"kubelet\" text=\"kubelet\" >}}\n\n### Log verbosity level\n\nThe `-v` flag controls log verbosity. Increasing the value increases the number of logged events.\nDecreasing the value decreases the number of logged events.  Increasing verbosity settings logs\nincreasingly less severe events. A verbosity setting of 0 logs only critical events.\n\n### Log location\n\nThere are two types of system components: those that run in a container and those\nthat do not run in a container. For example:\n\n* The Kubernetes scheduler and kube-proxy run in a container.\n* The kubelet and {{<glossary_tooltip term_id=\"container-runtime\" text=\"container runtime\">}}\n  do not run in containers.\n\nOn machines with systemd, the kubelet and container runtime write to journald.\nOtherwise, they write to `.log` files in the `/var/log` directory.\nSystem components inside containers always write to `.log` files in the `/var/log` directory,\nbypassing the default logging mechanism.\nSimilar to the container logs, you should rotate system component logs in the `/var/log` directory.\nIn Kubernetes clusters created by the `kube-up.sh` script, log rotation is configured by the `logrotate` tool.\nThe `logrotate` tool rotates logs daily, or once the log size is greater than 100MB.",
      "terms": [
        {
          "term": "klog",
          "tier": 1,
          "reasoning": "The Kubernetes logging library, a core component for system logging."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "log messages",
          "tier": 2,
          "reasoning": "Technical concept referring to the output generated by logging systems."
        },
        {
          "term": "system components",
          "tier": 2,
          "reasoning": "Refers to the various parts that make up the Kubernetes system."
        },
        {
          "term": "klog command line flags",
          "tier": 2,
          "reasoning": "Configuration options passed to klog via command line interface."
        },
        {
          "term": "--add-dir-header",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for logging configuration."
        },
        {
          "term": "--alsologtostderr",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for stderr logging."
        },
        {
          "term": "--log-backtrace-at",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for backtrace logging."
        },
        {
          "term": "--log-dir",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for log directory specification."
        },
        {
          "term": "--log-file",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for log file specification."
        },
        {
          "term": "--log-file-max-size",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for maximum log file size."
        },
        {
          "term": "--logtostderr",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for logging to stderr."
        },
        {
          "term": "--one-output",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for output configuration."
        },
        {
          "term": "--skip-headers",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for header handling."
        },
        {
          "term": "--skip-log-headers",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for log header handling."
        },
        {
          "term": "--stderrthreshold",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for stderr threshold configuration."
        },
        {
          "term": "stderr",
          "tier": 3,
          "reasoning": "Standard error output stream, a fundamental OS concept for output handling."
        },
        {
          "term": "stdout",
          "tier": 3,
          "reasoning": "Standard output stream, a fundamental OS concept for output handling."
        },
        {
          "term": "output format",
          "tier": 2,
          "reasoning": "Technical concept describing how log data is structured and presented."
        },
        {
          "term": "output redirection",
          "tier": 2,
          "reasoning": "Technical process of directing output to different destinations."
        },
        {
          "term": "Kubernetes component",
          "tier": 2,
          "reasoning": "Any of the individual parts that make up the Kubernetes system."
        },
        {
          "term": "POSIX shell",
          "tier": 3,
          "reasoning": "Standard shell interface specification relevant to output handling."
        },
        {
          "term": "systemd",
          "tier": 3,
          "reasoning": "Linux system and service manager used for component invocation."
        },
        {
          "term": "distroless container",
          "tier": 2,
          "reasoning": "Minimal container image type without shell or package manager."
        },
        {
          "term": "Windows system service",
          "tier": 3,
          "reasoning": "Windows service context where standard shell options are unavailable."
        },
        {
          "term": "kube-log-runner",
          "tier": 1,
          "reasoning": "Kubernetes binary wrapper for output redirection in restricted environments."
        },
        {
          "term": "/go-runner",
          "tier": 1,
          "reasoning": "Traditional name for the kube-log-runner binary in base images."
        },
        {
          "term": "Kubernetes base images",
          "tier": 2,
          "reasoning": "Foundation container images used for Kubernetes components."
        },
        {
          "term": "-log-file",
          "tier": 3,
          "reasoning": "kube-log-runner option for specifying log file destination."
        },
        {
          "term": "-also-stdout",
          "tier": 3,
          "reasoning": "kube-log-runner option for copying output to stdout."
        },
        {
          "term": "-redirect-stderr",
          "tier": 3,
          "reasoning": "kube-log-runner option for controlling stderr redirection."
        },
        {
          "term": "klog native format",
          "tier": 2,
          "reasoning": "The traditional output format used by klog for log messages."
        },
        {
          "term": "Structured Logging",
          "tier": 2,
          "reasoning": "Logging approach that introduces uniform structure for programmatic extraction."
        },
        {
          "term": "structured log messages",
          "tier": 2,
          "reasoning": "Log messages with consistent, parseable structure."
        },
        {
          "term": "unstructured log messages",
          "tier": 2,
          "reasoning": "Traditional log messages without uniform structure."
        },
        {
          "term": "log formatting",
          "tier": 2,
          "reasoning": "The process of structuring log output in a specific format."
        },
        {
          "term": "value serialization",
          "tier": 2,
          "reasoning": "Process of converting values to string representation in logs."
        },
        {
          "term": "klog header",
          "tier": 2,
          "reasoning": "The prefix portion of klog output containing metadata."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object shown in log message examples."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Kubernetes workload resource referenced in structured log examples."
        },
        {
          "term": "namespaces",
          "tier": 2,
          "reasoning": "Kubernetes resource for organizing and isolating cluster resources."
        },
        {
          "term": "kube-system",
          "tier": 1,
          "reasoning": "System namespace for Kubernetes core components."
        },
        {
          "term": "metrics-server",
          "tier": 1,
          "reasoning": "Kubernetes component for resource metrics collection."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating the maturity level of Structured Logging."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in log example paths."
        },
        {
          "term": "linux/amd64",
          "tier": 3,
          "reasoning": "Platform identifier indicating operating system and architecture."
        }
      ],
      "term_count": 46,
      "generated_at": "2026-02-08T21:59:19.379833",
      "elapsed_time": 23.73857569694519
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates.md",
      "content": "---\ntitle: DefaultHostNetworkHostPortsInPodTemplates\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: deprecated\n    defaultValue: false\n    fromVersion: \"1.28\"\n    toVersion: \"1.30\"\n\nremoved: true\n---\nThis feature gate controls the point at which a default value for\n`.spec.containers[*].ports[*].hostPort`\nis assigned, for Pods using `hostNetwork: true`. The default since Kubernetes v1.28 is to only set a default\nvalue in Pods.\n\nEnabling this means a default will be assigned even to the `.spec` of an embedded\n[PodTemplate](/docs/concepts/workloads/pods/#pod-templates) (for example, in a Deployment),\nwhich is the way that older releases of Kubernetes worked.\nYou should migrate your code so that it does not rely on the legacy behavior.",
      "terms": [
        {
          "term": "DefaultHostNetworkHostPortsInPodTemplates",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": "feature gate",
          "tier": 1,
          "reasoning": "Alternative form of the feature gate concept appearing in the documentation."
        },
        {
          "term": ".spec.containers[*].ports[*].hostPort",
          "tier": 1,
          "reasoning": "A specific API field path in the Pod specification for container port configuration."
        },
        {
          "term": "hostPort",
          "tier": 2,
          "reasoning": "A Kubernetes networking concept specifying which port on the host node to expose."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "hostNetwork",
          "tier": 2,
          "reasoning": "A Pod networking configuration option that uses the host's network namespace."
        },
        {
          "term": ".spec",
          "tier": 2,
          "reasoning": "The specification section of a Kubernetes resource definition."
        },
        {
          "term": "PodTemplate",
          "tier": 1,
          "reasoning": "A Kubernetes API object that defines a template for creating Pods."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "A core Kubernetes workload resource for managing replicated applications."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": "deprecated",
          "tier": 2,
          "reasoning": "A lifecycle stage indicating a feature is no longer recommended for use."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "A configuration property indicating the default state of a feature gate."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "The fundamental unit of application packaging in Kubernetes."
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Network port configuration for containers in Kubernetes."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "A Kubernetes concept category for applications running on the cluster."
        },
        {
          "term": "embedded",
          "tier": 3,
          "reasoning": "Technical term describing PodTemplates nested within other resources."
        },
        {
          "term": "default value",
          "tier": 2,
          "reasoning": "A configuration concept for automatic value assignment."
        },
        {
          "term": "stages",
          "tier": 2,
          "reasoning": "Feature gate lifecycle phases in Kubernetes."
        },
        {
          "term": "removed",
          "tier": 2,
          "reasoning": "A lifecycle state indicating the feature gate has been eliminated from Kubernetes."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T21:59:31.417594",
      "elapsed_time": 11.026712417602539
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a password.txt file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF >./password.txt\nusername=admin\npassword=secret\nEOF\n\ncat <<EOF >deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  labels:\n    app: my-app\nspec:\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: app\n        image: my-app\n        volumeMounts:\n        - name: password\n          mountPath: /secrets\n      volumes:\n      - name: password\n        secret:\n          secretName: example-secret-1\nEOF\n\ncat <<EOF >./kustomization.yaml\nresources:\n- deployment.yaml\nsecretGenerator:\n- name: example-secret-1\n  files:\n  - password.txt\nEOF\n```\n\n#### generatorOptions\n\nThe generated ConfigMaps and Secrets have a content hash suffix appended. This ensures that\na new ConfigMap or Secret is generated when the contents are changed. To disable the behavior\nof appending a suffix, one can use `generatorOptions`. Besides that, it is also possible to\nspecify cross-cutting options for generated ConfigMaps and Secrets.\n\n```shell\ncat <<EOF >./kustomization.yaml\nconfigMapGenerator:\n- name: example-configmap-3\n  literals:\n  - FOO=Bar\ngeneratorOptions:\n  disableNameSuffixHash: true\n  labels:\n    type: generated\n  annotations:\n    note: generated\nEOF\n```\n\nRun`kubectl kustomize ./` to view the generated ConfigMap:\n\n```yaml\napiVersion: v1\ndata:\n  FOO: Bar\nkind: ConfigMap\nmetadata:\n  annotations:\n    note: generated\n  labels:\n    type: generated\n  name: example-configmap-3\n```\n\n### Setting cross-cutting fields\n\nIt is quite common to set cross-cutting fields for all Kubernetes resources in a project.\nSome use cases for setting cross-cutting fields:\n\n* setting the same namespace for all resources\n* adding the same name prefix or suffix\n* adding the same set of labels\n* adding the same set of annotations\n\nHere is an example:\n\n```shell",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing application deployments"
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data"
        },
        {
          "term": "Secret",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing sensitive data like passwords"
        },
        {
          "term": "secretGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating Secret resources"
        },
        {
          "term": "configMapGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating ConfigMap resources"
        },
        {
          "term": "generatorOptions",
          "tier": 1,
          "reasoning": "Kustomize configuration block for controlling generator behavior"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "kustomize",
          "tier": 1,
          "reasoning": "Kubernetes configuration management tool referenced via kubectl kustomize"
        },
        {
          "term": "kubectl kustomize",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for running kustomize"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying API version"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API version for apps resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying resource type"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource metadata"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource specification"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for matching resources by labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector mechanism for label matching"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for organizing and selecting resources"
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata for attaching non-identifying information"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within Deployment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes spec field defining container configurations"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image specification in Kubernetes"
        },
        {
          "term": "volumeMounts",
          "tier": 2,
          "reasoning": "Kubernetes field for mounting volumes into containers"
        },
        {
          "term": "mountPath",
          "tier": 2,
          "reasoning": "Filesystem path where volume is mounted in container"
        },
        {
          "term": "volumes",
          "tier": 2,
          "reasoning": "Kubernetes field for defining storage volumes"
        },
        {
          "term": "secretName",
          "tier": 2,
          "reasoning": "Reference to a Secret resource by name"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kustomization field listing Kubernetes resource files"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes isolation mechanism for resources"
        },
        {
          "term": "name prefix",
          "tier": 2,
          "reasoning": "Kustomize feature for adding prefix to resource names"
        },
        {
          "term": "content hash suffix",
          "tier": 2,
          "reasoning": "Auto-generated suffix based on content for ConfigMaps/Secrets"
        },
        {
          "term": "disableNameSuffixHash",
          "tier": 2,
          "reasoning": "Kustomize option to disable automatic hash suffix"
        },
        {
          "term": "cross-cutting fields",
          "tier": 2,
          "reasoning": "Configuration applied uniformly across multiple resources"
        },
        {
          "term": "literals",
          "tier": 2,
          "reasoning": "Kustomize field for inline key-value configuration data"
        },
        {
          "term": "files",
          "tier": 2,
          "reasoning": "Kustomize field for referencing external files as data sources"
        },
        {
          "term": "kustomization.yaml",
          "tier": 3,
          "reasoning": "Configuration file for Kustomize"
        },
        {
          "term": "deployment.yaml",
          "tier": 3,
          "reasoning": "YAML file containing Deployment resource definition"
        },
        {
          "term": "password.txt",
          "tier": 3,
          "reasoning": "Example file used as secret data source"
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "Kubernetes core API version"
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:59:47.201418",
      "elapsed_time": 14.774433612823486
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec5",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Specifying a PodDisruptionBudget",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "A `PodDisruptionBudget` has three fields:\n\n- A label selector `.spec.selector` to specify the set of\n  pods to which it applies. This field is required.\n- `.spec.minAvailable` which is a description of the number of pods from that\n  set that must still be available after the eviction, even in the absence\n  of the evicted pod. `minAvailable` can be either an absolute number or a percentage.\n- `.spec.maxUnavailable` (available in Kubernetes 1.7 and higher) which is a description\n  of the number of pods from that set that can be unavailable after the eviction.\n  It can be either an absolute number or a percentage.\n\n{{< note >}}\nThe behavior for an empty selector differs between the policy/v1beta1 and policy/v1 APIs for\nPodDisruptionBudgets. For policy/v1beta1 an empty selector matches zero pods, while\nfor policy/v1 an empty selector matches every pod in the namespace.\n{{< /note >}}\n\nYou can specify only one of `maxUnavailable` and `minAvailable` in a single `PodDisruptionBudget`.\n`maxUnavailable` can only be used to control the eviction of pods\nthat all have the same associated controller managing them. In the examples below, \"desired replicas\"\nis the `scale` of the controller managing the pods being selected by the\n`PodDisruptionBudget`.\n\nExample 1: With a `minAvailable` of 5, evictions are allowed as long as they leave behind\n5 or more [healthy](#healthiness-of-a-pod) pods among those selected by the PodDisruptionBudget's `selector`.\n\nExample 2: With a `minAvailable` of 30%, evictions are allowed as long as at least 30%\nof the number of desired replicas are healthy.\n\nExample 3: With a `maxUnavailable` of 5, evictions are allowed as long as there are at most 5\nunhealthy replicas among the total number of desired replicas.\n\nExample 4: With a `maxUnavailable` of 30%, evictions are allowed as long as the number of \nunhealthy replicas does not exceed 30% of the total number of desired replica rounded up to \nthe nearest integer. If the total number of desired replicas is just one, that single replica\nis still allowed for disruption, leading to an effective unavailability of 100%.\n\nIn typical usage, a single budget would be used for a collection of pods managed by\na controller\u2014for example, the pods in a single ReplicaSet or StatefulSet.\n\n{{< note >}}\nA disruption budget does not truly guarantee that the specified\nnumber/percentage of pods will always be up. For example, a node that hosts a\npod from the collection may fail when the collection is at the minimum size\nspecified in the budget, thus bringing the number of available pods from the\ncollection below the specified size. The budget can only protect against\nvoluntary evictions, not all causes of unavailability.\n{{< /note >}}\n\nIf you set `maxUnavailable` to 0% or 0, or you set `minAvailable` to 100% or the number of replicas,\nyou are requiring zero voluntary evictions. When you set zero voluntary evictions for a workload\nobject such as ReplicaSet, then you cannot successfully drain a Node running one of those Pods.\nIf you try to drain a Node where an unevictable Pod is running, the drain never completes.\nThis is permitted as per the semantics of `PodDisruptionBudget`.\n\nYou can find examples of pod disruption budgets defined below. They match pods with the label\n`app: zookeeper`.\n\nExample PDB Using minAvailable:\n\n{{% code_sample file=\"policy/zookeeper-pod-disruption-budget-minavailable.yaml\" %}}\n\nExample PDB Using maxUnavailable:\n\n{{% code_sample file=\"policy/zookeeper-pod-disruption-budget-maxunavailable.yaml\" %}}\n\nFor example, if the above `zk-pdb` object selects the pods of a StatefulSet of size 3, both\nspecifications have the exact same meaning. The use of `maxUnavailable` is recommended as it\nautomatically responds to changes in the number of replicas of the corresponding controller.",
      "terms": [
        {
          "term": "PodDisruptionBudget",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing pod disruption policies."
        },
        {
          "term": "label selector",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for selecting resources based on labels."
        },
        {
          "term": ".spec.selector",
          "tier": 1,
          "reasoning": "Specific API field path for the PodDisruptionBudget selector configuration."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes resource unit being managed by the disruption budget."
        },
        {
          "term": ".spec.minAvailable",
          "tier": 1,
          "reasoning": "Specific API field for configuring minimum available pods in PDB."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Kubernetes process of removing pods from nodes."
        },
        {
          "term": "minAvailable",
          "tier": 1,
          "reasoning": "PodDisruptionBudget configuration parameter for minimum pod availability."
        },
        {
          "term": ".spec.maxUnavailable",
          "tier": 1,
          "reasoning": "Specific API field for configuring maximum unavailable pods in PDB."
        },
        {
          "term": "maxUnavailable",
          "tier": 1,
          "reasoning": "PodDisruptionBudget configuration parameter for maximum pod unavailability."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform being documented."
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching resources based on criteria."
        },
        {
          "term": "policy/v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API version for PodDisruptionBudget."
        },
        {
          "term": "policy/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API version for PodDisruptionBudget."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes isolation mechanism for resources."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "Kubernetes component that manages the lifecycle of resources."
        },
        {
          "term": "desired replicas",
          "tier": 2,
          "reasoning": "Target number of pod instances specified in a controller."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes concept for the number of replicas of a workload."
        },
        {
          "term": "healthy",
          "tier": 2,
          "reasoning": "Pod health status concept in Kubernetes disruption context."
        },
        {
          "term": "unhealthy replicas",
          "tier": 2,
          "reasoning": "Pods not meeting health criteria in the context of disruption budgets."
        },
        {
          "term": "ReplicaSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload controller that maintains pod replicas."
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload controller for stateful applications."
        },
        {
          "term": "disruption budget",
          "tier": 2,
          "reasoning": "Kubernetes concept for controlling voluntary pod disruptions."
        },
        {
          "term": "node",
          "tier": 1,
          "reasoning": "Kubernetes worker machine that runs pods."
        },
        {
          "term": "voluntary evictions",
          "tier": 2,
          "reasoning": "Intentional pod removals that can be controlled by PDB."
        },
        {
          "term": "unavailability",
          "tier": 2,
          "reasoning": "State of pods not being available in the cluster."
        },
        {
          "term": "zero voluntary evictions",
          "tier": 2,
          "reasoning": "Configuration preventing any intentional pod disruptions."
        },
        {
          "term": "drain",
          "tier": 2,
          "reasoning": "Kubernetes operation to safely remove pods from a node."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Kubernetes cluster component that hosts pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes resource (capitalized form as proper noun)."
        },
        {
          "term": "unevictable Pod",
          "tier": 2,
          "reasoning": "Pod protected from eviction by disruption budget settings."
        },
        {
          "term": "pod disruption budgets",
          "tier": 2,
          "reasoning": "Plural form of the PDB concept for managing disruptions."
        },
        {
          "term": "app: zookeeper",
          "tier": 2,
          "reasoning": "Example label selector value used in PDB configuration."
        },
        {
          "term": "PDB",
          "tier": 1,
          "reasoning": "Abbreviation for PodDisruptionBudget API object."
        },
        {
          "term": "zk-pdb",
          "tier": 1,
          "reasoning": "Example PodDisruptionBudget object name in documentation."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Number of pod instances managed by a controller."
        },
        {
          "term": "percentage",
          "tier": 3,
          "reasoning": "Value type for minAvailable/maxUnavailable configuration."
        },
        {
          "term": "absolute number",
          "tier": 3,
          "reasoning": "Value type for minAvailable/maxUnavailable configuration."
        },
        {
          "term": "evicted pod",
          "tier": 2,
          "reasoning": "Pod that has been removed through the eviction process."
        }
      ],
      "term_count": 38,
      "generated_at": "2026-02-08T22:00:09.994065",
      "elapsed_time": 21.785396575927734
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_options__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_options__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_options__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for options</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "-h",
          "tier": 1,
          "reasoning": "CLI flag shorthand for help option, a specific command-line interface element."
        },
        {
          "term": "--help",
          "tier": 1,
          "reasoning": "CLI flag for displaying help information, a standard command-line option."
        },
        {
          "term": "help",
          "tier": 3,
          "reasoning": "In CLI context, 'help' refers to the built-in documentation/usage information system."
        },
        {
          "term": "options",
          "tier": 3,
          "reasoning": "In CLI context, 'options' refers to command-line flags and parameters that modify command behavior."
        }
      ],
      "term_count": 4,
      "generated_at": "2026-02-08T22:00:15.446049",
      "elapsed_time": 4.4418535232543945
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec11",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create another patch set_memory.yaml",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF > set_memory.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  template:\n    spec:\n      containers:\n      - name: my-nginx\n        resources:\n          limits:\n            memory: 512Mi\nEOF\n\ncat <<EOF >./kustomization.yaml\nresources:\n- deployment.yaml\npatches:\n  - path: increase_replicas.yaml\n  - path: set_memory.yaml\nEOF\n```\n\nRun `kubectl kustomize ./` to view the Deployment:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      run: my-nginx\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - image: nginx\n        name: my-nginx\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            memory: 512Mi\n```\n\nNot all resources or fields support `strategicMerge` patches. To support modifying arbitrary fields in arbitrary resources,\nKustomize offers applying [JSON patch](https://tools.ietf.org/html/rfc6902) through `Json6902`.\nTo find the correct Resource for a `Json6902` patch, it is mandatory to specify the `target` field in `kustomization.yaml`.\n\nFor example, increasing the replica number of a Deployment object can also be done through `Json6902` patch. The target resource\nis matched using `group`, `version`, `kind`, and `name` from the `target` field.\n\n```shell",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing replicated applications"
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file name for Kustomize tool"
        },
        {
          "term": "Kustomize",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration management tool"
        },
        {
          "term": "kubectl kustomize",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for running Kustomize"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "Json6902",
          "tier": 1,
          "reasoning": "Specific Kustomize patch type named after RFC 6902"
        },
        {
          "term": "JSON patch",
          "tier": 2,
          "reasoning": "Technical patching mechanism based on RFC 6902 standard"
        },
        {
          "term": "strategicMerge",
          "tier": 2,
          "reasoning": "Kubernetes-specific merge strategy for patches"
        },
        {
          "term": "patches",
          "tier": 2,
          "reasoning": "Kustomize concept for modifying base resources"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kustomize field specifying base Kubernetes resources to manage"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes deployment configuration for pod count"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod specification field defining container configurations"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for matching pods to controllers"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector type for label-based matching"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for organizing and selecting resources"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within Deployment"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes resource specification field"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes resource metadata section"
        },
        {
          "term": "limits",
          "tier": 2,
          "reasoning": "Resource constraints specification in Kubernetes"
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "Resource type being limited in container specification"
        },
        {
          "term": "target",
          "tier": 2,
          "reasoning": "Kustomize field for specifying which resource to patch"
        },
        {
          "term": "group",
          "tier": 2,
          "reasoning": "Kubernetes API group identifier for resource targeting"
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Kubernetes API version for resource targeting"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes resource type identifier"
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Kubernetes resource identifier field"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying API version"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployments"
        },
        {
          "term": "nginx",
          "tier": 3,
          "reasoning": "Container image being deployed in the example"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container specification field for container image"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes field specifying exposed container port"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Container specification for network port configuration"
        },
        {
          "term": "path",
          "tier": 2,
          "reasoning": "Kustomize patches field specifying patch file location"
        },
        {
          "term": "Resource",
          "tier": 2,
          "reasoning": "Generic term for Kubernetes API objects in Kustomize context"
        },
        {
          "term": "512Mi",
          "tier": 3,
          "reasoning": "Kubernetes memory quantity notation (mebibytes)"
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T22:00:31.615971",
      "elapsed_time": 15.162225723266602
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation.md",
      "content": "---\ntitle: CronJobsScheduledAnnotation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.28\"\n    toVersion: \"1.31\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.32\"\n\n---\nSet the scheduled job time as an\n{{< glossary_tooltip text=\"annotation\" term_id=\"annotation\" >}} on Jobs that were created\non behalf of a CronJob.",
      "terms": [
        {
          "term": "CronJobsScheduledAnnotation",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling optional features, appearing as the content_type."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "A Kubernetes concept for attaching non-identifying metadata to objects."
        },
        {
          "term": "Jobs",
          "tier": 1,
          "reasoning": "A Kubernetes API object/resource that runs tasks to completion."
        },
        {
          "term": "CronJob",
          "tier": 1,
          "reasoning": "A Kubernetes API object that creates Jobs on a time-based schedule."
        },
        {
          "term": "scheduled job time",
          "tier": 2,
          "reasoning": "A domain concept referring to the time when a job is scheduled to run."
        },
        {
          "term": "beta",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is well-tested but not yet stable."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is production-ready and enabled by default."
        },
        {
          "term": "stage",
          "tier": 3,
          "reasoning": "Technical term describing the maturity phase of a feature gate in Kubernetes."
        },
        {
          "term": "defaultValue",
          "tier": 3,
          "reasoning": "A configuration property indicating whether a feature gate is enabled by default."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Technical metadata indicating the Kubernetes version when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Technical metadata indicating the Kubernetes version when a feature stage ends."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:00:40.211906",
      "elapsed_time": 7.588131904602051
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec16",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Issuer`     {#apiserver-config-k8s-io-v1-Issuer}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>Issuer provides the configuration for an external provider's specific settings.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>url points to the issuer URL in a format https://url or https://url/path.\nThis must match the &quot;iss&quot; claim in the presented JWT, and the issuer returned from discovery.\nSame value as the --oidc-issuer-url flag.\nDiscovery information is fetched from &quot;{url}/.well-known/openid-configuration&quot; unless overridden by discoveryURL.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>discoveryURL</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>discoveryURL, if specified, overrides the URL used to fetch discovery\ninformation instead of using &quot;{url}/.well-known/openid-configuration&quot;.\nThe exact value specified is used, so &quot;/.well-known/openid-configuration&quot;\nmust be included in discoveryURL if needed.</p>\n<p>The &quot;issuer&quot; field in the fetched discovery information must match the &quot;issuer.url&quot; field\nin the AuthenticationConfiguration and will be used to validate the &quot;iss&quot; claim in the presented JWT.\nThis is for scenarios where the well-known and jwks endpoints are hosted at a different\nlocation than the issuer (such as locally in the cluster).</p>\n<p>Example:\nA discovery url that is exposed using kubernetes service 'oidc' in namespace 'oidc-namespace'\nand discovery information is available at '/.well-known/openid-configuration'.\ndiscoveryURL: &quot;https://oidc.oidc-namespace/.well-known/openid-configuration&quot;\ncertificateAuthority is used to verify the TLS connection and the hostname on the leaf certificate\nmust be set to 'oidc.oidc-namespace'.</p>\n<p>curl https://oidc.oidc-namespace/.well-known/openid-configuration (.discoveryURL field)\n{\nissuer: &quot;https://oidc.example.com&quot; (.url field)\n}</p>\n<p>discoveryURL must be different from url.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>certificateAuthority</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>certificateAuthority contains PEM-encoded certificate authority certificates\nused to validate the connection when fetching discovery information.\nIf unset, the system verifier is used.\nSame value as the content of the file referenced by the --oidc-ca-file flag.</p>\n</td>\n</tr>\n<tr><td><code>audiences</code> <B>[Required]</B><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>audiences is the set of acceptable audiences the JWT must be issued to.\nAt least one of the entries must match the &quot;aud&quot; claim in presented JWTs.\nSame value as the --oidc-client-id flag (though this field supports an array).\nRequired to be non-empty.</p>\n</td>\n</tr>\n<tr><td><code>audienceMatchPolicy</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AudienceMatchPolicyType\"><code>AudienceMatchPolicyType</code></a>\n</td>\n<td>\n   <p>audienceMatchPolicy defines how the &quot;audiences&quot; field is used to match the &quot;aud&quot; claim in the presented JWT.\nAllowed values are:</p>\n<ol>\n<li>&quot;MatchAny&quot; when multiple audiences are specified and</li>\n<li>empty (or unset) or &quot;MatchAny&quot; when a single audience is specified.</li>\n</ol>\n<ul>\n<li>\n<p>MatchAny: the &quot;aud&quot; claim in the presented JWT must match at least one of the entries in the &quot;audiences&quot; field.\nFor example, if &quot;audiences&quot; is [&quot;foo&quot;, &quot;bar&quot;], the &quot;aud&quot; claim in the presented JWT must contain either &quot;foo&quot; or &quot;bar&quot; (and may contain both).</p>\n</li>\n<li>\n<p>&quot;&quot;: The match policy can be empty (or unset) when a single audience is specified in the &quot;audiences&quot; field. The &quot;aud&quot; claim in the presented JWT must contain the single audience (and may contain others).</p>\n</li>\n</ul>\n<p>For more nuanced audience validation, use claimValidationRules.\nexample: claimValidationRule[].expression: 'sets.equivalent(claims.aud, [&quot;bar&quot;, &quot;foo&quot;, &quot;baz&quot;])' to require an exact match.</p>\n</td>\n</tr>\n<tr><td><code>egressSelectorType</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-EgressSelectorType\"><code>EgressSelectorType</code></a>\n</td>\n<td>\n   <p>egressSelectorType is an indicator of which egress selection should be used for sending all traffic related\nto this issuer (discovery, JWKS, distributed claims, etc).  If unspecified, no custom dialer is used.\nWhen specified, the valid choices are &quot;controlplane&quot; and &quot;cluster&quot;.  These correspond to the associated\nvalues in the --egress-selector-config-file.</p>\n<ul>\n<li>\n<p>controlplane: for traffic intended to go to the control plane.</p>\n</li>\n<li>\n<p>cluster: for traffic intended to go to the system being managed by Kubernetes.</p>\n</li>\n</ul>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration"
        },
        {
          "term": "Issuer",
          "tier": 1,
          "reasoning": "Named configuration component for external identity provider settings"
        },
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for authentication settings"
        },
        {
          "term": "AudienceMatchPolicyType",
          "tier": 1,
          "reasoning": "Named Kubernetes API type for audience matching policy configuration"
        },
        {
          "term": "JWT",
          "tier": 2,
          "reasoning": "JSON Web Token - core authentication token format used throughout the document"
        },
        {
          "term": "JWT authenticators",
          "tier": 2,
          "reasoning": "Domain concept referring to authentication components that validate JWTs"
        },
        {
          "term": "url",
          "tier": 2,
          "reasoning": "Configuration field pointing to the issuer URL for JWT validation"
        },
        {
          "term": "discoveryURL",
          "tier": 2,
          "reasoning": "Configuration field that overrides the default OIDC discovery endpoint"
        },
        {
          "term": "certificateAuthority",
          "tier": 2,
          "reasoning": "Configuration field containing PEM-encoded CA certificates for TLS validation"
        },
        {
          "term": "audiences",
          "tier": 2,
          "reasoning": "Configuration field specifying acceptable JWT audience values"
        },
        {
          "term": "audienceMatchPolicy",
          "tier": 2,
          "reasoning": "Configuration field defining how audience claims are matched"
        },
        {
          "term": "iss",
          "tier": 2,
          "reasoning": "JWT claim field representing the token issuer"
        },
        {
          "term": "aud",
          "tier": 2,
          "reasoning": "JWT claim field representing the token audience"
        },
        {
          "term": "issuer",
          "tier": 2,
          "reasoning": "Identity provider that issues JWTs, referenced in discovery information"
        },
        {
          "term": "discovery information",
          "tier": 2,
          "reasoning": "OIDC metadata fetched from well-known endpoint for authentication configuration"
        },
        {
          "term": "openid-configuration",
          "tier": 2,
          "reasoning": "Standard OIDC discovery endpoint path for provider metadata"
        },
        {
          "term": ".well-known/openid-configuration",
          "tier": 2,
          "reasoning": "Standard well-known path for OIDC discovery endpoint"
        },
        {
          "term": "OIDC",
          "tier": 2,
          "reasoning": "OpenID Connect - authentication protocol referenced via flags and discovery"
        },
        {
          "term": "--oidc-issuer-url",
          "tier": 1,
          "reasoning": "CLI flag for configuring the OIDC issuer URL"
        },
        {
          "term": "--oidc-ca-file",
          "tier": 1,
          "reasoning": "CLI flag for specifying the OIDC CA certificate file"
        },
        {
          "term": "--oidc-client-id",
          "tier": 1,
          "reasoning": "CLI flag for configuring the OIDC client ID"
        },
        {
          "term": "egress selection configuration",
          "tier": 2,
          "reasoning": "Kubernetes network configuration concept for outbound connections"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol used for secure connections"
        },
        {
          "term": "TLS connection",
          "tier": 2,
          "reasoning": "Secure connection verified using certificate authority"
        },
        {
          "term": "PEM-encoded",
          "tier": 3,
          "reasoning": "Certificate encoding format for certificate authority data"
        },
        {
          "term": "certificate authority certificates",
          "tier": 2,
          "reasoning": "CA certificates used to validate TLS connections"
        },
        {
          "term": "leaf certificate",
          "tier": 2,
          "reasoning": "End-entity certificate whose hostname is validated"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Network identifier validated on leaf certificates"
        },
        {
          "term": "jwks endpoints",
          "tier": 2,
          "reasoning": "JSON Web Key Set endpoints for retrieving public keys"
        },
        {
          "term": "kubernetes service",
          "tier": 1,
          "reasoning": "Named Kubernetes resource type for service discovery"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes isolation concept referenced in service example"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster context where services are hosted"
        },
        {
          "term": "MatchAny",
          "tier": 2,
          "reasoning": "Specific audience match policy value for JWT validation"
        },
        {
          "term": "system verifier",
          "tier": 2,
          "reasoning": "Default certificate verification mechanism when CA is unset"
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Secure HTTP protocol required for issuer URLs"
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool referenced in discovery URL example"
        }
      ],
      "term_count": 36,
      "generated_at": "2026-02-08T22:01:01.684018",
      "elapsed_time": 20.460999250411987
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_logs__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_logs__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_logs__index.md",
      "content": "```\n  # Return snapshot logs from pod nginx with only one container\n  kubectl logs nginx\n  \n  # Return snapshot logs from pod nginx, prefixing each line with the source pod and container name\n  kubectl logs nginx --prefix\n  \n  # Return snapshot logs from pod nginx, limiting output to 500 bytes\n  kubectl logs nginx --limit-bytes=500\n  \n  # Return snapshot logs from pod nginx, waiting up to 20 seconds for it to start running.\n  kubectl logs nginx --pod-running-timeout=20s\n  \n  # Return snapshot logs from pod nginx with multi containers\n  kubectl logs nginx --all-containers=true\n  \n  # Return snapshot logs from all pods in the deployment nginx\n  kubectl logs deployment/nginx --all-pods=true\n  \n  # Return snapshot logs from all containers in pods defined by label app=nginx\n  kubectl logs -l app=nginx --all-containers=true\n  \n  # Return snapshot logs from all pods defined by label app=nginx, limiting concurrent log requests to 10 pods\n  kubectl logs -l app=nginx --max-log-requests=10\n  \n  # Return snapshot of previous terminated ruby container logs from pod web-1\n  kubectl logs -p -c ruby web-1\n  \n  # Begin streaming the logs from pod nginx, continuing even if errors occur\n  kubectl logs nginx -f --ignore-errors=true\n  \n  # Begin streaming the logs of the ruby container in pod web-1\n  kubectl logs -f -c ruby web-1\n  \n  # Begin streaming the logs from all containers in pods defined by label app=nginx\n  kubectl logs -f -l app=nginx --all-containers=true\n  \n  # Display only the most recent 20 lines of output in pod nginx\n  kubectl logs --tail=20 nginx\n  \n  # Show all logs from pod nginx written in the last hour\n  kubectl logs --since=1h nginx\n  \n  # Show all logs with timestamps from pod nginx starting from August 30, 2024, at 06:00:00 UTC\n  kubectl logs nginx --since-time=2024-08-30T06:00:00Z --timestamps=true\n  \n  # Show logs from a kubelet with an expired serving certificate\n  kubectl logs --insecure-skip-tls-verify-backend nginx\n  \n  # Return snapshot logs from first container of a job named hello\n  kubectl logs job/hello\n  \n  # Return snapshot logs from container nginx-1 of a deployment named nginx\n  kubectl logs deployment/nginx -c nginx-1\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout all examples"
        },
        {
          "term": "logs",
          "tier": 2,
          "reasoning": "Kubernetes subcommand for retrieving container/pod log output"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental unit of deployment"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container/pod name used as example, represents a well-known web server"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept - isolated runtime unit within pods"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form used in --all-containers flag context"
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing replicated applications"
        },
        {
          "term": "deployment/nginx",
          "tier": 1,
          "reasoning": "Resource reference syntax for Kubernetes deployments"
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources"
        },
        {
          "term": "app=nginx",
          "tier": 2,
          "reasoning": "Label selector syntax used to filter pods"
        },
        {
          "term": "ruby",
          "tier": 1,
          "reasoning": "Specific container name referenced in multi-container pod examples"
        },
        {
          "term": "web-1",
          "tier": 1,
          "reasoning": "Specific pod name used in examples"
        },
        {
          "term": "job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running batch workloads"
        },
        {
          "term": "job/hello",
          "tier": 1,
          "reasoning": "Resource reference syntax for Kubernetes jobs"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component mentioned in TLS context"
        },
        {
          "term": "--prefix",
          "tier": 2,
          "reasoning": "kubectl logs flag for prefixing output with source information"
        },
        {
          "term": "--limit-bytes",
          "tier": 2,
          "reasoning": "kubectl logs flag for limiting log output size"
        },
        {
          "term": "--pod-running-timeout",
          "tier": 2,
          "reasoning": "kubectl logs flag for waiting on pod startup"
        },
        {
          "term": "--all-containers",
          "tier": 2,
          "reasoning": "kubectl logs flag for retrieving logs from all containers"
        },
        {
          "term": "--all-pods",
          "tier": 2,
          "reasoning": "kubectl logs flag for retrieving logs from all pods in a resource"
        },
        {
          "term": "-l",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for label selector"
        },
        {
          "term": "--max-log-requests",
          "tier": 2,
          "reasoning": "kubectl logs flag for limiting concurrent log requests"
        },
        {
          "term": "-p",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for previous terminated container logs"
        },
        {
          "term": "-c",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for specifying container name"
        },
        {
          "term": "-f",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for following/streaming logs"
        },
        {
          "term": "--ignore-errors",
          "tier": 2,
          "reasoning": "kubectl logs flag for continuing despite errors"
        },
        {
          "term": "--tail",
          "tier": 2,
          "reasoning": "kubectl logs flag for limiting output to recent lines"
        },
        {
          "term": "--since",
          "tier": 2,
          "reasoning": "kubectl logs flag for time-based log filtering"
        },
        {
          "term": "--since-time",
          "tier": 2,
          "reasoning": "kubectl logs flag for absolute timestamp filtering"
        },
        {
          "term": "--timestamps",
          "tier": 2,
          "reasoning": "kubectl logs flag for including timestamps in output"
        },
        {
          "term": "--insecure-skip-tls-verify-backend",
          "tier": 2,
          "reasoning": "kubectl logs flag for bypassing TLS verification"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol referenced in certificate context"
        },
        {
          "term": "serving certificate",
          "tier": 2,
          "reasoning": "TLS certificate used by kubelet for serving requests"
        },
        {
          "term": "streaming",
          "tier": 2,
          "reasoning": "Technical concept for continuous real-time log output"
        },
        {
          "term": "snapshot logs",
          "tier": 2,
          "reasoning": "Point-in-time log retrieval as opposed to streaming"
        },
        {
          "term": "terminated",
          "tier": 2,
          "reasoning": "Container lifecycle state - previously stopped container"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of core Kubernetes resource used throughout"
        },
        {
          "term": "nginx-1",
          "tier": 1,
          "reasoning": "Specific container name in deployment example"
        },
        {
          "term": "UTC",
          "tier": 3,
          "reasoning": "Coordinated Universal Time - timestamp timezone reference"
        },
        {
          "term": "bytes",
          "tier": 3,
          "reasoning": "Unit of data measurement for log size limiting"
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:01:20.647765",
      "elapsed_time": 17.9552743434906
    },
    {
      "chunk_id": "tasks_tls_certificate-rotation_sec1",
      "doc_id": "tasks_tls_certificate-rotation",
      "heading": "Overview",
      "source_file": "tasks_tls_certificate-rotation.md",
      "content": "The kubelet uses certificates for authenticating to the Kubernetes API.  By\ndefault, these certificates are issued with one year expiration so that they do\nnot need to be renewed too frequently.\n\nKubernetes contains [kubelet certificate\nrotation](/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/),\nthat will automatically generate a new key and request a new certificate from\nthe Kubernetes API as the current certificate approaches expiration. Once the\nnew certificate is available, it will be used for authenticating connections to\nthe Kubernetes API.",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for managing pods on a node."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "The primary interface for interacting with Kubernetes clusters, a core infrastructure component."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "certificates",
          "tier": 2,
          "reasoning": "Security credentials used for authentication in the Kubernetes context."
        },
        {
          "term": "authenticating",
          "tier": 2,
          "reasoning": "Security process of verifying identity, a key domain concept in Kubernetes security."
        },
        {
          "term": "certificate",
          "tier": 2,
          "reasoning": "Individual security credential used for TLS/authentication purposes."
        },
        {
          "term": "expiration",
          "tier": 2,
          "reasoning": "Technical concept related to certificate lifecycle management."
        },
        {
          "term": "key",
          "tier": 2,
          "reasoning": "Cryptographic key used in certificate-based authentication."
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Referenced in the linked documentation path (kubelet-tls-bootstrapping), indicating Transport Layer Security protocol."
        },
        {
          "term": "bootstrapping",
          "tier": 2,
          "reasoning": "Referenced in the documentation path, describes the initial setup process for kubelet TLS."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, general technical term used in context of Kubernetes API."
        },
        {
          "term": "connections",
          "tier": 3,
          "reasoning": "Network connections being authenticated, relevant in the context of API communication."
        },
        {
          "term": "access-authn-authz",
          "tier": 2,
          "reasoning": "Path component indicating access, authentication, and authorization domain concepts."
        },
        {
          "term": "authn",
          "tier": 2,
          "reasoning": "Abbreviation for authentication appearing in the documentation path."
        },
        {
          "term": "authz",
          "tier": 2,
          "reasoning": "Abbreviation for authorization appearing in the documentation path."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T22:01:32.473051",
      "elapsed_time": 10.816485166549683
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec6",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Ingress class",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "Ingresses can be implemented by different controllers, often with different\nconfiguration. Each Ingress should specify a class, a reference to an\nIngressClass resource that contains additional configuration including the name\nof the controller that should implement the class.\n\n{{% code_sample file=\"service/networking/external-lb.yaml\" %}}\n\nThe `.spec.parameters` field of an IngressClass lets you reference another\nresource that provides configuration related to that IngressClass.\n\nThe specific type of parameters to use depends on the ingress controller\nthat you specify in the `.spec.controller` field of the IngressClass.\n\n### IngressClass scope\n\nDepending on your ingress controller, you may be able to use parameters\nthat you set cluster-wide, or just for one namespace.\n\n{{< tabs name=\"tabs_ingressclass_parameter_scope\" >}}\n{{% tab name=\"Cluster\" %}}\nThe default scope for IngressClass parameters is cluster-wide.\n\nIf you set the `.spec.parameters` field and don't set\n`.spec.parameters.scope`, or if you set `.spec.parameters.scope` to\n`Cluster`, then the IngressClass refers to a cluster-scoped resource.\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a cluster-scoped API (possibly a custom resource), and\nthe `name` of the parameters identifies a specific cluster scoped\nresource for that API.\n\nFor example:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-1\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in a\n    # ClusterIngressParameter (API group k8s.example.net) named\n    # \"external-config-1\". This definition tells Kubernetes to\n    # look for a cluster-scoped parameter resource.\n    scope: Cluster\n    apiGroup: k8s.example.net\n    kind: ClusterIngressParameter\n    name: external-config-1\n```\n\n{{% /tab %}}\n{{% tab name=\"Namespaced\" %}}\n{{< feature-state for_k8s_version=\"v1.23\" state=\"stable\" >}}\n\nIf you set the `.spec.parameters` field and set\n`.spec.parameters.scope` to `Namespace`, then the IngressClass refers\nto a namespaced-scoped resource. You must also set the `namespace`\nfield within `.spec.parameters` to the namespace that contains\nthe parameters you want to use.\n\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a namespaced API (for example: ConfigMap), and\nthe `name` of the parameters identifies a specific resource\nin the namespace you specified in `namespace`.\n\nNamespace-scoped parameters help the cluster operator delegate control over the\nconfiguration (for example: load balancer settings, API gateway definition)\nthat is used for a workload. If you used a cluster-scoped parameter then either:\n\n- the cluster operator team needs to approve a different team's changes every\n  time there's a new configuration change being applied.\n- the cluster operator must define specific access controls, such as\n  [RBAC](/docs/reference/access-authn-authz/rbac/) roles and bindings, that let\n  the application team make changes to the cluster-scoped parameters resource.\n\nThe IngressClass API itself is always cluster-scoped.\n\nHere is an example of an IngressClass that refers to parameters that are\nnamespaced:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-2\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in an\n    # IngressParameter (API group k8s.example.com) named \"external-config\",\n    # that's in the \"external-configuration\" namespace.\n    scope: Namespace\n    apiGroup: k8s.example.com\n    kind: IngressParameter\n    namespace: external-configuration\n    name: external-config\n```\n\n{{% /tab %}}\n{{< /tabs >}}\n\n### Deprecated annotation\n\nBefore the IngressClass resource and `ingressClassName` field were added in\nKubernetes 1.18, Ingress classes were specified with a\n`kubernetes.io/ingress.class` annotation on the Ingress. This annotation was\nnever formally defined, but was widely supported by Ingress controllers.\n\nThe newer `ingressClassName` field on Ingresses is a replacement for that\nannotation, but is not a direct equivalent. While the annotation was generally\nused to reference the name of the Ingress controller that should implement the\nIngress, the field is a reference to an IngressClass resource that contains\nadditional Ingress configuration, including the name of the Ingress controller.\n\n### Default IngressClass {#default-ingress-class}\n\nYou can mark a particular IngressClass as default for your cluster. Setting the\n`ingressclass.kubernetes.io/is-default-class` annotation to `true` on an\nIngressClass resource will ensure that new Ingresses without an\n`ingressClassName` field specified will be assigned this default IngressClass.\n\n{{< caution >}}\nIf you have more than one IngressClass marked as the default for your cluster,\nthe admission controller prevents creating new Ingress objects that don't have\nan `ingressClassName` specified. You can resolve this by ensuring that at most 1\nIngressClass is marked as default in your cluster.\n{{< /caution >}}\n\nStart by defining a\ndefault IngressClass. It is recommended though, to specify the default\nIngressClass:\n\n{{% code_sample file=\"service/networking/default-ingressclass.yaml\" %}}",
      "terms": [
        {
          "term": "Ingresses",
          "tier": 1,
          "reasoning": "Kubernetes API resource for managing external access to services in a cluster."
        },
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Kubernetes API object that manages external access to services, typically HTTP."
        },
        {
          "term": "controllers",
          "tier": 2,
          "reasoning": "Components that implement the control loop pattern to manage Kubernetes resources."
        },
        {
          "term": "IngressClass",
          "tier": 1,
          "reasoning": "Kubernetes API resource that contains configuration for Ingress controllers."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "A component that watches the state of the cluster and makes changes to move toward desired state."
        },
        {
          "term": ".spec.parameters",
          "tier": 1,
          "reasoning": "Specific field path in IngressClass resource for referencing configuration parameters."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "A Kubernetes API object that represents cluster state."
        },
        {
          "term": "ingress controller",
          "tier": 1,
          "reasoning": "A specialized controller that implements the Ingress specification."
        },
        {
          "term": ".spec.controller",
          "tier": 1,
          "reasoning": "Field in IngressClass that specifies which controller should implement the class."
        },
        {
          "term": "IngressClass scope",
          "tier": 2,
          "reasoning": "Concept describing whether IngressClass parameters apply cluster-wide or per-namespace."
        },
        {
          "term": "cluster-wide",
          "tier": 2,
          "reasoning": "Scope indicating resources or settings that apply across the entire cluster."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for isolating groups of resources within a cluster."
        },
        {
          "term": "cluster-scoped",
          "tier": 2,
          "reasoning": "Resources that exist at the cluster level rather than within a namespace."
        },
        {
          "term": ".spec.parameters.scope",
          "tier": 1,
          "reasoning": "Field that determines whether IngressClass parameters are cluster or namespace scoped."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Scope value indicating cluster-wide parameter applicability."
        },
        {
          "term": "apiGroup",
          "tier": 1,
          "reasoning": "Kubernetes API field specifying the API group of a referenced resource."
        },
        {
          "term": "kind",
          "tier": 1,
          "reasoning": "Kubernetes API field specifying the type of resource being referenced."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Extension of the Kubernetes API that allows users to define their own resource types."
        },
        {
          "term": "ClusterIngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for cluster-scoped Ingress parameters."
        },
        {
          "term": "apiVersion",
          "tier": 1,
          "reasoning": "Kubernetes manifest field specifying the API version of the resource."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for networking resources including Ingress."
        },
        {
          "term": "metadata",
          "tier": 1,
          "reasoning": "Kubernetes resource field containing identifying information like name and labels."
        },
        {
          "term": "spec",
          "tier": 1,
          "reasoning": "Kubernetes resource field containing the desired state specification."
        },
        {
          "term": "Namespace",
          "tier": 2,
          "reasoning": "Scope value indicating namespace-level parameter applicability."
        },
        {
          "term": "namespaced-scoped",
          "tier": 2,
          "reasoning": "Resources that exist within a specific namespace."
        },
        {
          "term": "namespaced API",
          "tier": 2,
          "reasoning": "Kubernetes APIs for resources that are scoped to a namespace."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object used to store non-confidential configuration data."
        },
        {
          "term": "cluster operator",
          "tier": 2,
          "reasoning": "Role responsible for managing and maintaining Kubernetes cluster infrastructure."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Component that distributes network traffic across multiple backend services."
        },
        {
          "term": "API gateway",
          "tier": 2,
          "reasoning": "Service that manages API traffic, routing, and policies."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Applications running on Kubernetes, typically as Pods."
        },
        {
          "term": "RBAC",
          "tier": 1,
          "reasoning": "Role-Based Access Control - Kubernetes authorization mechanism."
        },
        {
          "term": "roles",
          "tier": 2,
          "reasoning": "RBAC resources that define permissions within a namespace."
        },
        {
          "term": "bindings",
          "tier": 2,
          "reasoning": "RBAC resources that associate roles with users or service accounts."
        },
        {
          "term": "IngressClass API",
          "tier": 1,
          "reasoning": "The Kubernetes API for managing IngressClass resources."
        },
        {
          "term": "IngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for namespace-scoped Ingress parameters."
        },
        {
          "term": "ingressClassName",
          "tier": 1,
          "reasoning": "Field on Ingress resources that references an IngressClass."
        },
        {
          "term": "kubernetes.io/ingress.class",
          "tier": 1,
          "reasoning": "Deprecated annotation used to specify Ingress class before IngressClass resource existed."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for attaching arbitrary non-identifying information to objects."
        },
        {
          "term": "Kubernetes 1.18",
          "tier": 2,
          "reasoning": "Specific Kubernetes version when IngressClass resource was introduced."
        },
        {
          "term": "v1.23",
          "tier": 2,
          "reasoning": "Kubernetes version when namespace-scoped IngressClass parameters became stable."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready functionality."
        },
        {
          "term": "access controls",
          "tier": 2,
          "reasoning": "Mechanisms for restricting who can perform actions on resources."
        }
      ],
      "term_count": 43,
      "generated_at": "2026-02-08T22:01:56.216513",
      "elapsed_time": 22.734813690185547
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec3",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "JSONSchemaProps {#JSONSchemaProps}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "JSONSchemaProps is a JSON-Schema following Specification Draft 4 (http://json-schema.org/).\n\n<hr>\n\n- **$ref** (string)\n\n\n- **$schema** (string)\n\n\n- **additionalItems** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **additionalProperties** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **allOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **anyOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **default** (JSON)\n\n  default is a default value for undefined object fields. Defaulting is a beta feature under the CustomResourceDefaulting feature gate. Defaulting requires spec.preserveUnknownFields to be false.\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **definitions** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **dependencies** (map[string]JSONSchemaPropsOrStringArray)\n\n\n  <a name=\"JSONSchemaPropsOrStringArray\"></a>\n  *JSONSchemaPropsOrStringArray represents a JSONSchemaProps or a string array.*\n\n- **description** (string)\n\n\n- **enum** ([]JSON)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **example** (JSON)\n\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **exclusiveMaximum** (boolean)\n\n\n- **exclusiveMinimum** (boolean)\n\n\n- **externalDocs** (ExternalDocumentation)\n\n\n  <a name=\"ExternalDocumentation\"></a>\n  *ExternalDocumentation allows referencing an external resource for extended documentation.*\n\n  - **externalDocs.description** (string)\n\n\n  - **externalDocs.url** (string)\n\n\n- **format** (string)\n\n  format is an OpenAPI v3 format string. Unknown formats are ignored. The following formats are validated:\n  \n  - bsonobjectid: a bson object ID, i.e. a 24 characters hex string - uri: an URI as parsed by Golang net/url.ParseRequestURI - email: an email address as parsed by Golang net/mail.ParseAddress - hostname: a valid representation for an Internet host name, as defined by RFC 1034, section 3.1 [RFC1034]. - ipv4: an IPv4 IP as parsed by Golang net.ParseIP - ipv6: an IPv6 IP as parsed by Golang net.ParseIP - cidr: a CIDR as parsed by Golang net.ParseCIDR - mac: a MAC address as parsed by Golang net.ParseMAC - uuid: an UUID that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid3: an UUID3 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?3[0-9a-f]{3}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid4: an UUID4 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?4[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - uuid5: an UUID5 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?5[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - isbn: an ISBN10 or ISBN13 number string like \"0321751043\" or \"978-0321751041\" - isbn10: an ISBN10 number string like \"0321751043\" - isbn13: an ISBN13 number string like \"978-0321751041\" - creditcard: a credit card number defined by the regex ^(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|6(?:011|5[0-9][0-9])[0-9]{12}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|(?:2131|1800|35\\\\d{3})\\\\d{11})$ with any non digit characters mixed in - ssn: a U.S. social security number following the regex ^\\\\d{3}[- ]?\\\\d{2}[- ]?\\\\d{4}$ - hexcolor: an hexadecimal color code like \"#FFFFFF: following the regex ^#?([0-9a-fA-F]{3}|[0-9a-fA-F]{6})$ - rgbcolor: an RGB color code like rgb like \"rgb(255,255,2559\" - byte: base64 encoded binary data - password: any kind of string - date: a date string like \"2006-01-02\" as defined by full-date in RFC3339 - duration: a duration string like \"22 ns\" as parsed by Golang time.ParseDuration or compatible with Scala duration format - datetime: a date time string like \"2014-12-15T19:30:20.000Z\" as defined by date-time in RFC3339.\n\n- **id** (string)\n\n\n- **items** (JSONSchemaPropsOrArray)\n\n\n  <a name=\"JSONSchemaPropsOrArray\"></a>\n  *JSONSchemaPropsOrArray represents a value that can either be a JSONSchemaProps or an array of JSONSchemaProps. Mainly here for serialization purposes.*\n\n- **maxItems** (int64)\n\n\n- **maxLength** (int64)\n\n\n- **maxProperties** (int64)\n\n\n- **maximum** (double)\n\n\n- **minItems** (int64)\n\n\n- **minLength** (int64)\n\n\n- **minProperties** (int64)\n\n\n- **minimum** (double)\n\n\n- **multipleOf** (double)\n\n\n- **not** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **nullable** (boolean)\n\n\n- **oneOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **pattern** (string)\n\n\n- **patternProperties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **properties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **required** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **title** (string)\n\n\n- **type** (string)\n\n\n- **uniqueItems** (boolean)\n\n\n- **x-kubernetes-embedded-resource** (boolean)\n\n  x-kubernetes-embedded-resource defines that the value is an embedded Kubernetes runtime.Object, with TypeMeta and ObjectMeta. The type must be object. It is allowed to further restrict the embedded object. kind, apiVersion and metadata are validated automatically. x-kubernetes-preserve-unknown-fields is allowed to be true, but does not have to be if the object is fully specified (up to kind, apiVersion, metadata).\n\n- **x-kubernetes-int-or-string** (boolean)\n\n  x-kubernetes-int-or-string specifies that this value is either an integer or a string. If this is true, an empty type is allowed and type as child of anyOf is permitted if following one of the following patterns:\n  \n  1) anyOf:\n     - type: integer\n     - type: string\n  2) allOf:\n     - anyOf:\n       - type: integer\n       - type: string\n     - ... zero or more\n\n- **x-kubernetes-list-map-keys** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  x-kubernetes-list-map-keys annotates an array with the x-kubernetes-list-type `map` by specifying the keys used as the index of the map.\n  \n  This tag MUST only be used on lists that have the \"x-kubernetes-list-type\" extension set to \"map\". Also, the values specified for this attribute must be a scalar typed field of the child structure (no nesting is supported).\n  \n  The properties specified must either be required or have a default value, to ensure those properties are present for all list items.\n\n- **x-kubernetes-list-type** (string)\n\n  x-kubernetes-list-type annotates an array to further describe its topology. This extension must only be used on lists and may have 3 possible values:\n  \n  1) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic lists will be entirely replaced when updated. This extension\n       may be used on any type of list (struct, scalar, ...).\n  2) `set`:\n       Sets are lists that must not have multiple items with the same value. Each\n       value must be a scalar, an object with x-kubernetes-map-type `atomic` or an\n       array with x-kubernetes-list-type `atomic`.\n  3) `map`:\n       These lists are like maps in that their elements have a non-index key\n       used to identify them. Order is preserved upon merge. The map tag\n       must only be used on a list with elements of type object.\n  Defaults to atomic for arrays.\n\n- **x-kubernetes-map-type** (string)\n\n  x-kubernetes-map-type annotates an object to further describe its topology. This extension must only be used when type is object and may have 2 possible values:\n  \n  1) `granular`:\n       These maps are actual maps (key-value pairs) and each fields are independent\n       from each other (they can each be manipulated by separate actors). This is\n       the default behaviour for all maps.\n  2) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic maps will be entirely replaced when updated.\n\n- **x-kubernetes-preserve-unknown-fields** (boolean)\n\n  x-kubernetes-preserve-unknown-fields stops the API server decoding step from pruning fields which are not specified in the validation schema. This affects fields recursively, but switches back to normal pruning behaviour if nested properties or additionalProperties are specified in the schema. This can either be true or undefined. False is forbidden.\n\n- **x-kubernetes-validations** ([]ValidationRule)\n\n  *Patch strategy: merge on key `rule`*\n  \n  *Map: unique values on key rule will be kept during a merge*\n  \n  x-kubernetes-validations describes a list of validation rules written in the CEL expression language.\n\n  <a name=\"ValidationRule\"></a>\n  *ValidationRule describes a validation rule written in the CEL expression language.*\n\n  - **x-kubernetes-validations.rule** (string), required\n\n    Rule represents the expression which will be evaluated by CEL. ref: https://github.com/google/cel-spec The Rule is scoped to the location of the x-kubernetes-validations extension in the schema. The `self` variable in the CEL expression is bound to the scoped value. Example: - Rule scoped to the root of a resource with a status subresource: {\"rule\": \"self.status.actual \\<= self.spec.maxDesired\"}\n    \n    If the Rule is scoped to an object with properties, the accessible properties of the object are field selectable via `self.field` and field presence can be checked via `has(self.field)`. Null valued fields are treated as absent fields in CEL expressions. If the Rule is scoped to an object with additionalProperties (i.e. a map) the value of the map are accessible via `self[mapKey]`, map containment can be checked via `mapKey in self` and all entries of the map are accessible via CEL macros and functions such as `self.all(...)`. If the Rule is scoped to an array, the elements of the array are accessible via `self[i]` and also by macros and functions. If the Rule is scoped to a scalar, `self` is bound to the scalar value. Examples: - Rule scoped to a map of objects: {\"rule\": \"self.components['Widget'].priority \\< 10\"} - Rule scoped to a list of integers: {\"rule\": \"self.values.all(value, value >= 0 && value \\< 100)\"} - Rule scoped to a string value: {\"rule\": \"self.startsWith('kube')\"}\n    \n    The `apiVersion`, `kind`, `metadata.name` and `metadata.generateName` are always accessible from the root of the object and from any x-kubernetes-embedded-resource annotated objects. No other metadata properties are accessible.\n    \n    Unknown data preserved in custom resources via x-kubernetes-preserve-unknown-fields is not accessible in CEL expressions. This includes: - Unknown field values that are preserved by object schemas with x-kubernetes-preserve-unknown-fields. - Object properties where the property schema is of an \"unknown type\". An \"unknown type\" is recursively defined as:\n      - A schema with no type and x-kubernetes-preserve-unknown-fields set to true\n      - An array where the items schema is of an \"unknown type\"\n      - An object where the additionalProperties schema is of an \"unknown type\"\n    \n    Only property names of the form `[a-zA-Z_.-/][a-zA-Z0-9_.-/]*` are accessible. Accessible property names are escaped according to the following rules when accessed in the expression: - '__' escapes to '__underscores__' - '.' escapes to '__dot__' - '-' escapes to '__dash__' - '/' escapes to '__slash__' - Property names that exactly match a CEL RESERVED keyword escape to '__{keyword}__'. The keywords are:\n    \t  \"true\", \"false\", \"null\", \"in\", \"as\", \"break\", \"const\", \"continue\", \"else\", \"for\", \"function\", \"if\",\n    \t  \"import\", \"let\", \"loop\", \"package\", \"namespace\", \"return\".\n    Examples:\n      - Rule accessing a property named \"namespace\": {\"rule\": \"self.__namespace__ > 0\"}\n      - Rule accessing a property named \"x-prop\": {\"rule\": \"self.x__dash__prop > 0\"}\n      - Rule accessing a property named \"redact__d\": {\"rule\": \"self.redact__underscores__d > 0\"}\n    \n    Equality on arrays with x-kubernetes-list-type of 'set' or 'map' ignores element order, i.e. [1, 2] == [2, 1]. Concatenation on arrays with x-kubernetes-list-type use the semantics of the list type:\n      - 'set': `X + Y` performs a union where the array positions of all elements in `X` are preserved and\n        non-intersecting elements in `Y` are appended, retaining their partial order.\n      - 'map': `X + Y` performs a merge where the array positions of all keys in `X` are preserved but the values\n        are overwritten by values in `Y` when the key sets of `X` and `Y` intersect. Elements in `Y` with\n        non-intersecting keys are appended, retaining their partial order.\n    \n    If `rule` makes use of the `oldSelf` variable it is implicitly a `transition rule`.\n    \n    By default, the `oldSelf` variable is the same type as `self`. When `optionalOldSelf` is true, the `oldSelf` variable is a CEL optional\n     variable whose value() is the same type as `self`.\n    See the documentation for the `optionalOldSelf` field for details.\n    \n    Transition rules by default are applied only on UPDATE requests and are skipped if an old value could not be found. You can opt a transition rule into unconditional evaluation by setting `optionalOldSelf` to true.\n\n  - **x-kubernetes-validations.fieldPath** (string)\n\n    fieldPath represents the field path returned when the validation fails. It must be a relative JSON path (i.e. with array notation) scoped to the location of this x-kubernetes-validations extension in the schema and refer to an existing field. e.g. when validation checks if a specific attribute `foo` under a map `testMap`, the fieldPath could be set to `.testMap.foo` If the validation checks two lists must have unique attributes, the fieldPath could be set to either of the list: e.g. `.testList` It does not support list numeric index. It supports child operation to refer to an existing field currently. Refer to [JSONPath support in Kubernetes](https://kubernetes.io/docs/reference/kubectl/jsonpath/) for more info. Numeric index of array is not supported. For field name which contains special characters, use `['specialName']` to refer the field name. e.g. for attribute `foo.34$` appears in a list `testList`, the fieldPath could be set to `.testList['foo.34$']`\n\n  - **x-kubernetes-validations.message** (string)\n\n    Message represents the message displayed when validation fails. The message is required if the Rule contains line breaks. The message must not contain line breaks. If unset, the message is \"failed rule: {Rule}\". e.g. \"must be a URL with the host matching spec.host\"\n\n  - **x-kubernetes-validations.messageExpression** (string)\n\n    MessageExpression declares a CEL expression that evaluates to the validation failure message that is returned when this rule fails. Since messageExpression is used as a failure message, it must evaluate to a string. If both message and messageExpression are present on a rule, then messageExpression will be used if validation fails. If messageExpression results in a runtime error, the runtime error is logged, and the validation failure message is produced as if the messageExpression field were unset. If messageExpression evaluates to an empty string, a string with only spaces, or a string that contains line breaks, then the validation failure message will also be produced as if the messageExpression field were unset, and the fact that messageExpression produced an empty string/string with only spaces/string with line breaks will be logged. messageExpression has access to all the same variables as the rule; the only difference is the return type. Example: \"x must be less than max (\"+string(self.max)+\")\"\n\n  - **x-kubernetes-validations.optionalOldSelf** (boolean)\n\n    optionalOldSelf is used to opt a transition rule into evaluation even when the object is first created, or if the old object is missing the value.\n    \n    When enabled `oldSelf` will be a CEL optional whose value will be `None` if there is no old value, or when the object is initially created.\n    \n    You may check for presence of oldSelf using `oldSelf.hasValue()` and unwrap it after checking using `oldSelf.value()`. Check the CEL documentation for Optional types for more information: https://pkg.go.dev/github.com/google/cel-go/cel#OptionalTypes\n    \n    May not be set unless `oldSelf` is used in `rule`.\n\n  - **x-kubernetes-validations.reason** (string)\n\n    reason provides a machine-readable validation failure reason that is returned to the caller when a request fails this validation rule. The HTTP status code returned to the caller will match the reason of the reason of the first failed validation rule. The currently supported reasons are: \"FieldValueInvalid\", \"FieldValueForbidden\", \"FieldValueRequired\", \"FieldValueDuplicate\". If not set, default to use \"FieldValueInvalid\". All future added reasons must be accepted by clients when reading this value and unknown reasons should be treated as FieldValueInvalid.\n    \n    Possible enum values:\n     - `\"FieldValueDuplicate\"` is used to report collisions of values that must be unique (e.g. unique IDs).\n     - `\"FieldValueForbidden\"` is used to report valid (as per formatting rules) values which would be accepted under some conditions, but which are not permitted by the current conditions (such as security policy).\n     - `\"FieldValueInvalid\"` is used to report malformed values (e.g. failed regex match, too long, out of bounds).\n     - `\"FieldValueRequired\"` is used to report required values that are not provided (e.g. empty strings, null values, or empty arrays).",
      "terms": [
        {
          "term": "JSONSchemaProps",
          "tier": 1,
          "reasoning": "Core API type representing JSON Schema properties in Kubernetes CRD definitions"
        },
        {
          "term": "JSON-Schema",
          "tier": 2,
          "reasoning": "Domain standard specification that JSONSchemaProps follows"
        },
        {
          "term": "Specification Draft 4",
          "tier": 2,
          "reasoning": "Specific version of JSON Schema specification referenced"
        },
        {
          "term": "$ref",
          "tier": 3,
          "reasoning": "JSON Schema keyword for referencing other schemas"
        },
        {
          "term": "$schema",
          "tier": 3,
          "reasoning": "JSON Schema keyword for declaring schema version"
        },
        {
          "term": "additionalItems",
          "tier": 2,
          "reasoning": "JSON Schema property controlling validation of additional array items"
        },
        {
          "term": "JSONSchemaPropsOrBool",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or boolean value"
        },
        {
          "term": "additionalProperties",
          "tier": 2,
          "reasoning": "JSON Schema property controlling validation of additional object properties"
        },
        {
          "term": "allOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical AND"
        },
        {
          "term": "Atomic",
          "tier": 2,
          "reasoning": "Kubernetes merge strategy indicating field will be replaced during merge"
        },
        {
          "term": "anyOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical OR"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "JSON Schema property for specifying default values for undefined fields"
        },
        {
          "term": "CustomResourceDefaulting",
          "tier": 1,
          "reasoning": "Kubernetes feature gate controlling defaulting behavior for custom resources"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling features"
        },
        {
          "term": "spec.preserveUnknownFields",
          "tier": 1,
          "reasoning": "CRD spec field controlling preservation of unknown fields"
        },
        {
          "term": "JSON",
          "tier": 2,
          "reasoning": "Data format type representing valid JSON values in Kubernetes"
        },
        {
          "term": "definitions",
          "tier": 2,
          "reasoning": "JSON Schema keyword for reusable schema definitions"
        },
        {
          "term": "dependencies",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining property dependencies"
        },
        {
          "term": "JSONSchemaPropsOrStringArray",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or string array"
        },
        {
          "term": "description",
          "tier": 3,
          "reasoning": "JSON Schema property for human-readable descriptions"
        },
        {
          "term": "enum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining allowed values"
        },
        {
          "term": "example",
          "tier": 3,
          "reasoning": "JSON Schema property for providing example values"
        },
        {
          "term": "exclusiveMaximum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive upper bound validation"
        },
        {
          "term": "exclusiveMinimum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive lower bound validation"
        },
        {
          "term": "externalDocs",
          "tier": 2,
          "reasoning": "OpenAPI/JSON Schema property for external documentation references"
        },
        {
          "term": "ExternalDocumentation",
          "tier": 1,
          "reasoning": "Kubernetes type for referencing external documentation resources"
        },
        {
          "term": "format",
          "tier": 2,
          "reasoning": "JSON Schema/OpenAPI property for string format validation"
        },
        {
          "term": "OpenAPI v3",
          "tier": 2,
          "reasoning": "API specification standard used by Kubernetes"
        },
        {
          "term": "bsonobjectid",
          "tier": 3,
          "reasoning": "Format string for BSON object ID validation"
        },
        {
          "term": "uri",
          "tier": 3,
          "reasoning": "Format string for URI validation"
        },
        {
          "term": "email",
          "tier": 3,
          "reasoning": "Format string for email address validation"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Format string for hostname validation per RFC 1034"
        },
        {
          "term": "RFC 1034",
          "tier": 3,
          "reasoning": "Internet standard defining hostname format"
        },
        {
          "term": "ipv4",
          "tier": 3,
          "reasoning": "Format string for IPv4 address validation"
        },
        {
          "term": "ipv6",
          "tier": 3,
          "reasoning": "Format string for IPv6 address validation"
        },
        {
          "term": "cidr",
          "tier": 3,
          "reasoning": "Format string for CIDR notation validation"
        },
        {
          "term": "mac",
          "tier": 3,
          "reasoning": "Format string for MAC address validation"
        },
        {
          "term": "uuid",
          "tier": 3,
          "reasoning": "Format string for UUID validation"
        },
        {
          "term": "uuid3",
          "tier": 3,
          "reasoning": "Format string for UUID version 3 validation"
        },
        {
          "term": "uuid4",
          "tier": 3,
          "reasoning": "Format string for UUID version 4 validation"
        },
        {
          "term": "uuid5",
          "tier": 3,
          "reasoning": "Format string for UUID version 5 validation"
        },
        {
          "term": "isbn",
          "tier": 3,
          "reasoning": "Format string for ISBN number validation"
        },
        {
          "term": "isbn10",
          "tier": 3,
          "reasoning": "Format string for ISBN-10 validation"
        },
        {
          "term": "isbn13",
          "tier": 3,
          "reasoning": "Format string for ISBN-13 validation"
        },
        {
          "term": "creditcard",
          "tier": 3,
          "reasoning": "Format string for credit card number validation"
        },
        {
          "term": "custom-resource-definition-v1",
          "tier": 1,
          "reasoning": "Kubernetes API resource version reference for CRDs"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Kubernetes feature lifecycle stage indicating maturing feature"
        },
        {
          "term": "regex",
          "tier": 3,
          "reasoning": "Regular expression pattern used for format validation"
        },
        {
          "term": "Golang",
          "tier": 3,
          "reasoning": "Programming language used for parsing and validation implementations"
        },
        {
          "term": "net/url.ParseRequestURI",
          "tier": 3,
          "reasoning": "Go standard library function for URI parsing"
        },
        {
          "term": "net/mail.ParseAddress",
          "tier": 3,
          "reasoning": "Go standard library function for email parsing"
        },
        {
          "term": "net.ParseIP",
          "tier": 3,
          "reasoning": "Go standard library function for IP address parsing"
        },
        {
          "term": "net.ParseCIDR",
          "tier": 3,
          "reasoning": "Go standard library function for CIDR parsing"
        },
        {
          "term": "net.ParseMAC",
          "tier": 3,
          "reasoning": "Go standard library function for MAC address parsing"
        }
      ],
      "term_count": 54,
      "generated_at": "2026-02-08T22:02:18.898567",
      "elapsed_time": 21.672163248062134
    },
    {
      "chunk_id": "concepts_storage_volume-pvc-datasource_sec0",
      "doc_id": "concepts_storage_volume-pvc-datasource",
      "heading": "Introduction",
      "source_file": "concepts_storage_volume-pvc-datasource.md",
      "content": "---\nreviewers:\n- jsafrane\n- saad-ali\n- thockin\n- msau42\ntitle: CSI Volume Cloning\ncontent_type: concept\nweight: 70\n---\n\n<!-- overview -->\n\nThis document describes the concept of cloning existing CSI Volumes in Kubernetes.\nFamiliarity with [Volumes](/docs/concepts/storage/volumes) is suggested.\n\n<!-- body -->",
      "terms": [
        {
          "term": "CSI",
          "tier": 1,
          "reasoning": "Container Storage Interface - a core Kubernetes storage standard/protocol for volume plugins."
        },
        {
          "term": "CSI Volumes",
          "tier": 1,
          "reasoning": "Specific Kubernetes storage resource type using the Container Storage Interface."
        },
        {
          "term": "CSI Volume Cloning",
          "tier": 2,
          "reasoning": "A specific Kubernetes storage feature/process for duplicating CSI-based volumes."
        },
        {
          "term": "Volumes",
          "tier": 1,
          "reasoning": "Core Kubernetes storage API object/resource for persistent data."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "cloning",
          "tier": 2,
          "reasoning": "Technical process of duplicating storage volumes in the Kubernetes context."
        }
      ],
      "term_count": 6,
      "generated_at": "2026-02-08T22:02:24.887183",
      "elapsed_time": 4.97821044921875
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_run__index_sec3",
      "doc_id": "reference_kubectl_generated_kubectl_run__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_run__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--allow-missing-template-keys&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--annotations strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Annotations to apply to the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--attach</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for the Pod to start running, and then attach to the Pod as if 'kubectl attach ...' were called.  Default false, unless '-i/--stdin' is set, in which case the default is true. With '--restart=Never' the exit code of the container process is returned.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cascade string[=\"background\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"background\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;background&quot;, &quot;orphan&quot;, or &quot;foreground&quot;. Selects the deletion cascading strategy for the dependents (e.g. Pods created by a ReplicationController). Defaults to background.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--command</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true and extra arguments are present, use them as the 'command' field in the container, rather than the 'args' field which is the default.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--dry-run string[=\"unchanged\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;none&quot;, &quot;server&quot;, or &quot;client&quot;. If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--env strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Environment variables to set in the container.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--expose --port</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, create a ClusterIP service associated with the pod.  Requires --port.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--field-manager string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"kubectl-run\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the manager used to track field ownership.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-f, --filename strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>to use to replace the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--force</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, immediately remove resources from API and bypass graceful deletion. Note that immediate deletion of some resources may result in inconsistency or data loss and requires confirmation.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--grace-period int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: -1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Period of time in seconds given to the resource to terminate gracefully. Ignored if negative. Set to 1 for immediate shutdown. Can only be set to 0 when --force is true (force deletion).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for run</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image for the container to run.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image-pull-policy string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image pull policy for the container.  If left empty, this value will not be specified by the client and defaulted by the server.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-k, --kustomize string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process a kustomization directory. This flag can't be used together with -f or -R.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-l, --labels string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Comma separated labels to apply to the pod. Will override previous values.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--leave-stdin-open</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If the pod is started in interactive mode or with stdin, leave stdin open after the first attach completes. By default, stdin will be closed after the first attach completes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-o, --output string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Output format. One of: (json, yaml, kyaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--override-type string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"merge\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The method used to override the generated object: json, merge, or strategic.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--overrides string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>An inline JSON override for the generated object. If this is non-empty, it is used to override the generated object. Requires that the object supply a valid apiVersion field.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--pod-running-timeout duration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1m0s</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time (like 5s, 2m, or 3h, higher than zero) to wait until at least one pod is running</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--port string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The port that this container exposes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--privileged</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, run the container in privileged mode.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-q, --quiet</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, suppress prompt messages.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-R, --recursive</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--restart string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"Always\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The restart policy for this Pod.  Legal values [Always, OnFailure, Never].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--rm</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, delete the pod after it exits.  Only valid when attaching to the container, e.g. with '--attach' or with '-i/--stdin'.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--save-config</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the configuration of current object will be saved in its annotation. Otherwise, the annotation will be unchanged. This flag is useful when you want to perform kubectl apply on this object in the future.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--show-managed-fields</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, keep the managedFields when printing objects in JSON or YAML format.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-i, --stdin</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Keep stdin open on the container in the pod, even if nothing is attached.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--template string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--timeout duration</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time to wait before giving up on a delete, zero means determine a timeout from the size of the object</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-t, --tty</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Allocate a TTY for the container in the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--wait</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for resources to be gone before returning. This waits for finalizers.</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Kubernetes API object that ensures a specified number of pod replicas are running."
        },
        {
          "term": "ClusterIP service",
          "tier": 1,
          "reasoning": "Specific Kubernetes Service type that exposes the service on a cluster-internal IP."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool, referenced as 'kubectl attach' and 'kubectl-run'."
        },
        {
          "term": "kubectl attach",
          "tier": 1,
          "reasoning": "Specific kubectl command for attaching to a running container."
        },
        {
          "term": "kubectl-run",
          "tier": 1,
          "reasoning": "Field manager name for the kubectl run command."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing an isolated runtime environment for applications."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Technical concept for output formatting in golang and jsonpath contexts."
        },
        {
          "term": "golang",
          "tier": 3,
          "reasoning": "Programming language referenced as an output format type."
        },
        {
          "term": "jsonpath",
          "tier": 2,
          "reasoning": "Query language for JSON used as an output format in kubectl."
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching non-identifying information to objects."
        },
        {
          "term": "stdin",
          "tier": 3,
          "reasoning": "Standard input stream, referenced as -i/--stdin flag behavior."
        },
        {
          "term": "exit code",
          "tier": 3,
          "reasoning": "Technical concept for process termination status returned by container."
        },
        {
          "term": "cascade",
          "tier": 2,
          "reasoning": "Deletion strategy concept for handling dependent resources."
        },
        {
          "term": "deletion cascading strategy",
          "tier": 2,
          "reasoning": "Technical process for managing dependent resource deletion."
        },
        {
          "term": "dependents",
          "tier": 2,
          "reasoning": "Kubernetes concept for resources owned by or dependent on other resources."
        },
        {
          "term": "background",
          "tier": 2,
          "reasoning": "Cascade deletion mode where deletion happens asynchronously."
        },
        {
          "term": "orphan",
          "tier": 2,
          "reasoning": "Cascade deletion mode where dependents are left without owner references."
        },
        {
          "term": "foreground",
          "tier": 2,
          "reasoning": "Cascade deletion mode where owner waits for dependents to be deleted."
        },
        {
          "term": "command",
          "tier": 2,
          "reasoning": "Container specification field that overrides the container entrypoint."
        },
        {
          "term": "args",
          "tier": 2,
          "reasoning": "Container specification field for arguments passed to the entrypoint."
        },
        {
          "term": "dry-run",
          "tier": 2,
          "reasoning": "Operational mode for testing changes without persisting them."
        },
        {
          "term": "server-side request",
          "tier": 2,
          "reasoning": "API request processed by the Kubernetes API server."
        },
        {
          "term": "client strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where object is only printed locally."
        },
        {
          "term": "server strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where request is submitted but not persisted."
        },
        {
          "term": "environment variables",
          "tier": 2,
          "reasoning": "Configuration mechanism for passing values to containers."
        },
        {
          "term": "field manager",
          "tier": 2,
          "reasoning": "Server-side apply concept for tracking field ownership."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Kubernetes concept for tracking which manager controls which fields."
        },
        {
          "term": "--port",
          "tier": 2,
          "reasoning": "CLI flag for specifying port configuration."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "General Kubernetes term for API objects that can be created/managed."
        },
        {
          "term": "graceful deletion",
          "tier": 2,
          "reasoning": "Process allowing resources time to terminate cleanly."
        },
        {
          "term": "grace-period",
          "tier": 2,
          "reasoning": "Time period for graceful termination of resources."
        },
        {
          "term": "immediate deletion",
          "tier": 2,
          "reasoning": "Forced removal of resources without waiting for graceful shutdown."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in context of resource removal."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image used to run containers in pods."
        },
        {
          "term": "image-pull-policy",
          "tier": 2,
          "reasoning": "Kubernetes configuration for when to pull container images."
        },
        {
          "term": "attach",
          "tier": 2,
          "reasoning": "Operation to connect to a running container's stdin/stdout."
        },
        {
          "term": "--restart=Never",
          "tier": 2,
          "reasoning": "Pod restart policy option indicating no automatic restarts."
        },
        {
          "term": "container process",
          "tier": 2,
          "reasoning": "The main process running inside a container."
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T22:02:47.589850",
      "elapsed_time": 21.691736936569214
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_patch__index_sec2",
      "doc_id": "reference_kubectl_generated_kubectl_patch__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_patch__index.md",
      "content": "```\n  # Partially update a node using a strategic merge patch, specifying the patch as JSON\n  kubectl patch node k8s-node-1 -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Partially update a node using a strategic merge patch, specifying the patch as YAML\n  kubectl patch node k8s-node-1 -p $'spec:\\n unschedulable: true'\n  \n  # Partially update a node identified by the type and name specified in \"node.json\" using strategic merge patch\n  kubectl patch -f node.json -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Update a container's image; spec.containers[*].name is required because it's a merge key\n  kubectl patch pod valid-pod -p '{\"spec\":{\"containers\":[{\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"}]}}'\n  \n  # Update a container's image using a JSON patch with positional arrays\n  kubectl patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"}]'\n  \n  # Update a deployment's replicas through the 'scale' subresource using a merge patch\n  kubectl patch deployment nginx-deployment --subresource='scale' --type='merge' -p '{\"spec\":{\"replicas\":2}}'\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout the documentation chunk."
        },
        {
          "term": "node",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing replicated applications."
        },
        {
          "term": "k8s-node-1",
          "tier": 1,
          "reasoning": "Specific node name used as an example in the commands."
        },
        {
          "term": "valid-pod",
          "tier": 1,
          "reasoning": "Specific pod name used as an example in the commands."
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific deployment name used as an example in the commands."
        },
        {
          "term": "kubernetes-serve-hostname",
          "tier": 1,
          "reasoning": "Specific container name used as an example in the patch command."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Kubernetes operation for partially updating resources without replacing them entirely."
        },
        {
          "term": "strategic merge patch",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch strategy that understands the schema of Kubernetes objects."
        },
        {
          "term": "JSON patch",
          "tier": 2,
          "reasoning": "RFC 6902 standard patch format supported by Kubernetes for precise updates."
        },
        {
          "term": "merge patch",
          "tier": 2,
          "reasoning": "Patch type that merges the provided fields with existing object fields."
        },
        {
          "term": "subresource",
          "tier": 2,
          "reasoning": "Kubernetes concept for accessing specific aspects of a resource like scale or status."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes subresource for adjusting the number of replicas."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes object field containing the desired state specification."
        },
        {
          "term": "unschedulable",
          "tier": 2,
          "reasoning": "Node spec field that prevents new pods from being scheduled on the node."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod spec field containing the list of container definitions."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental unit of deployment within a pod."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container specification field defining the container image to run."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment/scale spec field defining the desired number of pod instances."
        },
        {
          "term": "merge key",
          "tier": 2,
          "reasoning": "Field used by strategic merge patch to identify list items for merging."
        },
        {
          "term": "positional arrays",
          "tier": 2,
          "reasoning": "JSON patch technique for addressing array elements by index position."
        },
        {
          "term": "JSON",
          "tier": 3,
          "reasoning": "Data format used for specifying patches in kubectl commands."
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data format alternative to JSON for specifying patches."
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Required container field that serves as the merge key for strategic merge patch."
        },
        {
          "term": "node.json",
          "tier": 2,
          "reasoning": "File reference for specifying resource type and name in patch operations."
        },
        {
          "term": "-p",
          "tier": 2,
          "reasoning": "kubectl patch flag for specifying the patch content."
        },
        {
          "term": "-f",
          "tier": 2,
          "reasoning": "kubectl flag for specifying a file containing resource definition."
        },
        {
          "term": "--type",
          "tier": 2,
          "reasoning": "kubectl patch flag for specifying the patch type (json, merge, strategic)."
        },
        {
          "term": "--subresource",
          "tier": 2,
          "reasoning": "kubectl flag for targeting a specific subresource of an object."
        },
        {
          "term": "op",
          "tier": 3,
          "reasoning": "JSON patch operation field specifying the action (replace, add, remove)."
        },
        {
          "term": "replace",
          "tier": 3,
          "reasoning": "JSON patch operation that replaces a value at a specified path."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "JSON patch field specifying the location in the object to modify."
        },
        {
          "term": "value",
          "tier": 3,
          "reasoning": "JSON patch field specifying the new value to set."
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T22:03:05.676438",
      "elapsed_time": 17.076692819595337
    },
    {
      "chunk_id": "tasks_debug_debug-application_get-shell-running-container_sec0",
      "doc_id": "tasks_debug_debug-application_get-shell-running-container",
      "heading": "Introduction",
      "source_file": "tasks_debug_debug-application_get-shell-running-container.md",
      "content": "---\nreviewers:\n- caesarxuchao\n- mikedanese\ntitle: Get a Shell to a Running Container\ncontent_type: task\n---\n\n<!-- overview -->\n\nThis page shows how to use `kubectl exec` to get a shell to a\nrunning container.",
      "terms": [
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for executing commands in containers, a core Kubernetes CLI operation."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool, a core CLI component."
        },
        {
          "term": "exec",
          "tier": 2,
          "reasoning": "A specific kubectl command/operation for executing commands inside containers."
        },
        {
          "term": "shell",
          "tier": 2,
          "reasoning": "Technical term referring to command-line interface access to a container's environment."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes/containerization concept representing an isolated runtime environment."
        },
        {
          "term": "running container",
          "tier": 2,
          "reasoning": "Domain-specific phrase describing a container in active execution state."
        },
        {
          "term": "task",
          "tier": 3,
          "reasoning": "Content type classification indicating procedural documentation in Kubernetes docs."
        }
      ],
      "term_count": 7,
      "generated_at": "2026-02-08T22:03:12.833014",
      "elapsed_time": 6.143071413040161
    },
    {
      "chunk_id": "reference_glossary_host-aliases_sec0",
      "doc_id": "reference_glossary_host-aliases",
      "heading": "Introduction",
      "source_file": "reference_glossary_host-aliases.md",
      "content": "---\ntitle: HostAliases\nid: HostAliases\ndate: 2019-01-31\nfull_link: /docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core\nshort_description: >\n  A HostAliases is a mapping between the IP address and hostname to be injected into a Pod's hosts file.\n\naka:\ntags:\n- operation\n---\n A HostAliases is a mapping between the IP address and hostname to be injected into a {{< glossary_tooltip text=\"Pod\" term_id=\"pod\" >}}'s hosts file.\n\n<!--more-->\n\n[HostAliases](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core) is an optional list of hostnames and IP addresses that will be injected into the Pod's hosts file if specified. This is only valid for non-hostNetwork Pods.",
      "terms": [
        {
          "term": "HostAliases",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for mapping IP addresses to hostnames in Pod hosts files"
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that HostAliases is injected into"
        },
        {
          "term": "IP address",
          "tier": 2,
          "reasoning": "Network addressing concept that is one half of the HostAliases mapping"
        },
        {
          "term": "hostname",
          "tier": 2,
          "reasoning": "Network naming concept that is the other half of the HostAliases mapping"
        },
        {
          "term": "hosts file",
          "tier": 3,
          "reasoning": "Operating system file that maps hostnames to IP addresses, target of HostAliases injection"
        },
        {
          "term": "hostNetwork",
          "tier": 2,
          "reasoning": "Kubernetes Pod networking mode that affects HostAliases validity"
        },
        {
          "term": "non-hostNetwork Pods",
          "tier": 2,
          "reasoning": "Specific Pod configuration context where HostAliases is valid"
        },
        {
          "term": "mapping",
          "tier": 3,
          "reasoning": "Technical concept describing the relationship between IP and hostname in HostAliases"
        },
        {
          "term": "injected",
          "tier": 3,
          "reasoning": "Technical process term describing how HostAliases entries are added to the hosts file"
        },
        {
          "term": "hostalias-v1-core",
          "tier": 1,
          "reasoning": "Kubernetes API reference identifier for the HostAlias resource in core v1 API"
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API documentation and specification"
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T22:03:21.913143",
      "elapsed_time": 8.069787502288818
    },
    {
      "chunk_id": "concepts_scheduling-eviction_dynamic-resource-allocation_sec1",
      "doc_id": "concepts_scheduling-eviction_dynamic-resource-allocation",
      "heading": "About DRA {#about-dra}",
      "source_file": "concepts_scheduling-eviction_dynamic-resource-allocation.md",
      "content": "{{< glossary_definition prepend=\"DRA is\" term_id=\"dra\" length=\"all\" >}}\n\nAllocating resources with DRA is a similar experience to\n[dynamic volume provisioning](/docs/concepts/storage/dynamic-provisioning/), in\nwhich you use PersistentVolumeClaims to claim storage capacity from storage\nclasses and request the claimed capacity in your Pods.\n\n### Benefits of DRA {#dra-benefits}\n\nDRA provides a flexible way to categorize, request, and use devices in your\ncluster. Using DRA provides benefits like the following:\n\n* **Flexible device filtering**: use common expression language (CEL) to perform\n  fine-grained filtering for specific device attributes.\n* **Device sharing**: share the same resource with multiple containers or Pods\n  by referencing the corresponding resource claim.\n* **Centralized device categorization**: device drivers and cluster admins can\n  use device classes to provide app operators with hardware categories that are\n  optimized for various use cases. For example, you can create a cost-optimized\n  device class for general-purpose workloads, and a high-performance device\n  class for critical jobs.\n* **Simplified Pod requests**: with DRA, app operators don't need to specify\n  device quantities in Pod resource requests. Instead, the Pod references a\n  resource claim, and the device configuration in that claim applies to the Pod.\n\nThese benefits provide significant improvements in the device allocation\nworkflow when compared to\n[device plugins](/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/),\nwhich require per-container device requests, don't support device sharing, and\ndon't support expression-based device filtering.\n\n### Types of DRA users {#dra-user-types}\n\nThe workflow of using DRA to allocate devices involves the following types of\nusers:\n\n* **Device owner**: responsible for devices. Device owners might be commercial\n  vendors, the cluster operator, or another entity. To use DRA, devices must\n  have DRA-compatible drivers that do the following:\n\n  * Create ResourceSlices that provide Kubernetes with information about\n    nodes and resources.\n  * Update ResourceSlices when resource capacity in the cluster changes.\n  * Optionally, create DeviceClasses that workload operators can use to\n    claim devices.\n\n* **Cluster admin**: responsible for configuring clusters and nodes,\n  attaching devices, installing drivers, and similar tasks. To use DRA,\n  cluster admins do the following:\n\n  * Attach devices to nodes.\n  * Install device drivers that support DRA.\n  * Optionally, create DeviceClasses that workload operators can use to claim\n    devices.\n\n* **Workload operator**: responsible for deploying and managing workloads in the\n  cluster. To use DRA to allocate devices to Pods, workload operators do the\n  following:\n\n  * Create ResourceClaims or ResourceClaimTemplates to request specific\n    configurations within DeviceClasses.\n  * Deploy workloads that use specific ResourceClaims or ResourceClaimTemplates.",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Core Kubernetes feature/API for Dynamic Resource Allocation, the main subject of this documentation."
        },
        {
          "term": "dynamic volume provisioning",
          "tier": 2,
          "reasoning": "Kubernetes concept for automatically provisioning storage volumes."
        },
        {
          "term": "PersistentVolumeClaims",
          "tier": 1,
          "reasoning": "Kubernetes API object for claiming persistent storage capacity."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Common Expression Language, a protocol/standard used for device filtering in DRA."
        },
        {
          "term": "common expression language",
          "tier": 2,
          "reasoning": "The full name of CEL, a domain-specific language for expressions."
        },
        {
          "term": "device filtering",
          "tier": 2,
          "reasoning": "Technical process for selecting devices based on attributes."
        },
        {
          "term": "device attributes",
          "tier": 2,
          "reasoning": "Technical concept describing properties of devices in DRA."
        },
        {
          "term": "resource claim",
          "tier": 2,
          "reasoning": "DRA concept for requesting device resources."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core Kubernetes/container orchestration concept for isolated runtime environments."
        },
        {
          "term": "device classes",
          "tier": 1,
          "reasoning": "DRA API object for categorizing devices by use case."
        },
        {
          "term": "DeviceClasses",
          "tier": 1,
          "reasoning": "Kubernetes API object name for device categorization in DRA."
        },
        {
          "term": "device drivers",
          "tier": 2,
          "reasoning": "Software components that enable device communication with Kubernetes."
        },
        {
          "term": "Pod resource requests",
          "tier": 2,
          "reasoning": "Kubernetes concept for specifying resource requirements in Pod specs."
        },
        {
          "term": "device allocation",
          "tier": 2,
          "reasoning": "Technical process of assigning devices to workloads."
        },
        {
          "term": "device plugins",
          "tier": 1,
          "reasoning": "Kubernetes extension mechanism for advertising device resources to nodes."
        },
        {
          "term": "ResourceSlices",
          "tier": 1,
          "reasoning": "DRA API object providing Kubernetes with node and resource information."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept representing worker machines in a cluster."
        },
        {
          "term": "resource capacity",
          "tier": 2,
          "reasoning": "Technical concept describing available resources in a cluster."
        },
        {
          "term": "ResourceClaims",
          "tier": 1,
          "reasoning": "DRA API object for requesting specific device configurations."
        },
        {
          "term": "ResourceClaimTemplates",
          "tier": 1,
          "reasoning": "DRA API object template for creating ResourceClaims."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes concept for applications running in the cluster."
        },
        {
          "term": "device owner",
          "tier": 2,
          "reasoning": "DRA user role responsible for devices and drivers."
        },
        {
          "term": "cluster admin",
          "tier": 2,
          "reasoning": "DRA user role responsible for cluster and node configuration."
        },
        {
          "term": "workload operator",
          "tier": 2,
          "reasoning": "DRA user role responsible for deploying and managing workloads."
        },
        {
          "term": "DRA-compatible drivers",
          "tier": 2,
          "reasoning": "Technical requirement for device drivers to work with DRA."
        },
        {
          "term": "device sharing",
          "tier": 2,
          "reasoning": "DRA capability allowing multiple containers/Pods to use the same device."
        },
        {
          "term": "expression-based device filtering",
          "tier": 2,
          "reasoning": "DRA capability for filtering devices using expressions like CEL."
        },
        {
          "term": "storage capacity",
          "tier": 2,
          "reasoning": "Technical concept for available storage in the cluster."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of core Kubernetes API object appearing in text."
        }
      ],
      "term_count": 31,
      "generated_at": "2026-02-08T22:03:40.500291",
      "elapsed_time": 17.5769464969635
    },
    {
      "chunk_id": "reference_using-api_server-side-apply_sec4",
      "doc_id": "reference_using-api_server-side-apply",
      "heading": "Merge strategy",
      "source_file": "reference_using-api_server-side-apply.md",
      "content": "The merging strategy, implemented with Server-Side Apply, provides a generally\nmore stable object lifecycle. Server-Side Apply tries to merge fields based on\nthe actor who manages them instead of overruling based on values. This way\nmultiple actors can update the same object without causing unexpected interference.\n\nWhen a user sends a _fully-specified intent_ object to the Server-Side Apply\nendpoint, the server merges it with the live object favoring the value from the\nrequest body if it is specified in both places. If the set of items present in\nthe applied config is not a superset of the items applied by the same user last\ntime, each missing item not managed by any other appliers is removed. For\nmore information about how an object's schema is used to make decisions when\nmerging, see\n[sigs.k8s.io/structured-merge-diff](https://sigs.k8s.io/structured-merge-diff).\n\nThe Kubernetes API (and the Go code that implements that API for Kubernetes) allows\ndefining _merge strategy markers_. These markers describe the merge strategy supported\nfor fields within Kubernetes objects.\nFor a {{< glossary_tooltip term_id=\"CustomResourceDefinition\" text=\"CustomResourceDefinition\" >}},\nyou can set these markers when you define the custom resource.\n\n| Golang marker   | OpenAPI extension            | Possible values                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| --------------- | ---------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `//+listType`   | `x-kubernetes-list-type`     | `atomic`/`set`/`map`                             | Applicable to lists. `set` applies to lists that include only scalar elements. These elements must be unique. `map` applies to lists of nested types only. The key values (see `listMapKey`) must be unique in the list. `atomic` can apply to any list. If configured as `atomic`, the entire list is replaced during merge. At any point in time, a single manager owns the list. If `set` or `map`, different managers can manage entries separately. |\n| `//+listMapKey` | `x-kubernetes-list-map-keys` | List of field names, e.g. `[\"port\", \"protocol\"]` | Only applicable when `+listType=map`. A list of field names whose values uniquely identify entries in the list. While there can be multiple keys, `listMapKey` is singular because keys need to be specified individually in the Go type. The key fields must be scalars.                                                                                                                                                                                |\n| `//+mapType`    | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to maps. `atomic` means that the map can only be entirely replaced by a single manager. `granular` means that the map supports separate managers updating individual fields.                                                                                                                                                                                                                                                                  |\n| `//+structType` | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to structs; otherwise same usage and OpenAPI annotation as `//+mapType`.                                                                                                                                                                                                                                                                                                                                                                      |\n\nIf `listType` is missing, the API server interprets a\n`patchStrategy=merge` marker as a `listType=map` and the\ncorresponding `patchMergeKey` marker as a `listMapKey`.\n\nThe `atomic` list type is recursive.\n\n(In the [Go](https://go.dev/) code for Kubernetes, these markers are specified as\ncomments and code authors need not repeat them as field tags).",
      "terms": [
        {
          "term": "Server-Side Apply",
          "tier": 1,
          "reasoning": "Core Kubernetes API mechanism for applying configuration changes with field ownership tracking."
        },
        {
          "term": "merging strategy",
          "tier": 2,
          "reasoning": "Technical concept describing how object fields are combined during updates."
        },
        {
          "term": "object lifecycle",
          "tier": 2,
          "reasoning": "Domain concept referring to the stages and management of Kubernetes objects over time."
        },
        {
          "term": "actor",
          "tier": 2,
          "reasoning": "Technical term referring to an entity (user/controller) that manages fields in Server-Side Apply."
        },
        {
          "term": "fully-specified intent",
          "tier": 2,
          "reasoning": "Domain-specific concept describing a complete object specification sent to the API."
        },
        {
          "term": "live object",
          "tier": 2,
          "reasoning": "Technical term for the current state of an object in the Kubernetes API server."
        },
        {
          "term": "request body",
          "tier": 3,
          "reasoning": "API/HTTP concept referring to the payload sent in an API request."
        },
        {
          "term": "applied config",
          "tier": 2,
          "reasoning": "Technical term for the configuration that has been applied to an object."
        },
        {
          "term": "appliers",
          "tier": 2,
          "reasoning": "Domain term for actors/managers that apply configurations to objects."
        },
        {
          "term": "schema",
          "tier": 3,
          "reasoning": "Technical term for the structure definition used in merge decisions."
        },
        {
          "term": "structured-merge-diff",
          "tier": 1,
          "reasoning": "Specific library/project name for implementing structured merging in Kubernetes."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core component name for the API that exposes Kubernetes functionality."
        },
        {
          "term": "merge strategy markers",
          "tier": 2,
          "reasoning": "Domain-specific concept for annotations that define how fields should be merged."
        },
        {
          "term": "Kubernetes objects",
          "tier": 2,
          "reasoning": "Core domain concept referring to resources managed by Kubernetes."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for defining custom resources."
        },
        {
          "term": "custom resource",
          "tier": 1,
          "reasoning": "Core Kubernetes concept for user-defined API extensions."
        },
        {
          "term": "Golang marker",
          "tier": 2,
          "reasoning": "Technical term for Go code annotations used to define merge behavior."
        },
        {
          "term": "OpenAPI extension",
          "tier": 2,
          "reasoning": "Technical concept for custom extensions to OpenAPI specifications."
        },
        {
          "term": "listType",
          "tier": 1,
          "reasoning": "Specific merge strategy marker name for defining list merge behavior."
        },
        {
          "term": "x-kubernetes-list-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension name for Kubernetes list type definitions."
        },
        {
          "term": "atomic",
          "tier": 2,
          "reasoning": "Merge strategy value indicating entire field replacement during merge."
        },
        {
          "term": "set",
          "tier": 2,
          "reasoning": "Merge strategy value for lists containing unique scalar elements."
        },
        {
          "term": "map",
          "tier": 2,
          "reasoning": "Merge strategy value for lists of nested types with unique keys."
        },
        {
          "term": "listMapKey",
          "tier": 1,
          "reasoning": "Specific merge strategy marker for defining unique key fields in map-type lists."
        },
        {
          "term": "x-kubernetes-list-map-keys",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for defining list map keys."
        },
        {
          "term": "mapType",
          "tier": 1,
          "reasoning": "Specific merge strategy marker for defining map merge behavior."
        },
        {
          "term": "x-kubernetes-map-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for Kubernetes map type definitions."
        },
        {
          "term": "granular",
          "tier": 2,
          "reasoning": "Merge strategy value allowing separate managers to update individual map fields."
        },
        {
          "term": "structType",
          "tier": 1,
          "reasoning": "Specific merge strategy marker for defining struct merge behavior."
        },
        {
          "term": "scalar elements",
          "tier": 2,
          "reasoning": "Technical term for simple/primitive values in lists."
        },
        {
          "term": "nested types",
          "tier": 2,
          "reasoning": "Technical term for complex/compound data structures within lists."
        },
        {
          "term": "key fields",
          "tier": 2,
          "reasoning": "Technical term for fields that uniquely identify entries in a list."
        },
        {
          "term": "manager",
          "tier": 2,
          "reasoning": "Domain term for an entity that owns and manages specific fields in an object."
        },
        {
          "term": "Go type",
          "tier": 3,
          "reasoning": "Programming language concept relevant to how markers are specified in Kubernetes code."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "API/networking term for the Server-Side Apply API location."
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term for individual properties within Kubernetes objects that can be managed."
        }
      ],
      "term_count": 36,
      "generated_at": "2026-02-08T22:04:02.759350",
      "elapsed_time": 21.24813437461853
    },
    {
      "chunk_id": "tasks_administer-cluster_kubelet-in-userns_sec6",
      "doc_id": "tasks_administer-cluster_kubelet-in-userns",
      "heading": "(unless you run another systemd in the namespace)",
      "source_file": "tasks_administer-cluster_kubelet-in-userns.md",
      "content": "SystemdCgroup = false\n```\n\nThe default path of the configuration file is `/etc/containerd/config.toml`.\nThe path can be specified with `containerd -c /path/to/containerd/config.toml`.\n\n{{% /tab %}}\n{{% tab name=\"CRI-O\" %}}\n\nRunning CRI-O in a user namespace is supported since CRI-O 1.22.\n\nCRI-O requires an environment variable `_CRIO_ROOTLESS=1` to be set.\n\nThe following configurations are also recommended:\n\n```toml\n[crio]\n  storage_driver = \"overlay\"",
      "terms": [
        {
          "term": "SystemdCgroup",
          "tier": 1,
          "reasoning": "Configuration parameter for container runtime cgroup management"
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Core container runtime component used in Kubernetes infrastructure"
        },
        {
          "term": "CRI-O",
          "tier": 1,
          "reasoning": "Container Runtime Interface implementation, a core Kubernetes container runtime"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Technical concept referring to system configuration storage"
        },
        {
          "term": "/etc/containerd/config.toml",
          "tier": 1,
          "reasoning": "Specific filesystem path for containerd configuration"
        },
        {
          "term": "config.toml",
          "tier": 2,
          "reasoning": "Configuration file format used by container runtimes"
        },
        {
          "term": "user namespace",
          "tier": 2,
          "reasoning": "Linux kernel namespace concept for user isolation, critical for rootless containers"
        },
        {
          "term": "_CRIO_ROOTLESS",
          "tier": 1,
          "reasoning": "Specific environment variable required for CRI-O rootless operation"
        },
        {
          "term": "environment variable",
          "tier": 2,
          "reasoning": "Technical concept for passing configuration to processes"
        },
        {
          "term": "storage_driver",
          "tier": 1,
          "reasoning": "Configuration parameter specifying container storage backend"
        },
        {
          "term": "overlay",
          "tier": 2,
          "reasoning": "Specific storage driver type using overlay filesystem"
        },
        {
          "term": "crio",
          "tier": 1,
          "reasoning": "Configuration section identifier for CRI-O settings"
        },
        {
          "term": "toml",
          "tier": 3,
          "reasoning": "Configuration file format used by container runtimes"
        },
        {
          "term": "rootless",
          "tier": 2,
          "reasoning": "Container execution mode without root privileges, security concept"
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Filesystem path concept relevant to configuration location"
        },
        {
          "term": "-c",
          "tier": 1,
          "reasoning": "CLI flag for specifying containerd configuration file path"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T22:04:12.537870",
      "elapsed_time": 8.76627516746521
    },
    {
      "chunk_id": "reference_access-authn-authz_kubelet-authn-authz_sec0",
      "doc_id": "reference_access-authn-authz_kubelet-authn-authz",
      "heading": "Overview",
      "source_file": "reference_access-authn-authz_kubelet-authn-authz.md",
      "content": "A kubelet's HTTPS endpoint exposes APIs which give access to data of varying sensitivity,\nand allow you to perform operations with varying levels of power on the node and within containers.\n\nThis document describes how to authenticate and authorize access to the kubelet's HTTPS endpoint.",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages containers."
        },
        {
          "term": "HTTPS endpoint",
          "tier": 2,
          "reasoning": "Technical concept describing the secure API access point exposed by the kubelet."
        },
        {
          "term": "HTTPS",
          "tier": 3,
          "reasoning": "Protocol standard for secure HTTP communication used by the kubelet's endpoint."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "Technical networking term referring to an accessible API interface."
        },
        {
          "term": "APIs",
          "tier": 2,
          "reasoning": "Application Programming Interfaces exposed by the kubelet for programmatic access."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to a worker machine in the cluster."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core domain concept for isolated runtime environments managed by Kubernetes."
        },
        {
          "term": "authenticate",
          "tier": 2,
          "reasoning": "Security process concept for verifying identity when accessing the kubelet API."
        },
        {
          "term": "authorize",
          "tier": 2,
          "reasoning": "Security process concept for determining permissions after authentication."
        },
        {
          "term": "access",
          "tier": 3,
          "reasoning": "Technical term in security context referring to the ability to interact with resources."
        },
        {
          "term": "data",
          "tier": 3,
          "reasoning": "Technical term referring to information exposed through the kubelet APIs."
        },
        {
          "term": "sensitivity",
          "tier": 3,
          "reasoning": "Security-related term describing the classification level of exposed data."
        },
        {
          "term": "operations",
          "tier": 3,
          "reasoning": "Technical term referring to actions that can be performed via the kubelet API."
        }
      ],
      "term_count": 13,
      "generated_at": "2026-02-08T22:04:21.654121",
      "elapsed_time": 8.097816467285156
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec1",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "CustomResourceDefinition {#CustomResourceDefinition}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "CustomResourceDefinition represents a resource that should be exposed on the API server.  Its name MUST be in the format \\<.spec.name>.\\<.spec.group>.\n\n<hr>\n\n- **apiVersion**: apiextensions.k8s.io/v1\n\n\n- **kind**: CustomResourceDefinition\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/object-meta#ObjectMeta\" >}}\">ObjectMeta</a>)\n\n  Standard object's metadata More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **spec** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#CustomResourceDefinitionSpec\" >}}\">CustomResourceDefinitionSpec</a>), required\n\n  spec describes how the user wants the resources to appear\n\n- **status** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#CustomResourceDefinitionStatus\" >}}\">CustomResourceDefinitionStatus</a>)\n\n  status indicates the actual state of the CustomResourceDefinition",
      "terms": [
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for extending the API server with custom resources."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that exposes the Kubernetes API."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the version of the API schema for an object."
        },
        {
          "term": "apiextensions.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific API group and version for CustomResourceDefinition resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Standard Kubernetes object field containing identifying information like name and labels."
        },
        {
          "term": "ObjectMeta",
          "tier": 1,
          "reasoning": "Kubernetes API type that defines the standard metadata structure for all objects."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes API field that describes the desired state of a resource."
        },
        {
          "term": "CustomResourceDefinitionSpec",
          "tier": 1,
          "reasoning": "Specific Kubernetes type defining the specification structure for CRDs."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API field that indicates the current observed state of a resource."
        },
        {
          "term": "CustomResourceDefinitionStatus",
          "tier": 1,
          "reasoning": "Specific Kubernetes type defining the status structure for CRDs."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to API objects that can be created and managed."
        },
        {
          "term": ".spec.name",
          "tier": 2,
          "reasoning": "Field path reference indicating the name field within the spec of a CRD."
        },
        {
          "term": ".spec.group",
          "tier": 2,
          "reasoning": "Field path reference indicating the API group field within the spec of a CRD."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Reference to Kubernetes API design conventions documentation."
        },
        {
          "term": "extend-resources",
          "tier": 2,
          "reasoning": "Kubernetes documentation category for resource extension mechanisms."
        },
        {
          "term": "common-definitions",
          "tier": 2,
          "reasoning": "Kubernetes documentation category for shared API type definitions."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T22:04:32.550043",
      "elapsed_time": 9.885009527206421
    },
    {
      "chunk_id": "concepts_security_security-checklist_sec1",
      "doc_id": "concepts_security_security-checklist",
      "heading": "Authentication & Authorization",
      "source_file": "concepts_security_security-checklist.md",
      "content": "- [ ] `system:masters` group is not used for user or component authentication after bootstrapping.\n- [ ] The kube-controller-manager is running with `--use-service-account-credentials`\n  enabled.\n- [ ] The root certificate is protected (either an offline CA, or a managed\n  online CA with effective access controls).\n- [ ] Intermediate and leaf certificates have an expiry date no more than 3\n  years in the future.\n- [ ] A process exists for periodic access review, and reviews occur no more\n  than 24 months apart.\n- [ ] The [Role Based Access Control Good Practices](/docs/concepts/security/rbac-good-practices/)\n  are followed for guidance related to authentication and authorization.\n\nAfter bootstrapping, neither users nor components should authenticate to the\nKubernetes API as `system:masters`. Similarly, running all of\nkube-controller-manager as `system:masters` should be avoided. In fact,\n`system:masters` should only be used as a break-glass mechanism, as opposed to\nan admin user.",
      "terms": [
        {
          "term": "system:masters",
          "tier": 1,
          "reasoning": "Kubernetes built-in group with superuser privileges, a specific named security principal."
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that runs controller processes."
        },
        {
          "term": "--use-service-account-credentials",
          "tier": 1,
          "reasoning": "CLI flag for kube-controller-manager configuration."
        },
        {
          "term": "root certificate",
          "tier": 2,
          "reasoning": "PKI/security concept referring to the top-level certificate authority."
        },
        {
          "term": "offline CA",
          "tier": 2,
          "reasoning": "Security architecture pattern for certificate authority management."
        },
        {
          "term": "CA",
          "tier": 2,
          "reasoning": "Abbreviation for Certificate Authority, a core PKI security concept."
        },
        {
          "term": "Intermediate and leaf certificates",
          "tier": 2,
          "reasoning": "PKI hierarchy concepts for certificate chain structure."
        },
        {
          "term": "Intermediate",
          "tier": 3,
          "reasoning": "Part of certificate hierarchy between root and leaf certificates."
        },
        {
          "term": "leaf certificates",
          "tier": 2,
          "reasoning": "End-entity certificates in PKI hierarchy."
        },
        {
          "term": "expiry date",
          "tier": 3,
          "reasoning": "Certificate lifecycle management concept."
        },
        {
          "term": "access review",
          "tier": 2,
          "reasoning": "Security compliance process for auditing permissions."
        },
        {
          "term": "Role Based Access Control",
          "tier": 2,
          "reasoning": "Authorization mechanism for controlling access based on roles."
        },
        {
          "term": "RBAC",
          "tier": 2,
          "reasoning": "Abbreviation visible in URL path, standard Kubernetes authorization mode."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Security concept for verifying identity of users and components."
        },
        {
          "term": "authorization",
          "tier": 2,
          "reasoning": "Security concept for determining permitted actions after authentication."
        },
        {
          "term": "bootstrapping",
          "tier": 2,
          "reasoning": "Cluster initialization process for setting up initial configuration."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for all Kubernetes operations and resource management."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, general technical term used in Kubernetes context."
        },
        {
          "term": "access controls",
          "tier": 2,
          "reasoning": "Security mechanisms for restricting resource access."
        },
        {
          "term": "user",
          "tier": 3,
          "reasoning": "Identity type in Kubernetes authentication context."
        },
        {
          "term": "component",
          "tier": 3,
          "reasoning": "Kubernetes system component in authentication context."
        },
        {
          "term": "admin user",
          "tier": 2,
          "reasoning": "Administrative identity role in Kubernetes security model."
        },
        {
          "term": "break-glass mechanism",
          "tier": 2,
          "reasoning": "Emergency access pattern for exceptional administrative situations."
        },
        {
          "term": "service account",
          "tier": 2,
          "reasoning": "Kubernetes identity type for workloads, referenced in the flag name."
        },
        {
          "term": "Good Practices",
          "tier": 3,
          "reasoning": "Part of the referenced documentation title for security guidance."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T22:04:47.089557",
      "elapsed_time": 13.528335809707642
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-pods-nodes_sec1",
      "doc_id": "tasks_configure-pod-container_assign-pods-nodes",
      "heading": "Create a pod that gets scheduled to your chosen node",
      "source_file": "tasks_configure-pod-container_assign-pods-nodes.md",
      "content": "This pod configuration file describes a pod that has a node selector,\n`disktype: ssd`. This means that the pod will get scheduled on a node that has\na `disktype=ssd` label.\n\n{{% code_sample file=\"pods/pod-nginx.yaml\" %}}\n\n1. Use the configuration file to create a pod that will get scheduled on your\n   chosen node:\n    \n    ```shell\n    kubectl apply -f https://k8s.io/examples/pods/pod-nginx.yaml\n    ```\n\n1. Verify that the pod is running on your chosen node:\n\n    ```shell\n    kubectl get pods --output=wide\n    ```\n\n    The output is similar to this:\n    \n    ```shell\n    NAME     READY     STATUS    RESTARTS   AGE    IP           NODE\n    nginx    1/1       Running   0          13s    10.200.0.4   worker0\n    ```",
      "terms": [
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit"
        },
        {
          "term": "node selector",
          "tier": 2,
          "reasoning": "Kubernetes scheduling mechanism that constrains pods to nodes with specific labels"
        },
        {
          "term": "disktype: ssd",
          "tier": 2,
          "reasoning": "Specific label key-value pair used for node selection criteria"
        },
        {
          "term": "disktype=ssd",
          "tier": 2,
          "reasoning": "Label selector syntax variant showing the node label requirement"
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Kubernetes worker machine that runs pods"
        },
        {
          "term": "scheduled",
          "tier": 2,
          "reasoning": "Kubernetes scheduling process of assigning pods to nodes"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "YAML/JSON file defining Kubernetes resource specifications"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster management"
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubectl command for declarative resource creation/updates"
        },
        {
          "term": "kubectl get pods",
          "tier": 1,
          "reasoning": "Kubectl command for listing pod resources"
        },
        {
          "term": "--output=wide",
          "tier": 2,
          "reasoning": "Kubectl flag for extended output format showing additional columns"
        },
        {
          "term": "pods/pod-nginx.yaml",
          "tier": 2,
          "reasoning": "Example configuration file path for nginx pod definition"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container image/application name used in the pod example"
        },
        {
          "term": "READY",
          "tier": 2,
          "reasoning": "Pod status field indicating container readiness state"
        },
        {
          "term": "STATUS",
          "tier": 2,
          "reasoning": "Pod lifecycle state indicator in kubectl output"
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "Pod phase indicating containers are executing"
        },
        {
          "term": "RESTARTS",
          "tier": 2,
          "reasoning": "Pod metric showing container restart count"
        },
        {
          "term": "AGE",
          "tier": 2,
          "reasoning": "Pod metadata showing time since creation"
        },
        {
          "term": "IP",
          "tier": 2,
          "reasoning": "Pod network address assigned within the cluster"
        },
        {
          "term": "NODE",
          "tier": 2,
          "reasoning": "Output column showing which node the pod is scheduled on"
        },
        {
          "term": "worker0",
          "tier": 2,
          "reasoning": "Example worker node name in the cluster"
        },
        {
          "term": "pod configuration file",
          "tier": 2,
          "reasoning": "Compound term for YAML file defining pod specifications"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for executing kubectl commands"
        },
        {
          "term": "1/1",
          "tier": 2,
          "reasoning": "Ready container count format showing running vs total containers"
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T22:05:01.068765",
      "elapsed_time": 12.96739912033081
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_config__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_config__index",
      "heading": "{{% heading \"synopsis\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_config__index.md",
      "content": "Modify kubeconfig files using subcommands like \"kubectl config set current-context my-context\".\n\n The loading order follows these rules:\n\n  1.  If the --kubeconfig flag is set, then only that file is loaded. The flag may only be set once and no merging takes place.\n  2.  If $KUBECONFIG environment variable is set, then it is used as a list of paths (normal path delimiting rules for your system). These paths are merged. When a value is modified, it is modified in the file that defines the stanza. When a value is created, it is created in the first file that exists. If no files in the chain exist, then it creates the last file in the list.\n  3.  Otherwise, ${HOME}/.kube/config is used and no merging takes place.\n\n```\nkubectl config SUBCOMMAND\n```",
      "terms": [
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Core Kubernetes configuration file type that stores cluster access credentials and context information."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used to interact with clusters."
        },
        {
          "term": "kubectl config",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for managing kubeconfig files."
        },
        {
          "term": "--kubeconfig",
          "tier": 1,
          "reasoning": "CLI flag used to specify a custom kubeconfig file path."
        },
        {
          "term": "$KUBECONFIG",
          "tier": 1,
          "reasoning": "Environment variable that specifies kubeconfig file paths for Kubernetes CLI tools."
        },
        {
          "term": "KUBECONFIG",
          "tier": 1,
          "reasoning": "Environment variable name referenced for configuring kubeconfig file locations."
        },
        {
          "term": "current-context",
          "tier": 2,
          "reasoning": "Kubernetes configuration concept referring to the active cluster/user/namespace combination."
        },
        {
          "term": "context",
          "tier": 2,
          "reasoning": "Kubernetes concept representing a cluster, user, and namespace combination in kubeconfig."
        },
        {
          "term": "set current-context",
          "tier": 2,
          "reasoning": "Kubectl config operation to change the active context."
        },
        {
          "term": "SUBCOMMAND",
          "tier": 3,
          "reasoning": "Technical term describing secondary commands under a main CLI command."
        },
        {
          "term": "flag",
          "tier": 3,
          "reasoning": "CLI concept for command-line options that modify behavior."
        },
        {
          "term": "environment variable",
          "tier": 3,
          "reasoning": "OS-level concept for storing configuration values accessible to processes."
        },
        {
          "term": "paths",
          "tier": 3,
          "reasoning": "Technical term for file system locations used in configuration."
        },
        {
          "term": "merged",
          "tier": 2,
          "reasoning": "Technical process describing how multiple kubeconfig files are combined."
        },
        {
          "term": "merging",
          "tier": 2,
          "reasoning": "Configuration management concept for combining multiple config sources."
        },
        {
          "term": "stanza",
          "tier": 2,
          "reasoning": "Technical term for a distinct section or block within a configuration file."
        },
        {
          "term": "file",
          "tier": 3,
          "reasoning": "Basic technical term for data storage unit, contextually relevant to config files."
        },
        {
          "term": "${HOME}/.kube/config",
          "tier": 1,
          "reasoning": "Default kubeconfig file path location in Kubernetes installations."
        },
        {
          "term": ".kube/config",
          "tier": 1,
          "reasoning": "Standard kubeconfig file path relative to user home directory."
        },
        {
          "term": "${HOME}",
          "tier": 3,
          "reasoning": "Environment variable representing user's home directory path."
        },
        {
          "term": "loading order",
          "tier": 2,
          "reasoning": "Technical concept describing the precedence of configuration file processing."
        },
        {
          "term": "path delimiting rules",
          "tier": 3,
          "reasoning": "System-specific rules for separating multiple paths in environment variables."
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T22:05:15.701395",
      "elapsed_time": 13.620336055755615
    },
    {
      "chunk_id": "tasks_debug_debug-cluster_topology_sec2",
      "doc_id": "tasks_debug_debug-cluster_topology",
      "heading": "Troubleshoot `TopologyAffinityError` {#TopologyAffinityError}",
      "source_file": "tasks_debug_debug-cluster_topology.md",
      "content": "This error typically occurs in the following situations:\n\n* a node has not enough resources available to satisfy the pod's request\n* the pod's request is rejected due to particular Topology Manager policy constraints\n\nThe error appears in the status of a pod:\n\n```shell\nkubectl get pods\n```\n\n```none\nNAME         READY   STATUS                  RESTARTS   AGE\nguaranteed   0/1     TopologyAffinityError   0          113s\n```\n\nUse `kubectl describe pod <id>` or `kubectl events` to obtain a detailed error message:\n\n```none\nWarning  TopologyAffinityError  10m   kubelet, dell8  Resources cannot be allocated with Topology locality\n```",
      "terms": [
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to a worker machine in the cluster"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Technical term referring to compute resources (CPU, memory) that can be requested by pods"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental deployable unit"
        },
        {
          "term": "request",
          "tier": 2,
          "reasoning": "Kubernetes resource management concept specifying minimum resources needed"
        },
        {
          "term": "Topology Manager",
          "tier": 1,
          "reasoning": "Specific Kubernetes component that manages NUMA topology-aware resource allocation"
        },
        {
          "term": "policy constraints",
          "tier": 2,
          "reasoning": "Technical concept referring to rules that govern resource allocation behavior"
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API field that describes the current state of an object"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters"
        },
        {
          "term": "kubectl get pods",
          "tier": 1,
          "reasoning": "Specific kubectl command to list pod resources"
        },
        {
          "term": "kubectl describe pod",
          "tier": 1,
          "reasoning": "Specific kubectl command to show detailed pod information"
        },
        {
          "term": "kubectl events",
          "tier": 1,
          "reasoning": "Specific kubectl command to view cluster events"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of pod, core Kubernetes API object"
        },
        {
          "term": "READY",
          "tier": 2,
          "reasoning": "Pod status field indicating container readiness state"
        },
        {
          "term": "STATUS",
          "tier": 2,
          "reasoning": "Pod status field showing current phase or error condition"
        },
        {
          "term": "RESTARTS",
          "tier": 2,
          "reasoning": "Pod status field tracking container restart count"
        },
        {
          "term": "AGE",
          "tier": 2,
          "reasoning": "Pod status field showing time since creation"
        },
        {
          "term": "TopologyAffinityError",
          "tier": 1,
          "reasoning": "Specific Kubernetes error status indicating topology-based scheduling failure"
        },
        {
          "term": "guaranteed",
          "tier": 2,
          "reasoning": "Kubernetes QoS class name indicating pods with equal requests and limits"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for pod lifecycle"
        },
        {
          "term": "Warning",
          "tier": 2,
          "reasoning": "Kubernetes event type indicating a non-fatal issue"
        },
        {
          "term": "Topology locality",
          "tier": 2,
          "reasoning": "Concept referring to NUMA-aware resource placement on nodes"
        },
        {
          "term": "error",
          "tier": 3,
          "reasoning": "Technical term describing failure conditions in system operations"
        },
        {
          "term": "error message",
          "tier": 3,
          "reasoning": "Technical output providing details about failure conditions"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for executing kubectl commands"
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T22:05:27.604739",
      "elapsed_time": 10.891401529312134
    },
    {
      "chunk_id": "tasks_debug_debug-cluster_kubectl-node-debug_sec2",
      "doc_id": "tasks_debug_debug-cluster_kubectl-node-debug",
      "heading": "Debugging a Node using `kubectl debug node`",
      "source_file": "tasks_debug_debug-cluster_kubectl-node-debug.md",
      "content": "Use the `kubectl debug node` command to deploy a Pod to a Node that you want to troubleshoot.\nThis command is helpful in scenarios where you can't access your Node by using an SSH connection.\nWhen the Pod is created, the Pod opens an interactive shell on the Node.\nTo create an interactive shell on a Node named \u201cmynode\u201d, run:\n\n```shell\nkubectl debug node/mynode -it --image=ubuntu\n```\n\n```console\nCreating debugging pod node-debugger-mynode-pdx84 with container debugger on node mynode.\nIf you don't see a command prompt, try pressing enter.\nroot@mynode:/#\n```\n\nThe debug command helps to gather information and troubleshoot issues. Commands \nthat you might use include `ip`, `ifconfig`, `nc`, `ping`, and `ps` and so on. You can also\ninstall other tools, such as `mtr`, `tcpdump`, and `curl`, from the respective package manager.\n\n{{< note >}}\n\nThe debug commands may differ based on the image the debugging pod is using and\nthese commands might need to be installed.\n\n{{< /note >}}\n\nThe debugging Pod can access the root filesystem of the Node, mounted at `/host` in the Pod.\nIf you run your kubelet in a filesystem namespace,\nthe debugging Pod sees the root for that namespace, not for the entire node. For a typical Linux node,\nyou can look at the following paths to find relevant logs:\n\n`/host/var/log/kubelet.log`\n: Logs from the `kubelet`, responsible for running containers on the node.\n\n`/host/var/log/kube-proxy.log`\n: Logs from `kube-proxy`, which is responsible for directing traffic to Service endpoints.\n\n`/host/var/log/containerd.log`\n: Logs from the `containerd` process running on the node.\n\n`/host/var/log/syslog`\n: Shows general messages and information regarding the system.\n\n`/host/var/log/kern.log`\n: Shows kernel logs.\n\nWhen creating a debugging session on a Node, keep in mind that:\n\n* `kubectl debug` automatically generates the name of the new pod, based on\n  the name of the node.\n* The root filesystem of the Node will be mounted at `/host`.\n* Although the container runs in the host IPC, Network, and PID namespaces,\n  the pod isn't privileged. This means that reading some process information might fail\n  because access to that information is restricted to superusers. For example, `chroot /host` will fail.\n  If you need a privileged pod, create it manually or use the `--profile=sysadmin` flag.\n* By applying [Debugging Profiles](/docs/tasks/debug/debug-application/debug-running-pod/#debugging-profiles), you can set specific properties such as [securityContext](/docs/tasks/configure-pod-container/security-context/) to a debugging Pod.",
      "terms": [
        {
          "term": "kubectl debug node",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for node debugging operations."
        },
        {
          "term": "kubectl debug",
          "tier": 1,
          "reasoning": "Core kubectl command for debugging resources."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and workload unit."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Core Kubernetes resource representing a worker machine."
        },
        {
          "term": "debugging pod",
          "tier": 1,
          "reasoning": "Specific type of Pod created for troubleshooting purposes."
        },
        {
          "term": "debugging Pod",
          "tier": 1,
          "reasoning": "Variant capitalization of debugging pod as used in the text."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for running containers."
        },
        {
          "term": "kube-proxy",
          "tier": 1,
          "reasoning": "Kubernetes network proxy component for Service traffic routing."
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Container runtime process running on nodes."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Kubernetes API object for network service abstraction."
        },
        {
          "term": "securityContext",
          "tier": 1,
          "reasoning": "Kubernetes Pod/container security configuration field."
        },
        {
          "term": "Debugging Profiles",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for configuring debug pod properties."
        },
        {
          "term": "--profile=sysadmin",
          "tier": 1,
          "reasoning": "Specific CLI flag for creating privileged debugging pods."
        },
        {
          "term": "--image",
          "tier": 1,
          "reasoning": "CLI flag specifying container image for debugging pod."
        },
        {
          "term": "SSH",
          "tier": 2,
          "reasoning": "Secure Shell protocol for remote node access."
        },
        {
          "term": "interactive shell",
          "tier": 2,
          "reasoning": "Terminal session concept for node troubleshooting."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core containerization concept for running workloads."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form of container as used in context."
        },
        {
          "term": "root filesystem",
          "tier": 2,
          "reasoning": "Linux filesystem concept relevant to node debugging access."
        },
        {
          "term": "filesystem namespace",
          "tier": 2,
          "reasoning": "Linux namespace type for filesystem isolation."
        },
        {
          "term": "host IPC",
          "tier": 2,
          "reasoning": "Inter-process communication namespace sharing with host."
        },
        {
          "term": "Network",
          "tier": 2,
          "reasoning": "Network namespace context for pod isolation."
        },
        {
          "term": "PID namespaces",
          "tier": 2,
          "reasoning": "Process ID namespace for container isolation."
        },
        {
          "term": "namespaces",
          "tier": 2,
          "reasoning": "Linux kernel isolation mechanism used by containers."
        },
        {
          "term": "privileged",
          "tier": 2,
          "reasoning": "Security context mode granting elevated container permissions."
        },
        {
          "term": "privileged pod",
          "tier": 2,
          "reasoning": "Pod with elevated security privileges."
        },
        {
          "term": "Service endpoints",
          "tier": 2,
          "reasoning": "Network destinations for Kubernetes Service traffic."
        },
        {
          "term": "traffic",
          "tier": 2,
          "reasoning": "Network traffic concept in context of kube-proxy routing."
        },
        {
          "term": "process information",
          "tier": 2,
          "reasoning": "System process data relevant to debugging."
        },
        {
          "term": "superusers",
          "tier": 2,
          "reasoning": "Privileged user access level for system operations."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image used for debugging pod."
        },
        {
          "term": "package manager",
          "tier": 2,
          "reasoning": "System tool for installing debugging utilities."
        },
        {
          "term": "ip",
          "tier": 3,
          "reasoning": "Linux networking command for troubleshooting."
        },
        {
          "term": "ifconfig",
          "tier": 3,
          "reasoning": "Network interface configuration command."
        },
        {
          "term": "nc",
          "tier": 3,
          "reasoning": "Netcat utility for network debugging."
        },
        {
          "term": "ping",
          "tier": 3,
          "reasoning": "Network connectivity testing command."
        },
        {
          "term": "ps",
          "tier": 3,
          "reasoning": "Process status command for debugging."
        },
        {
          "term": "mtr",
          "tier": 3,
          "reasoning": "Network diagnostic tool combining ping and traceroute."
        },
        {
          "term": "tcpdump",
          "tier": 3,
          "reasoning": "Packet capture tool for network troubleshooting."
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "HTTP client tool for testing endpoints."
        },
        {
          "term": "chroot",
          "tier": 3,
          "reasoning": "Linux command to change root directory."
        },
        {
          "term": "/host",
          "tier": 3,
          "reasoning": "Mount path for node root filesystem in debugging pod."
        },
        {
          "term": "/host/var/log/kubelet.log",
          "tier": 3,
          "reasoning": "Specific log file path for kubelet logs."
        },
        {
          "term": "/host/var/log/kube-proxy.log",
          "tier": 3,
          "reasoning": "Specific log file path for kube-proxy logs."
        },
        {
          "term": "/host/var/log/containerd.log",
          "tier": 3,
          "reasoning": "Specific log file path for containerd logs."
        },
        {
          "term": "/host/var/log/syslog",
          "tier": 3,
          "reasoning": "System log file path for general messages."
        },
        {
          "term": "/host/var/log/kern.log",
          "tier": 3,
          "reasoning": "Kernel log file path."
        },
        {
          "term": "kernel logs",
          "tier": 3,
          "reasoning": "Linux kernel logging output."
        },
        {
          "term": "syslog",
          "tier": 3,
          "reasoning": "System logging facility."
        },
        {
          "term": "ubuntu",
          "tier": 3,
          "reasoning": "Linux distribution used as debugging container image."
        },
        {
          "term": "Linux",
          "tier": 3,
          "reasoning": "Operating system context for node debugging."
        },
        {
          "term": "logs",
          "tier": 3,
          "reasoning": "Log files for troubleshooting node issues."
        }
      ],
      "term_count": 53,
      "generated_at": "2026-02-08T22:05:51.790696",
      "elapsed_time": 23.17345929145813
    },
    {
      "chunk_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1_sec1",
      "doc_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1",
      "heading": "ServiceCIDR {#ServiceCIDR}",
      "source_file": "reference_kubernetes-api_cluster-resources_service-cidr-v1.md",
      "content": "ServiceCIDR defines a range of IP addresses using CIDR format (e.g. 192.168.0.0/24 or 2001:db2::/64). This range is used to allocate ClusterIPs to Service objects.\n\n<hr>\n\n- **apiVersion**: networking.k8s.io/v1\n\n\n- **kind**: ServiceCIDR\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/object-meta#ObjectMeta\" >}}\">ObjectMeta</a>)\n\n  Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **spec** (<a href=\"{{< ref \"../cluster-resources/service-cidr-v1#ServiceCIDRSpec\" >}}\">ServiceCIDRSpec</a>)\n\n  spec is the desired state of the ServiceCIDR. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\n- **status** (<a href=\"{{< ref \"../cluster-resources/service-cidr-v1#ServiceCIDRStatus\" >}}\">ServiceCIDRStatus</a>)\n\n  status represents the current state of the ServiceCIDR. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status",
      "terms": [
        {
          "term": "ServiceCIDR",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for defining IP address ranges for Service allocation."
        },
        {
          "term": "CIDR",
          "tier": 2,
          "reasoning": "Domain-specific networking notation format for specifying IP address ranges."
        },
        {
          "term": "IP addresses",
          "tier": 3,
          "reasoning": "Fundamental networking concept used in the context of service allocation."
        },
        {
          "term": "ClusterIPs",
          "tier": 1,
          "reasoning": "Kubernetes-specific IP type allocated to Service objects within a cluster."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API object that receives ClusterIP allocations."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the API group and version for a resource."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for networking resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes API field containing standard object metadata like name and labels."
        },
        {
          "term": "ObjectMeta",
          "tier": 1,
          "reasoning": "Kubernetes API type that defines the structure of object metadata."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes API field representing the desired state specification of a resource."
        },
        {
          "term": "ServiceCIDRSpec",
          "tier": 1,
          "reasoning": "Kubernetes API type defining the specification structure for ServiceCIDR resources."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API field representing the current observed state of a resource."
        },
        {
          "term": "ServiceCIDRStatus",
          "tier": 1,
          "reasoning": "Kubernetes API type defining the status structure for ServiceCIDR resources."
        },
        {
          "term": "desired state",
          "tier": 2,
          "reasoning": "Core Kubernetes concept describing the intended configuration of a resource."
        },
        {
          "term": "current state",
          "tier": 2,
          "reasoning": "Core Kubernetes concept describing the actual observed state of a resource."
        },
        {
          "term": "cluster-resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources that operate at cluster scope."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Kubernetes development standards referenced for metadata, spec, and status patterns."
        },
        {
          "term": "networking.k8s.io",
          "tier": 1,
          "reasoning": "Kubernetes API group for networking-related resources."
        },
        {
          "term": "192.168.0.0/24",
          "tier": 3,
          "reasoning": "Example IPv4 CIDR notation demonstrating the format used by ServiceCIDR."
        },
        {
          "term": "2001:db2::/64",
          "tier": 3,
          "reasoning": "Example IPv6 CIDR notation demonstrating dual-stack support in ServiceCIDR."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:06:03.727126",
      "elapsed_time": 10.921918630599976
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec6",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "This comment and the empty line above it are ignored",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "```\n\n```shell\nkubectl create configmap game-config-env-file \\\n       --from-env-file=configure-pod-container/configmap/game-env-file.properties\n```\n\nwould produce a ConfigMap. View the ConfigMap:\n\n```shell\nkubectl get configmap game-config-env-file -o yaml\n```\n\nthe output is similar to:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2019-12-27T18:36:28Z\n  name: game-config-env-file\n  namespace: default\n  resourceVersion: \"809965\"\n  uid: d9d1ca5b-eb34-11e7-887b-42010a8002b8\ndata:\n  allowed: '\"true\"'\n  enemies: aliens\n  lives: \"3\"\n```\n\nStarting with Kubernetes v1.23, `kubectl` supports the `--from-env-file` argument to be\nspecified multiple times to create a ConfigMap from multiple data sources.\n\n```shell\nkubectl create configmap config-multi-env-files \\\n        --from-env-file=configure-pod-container/configmap/game-env-file.properties \\\n        --from-env-file=configure-pod-container/configmap/ui-env-file.properties\n```\n\nwould produce the following ConfigMap:\n\n```shell\nkubectl get configmap config-multi-env-files -o yaml\n```\n\nwhere the output is similar to this:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2019-12-27T18:38:34Z\n  name: config-multi-env-files\n  namespace: default\n  resourceVersion: \"810136\"\n  uid: 252c4572-eb35-11e7-887b-42010a8002b8\ndata:\n  allowed: '\"true\"'\n  color: purple\n  enemies: aliens\n  how: fairlyNice\n  lives: \"3\"\n  textmode: \"true\"\n```\n\n#### Define the key to use when creating a ConfigMap from a file\n\nYou can define a key other than the file name to use in the `data` section of your ConfigMap\nwhen using the `--from-file` argument:\n\n```shell\nkubectl create configmap game-config-3 --from-file=<my-key-name>=<path-to-file>\n```\n\nwhere `<my-key-name>` is the key you want to use in the ConfigMap and `<path-to-file>` is the\nlocation of the data source file you want the key to represent.\n\nFor example:\n\n```shell\nkubectl create configmap game-config-3 --from-file=game-special-key=configure-pod-container/configmap/game.properties\n```\n\nwould produce the following ConfigMap:\n```\nkubectl get configmaps game-config-3 -o yaml\n```\n\nwhere the output is similar to this:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2022-02-18T18:54:22Z\n  name: game-config-3\n  namespace: default\n  resourceVersion: \"530\"\n  uid: 05f8da22-d671-11e5-8cd0-68f728db1985\ndata:\n  game-special-key: |\n    enemies=aliens\n    lives=3\n    enemies.cheat=true\n    enemies.cheat.level=noGoodRotten\n    secret.code.passphrase=UUDDLRLRBABAS\n    secret.code.allowed=true\n    secret.code.lives=30\n```\n\n#### Create ConfigMaps from literal values\n\nYou can use `kubectl create configmap` with the `--from-literal` argument to define a literal\nvalue from the command line:\n\n```shell\nkubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm\n```\n\nYou can pass in multiple key-value pairs. Each pair provided on the command line is represented\nas a separate entry in the `data` section of the ConfigMap.\n\n```shell\nkubectl get configmaps special-config -o yaml\n```\n\nThe output is similar to this:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2022-02-18T19:14:38Z\n  name: special-config\n  namespace: default\n  resourceVersion: \"651\"\n  uid: dadce046-d673-11e5-8cd0-68f728db1985\ndata:\n  special.how: very\n  special.type: charm\n```\n\n### Create a ConfigMap from generator\n\nYou can also create a ConfigMap from generators and then apply it to create the object\nin the cluster's API server.\nYou should specify the generators in a `kustomization.yaml` file within a directory.\n\n#### Generate ConfigMaps from files\n\nFor example, to generate a ConfigMap from files `configure-pod-container/configmap/game.properties`\n\n```shell",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI tool used throughout for creating and managing ConfigMaps"
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Primary Kubernetes API object being created and configured throughout the documentation"
        },
        {
          "term": "configmap",
          "tier": 1,
          "reasoning": "Lowercase variant of ConfigMap used in kubectl commands"
        },
        {
          "term": "game-config-env-file",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource created in the example"
        },
        {
          "term": "config-multi-env-files",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource for multiple env files example"
        },
        {
          "term": "game-config-3",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource with custom key example"
        },
        {
          "term": "special-config",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource created from literal values"
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file used for Kustomize generators"
        },
        {
          "term": "--from-env-file",
          "tier": 2,
          "reasoning": "kubectl flag for creating ConfigMaps from environment file properties"
        },
        {
          "term": "--from-file",
          "tier": 2,
          "reasoning": "kubectl flag for creating ConfigMaps from files with custom keys"
        },
        {
          "term": "--from-literal",
          "tier": 2,
          "reasoning": "kubectl flag for defining literal values in ConfigMap creation"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes namespace concept shown in ConfigMap metadata"
        },
        {
          "term": "data",
          "tier": 2,
          "reasoning": "ConfigMap data section containing key-value configuration pairs"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes object metadata section containing name, namespace, uid"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API version field in resource definitions"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes resource type identifier in YAML definitions"
        },
        {
          "term": "resourceVersion",
          "tier": 2,
          "reasoning": "Kubernetes internal version tracking for resources"
        },
        {
          "term": "uid",
          "tier": 2,
          "reasoning": "Unique identifier for Kubernetes objects"
        },
        {
          "term": "creationTimestamp",
          "tier": 2,
          "reasoning": "Kubernetes metadata field showing resource creation time"
        },
        {
          "term": "generators",
          "tier": 2,
          "reasoning": "Kustomize feature for generating ConfigMaps programmatically"
        },
        {
          "term": "key-value pairs",
          "tier": 2,
          "reasoning": "Data structure concept for ConfigMap entries"
        },
        {
          "term": "API server",
          "tier": 2,
          "reasoning": "Kubernetes cluster component that receives generated ConfigMaps"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster where ConfigMaps are applied"
        },
        {
          "term": "Kubernetes",
          "tier": 2,
          "reasoning": "Container orchestration platform context for all operations"
        },
        {
          "term": "v1.23",
          "tier": 2,
          "reasoning": "Specific Kubernetes version introducing multiple --from-env-file support"
        },
        {
          "term": "v1",
          "tier": 2,
          "reasoning": "API version for ConfigMap resources"
        },
        {
          "term": "-o yaml",
          "tier": 3,
          "reasoning": "kubectl output format flag for YAML representation"
        },
        {
          "term": "default",
          "tier": 3,
          "reasoning": "Default namespace name in Kubernetes"
        },
        {
          "term": "properties",
          "tier": 3,
          "reasoning": "File format type for configuration properties files"
        },
        {
          "term": "data source file",
          "tier": 3,
          "reasoning": "Source file from which ConfigMap data is read"
        },
        {
          "term": "command line",
          "tier": 3,
          "reasoning": "Interface context for kubectl operations"
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "File system location for kustomization.yaml files"
        }
      ],
      "term_count": 32,
      "generated_at": "2026-02-08T22:06:19.798635",
      "elapsed_time": 15.05581021308899
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_UnauthenticatedHTTP2DOSMitigation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_UnauthenticatedHTTP2DOSMitigation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_UnauthenticatedHTTP2DOSMitigation.md",
      "content": "---\ntitle: UnauthenticatedHTTP2DOSMitigation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n \nstages:\n  - stage: beta\n    defaultValue: false\n    fromVersion: \"1.28\"\n    toVersion: \"1.28\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.29\" \n---\nEnables HTTP/2 Denial of Service (DoS) mitigations for unauthenticated clients.\nKubernetes v1.28.0 through v1.28.2 do not include this feature gate.",
      "terms": [
        {
          "term": "UnauthenticatedHTTP2DOSMitigation",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configurable feature."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "Kubernetes-specific mechanism for enabling/disabling optional features in the cluster."
        },
        {
          "term": "HTTP/2",
          "tier": 3,
          "reasoning": "A specific network protocol version relevant to the security mitigation being described."
        },
        {
          "term": "Denial of Service",
          "tier": 2,
          "reasoning": "A security concept describing a type of attack that this feature mitigates."
        },
        {
          "term": "DoS",
          "tier": 2,
          "reasoning": "Standard abbreviation for Denial of Service, a security attack vector."
        },
        {
          "term": "mitigations",
          "tier": 2,
          "reasoning": "Security domain term referring to measures taken to reduce risk or impact of attacks."
        },
        {
          "term": "unauthenticated clients",
          "tier": 2,
          "reasoning": "Security concept referring to clients that have not proven their identity."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform this documentation describes."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating a feature that is tested but not yet stable."
        },
        {
          "term": "stage",
          "tier": 2,
          "reasoning": "Technical term describing the maturity level of a feature gate in Kubernetes."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Configuration term indicating the default state of a feature gate."
        },
        {
          "term": "fromVersion",
          "tier": 2,
          "reasoning": "Version specification term indicating when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 2,
          "reasoning": "Version specification term indicating when a feature stage ends."
        },
        {
          "term": "v1.28",
          "tier": 2,
          "reasoning": "Specific Kubernetes version identifier relevant to feature availability."
        },
        {
          "term": "v1.28.0",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch version where the feature gate is absent."
        },
        {
          "term": "v1.28.2",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch version marking the end of versions without this feature gate."
        },
        {
          "term": "HTTP/2 Denial of Service",
          "tier": 2,
          "reasoning": "Compound security term describing the specific attack type this feature addresses."
        },
        {
          "term": "clients",
          "tier": 3,
          "reasoning": "Technical term for entities making requests to a server/API in this context."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T22:06:31.823898",
      "elapsed_time": 11.009517192840576
    },
    {
      "chunk_id": "concepts_security_hardening-guide_authentication-mechanisms_sec9",
      "doc_id": "concepts_security_hardening-guide_authentication-mechanisms",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "concepts_security_hardening-guide_authentication-mechanisms.md",
      "content": "- [User Authentication](/docs/reference/access-authn-authz/authentication/)\n- [Authenticating with Bootstrap Tokens](/docs/reference/access-authn-authz/bootstrap-tokens/)\n- [kubelet Authentication](/docs/reference/access-authn-authz/kubelet-authn-authz/#kubelet-authentication)\n- [Authenticating with Service Account Tokens](/docs/reference/access-authn-authz/service-accounts-admin/#bound-service-account-tokens)",
      "terms": [
        {
          "term": "User Authentication",
          "tier": 2,
          "reasoning": "Domain concept referring to the process of verifying user identity in Kubernetes."
        },
        {
          "term": "Authentication",
          "tier": 2,
          "reasoning": "Core security concept for verifying identity of users or services."
        },
        {
          "term": "Bootstrap Tokens",
          "tier": 1,
          "reasoning": "Specific Kubernetes authentication mechanism used during cluster bootstrapping."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for managing pods on a node."
        },
        {
          "term": "kubelet Authentication",
          "tier": 2,
          "reasoning": "Specific authentication process for the kubelet component."
        },
        {
          "term": "Service Account Tokens",
          "tier": 1,
          "reasoning": "Kubernetes API object tokens used for authenticating service accounts."
        },
        {
          "term": "Service Account",
          "tier": 1,
          "reasoning": "Kubernetes API resource providing identity for processes running in pods."
        },
        {
          "term": "Tokens",
          "tier": 2,
          "reasoning": "Security credentials used for authentication in Kubernetes context."
        },
        {
          "term": "Bound Service Account Tokens",
          "tier": 1,
          "reasoning": "Specific type of service account tokens that are bound to specific pods and have expiration."
        },
        {
          "term": "access-authn-authz",
          "tier": 2,
          "reasoning": "Kubernetes documentation category covering access control, authentication, and authorization."
        },
        {
          "term": "authn",
          "tier": 2,
          "reasoning": "Abbreviation for authentication commonly used in Kubernetes security context."
        },
        {
          "term": "authz",
          "tier": 2,
          "reasoning": "Abbreviation for authorization commonly used in Kubernetes security context."
        },
        {
          "term": "kubelet-authn-authz",
          "tier": 2,
          "reasoning": "Reference to kubelet's authentication and authorization configuration."
        },
        {
          "term": "service-accounts-admin",
          "tier": 2,
          "reasoning": "Administrative configuration reference for service accounts in Kubernetes."
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T22:06:41.102043",
      "elapsed_time": 8.26522421836853
    },
    {
      "chunk_id": "concepts_scheduling-eviction_dynamic-resource-allocation_sec3",
      "doc_id": "concepts_scheduling-eviction_dynamic-resource-allocation",
      "heading": "How resource allocation with DRA works {#how-it-works}",
      "source_file": "concepts_scheduling-eviction_dynamic-resource-allocation.md",
      "content": "The following sections describe the workflow for the various\n[types of DRA users](#dra-user-types) and for the Kubernetes system during\ndynamic resource allocation.\n\n### Workflow for users {#user-workflow}\n\n1. **Driver creation**: device owners or third-party entities create drivers\n   that can create and manage ResourceSlices in the cluster. These drivers\n   optionally also create DeviceClasses that define a category of devices and\n   how to request them.\n1. **Cluster configuration**: cluster admins create clusters, attach devices to\n   nodes, and install the DRA device drivers. Cluster admins optionally create\n   DeviceClasses that define categories of devices and how to request them.\n1. **Resource claims**: workload operators create ResourceClaimTemplates or\n   ResourceClaims that request specific device configurations within a\n   DeviceClass. In the same step, workload operators modify their Kubernetes\n   manifests to request those ResourceClaimTemplates or ResourceClaims.\n\n### Workflow for Kubernetes {#kubernetes-workflow}\n\n1. **ResourceSlice creation**: drivers in the cluster create ResourceSlices that\n   represent one or more devices in a managed pool of similar devices.\n1. **Workload creation**: the cluster control plane checks new workloads for\n   references to ResourceClaimTemplates or to specific ResourceClaims.\n\n   * If the workload uses a ResourceClaimTemplate, a controller named the\n     `resourceclaim-controller` generates ResourceClaims for every Pod in the\n     workload.\n   * If the workload uses a specific ResourceClaim, Kubernetes checks whether\n     that ResourceClaim exists in the cluster. If the ResourceClaim doesn't\n     exist, the Pods won't deploy.\n\n1. **ResourceSlice filtering**: for every Pod, Kubernetes checks the\n   ResourceSlices in the cluster to find a device that satisfies all of the\n   following criteria:\n\n   * The nodes that can access the resources are eligible to run the Pod.\n   * The ResourceSlice has unallocated resources that match the requirements of\n     the Pod's ResourceClaim.\n\n1. **Resource allocation**: after finding an eligible ResourceSlice for a\n   Pod's ResourceClaim, the Kubernetes scheduler updates the ResourceClaim\n   with the allocation details.\n1. **Pod scheduling**: when resource allocation is complete, the scheduler\n   places the Pod on a node that can access the allocated resource. The device\n   driver and the kubelet on that node configure the device and the Pod's access\n   to the device.",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Abbreviation for Dynamic Resource Allocation, a core Kubernetes feature being documented."
        },
        {
          "term": "dynamic resource allocation",
          "tier": 2,
          "reasoning": "The main domain concept this documentation describes, a Kubernetes resource management process."
        },
        {
          "term": "DRA user types",
          "tier": 2,
          "reasoning": "Specific categorization of users within the DRA system."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented."
        },
        {
          "term": "ResourceSlices",
          "tier": 1,
          "reasoning": "A Kubernetes API object representing devices in a managed pool."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to a set of nodes."
        },
        {
          "term": "drivers",
          "tier": 2,
          "reasoning": "Software components that create and manage ResourceSlices in DRA context."
        },
        {
          "term": "DeviceClasses",
          "tier": 1,
          "reasoning": "Kubernetes API object that defines categories of devices and how to request them."
        },
        {
          "term": "device drivers",
          "tier": 2,
          "reasoning": "DRA-specific drivers that manage device resources in the cluster."
        },
        {
          "term": "DRA device drivers",
          "tier": 1,
          "reasoning": "Specific component name for drivers in the Dynamic Resource Allocation system."
        },
        {
          "term": "cluster admins",
          "tier": 2,
          "reasoning": "Role/persona responsible for cluster configuration in Kubernetes."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing worker machines in a cluster."
        },
        {
          "term": "workload operators",
          "tier": 2,
          "reasoning": "Role/persona responsible for creating and managing workloads."
        },
        {
          "term": "ResourceClaimTemplates",
          "tier": 1,
          "reasoning": "Kubernetes API object used to template resource claims for workloads."
        },
        {
          "term": "ResourceClaims",
          "tier": 1,
          "reasoning": "Kubernetes API object that requests specific device configurations."
        },
        {
          "term": "device configurations",
          "tier": 2,
          "reasoning": "Technical concept describing how devices are configured within DeviceClasses."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural component that manages cluster state."
        },
        {
          "term": "cluster control plane",
          "tier": 2,
          "reasoning": "Specific reference to the control plane managing the cluster."
        },
        {
          "term": "resourceclaim-controller",
          "tier": 1,
          "reasoning": "Named Kubernetes controller component that generates ResourceClaims."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "Kubernetes architectural pattern for managing resource state."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, frequently used in the documentation."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Technical concept for applications running in Kubernetes."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Plural form referring to multiple applications in the cluster."
        },
        {
          "term": "resource allocation",
          "tier": 2,
          "reasoning": "Core process in DRA where resources are assigned to claims."
        },
        {
          "term": "scheduler",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for placing Pods on nodes."
        },
        {
          "term": "Kubernetes scheduler",
          "tier": 1,
          "reasoning": "Specific named component that handles Pod scheduling."
        },
        {
          "term": "allocation details",
          "tier": 2,
          "reasoning": "Technical information about how resources are allocated to claims."
        },
        {
          "term": "Pod scheduling",
          "tier": 2,
          "reasoning": "The process of placing Pods on appropriate nodes."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent that manages Pod lifecycle."
        },
        {
          "term": "device",
          "tier": 2,
          "reasoning": "Hardware resource managed through DRA in Kubernetes."
        },
        {
          "term": "devices",
          "tier": 2,
          "reasoning": "Plural form of device, representing hardware resources."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Individual worker machine in a Kubernetes cluster."
        },
        {
          "term": "pool",
          "tier": 2,
          "reasoning": "Collection of similar devices managed together in DRA."
        },
        {
          "term": "managed pool",
          "tier": 2,
          "reasoning": "Specific concept of a pool of devices under driver management."
        },
        {
          "term": "unallocated resources",
          "tier": 2,
          "reasoning": "Resources in a ResourceSlice not yet assigned to claims."
        },
        {
          "term": "allocated resource",
          "tier": 2,
          "reasoning": "Resource that has been assigned to a Pod's claim."
        },
        {
          "term": "ResourceSlice filtering",
          "tier": 2,
          "reasoning": "Process of finding suitable ResourceSlices for Pod requirements."
        }
      ],
      "term_count": 38,
      "generated_at": "2026-02-08T22:07:03.127661",
      "elapsed_time": 21.011798620224
    },
    {
      "chunk_id": "tasks_job_coarse-parallel-processing-work-queue_sec10",
      "doc_id": "tasks_job_coarse-parallel-processing-work-queue",
      "heading": "Run this on your computer, not in the Pod",
      "source_file": "tasks_job_coarse-parallel-processing-work-queue.md",
      "content": "/usr/bin/amqp-declare-queue --url=$BROKER_URL -q job1  -d\n```\n```\njob1\n```\nAdd items to the queue:\n```shell\nfor f in apple banana cherry date fig grape lemon melon\ndo\n  /usr/bin/amqp-publish --url=$BROKER_URL -r job1 -p -b $f\ndone\n```\n\nYou added 8 messages to the queue.",
      "terms": [
        {
          "term": "amqp-declare-queue",
          "tier": 1,
          "reasoning": "CLI tool/command for declaring AMQP message queues"
        },
        {
          "term": "BROKER_URL",
          "tier": 2,
          "reasoning": "Environment variable representing the message broker connection URL"
        },
        {
          "term": "queue",
          "tier": 2,
          "reasoning": "Core messaging concept - a data structure for storing messages in order"
        },
        {
          "term": "job1",
          "tier": 1,
          "reasoning": "Named queue resource identifier in this messaging context"
        },
        {
          "term": "amqp-publish",
          "tier": 1,
          "reasoning": "CLI tool/command for publishing messages to AMQP queues"
        },
        {
          "term": "-q",
          "tier": 3,
          "reasoning": "CLI flag for specifying queue name"
        },
        {
          "term": "-d",
          "tier": 3,
          "reasoning": "CLI flag likely for durable queue declaration"
        },
        {
          "term": "-r",
          "tier": 3,
          "reasoning": "CLI flag for specifying routing key"
        },
        {
          "term": "-p",
          "tier": 3,
          "reasoning": "CLI flag for persistent message delivery"
        },
        {
          "term": "-b",
          "tier": 3,
          "reasoning": "CLI flag for specifying message body"
        },
        {
          "term": "--url",
          "tier": 3,
          "reasoning": "CLI flag for specifying broker URL connection string"
        },
        {
          "term": "messages",
          "tier": 2,
          "reasoning": "Core messaging concept - units of data transmitted through the queue"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interpreter environment context"
        },
        {
          "term": "/usr/bin",
          "tier": 3,
          "reasoning": "Standard Unix/Linux binary executable path"
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T22:07:11.230555",
      "elapsed_time": 7.087721109390259
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec1",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`TracingConfiguration`     {#TracingConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [KubeletConfiguration](#kubelet-config-k8s-io-v1beta1-KubeletConfiguration)\n\n- [TracingConfiguration](#apiserver-k8s-io-v1alpha1-TracingConfiguration)\n\n- [TracingConfiguration](#apiserver-k8s-io-v1beta1-TracingConfiguration)\n\n\n<p>TracingConfiguration provides versioned configuration for OpenTelemetry tracing clients.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>endpoint</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>Endpoint of the collector this component will report traces to.\nThe connection is insecure, and does not currently support TLS.\nRecommended is unset, and endpoint is the otlp grpc default, localhost:4317.</p>\n</td>\n</tr>\n<tr><td><code>samplingRatePerMillion</code><br/>\n<code>int32</code>\n</td>\n<td>\n   <p>SamplingRatePerMillion is the number of samples to collect per million spans.\nRecommended is unset. If unset, sampler respects its parent span's sampling\nrate, but otherwise never samples.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "KubeletConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for the kubelet component"
        },
        {
          "term": "TracingConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for tracing settings"
        },
        {
          "term": "OpenTelemetry",
          "tier": 1,
          "reasoning": "Specific observability framework/standard for distributed tracing"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component (referenced via KubeletConfiguration)"
        },
        {
          "term": "apiserver",
          "tier": 1,
          "reasoning": "Core Kubernetes API server component referenced in configuration paths"
        },
        {
          "term": "endpoint",
          "tier": 2,
          "reasoning": "Technical field name specifying the collector connection target"
        },
        {
          "term": "collector",
          "tier": 2,
          "reasoning": "Component that receives and processes trace data in observability systems"
        },
        {
          "term": "traces",
          "tier": 2,
          "reasoning": "Distributed tracing data units used for observability"
        },
        {
          "term": "tracing",
          "tier": 2,
          "reasoning": "Observability concept for tracking requests across distributed systems"
        },
        {
          "term": "tracing clients",
          "tier": 2,
          "reasoning": "Components that generate and send trace data to collectors"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol mentioned as not currently supported"
        },
        {
          "term": "otlp",
          "tier": 2,
          "reasoning": "OpenTelemetry Protocol - standard protocol for transmitting telemetry data"
        },
        {
          "term": "grpc",
          "tier": 3,
          "reasoning": "Remote procedure call protocol used as default transport for OTLP"
        },
        {
          "term": "samplingRatePerMillion",
          "tier": 2,
          "reasoning": "Configuration field controlling trace sampling frequency"
        },
        {
          "term": "sampler",
          "tier": 2,
          "reasoning": "Component that decides which spans to collect based on sampling rate"
        },
        {
          "term": "spans",
          "tier": 2,
          "reasoning": "Individual units of work in distributed tracing representing operations"
        },
        {
          "term": "parent span",
          "tier": 2,
          "reasoning": "Hierarchical tracing concept where spans can have parent-child relationships"
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "Kubernetes API version indicating beta stability level"
        },
        {
          "term": "v1alpha1",
          "tier": 2,
          "reasoning": "Kubernetes API version indicating alpha stability level"
        },
        {
          "term": "localhost:4317",
          "tier": 3,
          "reasoning": "Default OTLP gRPC endpoint address for trace collection"
        },
        {
          "term": "int32",
          "tier": 3,
          "reasoning": "Data type specification for the sampling rate field"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the endpoint field"
        },
        {
          "term": "connection",
          "tier": 3,
          "reasoning": "Network connection concept relevant to collector communication"
        },
        {
          "term": "insecure",
          "tier": 3,
          "reasoning": "Security term describing the connection type without TLS"
        },
        {
          "term": "component",
          "tier": 3,
          "reasoning": "Technical term referring to Kubernetes system parts that report traces"
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T22:07:24.429834",
      "elapsed_time": 12.183044195175171
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_attach__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_attach__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_attach__index.md",
      "content": "```\n  # Get output from running pod mypod; use the 'kubectl.kubernetes.io/default-container' annotation\n  # for selecting the container to be attached or the first container in the pod will be chosen\n  kubectl attach mypod\n  \n  # Get output from ruby-container from pod mypod\n  kubectl attach mypod -c ruby-container\n  \n  # Switch to raw terminal mode; sends stdin to 'bash' in ruby-container from pod mypod\n  # and sends stdout/stderr from 'bash' back to the client\n  kubectl attach mypod -c ruby-container -i -t\n  \n  # Get output from the first pod of a replica set named nginx\n  kubectl attach rs/nginx\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout the examples"
        },
        {
          "term": "kubectl attach",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for attaching to running containers"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and resource type referenced multiple times"
        },
        {
          "term": "mypod",
          "tier": 1,
          "reasoning": "Example pod name used in the documentation examples"
        },
        {
          "term": "ruby-container",
          "tier": 1,
          "reasoning": "Example container name used in the documentation"
        },
        {
          "term": "replica set",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing pod replicas, referenced as rs/nginx"
        },
        {
          "term": "rs/nginx",
          "tier": 1,
          "reasoning": "Specific resource reference syntax for a replica set named nginx"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Named replica set resource in the example"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes concept - the unit being attached to within a pod"
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism used for default container selection"
        },
        {
          "term": "kubectl.kubernetes.io/default-container",
          "tier": 1,
          "reasoning": "Specific Kubernetes annotation for selecting default container"
        },
        {
          "term": "stdin",
          "tier": 3,
          "reasoning": "Standard input stream - Linux/OS concept used in terminal attachment"
        },
        {
          "term": "stdout",
          "tier": 3,
          "reasoning": "Standard output stream - Linux/OS concept for receiving container output"
        },
        {
          "term": "stderr",
          "tier": 3,
          "reasoning": "Standard error stream - Linux/OS concept for receiving container errors"
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Shell program running inside the container being attached to"
        },
        {
          "term": "raw terminal mode",
          "tier": 2,
          "reasoning": "Terminal mode concept for direct I/O with container processes"
        },
        {
          "term": "client",
          "tier": 2,
          "reasoning": "Technical term referring to the kubectl client receiving output"
        },
        {
          "term": "-c",
          "tier": 2,
          "reasoning": "CLI flag for specifying container name in kubectl commands"
        },
        {
          "term": "-i",
          "tier": 2,
          "reasoning": "CLI flag for interactive mode, passing stdin to container"
        },
        {
          "term": "-t",
          "tier": 2,
          "reasoning": "CLI flag for TTY allocation in terminal mode"
        },
        {
          "term": "attach",
          "tier": 2,
          "reasoning": "Technical operation for connecting to a running container's process"
        },
        {
          "term": "output",
          "tier": 2,
          "reasoning": "Technical term for data streams from container processes"
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T22:07:36.338860",
      "elapsed_time": 10.89553952217102
    },
    {
      "chunk_id": "concepts_security_security-checklist_sec2",
      "doc_id": "concepts_security_security-checklist",
      "heading": "Network security",
      "source_file": "concepts_security_security-checklist.md",
      "content": "- [ ] CNI plugins in use support network policies.\n- [ ] Ingress and egress network policies are applied to all workloads in the\n  cluster.\n- [ ] Default network policies within each namespace, selecting all pods, denying\n  everything, are in place.\n- [ ] If appropriate, a service mesh is used to encrypt all communications inside of the cluster.\n- [ ] The Kubernetes API, kubelet API and etcd are not exposed publicly on Internet.\n- [ ] Access from the workloads to the cloud metadata API is filtered.\n- [ ] Use of LoadBalancer and ExternalIPs is restricted.\n\nA number of [Container Network Interface (CNI) plugins](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)\nplugins provide the functionality to\nrestrict network resources that pods may communicate with. This is most commonly done\nthrough [Network Policies](/docs/concepts/services-networking/network-policies/)\nwhich provide a namespaced resource to define rules. Default network policies\nthat block all egress and ingress, in each namespace, selecting all pods, can be\nuseful to adopt an allow list approach to ensure that no workloads are missed.\n\nNot all CNI plugins provide encryption in transit. If the chosen plugin lacks this\nfeature, an alternative solution could be to use a service mesh to provide that\nfunctionality.\n\nThe etcd datastore of the control plane should have controls to limit access and\nnot be publicly exposed on the Internet. Furthermore, mutual TLS (mTLS) should\nbe used to communicate securely with it. The certificate authority for this\nshould be unique to etcd.\n\nExternal Internet access to the Kubernetes API server should be restricted to\nnot expose the API publicly. Be careful, as many managed Kubernetes distributions\nare publicly exposing the API server by default. You can then use a bastion host\nto access the server.\n\nThe [kubelet](/docs/reference/command-line-tools-reference/kubelet/) API access\nshould be restricted and not exposed publicly, the default authentication and\nauthorization settings, when no configuration file specified with the `--config`\nflag, are overly permissive.\n\nIf a cloud provider is used for hosting Kubernetes, the access from pods to the cloud\nmetadata API `169.254.169.254` should also be restricted or blocked if not needed\nbecause it may leak information.\n\nFor restricted LoadBalancer and ExternalIPs use, see\n[CVE-2020-8554: Man in the middle using LoadBalancer or ExternalIPs](https://github.com/kubernetes/kubernetes/issues/97076)\nand the [DenyServiceExternalIPs admission controller](/docs/reference/access-authn-authz/admission-controllers/#denyserviceexternalips)\nfor further information.",
      "terms": [
        {
          "term": "CNI plugins",
          "tier": 1,
          "reasoning": "Container Network Interface plugins are specific Kubernetes networking components."
        },
        {
          "term": "Container Network Interface",
          "tier": 1,
          "reasoning": "Full name of CNI, a core Kubernetes networking standard."
        },
        {
          "term": "network policies",
          "tier": 1,
          "reasoning": "Kubernetes API resource for controlling pod network traffic."
        },
        {
          "term": "Network Policies",
          "tier": 1,
          "reasoning": "Capitalized reference to the Kubernetes API object."
        },
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Kubernetes concept for inbound network traffic control."
        },
        {
          "term": "egress",
          "tier": 2,
          "reasoning": "Kubernetes networking concept for outbound traffic."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes term for applications running in the cluster."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept for a set of nodes."
        },
        {
          "term": "namespace",
          "tier": 1,
          "reasoning": "Kubernetes API object for resource isolation and organization."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes workload resource unit."
        },
        {
          "term": "service mesh",
          "tier": 2,
          "reasoning": "Infrastructure layer concept for service-to-service communication."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for interacting with Kubernetes control plane."
        },
        {
          "term": "kubelet API",
          "tier": 1,
          "reasoning": "API exposed by the kubelet node agent component."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Primary node agent that runs on each Kubernetes node."
        },
        {
          "term": "etcd",
          "tier": 1,
          "reasoning": "Distributed key-value store used as Kubernetes backing store."
        },
        {
          "term": "cloud metadata API",
          "tier": 2,
          "reasoning": "Cloud provider service endpoint for instance metadata."
        },
        {
          "term": "LoadBalancer",
          "tier": 1,
          "reasoning": "Kubernetes Service type for external load balancing."
        },
        {
          "term": "ExternalIPs",
          "tier": 1,
          "reasoning": "Kubernetes Service field for external IP addresses."
        },
        {
          "term": "network resources",
          "tier": 2,
          "reasoning": "Technical term for network-related Kubernetes resources."
        },
        {
          "term": "namespaced resource",
          "tier": 2,
          "reasoning": "Kubernetes concept for resources scoped to a namespace."
        },
        {
          "term": "allow list",
          "tier": 2,
          "reasoning": "Security concept for explicitly permitted access."
        },
        {
          "term": "encryption in transit",
          "tier": 2,
          "reasoning": "Security concept for protecting data during transmission."
        },
        {
          "term": "etcd datastore",
          "tier": 1,
          "reasoning": "Specific reference to etcd as the control plane data store."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Kubernetes architectural component managing cluster state."
        },
        {
          "term": "mutual TLS",
          "tier": 2,
          "reasoning": "Security protocol for bidirectional certificate authentication."
        },
        {
          "term": "mTLS",
          "tier": 2,
          "reasoning": "Abbreviation for mutual TLS, common security term."
        },
        {
          "term": "certificate authority",
          "tier": 2,
          "reasoning": "PKI concept for issuing and managing certificates."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component (kube-apiserver)."
        },
        {
          "term": "bastion host",
          "tier": 2,
          "reasoning": "Security architecture term for a hardened access point."
        },
        {
          "term": "managed Kubernetes distributions",
          "tier": 2,
          "reasoning": "Cloud provider Kubernetes offerings concept."
        },
        {
          "term": "--config",
          "tier": 1,
          "reasoning": "CLI flag for kubelet configuration file specification."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Security concept for identity verification."
        },
        {
          "term": "authorization",
          "tier": 2,
          "reasoning": "Security concept for access control decisions."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Kubernetes integration concept for cloud infrastructure."
        },
        {
          "term": "169.254.169.254",
          "tier": 3,
          "reasoning": "Specific IP address for cloud metadata API endpoint."
        },
        {
          "term": "CVE-2020-8554",
          "tier": 1,
          "reasoning": "Specific security vulnerability identifier referenced."
        },
        {
          "term": "DenyServiceExternalIPs admission controller",
          "tier": 1,
          "reasoning": "Specific Kubernetes admission controller component."
        },
        {
          "term": "admission controller",
          "tier": 1,
          "reasoning": "Kubernetes component that intercepts API requests."
        },
        {
          "term": "default network policies",
          "tier": 2,
          "reasoning": "Kubernetes security pattern for baseline network rules."
        },
        {
          "term": "Internet",
          "tier": 3,
          "reasoning": "Network context term for external public network access."
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:07:56.041461",
      "elapsed_time": 18.688344955444336
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec0",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Introduction",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "---\ntitle: Specifying a Disruption Budget for your Application\ncontent_type: task\nweight: 110\nmin-kubernetes-server-version: v1.21\n---\n\n<!-- overview -->\n\n{{< feature-state for_k8s_version=\"v1.21\" state=\"stable\" >}}\n\nThis page shows how to limit the number of concurrent disruptions\nthat your application experiences, allowing for higher availability\nwhile permitting the cluster administrator to manage the clusters\nnodes.",
      "terms": [
        {
          "term": "Disruption Budget",
          "tier": 1,
          "reasoning": "Core Kubernetes API object (PodDisruptionBudget) referenced in the title for managing pod disruptions."
        },
        {
          "term": "Application",
          "tier": 2,
          "reasoning": "Domain concept referring to workloads running on Kubernetes that the disruption budget protects."
        },
        {
          "term": "concurrent disruptions",
          "tier": 2,
          "reasoning": "Technical concept describing simultaneous pod terminations that disruption budgets limit."
        },
        {
          "term": "disruptions",
          "tier": 2,
          "reasoning": "Domain concept referring to voluntary or involuntary pod terminations in Kubernetes."
        },
        {
          "term": "availability",
          "tier": 2,
          "reasoning": "Architectural term describing the operational uptime goal that disruption budgets help maintain."
        },
        {
          "term": "higher availability",
          "tier": 2,
          "reasoning": "Architectural concept describing improved uptime through controlled disruption management."
        },
        {
          "term": "cluster administrator",
          "tier": 2,
          "reasoning": "Domain role responsible for managing Kubernetes cluster infrastructure and nodes."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes resource representing worker machines in the cluster."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle state indicating the feature has graduated to production-ready status in Kubernetes."
        },
        {
          "term": "v1.21",
          "tier": 3,
          "reasoning": "Kubernetes API version indicating when this feature became stable."
        },
        {
          "term": "min-kubernetes-server-version",
          "tier": 3,
          "reasoning": "Metadata field specifying minimum Kubernetes version requirement for the feature."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:08:05.956809",
      "elapsed_time": 8.896676301956177
    },
    {
      "chunk_id": "concepts_workloads_controllers__index_sec0",
      "doc_id": "concepts_workloads_controllers__index",
      "heading": "Introduction",
      "source_file": "concepts_workloads_controllers__index.md",
      "content": "---\ntitle: \"Workload Management\"\nweight: 20\nsimple_list: true\n---\n\nKubernetes provides several built-in APIs for declarative management of your\n{{< glossary_tooltip text=\"workloads\" term_id=\"workload\" >}}\nand the components of those workloads.\n\nUltimately, your applications run as containers inside\n{{< glossary_tooltip term_id=\"Pod\" text=\"Pods\" >}}; however, managing individual\nPods would be a lot of effort. For example, if a Pod fails, you probably want to\nrun a new Pod to replace it. Kubernetes can do that for you.\n\nYou use the Kubernetes API to create a workload\n{{< glossary_tooltip text=\"object\" term_id=\"object\" >}} that represents a higher abstraction level\nthan a Pod, and then the Kubernetes\n{{< glossary_tooltip text=\"control plane\" term_id=\"control-plane\" >}} automatically manages\nPod objects on your behalf, based on the specification for the workload object you defined.\n\nThe built-in APIs for managing workloads are:\n\n[Deployment](/docs/concepts/workloads/controllers/deployment/) (and, indirectly, [ReplicaSet](/docs/concepts/workloads/controllers/replicaset/)),\nthe most common way to run an application on your cluster.\nDeployment is a good fit for managing a stateless application workload on your cluster, where\nany Pod in the Deployment is interchangeable and can be replaced if needed.\n(Deployments are a replacement for the legacy\n{{< glossary_tooltip text=\"ReplicationController\" term_id=\"replication-controller\" >}} API).\n\nA [StatefulSet](/docs/concepts/workloads/controllers/statefulset/) lets you\nmanage one or more Pods \u2013 all running the same application code \u2013 where the Pods rely\non having a distinct identity. This is different from a Deployment where the Pods are\nexpected to be interchangeable.\nThe most common use for a StatefulSet is to be able to make a link between its Pods and\ntheir persistent storage. For example, you can run a StatefulSet that associates each Pod\nwith a [PersistentVolume](/docs/concepts/storage/persistent-volumes/). If one of the Pods\nin the StatefulSet fails, Kubernetes makes a replacement Pod that is connected to the\nsame PersistentVolume.\n\nA [DaemonSet](/docs/concepts/workloads/controllers/daemonset/) defines Pods that provide\nfacilities that are local to a specific {{< glossary_tooltip text=\"node\" term_id=\"node\" >}};\nfor example, a driver that lets containers on that node access a storage system. You use a DaemonSet\nwhen the driver, or other node-level service, has to run on the node where it's useful.\nEach Pod in a DaemonSet performs a role similar to a system daemon on a classic Unix / POSIX\nserver.\nA DaemonSet might be fundamental to the operation of your cluster,\nsuch as a plugin to let that node access\n[cluster networking](/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-network-model),\nit might help you to manage the node,\nor it could provide less essential facilities that enhance the container platform you are running.\nYou can run DaemonSets (and their pods) across every node in your cluster, or across just a subset (for example,\nonly install the GPU accelerator driver on nodes that have a GPU installed).\n\nYou can use a [Job](/docs/concepts/workloads/controllers/job/) and / or\na [CronJob](/docs/concepts/workloads/controllers/cron-jobs/) to\ndefine tasks that run to completion and then stop. A Job represents a one-off task,\nwhereas each CronJob repeats according to a schedule.\n\nOther topics in this section:\n<!-- relies on simple_list: true in the front matter -->",
      "terms": [
        {
          "term": "Workload Management",
          "tier": 2,
          "reasoning": "Title concept describing the management of workloads in Kubernetes"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core platform/system name that is the subject of the documentation"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Domain concept referring to applications and their components running on Kubernetes"
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental unit of deployment"
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, frequently used throughout the document"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core concept - the runtime units that applications run inside"
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "The API interface for interacting with Kubernetes resources"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Kubernetes domain term for API resources/entities"
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core architectural concept - the brain of Kubernetes that manages cluster state"
        },
        {
          "term": "Pod objects",
          "tier": 1,
          "reasoning": "Specific reference to Pod as an API object type"
        },
        {
          "term": "workload object",
          "tier": 2,
          "reasoning": "Higher-level abstraction representing workloads in Kubernetes"
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing stateless applications"
        },
        {
          "term": "ReplicaSet",
          "tier": 1,
          "reasoning": "Kubernetes API object that Deployment manages indirectly"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept - a set of nodes running containerized applications"
        },
        {
          "term": "stateless application",
          "tier": 2,
          "reasoning": "Application architecture concept where pods are interchangeable"
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Legacy Kubernetes API object replaced by Deployment"
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing stateful applications with distinct identities"
        },
        {
          "term": "persistent storage",
          "tier": 2,
          "reasoning": "Storage concept for data that persists beyond pod lifecycle"
        },
        {
          "term": "PersistentVolume",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a piece of storage in the cluster"
        },
        {
          "term": "DaemonSet",
          "tier": 1,
          "reasoning": "Kubernetes API object ensuring pods run on specific nodes"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Core Kubernetes concept - a worker machine in the cluster"
        },
        {
          "term": "driver",
          "tier": 2,
          "reasoning": "Technical term for software enabling access to hardware/systems"
        },
        {
          "term": "storage system",
          "tier": 2,
          "reasoning": "Infrastructure concept for persistent data storage"
        },
        {
          "term": "node-level service",
          "tier": 2,
          "reasoning": "Service concept specific to individual nodes"
        },
        {
          "term": "system daemon",
          "tier": 2,
          "reasoning": "Unix/POSIX concept for background services, analogous to DaemonSet pods"
        },
        {
          "term": "Unix",
          "tier": 3,
          "reasoning": "Operating system family referenced for daemon concept"
        },
        {
          "term": "POSIX",
          "tier": 3,
          "reasoning": "Standard referenced for daemon concept"
        },
        {
          "term": "plugin",
          "tier": 2,
          "reasoning": "Extensibility concept for adding functionality"
        },
        {
          "term": "cluster networking",
          "tier": 2,
          "reasoning": "Networking concept specific to Kubernetes clusters"
        },
        {
          "term": "container platform",
          "tier": 2,
          "reasoning": "Infrastructure concept for running containerized applications"
        },
        {
          "term": "GPU",
          "tier": 3,
          "reasoning": "Hardware component referenced in context of node-specific drivers"
        },
        {
          "term": "GPU accelerator driver",
          "tier": 2,
          "reasoning": "Specific driver type for GPU hardware acceleration"
        },
        {
          "term": "Job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running tasks to completion"
        },
        {
          "term": "CronJob",
          "tier": 1,
          "reasoning": "Kubernetes API object for scheduled recurring tasks"
        },
        {
          "term": "tasks",
          "tier": 2,
          "reasoning": "Workload concept for discrete units of work"
        },
        {
          "term": "schedule",
          "tier": 2,
          "reasoning": "Timing concept for CronJob execution"
        },
        {
          "term": "distinct identity",
          "tier": 2,
          "reasoning": "StatefulSet concept where each pod has unique, stable identity"
        },
        {
          "term": "interchangeable",
          "tier": 2,
          "reasoning": "Deployment concept where pods can replace each other"
        },
        {
          "term": "APIs",
          "tier": 3,
          "reasoning": "General technical term for programmatic interfaces"
        },
        {
          "term": "declarative management",
          "tier": 2,
          "reasoning": "Kubernetes operational pattern for defining desired state"
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:08:25.433670",
      "elapsed_time": 18.462199211120605
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec21",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "* [Managing Kubernetes Objects Using Imperative Commands](/docs/tasks/manage-kubernetes-objects/imperative-command/)\n* [Imperative Management of Kubernetes Objects Using Configuration Files](/docs/tasks/manage-kubernetes-objects/imperative-config/)\n* [Kubectl Command Reference](/docs/reference/generated/kubectl/kubectl-commands/)\n* [Kubernetes API Reference](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/)",
      "terms": [
        {
          "term": "Kubernetes Objects",
          "tier": 1,
          "reasoning": "Core API resources that represent the state of a Kubernetes cluster."
        },
        {
          "term": "Imperative Commands",
          "tier": 2,
          "reasoning": "A management approach where users directly specify operations to perform on cluster resources."
        },
        {
          "term": "Imperative Management",
          "tier": 2,
          "reasoning": "A paradigm for managing Kubernetes resources through direct commands rather than declarative configuration."
        },
        {
          "term": "Configuration Files",
          "tier": 2,
          "reasoning": "Files used to define and manage Kubernetes resource specifications."
        },
        {
          "term": "Kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool for interacting with clusters."
        },
        {
          "term": "kubectl-commands",
          "tier": 1,
          "reasoning": "Reference to the set of commands available in the kubectl CLI tool."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "The primary interface for interacting with Kubernetes clusters programmatically."
        },
        {
          "term": "API Reference",
          "tier": 2,
          "reasoning": "Documentation describing the Kubernetes API endpoints and resources."
        },
        {
          "term": "Command Reference",
          "tier": 2,
          "reasoning": "Documentation describing available CLI commands and their usage."
        },
        {
          "term": "Managing",
          "tier": 2,
          "reasoning": "Technical process of creating, updating, and deleting Kubernetes resources."
        },
        {
          "term": "Imperative",
          "tier": 2,
          "reasoning": "A resource management paradigm in Kubernetes contrasted with declarative approaches."
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Refers to API versioning in Kubernetes, a key concept for API stability and compatibility."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:08:35.985150",
      "elapsed_time": 9.53627347946167
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec5",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a password.txt file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF >./password.txt\nusername=admin\npassword=secret\nEOF\n\ncat <<EOF >./kustomization.yaml\nsecretGenerator:\n- name: example-secret-1\n  files:\n  - password.txt\nEOF\n```\n\nThe generated Secret is as follows:\n\n```yaml\napiVersion: v1\ndata:\n  password.txt: dXNlcm5hbWU9YWRtaW4KcGFzc3dvcmQ9c2VjcmV0Cg==\nkind: Secret\nmetadata:\n  name: example-secret-1-t2kt65hgtb\ntype: Opaque\n```\n\nTo generate a Secret from a literal key-value pair, add an entry to `literals` list\nin `secretGenerator`. Here is an example of generating a Secret with a data item from a key-value pair:\n\n```shell\ncat <<EOF >./kustomization.yaml\nsecretGenerator:\n- name: example-secret-2\n  literals:\n  - username=admin\n  - password=secret\nEOF\n```\n\nThe generated Secret is as follows:\n\n```yaml\napiVersion: v1\ndata:\n  password: c2VjcmV0\n  username: YWRtaW4=\nkind: Secret\nmetadata:\n  name: example-secret-2-t52t6g96d8\ntype: Opaque\n```\n\nLike ConfigMaps, generated Secrets can be used in Deployments by referring to the name of the secretGenerator:\n\n```shell",
      "terms": [
        {
          "term": "Secret",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for storing sensitive data like passwords and tokens."
        },
        {
          "term": "secretGenerator",
          "tier": 1,
          "reasoning": "Kustomize-specific resource generator for creating Secret objects."
        },
        {
          "term": "ConfigMaps",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for storing non-sensitive configuration data."
        },
        {
          "term": "Deployments",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing replicated applications."
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Configuration file used by Kustomize to define resource customizations."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section containing resource identification information."
        },
        {
          "term": "data",
          "tier": 2,
          "reasoning": "Field in Secret/ConfigMap resources containing the actual stored values."
        },
        {
          "term": "type",
          "tier": 2,
          "reasoning": "Field in Secret resources specifying the secret type classification."
        },
        {
          "term": "Opaque",
          "tier": 2,
          "reasoning": "Default Secret type in Kubernetes for arbitrary user-defined data."
        },
        {
          "term": "literals",
          "tier": 2,
          "reasoning": "Kustomize secretGenerator field for specifying inline key-value pairs."
        },
        {
          "term": "files",
          "tier": 2,
          "reasoning": "Kustomize secretGenerator field for specifying file-based secret sources."
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Kubernetes metadata field identifying the resource within a namespace."
        },
        {
          "term": "key-value pair",
          "tier": 2,
          "reasoning": "Data structure concept used for storing secret literals."
        },
        {
          "term": "generated Secret",
          "tier": 2,
          "reasoning": "Secret resource created by Kustomize's secretGenerator."
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "Kubernetes core API version identifier."
        },
        {
          "term": "password.txt",
          "tier": 3,
          "reasoning": "Example file used as source for secret data in the documentation."
        },
        {
          "term": "username",
          "tier": 3,
          "reasoning": "Key name used in the secret data examples."
        },
        {
          "term": "password",
          "tier": 3,
          "reasoning": "Key name used in the secret data examples."
        },
        {
          "term": "cat",
          "tier": 3,
          "reasoning": "Shell command used to create files in the examples."
        },
        {
          "term": "EOF",
          "tier": 3,
          "reasoning": "Here-document delimiter used in shell examples."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for the examples."
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes manifests."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T22:08:49.821377",
      "elapsed_time": 12.820742130279541
    },
    {
      "chunk_id": "reference_using-api_deprecation-policy_sec4",
      "doc_id": "reference_using-api_deprecation-policy",
      "heading": "Deprecating a metric",
      "source_file": "reference_using-api_deprecation-policy.md",
      "content": "Each component of the Kubernetes control-plane exposes metrics (usually the\n`/metrics` endpoint), which are typically ingested by cluster administrators.\nNot all metrics are the same: some metrics are commonly used as SLIs or used\nto determine SLOs, these tend to have greater import. Other metrics are more\nexperimental in nature or are used primarily in the Kubernetes development\nprocess.\n\nAccordingly, metrics fall under three stability classes (`ALPHA`, `BETA` `STABLE`);\nthis impacts removal of a metric during a Kubernetes release. These classes\nare determined by the perceived importance of the metric. The rules for\ndeprecating and removing a metric are as follows:\n\n**Rule #11a: Metrics, for the corresponding stability class, must function for no less than:**\n\n* **STABLE: 4 releases or 12 months (whichever is longer)**\n* **BETA: 2 releases or 8 months (whichever is longer)**\n* **ALPHA: 0 releases**\n\n**Rule #11b: Metrics, after their _announced deprecation_, must function for no less than:**\n\n* **STABLE: 3 releases or 9 months (whichever is longer)**\n* **BETA: 1 releases or 4 months (whichever is longer)**\n* **ALPHA: 0 releases**\n\nDeprecated metrics will have their description text prefixed with a deprecation notice\nstring '(Deprecated from x.y)' and a warning log will be emitted during metric\nregistration. Like their stable undeprecated counterparts, deprecated metrics will\nbe automatically registered to the metrics endpoint and therefore visible.\n\nOn a subsequent release (when the metric's `deprecatedVersion` is equal to\n_current_kubernetes_version - 3_), a deprecated metric will become a _hidden_ metric.\n**_Unlike_** their deprecated counterparts, hidden metrics will _no longer_ be\nautomatically registered to the metrics endpoint (hence hidden). However, they\ncan be explicitly enabled through a command line flag on the binary\n(`--show-hidden-metrics-for-version=`). This provides cluster admins an\nescape hatch to properly migrate off of a deprecated metric, if they were not\nable to react to the earlier deprecation warnings. Hidden metrics should be\ndeleted after one release.",
      "terms": [
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core platform name, the primary subject of this documentation."
        },
        {
          "term": "control-plane",
          "tier": 1,
          "reasoning": "Named Kubernetes architectural component that manages the cluster."
        },
        {
          "term": "metrics",
          "tier": 2,
          "reasoning": "Core domain concept referring to quantitative measurements exposed by components."
        },
        {
          "term": "/metrics",
          "tier": 1,
          "reasoning": "Specific API endpoint path for accessing metrics data."
        },
        {
          "term": "endpoint",
          "tier": 2,
          "reasoning": "Technical networking concept referring to an accessible URL/path."
        },
        {
          "term": "cluster administrators",
          "tier": 2,
          "reasoning": "Domain-specific role responsible for managing Kubernetes clusters."
        },
        {
          "term": "SLIs",
          "tier": 2,
          "reasoning": "Service Level Indicators - key reliability engineering concept for measuring service performance."
        },
        {
          "term": "SLOs",
          "tier": 2,
          "reasoning": "Service Level Objectives - reliability engineering concept for defining performance targets."
        },
        {
          "term": "stability classes",
          "tier": 2,
          "reasoning": "Domain concept describing the maturity classification system for metrics."
        },
        {
          "term": "ALPHA",
          "tier": 2,
          "reasoning": "Stability class designation indicating experimental/early-stage features."
        },
        {
          "term": "BETA",
          "tier": 2,
          "reasoning": "Stability class designation indicating pre-stable features with some guarantees."
        },
        {
          "term": "STABLE",
          "tier": 2,
          "reasoning": "Stability class designation indicating production-ready features with strong guarantees."
        },
        {
          "term": "Kubernetes release",
          "tier": 2,
          "reasoning": "Domain concept referring to versioned releases of the Kubernetes platform."
        },
        {
          "term": "deprecating",
          "tier": 2,
          "reasoning": "Technical process of marking features/metrics for future removal."
        },
        {
          "term": "deprecation",
          "tier": 2,
          "reasoning": "Technical lifecycle concept for phasing out features."
        },
        {
          "term": "releases",
          "tier": 2,
          "reasoning": "Technical concept referring to software version releases."
        },
        {
          "term": "announced deprecation",
          "tier": 2,
          "reasoning": "Specific lifecycle phase when deprecation is formally communicated."
        },
        {
          "term": "deprecated metrics",
          "tier": 2,
          "reasoning": "Metrics that have been marked for future removal."
        },
        {
          "term": "deprecation notice",
          "tier": 2,
          "reasoning": "Formal notification string indicating a metric is deprecated."
        },
        {
          "term": "warning log",
          "tier": 2,
          "reasoning": "Logging mechanism for alerting about deprecated functionality."
        },
        {
          "term": "metrics endpoint",
          "tier": 2,
          "reasoning": "The API endpoint where metrics are exposed for collection."
        },
        {
          "term": "deprecatedVersion",
          "tier": 1,
          "reasoning": "Specific field/attribute tracking when a metric was deprecated."
        },
        {
          "term": "current_kubernetes_version",
          "tier": 2,
          "reasoning": "Variable representing the current running Kubernetes version."
        },
        {
          "term": "hidden metric",
          "tier": 2,
          "reasoning": "Specific metric state where metrics are not automatically registered."
        },
        {
          "term": "hidden metrics",
          "tier": 2,
          "reasoning": "Plural form of hidden metric, metrics no longer auto-registered."
        },
        {
          "term": "command line flag",
          "tier": 2,
          "reasoning": "CLI configuration mechanism for binary execution options."
        },
        {
          "term": "binary",
          "tier": 3,
          "reasoning": "Executable program file in the context of Kubernetes components."
        },
        {
          "term": "--show-hidden-metrics-for-version=",
          "tier": 1,
          "reasoning": "Specific CLI flag for enabling hidden metrics visibility."
        },
        {
          "term": "cluster admins",
          "tier": 2,
          "reasoning": "Shortened form of cluster administrators role."
        },
        {
          "term": "escape hatch",
          "tier": 2,
          "reasoning": "Technical pattern providing fallback mechanism for migration."
        },
        {
          "term": "deprecation warnings",
          "tier": 2,
          "reasoning": "Alert messages about deprecated functionality."
        }
      ],
      "term_count": 31,
      "generated_at": "2026-02-08T22:09:07.404595",
      "elapsed_time": 16.56701946258545
    },
    {
      "chunk_id": "tasks_extend-kubernetes_configure-aggregation-layer_sec1",
      "doc_id": "tasks_extend-kubernetes_configure-aggregation-layer",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_extend-kubernetes_configure-aggregation-layer.md",
      "content": "{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n{{< note >}}\nThere are a few setup requirements for getting the aggregation layer working in\nyour environment to support mutual TLS auth between the proxy and extension apiservers.\nKubernetes and the kube-apiserver have multiple CAs, so make sure that the proxy is\nsigned by the aggregation layer CA and not by something else, like the Kubernetes general CA.\n{{< /note >}}\n\n{{< caution >}}\nReusing the same CA for different client types can negatively impact the cluster's\nability to function. For more information, see [CA Reusage and Conflicts](#ca-reusage-and-conflicts).\n{{< /caution >}}\n\n<!-- steps -->",
      "terms": [
        {
          "term": "aggregation layer",
          "tier": 1,
          "reasoning": "Core Kubernetes component that enables extending the API server with additional APIs."
        },
        {
          "term": "mutual TLS auth",
          "tier": 2,
          "reasoning": "Security concept describing bidirectional TLS authentication between components."
        },
        {
          "term": "mutual TLS",
          "tier": 2,
          "reasoning": "Abbreviated form of the authentication mechanism referenced in the chunk."
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol, foundational security concept."
        },
        {
          "term": "proxy",
          "tier": 2,
          "reasoning": "Technical component that intermediates requests between API server and extensions."
        },
        {
          "term": "extension apiservers",
          "tier": 1,
          "reasoning": "Kubernetes component that extends the main API server with custom APIs."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented."
        },
        {
          "term": "kube-apiserver",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that exposes the Kubernetes API."
        },
        {
          "term": "CA",
          "tier": 2,
          "reasoning": "Certificate Authority - cryptographic concept for signing certificates."
        },
        {
          "term": "CAs",
          "tier": 2,
          "reasoning": "Plural form of Certificate Authority as used in the text."
        },
        {
          "term": "aggregation layer CA",
          "tier": 1,
          "reasoning": "Specific Certificate Authority used for signing aggregation layer components."
        },
        {
          "term": "Kubernetes general CA",
          "tier": 1,
          "reasoning": "The main Certificate Authority used by Kubernetes for general purposes."
        },
        {
          "term": "client types",
          "tier": 2,
          "reasoning": "Technical concept referring to different categories of API clients."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "CA Reusage and Conflicts",
          "tier": 2,
          "reasoning": "Named section/concept describing certificate authority management issues."
        },
        {
          "term": "auth",
          "tier": 3,
          "reasoning": "Abbreviation for authentication used in technical context."
        },
        {
          "term": "signed",
          "tier": 3,
          "reasoning": "Cryptographic operation relevant to certificate management."
        },
        {
          "term": "environment",
          "tier": 3,
          "reasoning": "Technical context referring to the deployment/runtime environment."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T22:09:18.388763",
      "elapsed_time": 9.968626022338867
    },
    {
      "chunk_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1_sec4",
      "doc_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1",
      "heading": "ServiceCIDRList {#ServiceCIDRList}",
      "source_file": "reference_kubernetes-api_cluster-resources_service-cidr-v1.md",
      "content": "ServiceCIDRList contains a list of ServiceCIDR objects.\n\n<hr>\n\n- **apiVersion**: networking.k8s.io/v1\n\n\n- **kind**: ServiceCIDRList\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/list-meta#ListMeta\" >}}\">ListMeta</a>)\n\n  Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **items** ([]<a href=\"{{< ref \"../cluster-resources/service-cidr-v1#ServiceCIDR\" >}}\">ServiceCIDR</a>), required\n\n  items is the list of ServiceCIDRs.",
      "terms": [
        {
          "term": "ServiceCIDRList",
          "tier": 1,
          "reasoning": "Named Kubernetes API object that contains a list of ServiceCIDR objects."
        },
        {
          "term": "ServiceCIDR",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource referenced as items in the list."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the version of the API schema."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for networking resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes API field containing standard object metadata."
        },
        {
          "term": "ListMeta",
          "tier": 1,
          "reasoning": "Named Kubernetes common definition type for list metadata."
        },
        {
          "term": "items",
          "tier": 2,
          "reasoning": "Kubernetes API field containing the array of resources in a list."
        },
        {
          "term": "CIDR",
          "tier": 2,
          "reasoning": "Networking concept (Classless Inter-Domain Routing) embedded in the resource name."
        },
        {
          "term": "object",
          "tier": 3,
          "reasoning": "Technical term referring to Kubernetes API objects/resources."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Technical acronym for Application Programming Interface, fundamental to Kubernetes."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Reference to Kubernetes API conventions documentation for metadata standards."
        },
        {
          "term": "cluster-resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources that are cluster-scoped."
        },
        {
          "term": "networking.k8s.io",
          "tier": 1,
          "reasoning": "Kubernetes API group for networking-related resources."
        },
        {
          "term": "required",
          "tier": 3,
          "reasoning": "API field validation term indicating mandatory fields in Kubernetes specs."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T22:09:28.752498",
      "elapsed_time": 9.345441341400146
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DisableCloudProviders_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DisableCloudProviders",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DisableCloudProviders.md",
      "content": "---\ntitle: DisableCloudProviders\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha\n    defaultValue: false\n    fromVersion: \"1.22\"\n    toVersion: \"1.28\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.29\"\n    toVersion: \"1.30\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.31\"\n    toVersion: \"1.32\"\n\nremoved: true\n---\nEnabling this feature gate deactivated functionality in `kube-apiserver`,\n`kube-controller-manager` and `kubelet` that related to the `--cloud-provider`\ncommand line argument.\n\nIn Kubernetes v1.31 and later, the only valid values for `--cloud-provider`\nare the empty string (no cloud provider integration), or \"external\"\n(integration via a separate cloud-controller-manager).",
      "terms": [
        {
          "term": "DisableCloudProviders",
          "tier": 1,
          "reasoning": "Named feature gate in Kubernetes that controls cloud provider functionality."
        },
        {
          "term": "feature_gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling optional features."
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating experimental status in Kubernetes."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating pre-stable testing phase in Kubernetes."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready status in Kubernetes."
        },
        {
          "term": "kube-apiserver",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that exposes the Kubernetes API."
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that runs controller processes."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Primary node agent that runs on each node in the cluster."
        },
        {
          "term": "--cloud-provider",
          "tier": 1,
          "reasoning": "CLI flag/command line argument for configuring cloud provider integration."
        },
        {
          "term": "command line argument",
          "tier": 3,
          "reasoning": "Technical term for parameters passed to executables at runtime."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Domain concept referring to infrastructure providers integrated with Kubernetes."
        },
        {
          "term": "cloud provider integration",
          "tier": 2,
          "reasoning": "Technical concept describing how Kubernetes connects with cloud infrastructure."
        },
        {
          "term": "cloud-controller-manager",
          "tier": 1,
          "reasoning": "Kubernetes component that embeds cloud-specific control logic."
        },
        {
          "term": "external",
          "tier": 2,
          "reasoning": "Valid configuration value for --cloud-provider indicating out-of-tree cloud controller."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": "v1.31",
          "tier": 2,
          "reasoning": "Specific Kubernetes version referenced for feature behavior."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Configuration property indicating the default state of a feature gate."
        },
        {
          "term": "fromVersion",
          "tier": 2,
          "reasoning": "Configuration property indicating when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 2,
          "reasoning": "Configuration property indicating when a feature stage ends."
        },
        {
          "term": "stage",
          "tier": 2,
          "reasoning": "Technical term describing feature maturity level in Kubernetes lifecycle."
        },
        {
          "term": "removed",
          "tier": 2,
          "reasoning": "Feature gate status indicating the gate has been removed from Kubernetes."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:09:41.997774",
      "elapsed_time": 12.229445219039917
    },
    {
      "chunk_id": "reference_kubernetes-api_config-and-storage-resources_volume-attributes-class-v1_sec1",
      "doc_id": "reference_kubernetes-api_config-and-storage-resources_volume-attributes-class-v1",
      "heading": "VolumeAttributesClass {#VolumeAttributesClass}",
      "source_file": "reference_kubernetes-api_config-and-storage-resources_volume-attributes-class-v1.md",
      "content": "VolumeAttributesClass represents a specification of mutable volume attributes defined by the CSI driver. The class can be specified during dynamic provisioning of PersistentVolumeClaims, and changed in the PersistentVolumeClaim spec after provisioning.\n\n<hr>\n\n- **apiVersion**: storage.k8s.io/v1\n\n\n- **kind**: VolumeAttributesClass\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/object-meta#ObjectMeta\" >}}\">ObjectMeta</a>)\n\n  Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **driverName** (string), required\n\n  Name of the CSI driver This field is immutable.\n\n- **parameters** (map[string]string)\n\n  parameters hold volume attributes defined by the CSI driver. These values are opaque to the Kubernetes and are passed directly to the CSI driver. The underlying storage provider supports changing these attributes on an existing volume, however the parameters field itself is immutable. To invoke a volume update, a new VolumeAttributesClass should be created with new parameters, and the PersistentVolumeClaim should be updated to reference the new VolumeAttributesClass.\n  \n  This field is required and must contain at least one key/value pair. The keys cannot be empty, and the maximum number of parameters is 512, with a cumulative max size of 256K. If the CSI driver rejects invalid parameters, the target PersistentVolumeClaim will be set to an \"Infeasible\" state in the modifyVolumeStatus field.",
      "terms": [
        {
          "term": "VolumeAttributesClass",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for specifying mutable volume attributes defined by CSI driver."
        },
        {
          "term": "CSI driver",
          "tier": 1,
          "reasoning": "Named infrastructure component - Container Storage Interface driver that manages storage operations."
        },
        {
          "term": "PersistentVolumeClaims",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for requesting persistent storage."
        },
        {
          "term": "PersistentVolumeClaim",
          "tier": 1,
          "reasoning": "Singular form of the core Kubernetes storage API resource."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the version of the API schema."
        },
        {
          "term": "storage.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for storage resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes API field containing object identification and management data."
        },
        {
          "term": "ObjectMeta",
          "tier": 1,
          "reasoning": "Kubernetes API type that defines standard object metadata structure."
        },
        {
          "term": "driverName",
          "tier": 2,
          "reasoning": "Required field specifying the name of the CSI driver for the volume class."
        },
        {
          "term": "parameters",
          "tier": 2,
          "reasoning": "Field holding volume attributes as key/value pairs passed to CSI driver."
        },
        {
          "term": "dynamic provisioning",
          "tier": 2,
          "reasoning": "Kubernetes storage concept for automatically creating volumes on demand."
        },
        {
          "term": "immutable",
          "tier": 2,
          "reasoning": "Technical property indicating a field cannot be changed after creation."
        },
        {
          "term": "volume attributes",
          "tier": 2,
          "reasoning": "Domain concept referring to configurable properties of storage volumes."
        },
        {
          "term": "mutable volume attributes",
          "tier": 2,
          "reasoning": "Volume properties that can be changed after initial provisioning."
        },
        {
          "term": "storage provider",
          "tier": 2,
          "reasoning": "Infrastructure concept referring to the underlying storage system."
        },
        {
          "term": "volume update",
          "tier": 2,
          "reasoning": "Process of modifying volume attributes on an existing volume."
        },
        {
          "term": "modifyVolumeStatus",
          "tier": 2,
          "reasoning": "Kubernetes field tracking the status of volume modification operations."
        },
        {
          "term": "Infeasible",
          "tier": 2,
          "reasoning": "Specific status value indicating CSI driver rejected invalid parameters."
        },
        {
          "term": "CSI",
          "tier": 1,
          "reasoning": "Container Storage Interface - standard protocol for storage integration in Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes API concept referring to the desired state specification of a resource."
        },
        {
          "term": "provisioning",
          "tier": 2,
          "reasoning": "Process of creating and configuring storage resources."
        },
        {
          "term": "key/value pair",
          "tier": 3,
          "reasoning": "Data structure format used for parameters passed to CSI driver."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the driverName field."
        },
        {
          "term": "map[string]string",
          "tier": 3,
          "reasoning": "Go-style type notation indicating a string-to-string mapping for parameters."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - referenced in context of Kubernetes conventions."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Kubernetes documentation reference for API design standards."
        }
      ],
      "term_count": 28,
      "generated_at": "2026-02-08T22:09:57.652185",
      "elapsed_time": 14.633269309997559
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_rollout__index_sec4",
      "doc_id": "reference_kubectl_generated_kubectl_rollout__index",
      "heading": "{{% heading \"seealso\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_rollout__index.md",
      "content": "* [kubectl](../kubectl/)\t - kubectl controls the Kubernetes cluster manager\n* [kubectl rollout history](kubectl_rollout_history/)\t - View rollout history\n* [kubectl rollout pause](kubectl_rollout_pause/)\t - Mark the provided resource as paused\n* [kubectl rollout restart](kubectl_rollout_restart/)\t - Restart a resource\n* [kubectl rollout resume](kubectl_rollout_resume/)\t - Resume a paused resource\n* [kubectl rollout status](kubectl_rollout_status/)\t - Show the status of the rollout\n* [kubectl rollout undo](kubectl_rollout_undo/)\t - Undo a previous rollout",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool, a core named component for cluster management."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that kubectl controls."
        },
        {
          "term": "cluster manager",
          "tier": 2,
          "reasoning": "Domain concept describing the role of managing a Kubernetes cluster."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept representing a set of nodes running containerized applications."
        },
        {
          "term": "kubectl rollout",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for managing rollouts of resources."
        },
        {
          "term": "kubectl rollout history",
          "tier": 1,
          "reasoning": "Specific kubectl command to view rollout history."
        },
        {
          "term": "kubectl rollout pause",
          "tier": 1,
          "reasoning": "Specific kubectl command to pause a rollout."
        },
        {
          "term": "kubectl rollout restart",
          "tier": 1,
          "reasoning": "Specific kubectl command to restart a resource's rollout."
        },
        {
          "term": "kubectl rollout resume",
          "tier": 1,
          "reasoning": "Specific kubectl command to resume a paused rollout."
        },
        {
          "term": "kubectl rollout status",
          "tier": 1,
          "reasoning": "Specific kubectl command to show rollout status."
        },
        {
          "term": "kubectl rollout undo",
          "tier": 1,
          "reasoning": "Specific kubectl command to undo a previous rollout."
        },
        {
          "term": "rollout",
          "tier": 2,
          "reasoning": "Core Kubernetes deployment concept describing the process of updating resources."
        },
        {
          "term": "rollout history",
          "tier": 2,
          "reasoning": "Domain concept for tracking the history of deployment changes."
        },
        {
          "term": "paused",
          "tier": 2,
          "reasoning": "Technical state in Kubernetes rollout lifecycle where updates are suspended."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Kubernetes domain term for API objects that can be managed."
        },
        {
          "term": "status",
          "tier": 3,
          "reasoning": "Technical term describing the current state of a Kubernetes resource or operation."
        },
        {
          "term": "undo",
          "tier": 2,
          "reasoning": "Technical operation concept for reverting to a previous rollout state."
        },
        {
          "term": "pause",
          "tier": 2,
          "reasoning": "Technical operation to halt a rollout in progress."
        },
        {
          "term": "resume",
          "tier": 2,
          "reasoning": "Technical operation to continue a paused rollout."
        },
        {
          "term": "restart",
          "tier": 2,
          "reasoning": "Technical operation to trigger a new rollout of a resource."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T22:10:07.702845",
      "elapsed_time": 9.027247905731201
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec10",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`AnonymousAuthConfig`     {#apiserver-config-k8s-io-v1-AnonymousAuthConfig}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [AuthenticationConfiguration](#apiserver-config-k8s-io-v1-AuthenticationConfiguration)\n\n\n<p>AnonymousAuthConfig provides the configuration for the anonymous authenticator.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>enabled</code> <B>[Required]</B><br/>\n<code>bool</code>\n</td>\n<td>\n   <span class=\"text-muted\">No description provided.</span></td>\n</tr>\n<tr><td><code>conditions</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AnonymousAuthCondition\"><code>[]AnonymousAuthCondition</code></a>\n</td>\n<td>\n   <p>If set, anonymous auth is only allowed if the request meets one of the\nconditions.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for authentication settings."
        },
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Named configuration structure for the anonymous authenticator component."
        },
        {
          "term": "AnonymousAuthCondition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type defining conditions for anonymous authentication."
        },
        {
          "term": "anonymous authenticator",
          "tier": 2,
          "reasoning": "Domain concept referring to the authentication mechanism that handles anonymous requests."
        },
        {
          "term": "anonymous auth",
          "tier": 2,
          "reasoning": "Abbreviated form of anonymous authentication, a security concept in Kubernetes."
        },
        {
          "term": "enabled",
          "tier": 3,
          "reasoning": "Configuration field that controls whether a feature is active, technical term in config context."
        },
        {
          "term": "conditions",
          "tier": 2,
          "reasoning": "Technical term referring to criteria that must be met for authentication to proceed."
        },
        {
          "term": "request",
          "tier": 3,
          "reasoning": "Technical term referring to API requests in the authentication context."
        },
        {
          "term": "configuration",
          "tier": 3,
          "reasoning": "Technical term describing settings and parameters for system behavior."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "API group and version identifier for Kubernetes API server configuration."
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "Data type specification indicating a boolean field in the configuration."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term referring to a configuration parameter in the API object schema."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:10:16.719404",
      "elapsed_time": 7.999697685241699
    },
    {
      "chunk_id": "reference_glossary_name_sec0",
      "doc_id": "reference_glossary_name",
      "heading": "Introduction",
      "source_file": "reference_glossary_name.md",
      "content": "---\ntitle: Name\nid: name\ndate: 2018-04-12\nfull_link: /docs/concepts/overview/working-with-objects/names\nshort_description: >\n  A client-provided string that refers to an object in a resource URL, such as `/api/v1/pods/some-name`.\n\naka: \ntags:\n- fundamental\n---\nA client-provided string that refers to an object in a {{< glossary_tooltip text=\"resource\" term_id=\"api-resource\" >}}\nURL, such as `/api/v1/pods/some-name`.\n\n<!--more--> \n\nOnly one object of a given kind can have a given name at a time. However, if you delete the object, you can make a new object with the same name.",
      "terms": [
        {
          "term": "Name",
          "tier": 1,
          "reasoning": "Core Kubernetes concept for identifying objects, the main subject of this glossary entry"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept referring to persistent entities in the system"
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to API endpoints and object types"
        },
        {
          "term": "resource URL",
          "tier": 2,
          "reasoning": "Technical concept describing the API path structure for accessing Kubernetes resources"
        },
        {
          "term": "URL",
          "tier": 3,
          "reasoning": "Standard web protocol concept used in context of Kubernetes API addressing"
        },
        {
          "term": "api",
          "tier": 2,
          "reasoning": "Core technical concept appearing in the resource URL path example"
        },
        {
          "term": "/api/v1/pods/some-name",
          "tier": 2,
          "reasoning": "Example API path demonstrating Kubernetes resource URL structure"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes resource type appearing in the example URL path"
        },
        {
          "term": "v1",
          "tier": 2,
          "reasoning": "API version identifier in Kubernetes API path structure"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the type/category of an API object"
        },
        {
          "term": "client-provided string",
          "tier": 2,
          "reasoning": "Technical description of how names are specified by users/clients"
        },
        {
          "term": "client",
          "tier": 3,
          "reasoning": "Technical term referring to the entity making API requests"
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:10:26.494680",
      "elapsed_time": 8.75869345664978
    },
    {
      "chunk_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information_sec0",
      "doc_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information",
      "heading": "Introduction",
      "source_file": "tasks_inject-data-application_downward-api-volume-expose-pod-information.md",
      "content": "---\ntitle: Expose Pod Information to Containers Through Files\ncontent_type: task\nweight: 40\n---\n\n<!-- overview -->\n\nThis page shows how a Pod can use a\n[`downwardAPI` volume](/docs/concepts/storage/volumes/#downwardapi),\nto expose information about itself to containers running in the Pod.\nA `downwardAPI` volume can expose Pod fields and container fields.\n\nIn Kubernetes, there are two ways to expose Pod and container fields to a running container:\n\n* [Environment variables](/docs/tasks/inject-data-application/environment-variable-expose-pod-information/)\n* Volume files, as explained in this task\n\nTogether, these two ways of exposing Pod and container fields are called the\n_downward API_.",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental unit of deployment."
        },
        {
          "term": "downwardAPI",
          "tier": 1,
          "reasoning": "Specific Kubernetes volume type for exposing pod metadata."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core domain concept representing isolated runtime environments in Kubernetes."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Kubernetes storage abstraction concept for persistent or ephemeral data."
        },
        {
          "term": "Pod fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata attributes of a Pod object."
        },
        {
          "term": "container fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata attributes of container specifications."
        },
        {
          "term": "Environment variables",
          "tier": 2,
          "reasoning": "Standard mechanism for passing configuration data to containers."
        },
        {
          "term": "Volume files",
          "tier": 2,
          "reasoning": "Method of exposing data to containers through the filesystem."
        },
        {
          "term": "downward API",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for exposing pod and container metadata to running containers."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "running container",
          "tier": 2,
          "reasoning": "Technical concept describing an active container process within a pod."
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T22:10:35.316501",
      "elapsed_time": 7.803985834121704
    },
    {
      "chunk_id": "concepts_security_multi-tenancy_sec1",
      "doc_id": "concepts_security_multi-tenancy",
      "heading": "Use cases",
      "source_file": "concepts_security_multi-tenancy.md",
      "content": "The first step to determining how to share your cluster is understanding your use case, so you can\nevaluate the patterns and tools available. In general, multi-tenancy in Kubernetes clusters falls\ninto two broad categories, though many variations and hybrids are also possible.\n\n### Multiple teams\n\nA common form of multi-tenancy is to share a cluster between multiple teams within an\norganization, each of whom may operate one or more workloads. These workloads frequently need to\ncommunicate with each other, and with other workloads located on the same or different clusters.\n\nIn this scenario, members of the teams often have direct access to Kubernetes resources via tools\nsuch as `kubectl`, or indirect access through GitOps controllers or other types of release\nautomation tools. There is often some level of trust between members of different teams, but\nKubernetes policies such as RBAC, quotas, and network policies are essential to safely and fairly\nshare clusters.\n\n### Multiple customers\n\nThe other major form of multi-tenancy frequently involves a Software-as-a-Service (SaaS) vendor\nrunning multiple instances of a workload for customers. This business model is so strongly\nassociated with this deployment style that many people call it \"SaaS tenancy.\" However, a better\nterm might be \"multi-customer tenancy,\" since SaaS vendors may also use other deployment models,\nand this deployment model can also be used outside of SaaS.\n\nIn this scenario, the customers do not have access to the cluster; Kubernetes is invisible from\ntheir perspective and is only used by the vendor to manage the workloads. Cost optimization is\nfrequently a critical concern, and Kubernetes policies are used to ensure that the workloads are\nstrongly isolated from each other.",
      "terms": [
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "multi-tenancy",
          "tier": 2,
          "reasoning": "Key architectural pattern for sharing Kubernetes resources among multiple users or teams"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform that is the subject of this documentation"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Technical term for applications and services running on Kubernetes"
        },
        {
          "term": "clusters",
          "tier": 2,
          "reasoning": "Plural form of cluster, referring to multiple Kubernetes environments"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters"
        },
        {
          "term": "GitOps controllers",
          "tier": 2,
          "reasoning": "Automation tools that implement GitOps methodology for Kubernetes deployments"
        },
        {
          "term": "Kubernetes resources",
          "tier": 2,
          "reasoning": "API objects and entities managed within a Kubernetes cluster"
        },
        {
          "term": "RBAC",
          "tier": 1,
          "reasoning": "Role-Based Access Control - a core Kubernetes authorization mechanism"
        },
        {
          "term": "quotas",
          "tier": 2,
          "reasoning": "Kubernetes resource management mechanism for limiting resource consumption"
        },
        {
          "term": "network policies",
          "tier": 2,
          "reasoning": "Kubernetes resources that control network traffic between pods"
        },
        {
          "term": "Kubernetes policies",
          "tier": 2,
          "reasoning": "Configuration rules that govern behavior and access in Kubernetes"
        },
        {
          "term": "Software-as-a-Service",
          "tier": 2,
          "reasoning": "Cloud computing service model relevant to multi-tenancy deployment patterns"
        },
        {
          "term": "SaaS",
          "tier": 2,
          "reasoning": "Abbreviation for Software-as-a-Service, a common deployment model"
        },
        {
          "term": "SaaS tenancy",
          "tier": 2,
          "reasoning": "Specific multi-tenancy pattern associated with SaaS deployments"
        },
        {
          "term": "multi-customer tenancy",
          "tier": 2,
          "reasoning": "Alternative term for SaaS-style multi-tenancy deployment model"
        },
        {
          "term": "deployment model",
          "tier": 2,
          "reasoning": "Architectural pattern for how applications are deployed and managed"
        },
        {
          "term": "cost optimization",
          "tier": 3,
          "reasoning": "Operational concern relevant to multi-tenant Kubernetes deployments"
        },
        {
          "term": "isolated",
          "tier": 3,
          "reasoning": "Technical concept referring to workload separation and security boundaries"
        },
        {
          "term": "vendor",
          "tier": 3,
          "reasoning": "Role in SaaS context managing Kubernetes infrastructure for customers"
        },
        {
          "term": "customers",
          "tier": 3,
          "reasoning": "Tenants in a multi-customer deployment model"
        },
        {
          "term": "teams",
          "tier": 3,
          "reasoning": "Organizational units that share cluster resources in multi-tenancy"
        },
        {
          "term": "use case",
          "tier": 3,
          "reasoning": "Technical planning term for evaluating deployment patterns"
        },
        {
          "term": "deployment style",
          "tier": 2,
          "reasoning": "Pattern or approach for deploying applications in Kubernetes"
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T22:10:50.036469",
      "elapsed_time": 13.701468229293823
    },
    {
      "chunk_id": "tasks_debug_debug-application_get-shell-running-container_sec5",
      "doc_id": "tasks_debug_debug-application_get-shell-running-container",
      "heading": "Opening a shell when a Pod has more than one container",
      "source_file": "tasks_debug_debug-application_get-shell-running-container.md",
      "content": "If a Pod has more than one container, use `--container` or `-c` to\nspecify a container in the `kubectl exec` command. For example,\nsuppose you have a Pod named my-pod, and the Pod has two containers\nnamed _main-app_ and _helper-app_. The following command would open a\nshell to the _main-app_ container.\n\n```shell\nkubectl exec -i -t my-pod --container main-app -- /bin/bash\n```\n\n{{< note >}}\nThe short options `-i` and `-t` are the same as the long options `--stdin` and `--tty`\n{{< /note >}}",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing a group of containers"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental domain concept in Kubernetes representing an isolated runtime unit"
        },
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for executing commands in containers"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "--container",
          "tier": 3,
          "reasoning": "CLI flag for specifying target container in kubectl commands"
        },
        {
          "term": "-c",
          "tier": 3,
          "reasoning": "Short form CLI flag for container specification"
        },
        {
          "term": "my-pod",
          "tier": 3,
          "reasoning": "Example Pod name used in documentation to illustrate command usage"
        },
        {
          "term": "main-app",
          "tier": 3,
          "reasoning": "Example container name demonstrating multi-container Pod usage"
        },
        {
          "term": "helper-app",
          "tier": 3,
          "reasoning": "Example container name illustrating sidecar/helper container pattern"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Technical term for command-line interface opened via exec"
        },
        {
          "term": "/bin/bash",
          "tier": 3,
          "reasoning": "Linux shell path used as exec target command"
        },
        {
          "term": "-i",
          "tier": 3,
          "reasoning": "Short CLI flag for stdin passthrough in kubectl exec"
        },
        {
          "term": "-t",
          "tier": 3,
          "reasoning": "Short CLI flag for TTY allocation in kubectl exec"
        },
        {
          "term": "--stdin",
          "tier": 3,
          "reasoning": "Long form CLI flag enabling stdin passthrough to container"
        },
        {
          "term": "--tty",
          "tier": 3,
          "reasoning": "Long form CLI flag for allocating a TTY for interactive sessions"
        },
        {
          "term": "exec",
          "tier": 2,
          "reasoning": "Kubernetes operation concept for running commands inside containers"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T22:10:59.589001",
      "elapsed_time": 8.532642364501953
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec0",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "Introduction",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "---\ntitle: Declarative Management of Kubernetes Objects Using Configuration Files\ncontent_type: task\nweight: 10\n---\n\n<!-- overview -->\nKubernetes objects can be created, updated, and deleted by storing multiple\nobject configuration files in a directory and using `kubectl apply` to\nrecursively create and update those objects as needed. This method\nretains writes made to live objects without merging the changes\nback into the object configuration files. `kubectl diff` also gives you a\npreview of what changes `apply` will make.",
      "terms": [
        {
          "term": "Kubernetes objects",
          "tier": 1,
          "reasoning": "Core concept referring to the fundamental API resources managed by Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "object configuration files",
          "tier": 2,
          "reasoning": "Domain-specific term for files that define the desired state of Kubernetes objects."
        },
        {
          "term": "configuration files",
          "tier": 2,
          "reasoning": "Technical term for files containing object specifications used with declarative management."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl CLI command for declarative object management."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool."
        },
        {
          "term": "apply",
          "tier": 2,
          "reasoning": "Kubernetes-specific operation for declarative resource management."
        },
        {
          "term": "kubectl diff",
          "tier": 1,
          "reasoning": "Specific kubectl CLI command for previewing changes before applying."
        },
        {
          "term": "diff",
          "tier": 2,
          "reasoning": "Kubernetes operation to compare live objects with configuration files."
        },
        {
          "term": "live objects",
          "tier": 2,
          "reasoning": "Domain concept referring to the current state of objects running in the cluster."
        },
        {
          "term": "objects",
          "tier": 2,
          "reasoning": "Short form reference to Kubernetes API objects/resources."
        },
        {
          "term": "Declarative Management",
          "tier": 2,
          "reasoning": "Core Kubernetes operational paradigm where desired state is declared in configuration."
        },
        {
          "term": "created",
          "tier": 3,
          "reasoning": "Technical operation in the Kubernetes object lifecycle."
        },
        {
          "term": "updated",
          "tier": 3,
          "reasoning": "Technical operation in the Kubernetes object lifecycle."
        },
        {
          "term": "deleted",
          "tier": 3,
          "reasoning": "Technical operation in the Kubernetes object lifecycle."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "File system concept relevant to storing multiple configuration files."
        },
        {
          "term": "recursively",
          "tier": 3,
          "reasoning": "Technical term describing how kubectl apply traverses directory structures."
        },
        {
          "term": "merging",
          "tier": 2,
          "reasoning": "Technical process concept related to how changes are combined in declarative management."
        },
        {
          "term": "writes",
          "tier": 3,
          "reasoning": "Technical term referring to modifications made to live objects."
        },
        {
          "term": "changes",
          "tier": 3,
          "reasoning": "Technical term in context of tracking modifications to objects."
        },
        {
          "term": "preview",
          "tier": 3,
          "reasoning": "Technical capability provided by kubectl diff to see pending changes."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:11:12.897758",
      "elapsed_time": 12.291944026947021
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_HPAContainerMetrics_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_HPAContainerMetrics",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_HPAContainerMetrics.md",
      "content": "---\ntitle: HPAContainerMetrics\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha\n    defaultValue: false\n    fromVersion: \"1.20\"\n    toVersion: \"1.26\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.27\"\n    toVersion: \"1.29\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.30\"\n    toVersion: \"1.31\"\n\nremoved: true\n---\nAllow {{< glossary_tooltip text=\"HorizontalPodAutoscalers\" term_id=\"horizontal-pod-autoscaler\" >}}\nto scale based on metrics from individual containers within target pods.",
      "terms": [
        {
          "term": "HPAContainerMetrics",
          "tier": 1,
          "reasoning": "Feature gate name that is the primary subject of this documentation chunk."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "Kubernetes mechanism for enabling/disabling features, explicitly referenced as content_type."
        },
        {
          "term": "HorizontalPodAutoscalers",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for automatic horizontal scaling of pods."
        },
        {
          "term": "horizontal-pod-autoscaler",
          "tier": 1,
          "reasoning": "Glossary term ID referencing the HPA Kubernetes resource."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes workload unit, referenced as 'target pods'."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing individual container units within pods."
        },
        {
          "term": "metrics",
          "tier": 2,
          "reasoning": "Technical concept for measurements used in autoscaling decisions."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Domain-specific action referring to adjusting replica counts in Kubernetes."
        },
        {
          "term": "alpha",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating experimental/early development status."
        },
        {
          "term": "beta",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating pre-stable testing phase."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating production-ready status."
        },
        {
          "term": "stage",
          "tier": 3,
          "reasoning": "Technical term describing feature gate lifecycle phases."
        },
        {
          "term": "defaultValue",
          "tier": 3,
          "reasoning": "Configuration property indicating whether feature is enabled by default."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Version boundary marker for feature gate availability."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Version boundary marker for feature gate availability end."
        },
        {
          "term": "target pods",
          "tier": 2,
          "reasoning": "Domain concept referring to pods being monitored/scaled by HPA."
        },
        {
          "term": "individual containers",
          "tier": 2,
          "reasoning": "Concept distinguishing per-container metrics from pod-level metrics."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T22:11:25.972885",
      "elapsed_time": 12.057783603668213
    },
    {
      "chunk_id": "tasks_administer-cluster_kubelet-in-userns_sec3",
      "doc_id": "tasks_administer-cluster_kubelet-in-userns",
      "heading": "Running Kubernetes inside Unprivileged Containers",
      "source_file": "tasks_administer-cluster_kubelet-in-userns.md",
      "content": "{{% thirdparty-content %}}\n\n### sysbox\n\n[Sysbox](https://github.com/nestybox/sysbox) is an open-source container runtime\n(similar to \"runc\") that supports running system-level workloads such as Docker\nand Kubernetes inside unprivileged containers isolated with the Linux user\nnamespace.\n\nSee [Sysbox Quick Start Guide: Kubernetes-in-Docker](https://github.com/nestybox/sysbox/blob/master/docs/quickstart/kind.md) for more info.\n\nSysbox supports running Kubernetes inside unprivileged containers without\nrequiring Cgroup v2 and without the `KubeletInUserNamespace` feature gate. It\ndoes this by exposing specially crafted `/proc` and `/sys` filesystems inside\nthe container plus several other advanced OS virtualization techniques.",
      "terms": [
        {
          "term": "sysbox",
          "tier": 1,
          "reasoning": "Named open-source container runtime, proper noun and specific tool name"
        },
        {
          "term": "Sysbox",
          "tier": 1,
          "reasoning": "Capitalized variant of the container runtime name as it appears in text"
        },
        {
          "term": "container runtime",
          "tier": 2,
          "reasoning": "Core domain concept describing software that runs containers"
        },
        {
          "term": "runc",
          "tier": 1,
          "reasoning": "Named container runtime tool, proper noun reference"
        },
        {
          "term": "Docker",
          "tier": 1,
          "reasoning": "Named container platform and proper noun"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core domain proper noun, the container orchestration platform"
        },
        {
          "term": "unprivileged containers",
          "tier": 2,
          "reasoning": "Domain concept describing containers running without elevated privileges"
        },
        {
          "term": "Kubernetes-in-Docker",
          "tier": 2,
          "reasoning": "Specific architectural pattern for running Kubernetes inside Docker containers"
        },
        {
          "term": "Cgroup v2",
          "tier": 2,
          "reasoning": "Linux kernel feature for resource control, specific version reference"
        },
        {
          "term": "KubeletInUserNamespace",
          "tier": 1,
          "reasoning": "Named Kubernetes feature gate, proper noun"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes concept for enabling/disabling features"
        },
        {
          "term": "/proc",
          "tier": 2,
          "reasoning": "Linux virtual filesystem providing process information"
        },
        {
          "term": "/sys",
          "tier": 2,
          "reasoning": "Linux virtual filesystem providing kernel/device information"
        },
        {
          "term": "filesystems",
          "tier": 3,
          "reasoning": "General technical term for file system structures"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept for isolated application environments"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form of core container concept as used in text"
        },
        {
          "term": "OS virtualization",
          "tier": 2,
          "reasoning": "Technical concept for operating system-level virtualization techniques"
        },
        {
          "term": "system-level workloads",
          "tier": 2,
          "reasoning": "Domain concept describing workloads requiring system access"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Core isolation concept in both Linux and Kubernetes contexts"
        },
        {
          "term": "Linux",
          "tier": 3,
          "reasoning": "Operating system platform referenced for kernel features"
        },
        {
          "term": "open-source",
          "tier": 3,
          "reasoning": "Technical term describing software licensing model"
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:11:38.196930",
      "elapsed_time": 11.204795837402344
    },
    {
      "chunk_id": "tutorials_kubernetes-basics_create-cluster_cluster-intro_sec0",
      "doc_id": "tutorials_kubernetes-basics_create-cluster_cluster-intro",
      "heading": "Kubernetes Clusters",
      "source_file": "tutorials_kubernetes-basics_create-cluster_cluster-intro.md",
      "content": "{{% alert %}}\n_Kubernetes is a production-grade, open-source platform that orchestrates\nthe placement (scheduling) and execution of application containers\nwithin and across computer clusters._\n{{% /alert %}}\n\n**Kubernetes coordinates a highly available cluster of computers that are connected\nto work as a single unit.** The abstractions in Kubernetes allow you to deploy\ncontainerized applications to a cluster without tying them specifically to individual\nmachines. To make use of this new model of deployment, applications need to be packaged\nin a way that decouples them from individual hosts: they need to be containerized.\nContainerized applications are more flexible and available than in past deployment models,\nwhere applications were installed directly onto specific machines as packages deeply\nintegrated into the host. **Kubernetes automates the distribution and scheduling of\napplication containers across a cluster in a more efficient way.** Kubernetes is an\nopen-source platform and is production-ready.\n\nA Kubernetes cluster consists of two types of resources:\n\n* The **Control Plane** coordinates the cluster\n* **Nodes** are the workers that run applications\n\n### Cluster Diagram\n\n{{< figure src=\"/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg\" style=\"width: 100%;\" >}}\n\n**The Control Plane is responsible for managing the cluster.** The Control Plane\ncoordinates all activities in your cluster, such as scheduling applications, maintaining\napplications' desired state, scaling applications, and rolling out new updates.\n\n{{% alert %}}\n_Control Planes manage the cluster and the nodes that are used to host the running\napplications._\n{{% /alert %}}\n\n**A node is a VM or a physical computer that serves as a worker machine in a Kubernetes\ncluster.** Each node has a Kubelet, which is an agent for managing the node and\ncommunicating with the Kubernetes control plane. The node should also have tools for\nhandling container operations, such as {{< glossary_tooltip text=\"containerd\" term_id=\"containerd\" >}}\nor {{< glossary_tooltip term_id=\"cri-o\" >}}. A Kubernetes cluster that handles production\ntraffic should have a minimum of three nodes because if one node goes down, both an\n[etcd](/docs/concepts/architecture/#etcd) member and a control plane instance are lost,\nand redundancy is compromised. You can mitigate this risk by adding more control plane nodes.\n\nWhen you deploy applications on Kubernetes, you tell the control plane to start\nthe application containers. The control plane schedules the containers to run on\nthe cluster's nodes. **Node-level components, such as the kubelet, communicate\nwith the control plane using the [Kubernetes API](/docs/concepts/overview/kubernetes-api/)**,\nwhich the control plane exposes. End users can also use the Kubernetes API directly\nto interact with the cluster.\n\nA Kubernetes cluster can be deployed on either physical or virtual machines. To\nget started with Kubernetes development, you can use Minikube. Minikube is a lightweight\nKubernetes implementation that creates a VM on your local machine and deploys a\nsimple cluster containing only one node. Minikube is available for Linux, macOS,\nand Windows systems. The Minikube CLI provides basic bootstrapping operations for\nworking with your cluster, including start, stop, status, and delete.",
      "terms": [
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core platform name and the primary subject of the documentation."
        },
        {
          "term": "Control Plane",
          "tier": 1,
          "reasoning": "Named Kubernetes component responsible for managing the cluster."
        },
        {
          "term": "Nodes",
          "tier": 1,
          "reasoning": "Named Kubernetes resource type representing worker machines."
        },
        {
          "term": "Kubelet",
          "tier": 1,
          "reasoning": "Named Kubernetes agent component running on each node."
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Named container runtime implementation used by Kubernetes."
        },
        {
          "term": "cri-o",
          "tier": 1,
          "reasoning": "Named container runtime implementation for Kubernetes."
        },
        {
          "term": "etcd",
          "tier": 1,
          "reasoning": "Named distributed key-value store component of Kubernetes architecture."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Named API interface exposed by the control plane for cluster interaction."
        },
        {
          "term": "Minikube",
          "tier": 1,
          "reasoning": "Named lightweight Kubernetes implementation tool for local development."
        },
        {
          "term": "Minikube CLI",
          "tier": 1,
          "reasoning": "Named command-line interface for Minikube operations."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core architectural concept representing connected computers working as a unit."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Domain process for placing and executing application containers."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core concept for packaged application units in Kubernetes."
        },
        {
          "term": "containerized applications",
          "tier": 2,
          "reasoning": "Domain concept describing applications packaged as containers."
        },
        {
          "term": "application containers",
          "tier": 2,
          "reasoning": "Domain concept for containers running applications."
        },
        {
          "term": "container operations",
          "tier": 2,
          "reasoning": "Domain concept for handling container lifecycle activities."
        },
        {
          "term": "computer clusters",
          "tier": 2,
          "reasoning": "Infrastructure concept for grouped computing resources."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Domain concept describing the role of nodes in a cluster."
        },
        {
          "term": "control plane instance",
          "tier": 2,
          "reasoning": "Domain concept for a running instance of the control plane."
        },
        {
          "term": "control plane nodes",
          "tier": 2,
          "reasoning": "Domain concept for nodes running control plane components."
        },
        {
          "term": "Node-level components",
          "tier": 2,
          "reasoning": "Architectural concept for components running on worker nodes."
        },
        {
          "term": "highly available",
          "tier": 2,
          "reasoning": "Architectural concept for fault-tolerant system design."
        },
        {
          "term": "redundancy",
          "tier": 2,
          "reasoning": "Architectural concept for system reliability through duplication."
        },
        {
          "term": "production-ready",
          "tier": 2,
          "reasoning": "Operational concept indicating readiness for production use."
        },
        {
          "term": "production-grade",
          "tier": 2,
          "reasoning": "Quality concept indicating enterprise-level reliability."
        },
        {
          "term": "deploy",
          "tier": 2,
          "reasoning": "Domain process for releasing applications to a cluster."
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Domain concept for the process of deploying applications."
        },
        {
          "term": "scaling applications",
          "tier": 2,
          "reasoning": "Domain process for adjusting application capacity."
        },
        {
          "term": "rolling out new updates",
          "tier": 2,
          "reasoning": "Domain process for incrementally deploying changes."
        },
        {
          "term": "desired state",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for declarative configuration management."
        },
        {
          "term": "scheduling applications",
          "tier": 2,
          "reasoning": "Domain process for assigning applications to nodes."
        },
        {
          "term": "bootstrapping operations",
          "tier": 2,
          "reasoning": "Domain concept for initial cluster setup procedures."
        },
        {
          "term": "open-source platform",
          "tier": 2,
          "reasoning": "Domain concept describing Kubernetes licensing and development model."
        },
        {
          "term": "VM",
          "tier": 3,
          "reasoning": "Abbreviation for virtual machine, infrastructure concept for node types."
        },
        {
          "term": "virtual machines",
          "tier": 3,
          "reasoning": "Infrastructure concept for virtualized computing resources."
        },
        {
          "term": "physical computer",
          "tier": 3,
          "reasoning": "Infrastructure concept for bare-metal node types."
        },
        {
          "term": "host",
          "tier": 3,
          "reasoning": "Infrastructure concept for the machine running containers."
        },
        {
          "term": "agent",
          "tier": 3,
          "reasoning": "Technical concept describing kubelet's role on nodes."
        },
        {
          "term": "Linux",
          "tier": 3,
          "reasoning": "Operating system platform supported by Minikube."
        },
        {
          "term": "macOS",
          "tier": 3,
          "reasoning": "Operating system platform supported by Minikube."
        },
        {
          "term": "Windows",
          "tier": 3,
          "reasoning": "Operating system platform supported by Minikube."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical concept for programmatic interfaces."
        },
        {
          "term": "packages",
          "tier": 3,
          "reasoning": "Technical concept for software distribution units."
        }
      ],
      "term_count": 43,
      "generated_at": "2026-02-08T22:11:59.889678",
      "elapsed_time": 20.674800634384155
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DynamicResourceAllocation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DynamicResourceAllocation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DynamicResourceAllocation.md",
      "content": "---\ntitle: DynamicResourceAllocation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha\n    defaultValue: false\n    fromVersion: \"1.30\"\n    toVersion: \"1.31\"\n  - stage: beta\n    defaultValue: false\n    fromVersion: \"1.32\"\n    toVersion: \"1.33\"\n  - stage: stable\n    defaultValue: true\n    locked: false\n    fromVersion: \"1.34\"\n    toVersion: \"1.34\"\n  - stage: stable\n    defaultValue: true\n    locked: true\n    fromVersion: \"1.35\"\n\n---\nEnables support for resources with custom parameters and a lifecycle\nthat is independent of a Pod. Allocation of resources is handled\nby the Kubernetes scheduler based on \"structured parameters\".",
      "terms": [
        {
          "term": "DynamicResourceAllocation",
          "tier": 1,
          "reasoning": "Named Kubernetes feature gate that enables dynamic resource allocation functionality."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "Kubernetes mechanism for enabling/disabling optional features, explicitly referenced as content_type."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit, referenced in context of resource lifecycle."
        },
        {
          "term": "Kubernetes scheduler",
          "tier": 1,
          "reasoning": "Named Kubernetes component responsible for assigning pods to nodes and handling resource allocation."
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating early experimental status."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating pre-stable testing phase."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating production-ready status."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Domain concept referring to compute or custom resources that can be allocated to workloads."
        },
        {
          "term": "custom parameters",
          "tier": 2,
          "reasoning": "Technical concept describing user-defined configuration options for resources."
        },
        {
          "term": "lifecycle",
          "tier": 2,
          "reasoning": "Domain concept describing the stages and management of resource existence over time."
        },
        {
          "term": "Allocation",
          "tier": 2,
          "reasoning": "Technical process of assigning resources to workloads in Kubernetes."
        },
        {
          "term": "structured parameters",
          "tier": 2,
          "reasoning": "Specific technical concept for the parameter format used in dynamic resource allocation."
        },
        {
          "term": "scheduler",
          "tier": 2,
          "reasoning": "Core Kubernetes component concept responsible for resource placement decisions."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Feature gate configuration property indicating whether feature is enabled by default."
        },
        {
          "term": "locked",
          "tier": 2,
          "reasoning": "Feature gate property indicating whether the feature state can be changed."
        },
        {
          "term": "stage",
          "tier": 2,
          "reasoning": "Technical term describing the maturity phase of a Kubernetes feature."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Version metadata indicating when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Version metadata indicating when a feature stage ends."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T22:12:11.421032",
      "elapsed_time": 10.50406527519226
    },
    {
      "chunk_id": "reference_using-api_server-side-apply_sec7",
      "doc_id": "reference_using-api_server-side-apply",
      "heading": "Transferring ownership",
      "source_file": "reference_using-api_server-side-apply.md",
      "content": "In addition to the concurrency controls provided by [conflict resolution](#conflicts),\nServer-Side Apply provides ways to perform coordinated\nfield ownership transfers from users to controllers.\n\nThis is best explained by example. Let's look at how to safely transfer\nownership of the `replicas` field from a user to a controller while enabling\nautomatic horizontal scaling for a Deployment, using the HorizontalPodAutoscaler\nresource and its accompanying controller.\n\nSay a user has defined Deployment with `replicas` set to the desired value:\n\n{{% code_sample file=\"application/ssa/nginx-deployment.yaml\" %}}\n\nAnd the user has created the Deployment using Server-Side Apply, like so:\n\n```shell\nkubectl apply -f https://k8s.io/examples/application/ssa/nginx-deployment.yaml --server-side\n```\n\nThen later, automatic scaling is enabled for the Deployment; for example:\n\n```shell\nkubectl autoscale deployment nginx-deployment --cpu-percent=50 --min=1 --max=10\n```\n\nNow, the user would like to remove `replicas` from their configuration, so they\ndon't accidentally fight with the HorizontalPodAutoscaler (HPA) and its controller.\nHowever, there is a race: it might take some time before the HPA feels the need\nto adjust `.spec.replicas`; if the user removes `.spec.replicas` before the HPA writes\nto the field and becomes its owner, then the API server would set `.spec.replicas` to\n1 (the default replica count for Deployment).\nThis is not what the user wants to happen, even temporarily - it might well degrade\na running workload.\n\nThere are two solutions:\n\n- (basic) Leave `replicas` in the configuration; when the HPA eventually writes to that\n  field, the system gives the user a conflict over it. At that point, it is safe\n  to remove from the configuration.\n\n- (more advanced) If, however, the user doesn't want to wait, for example\n  because they want to keep the cluster legible to their colleagues, then they\n  can take the following steps to make it safe to remove `replicas` from their\n  configuration:\n\nFirst, the user defines a new manifest containing only the `replicas` field:\n\n```yaml",
      "terms": [
        {
          "term": "Server-Side Apply",
          "tier": 1,
          "reasoning": "Core Kubernetes API mechanism for applying resource configurations with field ownership tracking."
        },
        {
          "term": "conflict resolution",
          "tier": 2,
          "reasoning": "Technical process for handling competing updates to resource fields in Kubernetes."
        },
        {
          "term": "concurrency controls",
          "tier": 2,
          "reasoning": "Technical mechanism for managing simultaneous access to shared resources."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Kubernetes concept where managers claim ownership of specific fields in a resource."
        },
        {
          "term": "controllers",
          "tier": 2,
          "reasoning": "Kubernetes control loop components that manage resource state."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes field specifying the desired number of pod instances for a workload."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for managing stateless application workloads."
        },
        {
          "term": "HorizontalPodAutoscaler",
          "tier": 1,
          "reasoning": "Kubernetes API resource that automatically scales workloads based on metrics."
        },
        {
          "term": "automatic horizontal scaling",
          "tier": 2,
          "reasoning": "Kubernetes capability to automatically adjust replica count based on load."
        },
        {
          "term": "HPA",
          "tier": 1,
          "reasoning": "Abbreviation for HorizontalPodAutoscaler, a core Kubernetes resource."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for declaratively applying configurations."
        },
        {
          "term": "kubectl autoscale",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for creating autoscaling configurations."
        },
        {
          "term": "--server-side",
          "tier": 1,
          "reasoning": "kubectl flag enabling Server-Side Apply mode."
        },
        {
          "term": "--cpu-percent",
          "tier": 1,
          "reasoning": "kubectl autoscale flag specifying CPU utilization target."
        },
        {
          "term": "--min",
          "tier": 1,
          "reasoning": "kubectl autoscale flag specifying minimum replica count."
        },
        {
          "term": "--max",
          "tier": 1,
          "reasoning": "kubectl autoscale flag specifying maximum replica count."
        },
        {
          "term": ".spec.replicas",
          "tier": 2,
          "reasoning": "Kubernetes resource field path specifying desired replica count."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component handling API requests."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical term for declarative resource definitions in Kubernetes."
        },
        {
          "term": "manifest",
          "tier": 2,
          "reasoning": "Kubernetes term for YAML/JSON resource definition files."
        },
        {
          "term": "default replica count",
          "tier": 2,
          "reasoning": "Kubernetes concept of fallback value when replicas field is unset."
        },
        {
          "term": "race",
          "tier": 2,
          "reasoning": "Technical term for timing-dependent condition between concurrent operations."
        },
        {
          "term": "conflict",
          "tier": 2,
          "reasoning": "Server-Side Apply concept when multiple managers claim the same field."
        },
        {
          "term": "owner",
          "tier": 2,
          "reasoning": "Server-Side Apply concept of the manager controlling a field."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes term for applications running in the cluster."
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific example Deployment resource name used in documentation."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes architectural term for the complete container orchestration environment."
        },
        {
          "term": "user",
          "tier": 2,
          "reasoning": "Kubernetes concept of human operator managing resources, distinct from controllers."
        }
      ],
      "term_count": 29,
      "generated_at": "2026-02-08T22:12:27.205874",
      "elapsed_time": 14.764238595962524
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec2",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "CustomResourceDefinitionSpec {#CustomResourceDefinitionSpec}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "CustomResourceDefinitionSpec describes how a user wants their resource to appear\n\n<hr>\n\n- **group** (string), required\n\n  group is the API group of the defined custom resource. The custom resources are served under `/apis/\\<group>/...`. Must match the name of the CustomResourceDefinition (in the form `\\<names.plural>.\\<group>`).\n\n- **names** (CustomResourceDefinitionNames), required\n\n  names specify the resource and kind names for the custom resource.\n\n  <a name=\"CustomResourceDefinitionNames\"></a>\n  *CustomResourceDefinitionNames indicates the names to serve this CustomResourceDefinition*\n\n  - **names.kind** (string), required\n\n    kind is the serialized kind of the resource. It is normally CamelCase and singular. Custom resource instances will use this value as the `kind` attribute in API calls.\n\n  - **names.plural** (string), required\n\n    plural is the plural name of the resource to serve. The custom resources are served under `/apis/\\<group>/\\<version>/.../\\<plural>`. Must match the name of the CustomResourceDefinition (in the form `\\<names.plural>.\\<group>`). Must be all lowercase.\n\n  - **names.categories** ([]string)\n\n    *Atomic: will be replaced during a merge*\n    \n    categories is a list of grouped resources this custom resource belongs to (e.g. 'all'). This is published in API discovery documents, and used by clients to support invocations like `kubectl get all`.\n\n  - **names.listKind** (string)\n\n    listKind is the serialized kind of the list for this resource. Defaults to \"`kind`List\".\n\n  - **names.shortNames** ([]string)\n\n    *Atomic: will be replaced during a merge*\n    \n    shortNames are short names for the resource, exposed in API discovery documents, and used by clients to support invocations like `kubectl get \\<shortname>`. It must be all lowercase.\n\n  - **names.singular** (string)\n\n    singular is the singular name of the resource. It must be all lowercase. Defaults to lowercased `kind`.\n\n- **scope** (string), required\n\n  scope indicates whether the defined custom resource is cluster- or namespace-scoped. Allowed values are `Cluster` and `Namespaced`.\n\n- **versions** ([]CustomResourceDefinitionVersion), required\n\n  *Atomic: will be replaced during a merge*\n  \n  versions is the list of all API versions of the defined custom resource. Version names are used to compute the order in which served versions are listed in API discovery. If the version string is \"kube-like\", it will sort above non \"kube-like\" version strings, which are ordered lexicographically. \"Kube-like\" versions start with a \"v\", then are followed by a number (the major version), then optionally the string \"alpha\" or \"beta\" and another number (the minor version). These are sorted first by GA > beta > alpha (where GA is a version with no suffix such as beta or alpha), and then by comparing major version, then minor version. An example sorted list of versions: v10, v2, v1, v11beta2, v10beta3, v3beta1, v12alpha1, v11alpha2, foo1, foo10.\n\n  <a name=\"CustomResourceDefinitionVersion\"></a>\n  *CustomResourceDefinitionVersion describes a version for CRD.*\n\n  - **versions.name** (string), required\n\n    name is the version name, e.g. \u201cv1\u201d, \u201cv2beta1\u201d, etc. The custom resources are served under this version at `/apis/\\<group>/\\<version>/...` if `served` is true.\n\n  - **versions.served** (boolean), required\n\n    served is a flag enabling/disabling this version from being served via REST APIs\n\n  - **versions.storage** (boolean), required\n\n    storage indicates this version should be used when persisting custom resources to storage. There must be exactly one version with storage=true.\n\n  - **versions.additionalPrinterColumns** ([]CustomResourceColumnDefinition)\n\n    *Atomic: will be replaced during a merge*\n    \n    additionalPrinterColumns specifies additional columns returned in Table output. See https://kubernetes.io/docs/reference/using-api/api-concepts/#receiving-resources-as-tables for details. If no columns are specified, a single column displaying the age of the custom resource is used.\n\n    <a name=\"CustomResourceColumnDefinition\"></a>\n    *CustomResourceColumnDefinition specifies a column for server side printing.*\n\n    - **versions.additionalPrinterColumns.jsonPath** (string), required\n\n      jsonPath is a simple JSON path (i.e. with array notation) which is evaluated against each custom resource to produce the value for this column.\n\n    - **versions.additionalPrinterColumns.name** (string), required\n\n      name is a human readable name for the column.\n\n    - **versions.additionalPrinterColumns.type** (string), required\n\n      type is an OpenAPI type definition for this column. See https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md#data-types for details.\n\n    - **versions.additionalPrinterColumns.description** (string)\n\n      description is a human readable description of this column.\n\n    - **versions.additionalPrinterColumns.format** (string)\n\n      format is an optional OpenAPI type definition for this column. The 'name' format is applied to the primary identifier column to assist in clients identifying column is the resource name. See https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md#data-types for details.\n\n    - **versions.additionalPrinterColumns.priority** (int32)\n\n      priority is an integer defining the relative importance of this column compared to others. Lower numbers are considered higher priority. Columns that may be omitted in limited space scenarios should be given a priority greater than 0.\n\n  - **versions.deprecated** (boolean)\n\n    deprecated indicates this version of the custom resource API is deprecated. When set to true, API requests to this version receive a warning header in the server response. Defaults to false.\n\n  - **versions.deprecationWarning** (string)\n\n    deprecationWarning overrides the default warning returned to API clients. May only be set when `deprecated` is true. The default warning indicates this version is deprecated and recommends use of the newest served version of equal or greater stability, if one exists.\n\n  - **versions.schema** (CustomResourceValidation)\n\n    schema describes the schema used for validation, pruning, and defaulting of this version of the custom resource.\n\n    <a name=\"CustomResourceValidation\"></a>\n    *CustomResourceValidation is a list of validation methods for CustomResources.*\n\n    - **versions.schema.openAPIV3Schema** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n      openAPIV3Schema is the OpenAPI v3 schema to use for validation and pruning.\n\n  - **versions.selectableFields** ([]SelectableField)\n\n    *Atomic: will be replaced during a merge*\n    \n    selectableFields specifies paths to fields that may be used as field selectors. A maximum of 8 selectable fields are allowed. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors\n\n    <a name=\"SelectableField\"></a>\n    *SelectableField specifies the JSON path of a field that may be used with field selectors.*\n\n    - **versions.selectableFields.jsonPath** (string), required\n\n      jsonPath is a simple JSON path which is evaluated against each custom resource to produce a field selector value. Only JSON paths without the array notation are allowed. Must point to a field of type string, boolean or integer. Types with enum values and strings with formats are allowed. If jsonPath refers to absent field in a resource, the jsonPath evaluates to an empty string. Must not point to metdata fields. Required.\n\n  - **versions.subresources** (CustomResourceSubresources)\n\n    subresources specify what subresources this version of the defined custom resource have.\n\n    <a name=\"CustomResourceSubresources\"></a>\n    *CustomResourceSubresources defines the status and scale subresources for CustomResources.*\n\n    - **versions.subresources.scale** (CustomResourceSubresourceScale)\n\n      scale indicates the custom resource should serve a `/scale` subresource that returns an `autoscaling/v1` Scale object.\n\n      <a name=\"CustomResourceSubresourceScale\"></a>\n      *CustomResourceSubresourceScale defines how to serve the scale subresource for CustomResources.*\n\n      - **versions.subresources.scale.specReplicasPath** (string), required\n\n        specReplicasPath defines the JSON path inside of a custom resource that corresponds to Scale `spec.replicas`. Only JSON paths without the array notation are allowed. Must be a JSON Path under `.spec`. If there is no value under the given path in the custom resource, the `/scale` subresource will return an error on GET.\n\n      - **versions.subresources.scale.statusReplicasPath** (string), required\n\n        statusReplicasPath defines the JSON path inside of a custom resource that corresponds to Scale `status.replicas`. Only JSON paths without the array notation are allowed. Must be a JSON Path under `.status`. If there is no value under the given path in the custom resource, the `status.replicas` value in the `/scale` subresource will default to 0.\n\n      - **versions.subresources.scale.labelSelectorPath** (string)\n\n        labelSelectorPath defines the JSON path inside of a custom resource that corresponds to Scale `status.selector`. Only JSON paths without the array notation are allowed. Must be a JSON Path under `.status` or `.spec`. Must be set to work with HorizontalPodAutoscaler. The field pointed by this JSON path must be a string field (not a complex selector struct) which contains a serialized label selector in string form. More info: https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions#scale-subresource If there is no value under the given path in the custom resource, the `status.selector` value in the `/scale` subresource will default to the empty string.\n\n    - **versions.subresources.status** (CustomResourceSubresourceStatus)\n\n      status indicates the custom resource should serve a `/status` subresource. When enabled: 1. requests to the custom resource primary endpoint ignore changes to the `status` stanza of the object. 2. requests to the custom resource `/status` subresource ignore changes to anything other than the `status` stanza of the object.\n\n      <a name=\"CustomResourceSubresourceStatus\"></a>\n      *CustomResourceSubresourceStatus defines how to serve the status subresource for CustomResources. Status is represented by the `.status` JSON path inside of a CustomResource. When set, * exposes a /status subresource for the custom resource * PUT requests to the /status subresource take a custom resource object, and ignore changes to anything except the status stanza * PUT/POST/PATCH requests to the custom resource ignore changes to the status stanza*\n\n- **conversion** (CustomResourceConversion)\n\n  conversion defines conversion settings for the CRD.\n\n  <a name=\"CustomResourceConversion\"></a>\n  *CustomResourceConversion describes how to convert different versions of a CR.*\n\n  - **conversion.strategy** (string), required\n\n    strategy specifies how custom resources are converted between versions. Allowed values are: - `\"None\"`: The converter only change the apiVersion and would not touch any other field in the custom resource. - `\"Webhook\"`: API Server will call to an external webhook to do the conversion. Additional information\n      is needed for this option. This requires spec.preserveUnknownFields to be false, and spec.conversion.webhook to be set.\n\n  - **conversion.webhook** (WebhookConversion)\n\n    webhook describes how to call the conversion webhook. Required when `strategy` is set to `\"Webhook\"`.\n\n    <a name=\"WebhookConversion\"></a>\n    *WebhookConversion describes how to call a conversion webhook*\n\n    - **conversion.webhook.conversionReviewVersions** ([]string), required\n\n      *Atomic: will be replaced during a merge*\n      \n      conversionReviewVersions is an ordered list of preferred `ConversionReview` versions the Webhook expects. The API server will use the first version in the list which it supports. If none of the versions specified in this list are supported by API server, conversion will fail for the custom resource. If a persisted Webhook configuration specifies allowed versions and does not include any versions known to the API Server, calls to the webhook will fail.\n\n    - **conversion.webhook.clientConfig** (WebhookClientConfig)\n\n      clientConfig is the instructions for how to call the webhook if strategy is `Webhook`.\n\n      <a name=\"WebhookClientConfig\"></a>\n      *WebhookClientConfig contains the information to make a TLS connection with the webhook.*\n\n      - **conversion.webhook.clientConfig.caBundle** ([]byte)\n\n        caBundle is a PEM encoded CA bundle which will be used to validate the webhook's server certificate. If unspecified, system trust roots on the apiserver are used.\n\n      - **conversion.webhook.clientConfig.service** (ServiceReference)\n\n        service is a reference to the service for this webhook. Either service or url must be specified.\n        \n        If the webhook is running within the cluster, then you should use `service`.\n\n        <a name=\"ServiceReference\"></a>\n        *ServiceReference holds a reference to Service.legacy.k8s.io*\n\n        - **conversion.webhook.clientConfig.service.name** (string), required\n\n          name is the name of the service. Required\n\n        - **conversion.webhook.clientConfig.service.namespace** (string), required\n\n          namespace is the namespace of the service. Required\n\n        - **conversion.webhook.clientConfig.service.path** (string)\n\n          path is an optional URL path at which the webhook will be contacted.\n\n        - **conversion.webhook.clientConfig.service.port** (int32)\n\n          port is an optional service port at which the webhook will be contacted. `port` should be a valid port number (1-65535, inclusive). Defaults to 443 for backward compatibility.\n\n      - **conversion.webhook.clientConfig.url** (string)\n\n        url gives the location of the webhook, in standard URL form (`scheme://host:port/path`). Exactly one of `url` or `service` must be specified.\n        \n        The `host` should not refer to a service running in the cluster; use the `service` field instead. The host might be resolved via external DNS in some apiservers (e.g., `kube-apiserver` cannot resolve in-cluster DNS as that would be a layering violation). `host` may also be an IP address.\n        \n        Please note that using `localhost` or `127.0.0.1` as a `host` is risky unless you take great care to run this webhook on all hosts which run an apiserver which might need to make calls to this webhook. Such installs are likely to be non-portable, i.e., not easy to turn up in a new cluster.\n        \n        The scheme must be \"https\"; the URL must begin with \"https://\".\n        \n        A path is optional, and if present may be any string permissible in a URL. You may use the path to pass an arbitrary string to the webhook, for example, a cluster identifier.\n        \n        Attempting to use a user or basic auth e.g. \"user:password@\" is not allowed. Fragments (\"#...\") and query parameters (\"?...\") are not allowed, either.\n\n- **preserveUnknownFields** (boolean)\n\n  preserveUnknownFields indicates that object fields which are not specified in the OpenAPI schema should be preserved when persisting to storage. apiVersion, kind, metadata and known fields inside metadata are always preserved. This field is deprecated in favor of setting `x-preserve-unknown-fields` to true in `spec.versions[*].schema.openAPIV3Schema`. See https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#field-pruning for details.",
      "terms": [
        {
          "term": "CustomResourceDefinitionSpec",
          "tier": 1,
          "reasoning": "Named Kubernetes API object specification type for custom resources"
        },
        {
          "term": "CustomResourceDefinitionNames",
          "tier": 1,
          "reasoning": "Named Kubernetes API type that specifies naming conventions for custom resources"
        },
        {
          "term": "CustomResourceDefinitionVersion",
          "tier": 1,
          "reasoning": "Named Kubernetes API type describing a version for CRD"
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for extending the API with custom resources"
        },
        {
          "term": "CustomResourceColumnDefinition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type for defining additional printer columns"
        },
        {
          "term": "custom resource",
          "tier": 1,
          "reasoning": "Core Kubernetes concept for user-defined API extensions"
        },
        {
          "term": "custom resources",
          "tier": 1,
          "reasoning": "Plural form of custom resource, frequently used in the documentation"
        },
        {
          "term": "CRD",
          "tier": 1,
          "reasoning": "Standard abbreviation for CustomResourceDefinition, a core Kubernetes resource"
        },
        {
          "term": "API group",
          "tier": 2,
          "reasoning": "Kubernetes concept for organizing API resources into logical groups"
        },
        {
          "term": "group",
          "tier": 2,
          "reasoning": "Field name representing the API group in CustomResourceDefinitionSpec"
        },
        {
          "term": "names",
          "tier": 2,
          "reasoning": "Configuration field specifying resource and kind names for custom resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes concept for the type of resource, used in API calls"
        },
        {
          "term": "plural",
          "tier": 2,
          "reasoning": "Naming convention field for the plural form of resource names in API paths"
        },
        {
          "term": "singular",
          "tier": 2,
          "reasoning": "Naming convention field for the singular form of resource names"
        },
        {
          "term": "categories",
          "tier": 2,
          "reasoning": "Field for grouping custom resources into logical categories like 'all'"
        },
        {
          "term": "listKind",
          "tier": 2,
          "reasoning": "Field specifying the serialized kind name for list operations"
        },
        {
          "term": "shortNames",
          "tier": 2,
          "reasoning": "Field for defining abbreviated names for resources in kubectl commands"
        },
        {
          "term": "scope",
          "tier": 2,
          "reasoning": "Field indicating whether a custom resource is cluster or namespace scoped"
        },
        {
          "term": "versions",
          "tier": 2,
          "reasoning": "Field containing all API versions of a custom resource definition"
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Concept representing a specific API version of a resource"
        },
        {
          "term": "served",
          "tier": 2,
          "reasoning": "Boolean flag controlling whether a version is available via REST APIs"
        },
        {
          "term": "storage",
          "tier": 2,
          "reasoning": "Boolean flag indicating which version is used for persisting resources"
        },
        {
          "term": "additionalPrinterColumns",
          "tier": 2,
          "reasoning": "Field for specifying extra columns in kubectl table output"
        },
        {
          "term": "API discovery",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for discovering available API resources"
        },
        {
          "term": "REST APIs",
          "tier": 2,
          "reasoning": "The interface through which Kubernetes resources are served"
        },
        {
          "term": "namespace-scoped",
          "tier": 2,
          "reasoning": "Scope type indicating resource exists within a namespace"
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Allowed value for scope field indicating cluster-level resources"
        },
        {
          "term": "Namespaced",
          "tier": 2,
          "reasoning": "Allowed value for scope field indicating namespace-level resources"
        },
        {
          "term": "CamelCase",
          "tier": 3,
          "reasoning": "Naming convention specified for kind values"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Kubernetes CLI tool referenced for resource operations"
        },
        {
          "term": "kubectl get",
          "tier": 1,
          "reasoning": "Specific kubectl command referenced for retrieving resources"
        },
        {
          "term": "Table output",
          "tier": 2,
          "reasoning": "Kubernetes API concept for returning resources in tabular format"
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface used throughout"
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Kubernetes version lifecycle stage indicating early experimental features"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Kubernetes version lifecycle stage indicating pre-stable features"
        },
        {
          "term": "GA",
          "tier": 2,
          "reasoning": "General Availability version stage with no suffix, indicating stable features"
        },
        {
          "term": "major version",
          "tier": 3,
          "reasoning": "Version numbering concept for primary version number"
        },
        {
          "term": "minor version",
          "tier": 3,
          "reasoning": "Version numbering concept for secondary version number"
        },
        {
          "term": "Atomic",
          "tier": 2,
          "reasoning": "Kubernetes merge strategy indicating field will be replaced during merge"
        },
        {
          "term": "merge",
          "tier": 3,
          "reasoning": "Operation concept for combining resource configurations"
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:12:46.631238",
      "elapsed_time": 18.40497326850891
    },
    {
      "chunk_id": "reference_glossary_pod-lifecycle_sec0",
      "doc_id": "reference_glossary_pod-lifecycle",
      "heading": "Introduction",
      "source_file": "reference_glossary_pod-lifecycle.md",
      "content": "---\ntitle: Pod Lifecycle\nid: pod-lifecycle\ndate: 2019-02-17\nfull-link: /docs/concepts/workloads/pods/pod-lifecycle/\nrelated:\n - pod\n - container\ntags:\n - fundamental\nshort_description: >\n  The sequence of states through which a Pod passes during its lifetime.\n \n---\n The sequence of states through which a Pod passes during its lifetime.\n\n<!--more--> \n\nThe [Pod Lifecycle](/docs/concepts/workloads/pods/pod-lifecycle/) is defined by the states or phases of a Pod. There are five possible Pod phases: Pending, Running, Succeeded, Failed, and Unknown. A high-level description of the Pod state is summarized in the [PodStatus](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#podstatus-v1-core) `phase` field.",
      "terms": [
        {
          "term": "Pod Lifecycle",
          "tier": 1,
          "reasoning": "Core Kubernetes concept describing the sequence of states a Pod passes through, appears as the document title and main subject."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object and resource, the primary subject of this documentation."
        },
        {
          "term": "pod-lifecycle",
          "tier": 1,
          "reasoning": "The identifier/slug for this concept, used in documentation URLs and references."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes concept listed as a related term, fundamental unit that Pods encapsulate."
        },
        {
          "term": "Pod phases",
          "tier": 2,
          "reasoning": "Technical concept describing the discrete states a Pod can be in during its lifecycle."
        },
        {
          "term": "Pending",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states in Kubernetes."
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating active execution."
        },
        {
          "term": "Succeeded",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating successful completion."
        },
        {
          "term": "Failed",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating unsuccessful termination."
        },
        {
          "term": "Unknown",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating indeterminate status."
        },
        {
          "term": "PodStatus",
          "tier": 1,
          "reasoning": "Kubernetes API object/field that contains Pod state information including the phase field."
        },
        {
          "term": "phase",
          "tier": 2,
          "reasoning": "Technical field within PodStatus that summarizes the Pod's current state."
        },
        {
          "term": "states",
          "tier": 3,
          "reasoning": "Technical term describing the discrete conditions a Pod can be in during its lifecycle."
        },
        {
          "term": "phases",
          "tier": 2,
          "reasoning": "Synonym for states in Pod lifecycle context, specifically the five possible Pod conditions."
        },
        {
          "term": "lifetime",
          "tier": 3,
          "reasoning": "Technical term describing the duration from Pod creation to termination."
        },
        {
          "term": "Pod state",
          "tier": 2,
          "reasoning": "Compound term referring to the current condition of a Pod within its lifecycle."
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T22:12:56.723576",
      "elapsed_time": 9.065295934677124
    },
    {
      "chunk_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions_sec1",
      "doc_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions.md",
      "content": "{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\nIf you are using an older version of Kubernetes that is still supported, switch to\nthe documentation for that version to see advice that is relevant for your cluster.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Technical concept referring to specific releases of Kubernetes software."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept representing a set of nodes running containerized applications."
        },
        {
          "term": "documentation",
          "tier": 3,
          "reasoning": "Technical reference material for the Kubernetes platform, contextually relevant to versioning."
        }
      ],
      "term_count": 4,
      "generated_at": "2026-02-08T22:13:01.666399",
      "elapsed_time": 3.9238855838775635
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster_sec3",
      "doc_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster",
      "heading": "Optional: enable additional DRA API groups {#enable-dra}",
      "source_file": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster.md",
      "content": "DRA overall is a stable feature in Kubernetes; however, aspects of it may still be alpha or beta.\nIf you want to use any aspect of DRA that is not yet stable,\nand the associated feature relies on a dedicated API kind,\nthen you must enable the associated alpha or beta API groups.\n\nSome older DRA drivers or workloads might still need the\nv1beta1 API from Kubernetes 1.30 or v1beta2 from Kubernetes 1.32.\nIf and only if support for those is desired, then enable the following\n{{< glossary_tooltip text=\"API groups\" term_id=\"api-group\" >}}:\n\n    * `resource.k8s.io/v1beta1`\n    * `resource.k8s.io/v1beta2`\n\nAlpha features with separate API types need:\n\n   * `resource.k8s.io/v1alpha3`\n\nFor more information, see\n[Enabling or disabling API groups](/docs/reference/using-api/#enabling-or-disabling).",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Dynamic Resource Allocation - a specific Kubernetes feature/API for resource management"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented"
        },
        {
          "term": "API groups",
          "tier": 2,
          "reasoning": "Kubernetes concept for organizing and versioning API resources"
        },
        {
          "term": "API kind",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to a specific type of API resource"
        },
        {
          "term": "feature",
          "tier": 2,
          "reasoning": "Technical term describing a capability or functionality in Kubernetes"
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready status in Kubernetes"
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating early experimental status in Kubernetes"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating pre-stable testing status in Kubernetes"
        },
        {
          "term": "DRA drivers",
          "tier": 1,
          "reasoning": "Specific driver components that implement DRA functionality"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to applications running on the cluster"
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "Specific API version identifier for beta stage APIs"
        },
        {
          "term": "v1beta2",
          "tier": 2,
          "reasoning": "Specific API version identifier for beta stage APIs"
        },
        {
          "term": "v1alpha3",
          "tier": 2,
          "reasoning": "Specific API version identifier for alpha stage APIs"
        },
        {
          "term": "resource.k8s.io/v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group path for DRA beta resources"
        },
        {
          "term": "resource.k8s.io/v1beta2",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group path for DRA beta resources"
        },
        {
          "term": "resource.k8s.io/v1alpha3",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group path for DRA alpha resources"
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - fundamental technical concept for Kubernetes interaction"
        },
        {
          "term": "Alpha features",
          "tier": 2,
          "reasoning": "Compound term describing features in early experimental stage"
        },
        {
          "term": "API types",
          "tier": 2,
          "reasoning": "Technical term referring to different kinds of API resources"
        },
        {
          "term": "Kubernetes 1.30",
          "tier": 1,
          "reasoning": "Specific Kubernetes version release"
        },
        {
          "term": "Kubernetes 1.32",
          "tier": 1,
          "reasoning": "Specific Kubernetes version release"
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:13:13.241754",
      "elapsed_time": 10.55471920967102
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec20",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`PrefixedClaimOrExpression`     {#apiserver-config-k8s-io-v1-PrefixedClaimOrExpression}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [ClaimMappings](#apiserver-config-k8s-io-v1-ClaimMappings)\n\n\n<p>PrefixedClaimOrExpression provides the configuration for a single prefixed claim or expression.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>claim</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>claim is the JWT claim to use.\nMutually exclusive with expression.</p>\n</td>\n</tr>\n<tr><td><code>prefix</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>prefix is prepended to claim's value to prevent clashes with existing names.\nprefix needs to be set if claim is set and can be the empty string.\nMutually exclusive with expression.</p>\n</td>\n</tr>\n<tr><td><code>expression</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>expression represents the expression which will be evaluated by CEL.</p>\n<p>CEL expressions have access to the contents of the token claims, organized into CEL variable:</p>\n<ul>\n<li>'claims' is a map of claim names to claim values.\nFor example, a variable named 'sub' can be accessed as 'claims.sub'.\nNested claims can be accessed using dot notation, e.g. 'claims.foo.bar'.</li>\n</ul>\n<p>Documentation on CEL: https://kubernetes.io/docs/reference/using-api/cel/</p>\n<p>Mutually exclusive with claim and prefix.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "ClaimMappings",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for mapping claims"
        },
        {
          "term": "PrefixedClaimOrExpression",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration type for prefixed claims or expressions"
        },
        {
          "term": "claim",
          "tier": 2,
          "reasoning": "Technical field representing a JWT claim in authentication context"
        },
        {
          "term": "JWT claim",
          "tier": 2,
          "reasoning": "Domain concept referring to claims within JSON Web Tokens for authentication"
        },
        {
          "term": "prefix",
          "tier": 2,
          "reasoning": "Technical field for prepending values to prevent naming clashes"
        },
        {
          "term": "expression",
          "tier": 2,
          "reasoning": "Technical field representing a CEL expression for evaluation"
        },
        {
          "term": "CEL",
          "tier": 1,
          "reasoning": "Common Expression Language - specific technology used by Kubernetes for expressions"
        },
        {
          "term": "CEL variable",
          "tier": 2,
          "reasoning": "Domain concept for variables accessible within CEL expressions"
        },
        {
          "term": "CEL expressions",
          "tier": 2,
          "reasoning": "Domain concept for expressions evaluated by the CEL engine"
        },
        {
          "term": "claims",
          "tier": 2,
          "reasoning": "Technical term for the map of claim names to values in token context"
        },
        {
          "term": "token claims",
          "tier": 2,
          "reasoning": "Domain concept for claims contained within authentication tokens"
        },
        {
          "term": "claim names",
          "tier": 2,
          "reasoning": "Technical term for identifiers of claims within tokens"
        },
        {
          "term": "claim values",
          "tier": 2,
          "reasoning": "Technical term for the data associated with claim names"
        },
        {
          "term": "dot notation",
          "tier": 3,
          "reasoning": "Technical syntax pattern for accessing nested claims"
        },
        {
          "term": "Nested claims",
          "tier": 2,
          "reasoning": "Domain concept for hierarchically structured claims in tokens"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the configuration fields"
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version identifier for apiserver configuration"
        },
        {
          "term": "token",
          "tier": 2,
          "reasoning": "Authentication concept referring to JWT or similar authentication tokens"
        },
        {
          "term": "map",
          "tier": 3,
          "reasoning": "Data structure type used to describe claims organization"
        },
        {
          "term": "Mutually exclusive",
          "tier": 3,
          "reasoning": "Technical constraint term describing field relationships in API configuration"
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T22:13:26.579284",
      "elapsed_time": 12.318711757659912
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_create_kubectl_create_priorityclass_sec3",
      "doc_id": "reference_kubectl_generated_kubectl_create_kubectl_create_priorityclass",
      "heading": "{{% heading \"parentoptions\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_create_kubectl_create_priorityclass.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--as string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Username to impersonate for the operation. User could be a regular user or a service account in a namespace.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--as-group strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Group to impersonate for the operation, this flag can be repeated to specify multiple groups.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--as-uid string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>UID to impersonate for the operation.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--as-user-extra strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>User extras to impersonate for the operation, this flag can be repeated to specify multiple values for the same key.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cache-dir string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"$HOME/.kube/cache\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Default cache directory</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--certificate-authority string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to a cert file for the certificate authority</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--client-certificate string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to a client certificate file for TLS</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--client-key string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to a client key file for TLS</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cluster string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The name of the kubeconfig cluster to use</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--context string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The name of the kubeconfig context to use</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--disable-compression</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, opt-out of response compression for all requests to the server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--insecure-skip-tls-verify</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--kubeconfig string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to the kubeconfig file to use for CLI requests.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--kuberc string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to the kuberc file to use for preferences. This can be disabled by exporting KUBECTL_KUBERC=false feature gate or turning off the feature KUBERC=off.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--match-server-version</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Require server version to match client version</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-n, --namespace string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If present, the namespace scope for this CLI request</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--password string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Password for basic authentication to the API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--profile string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of profile to capture. One of (none|cpu|heap|goroutine|threadcreate|block|mutex|trace)</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--profile-output string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"profile.pprof\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the file to write the profile to</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--request-timeout string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"0\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-s, --server string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The address and port of the Kubernetes API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-buffer-duration duration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1m0s</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Writes in the storage driver will be buffered for this duration, and committed to the non memory backends as a single transaction</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-db string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"cadvisor\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database name</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-host string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"localhost:8086\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database host:port</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-password string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"root\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database password</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-secure</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>use secure connection with database</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-table string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"stats\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>table name</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-user string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"root\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database username</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--tls-server-name string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--token string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Bearer token for authentication to the API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--user string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The name of the kubeconfig user to use</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--username string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Username for basic authentication to the API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--version version[=true]</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>--version, --version=raw prints version information and quits; --version=vX.Y.Z... sets the reported version</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--warnings-as-errors</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Treat warnings received from the server as errors and exit with a non-zero exit code</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "--as",
          "tier": 1,
          "reasoning": "CLI flag for user impersonation in kubectl operations"
        },
        {
          "term": "--as-group",
          "tier": 1,
          "reasoning": "CLI flag for group impersonation in kubectl operations"
        },
        {
          "term": "--as-uid",
          "tier": 1,
          "reasoning": "CLI flag for UID impersonation in kubectl operations"
        },
        {
          "term": "--as-user-extra",
          "tier": 1,
          "reasoning": "CLI flag for user extras impersonation in kubectl operations"
        },
        {
          "term": "--cache-dir",
          "tier": 1,
          "reasoning": "CLI flag specifying the cache directory location"
        },
        {
          "term": "--certificate-authority",
          "tier": 1,
          "reasoning": "CLI flag for specifying certificate authority file path"
        },
        {
          "term": "--client-certificate",
          "tier": 1,
          "reasoning": "CLI flag for specifying client certificate file for TLS"
        },
        {
          "term": "--client-key",
          "tier": 1,
          "reasoning": "CLI flag for specifying client key file for TLS"
        },
        {
          "term": "--cluster",
          "tier": 1,
          "reasoning": "CLI flag for specifying kubeconfig cluster name"
        },
        {
          "term": "--context",
          "tier": 1,
          "reasoning": "CLI flag for specifying kubeconfig context name"
        },
        {
          "term": "--disable-compression",
          "tier": 1,
          "reasoning": "CLI flag to opt-out of response compression"
        },
        {
          "term": "--insecure-skip-tls-verify",
          "tier": 1,
          "reasoning": "CLI flag to skip TLS certificate verification"
        },
        {
          "term": "--kubeconfig",
          "tier": 1,
          "reasoning": "CLI flag for specifying kubeconfig file path"
        },
        {
          "term": "--kuberc",
          "tier": 1,
          "reasoning": "CLI flag for specifying kuberc preferences file path"
        },
        {
          "term": "--match-server-version",
          "tier": 1,
          "reasoning": "CLI flag requiring server version to match client version"
        },
        {
          "term": "--namespace",
          "tier": 1,
          "reasoning": "CLI flag for specifying namespace scope for requests"
        },
        {
          "term": "--password",
          "tier": 1,
          "reasoning": "CLI flag for basic authentication password"
        },
        {
          "term": "--profile",
          "tier": 1,
          "reasoning": "CLI flag for specifying profiling type to capture"
        },
        {
          "term": "service account",
          "tier": 1,
          "reasoning": "Kubernetes identity resource that can be impersonated"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for scoping resources and requests"
        },
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Configuration file for kubectl CLI requests"
        },
        {
          "term": "kuberc",
          "tier": 1,
          "reasoning": "Configuration file for kubectl preferences"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster concept referenced in kubeconfig"
        },
        {
          "term": "context",
          "tier": 2,
          "reasoning": "Kubeconfig context for specifying cluster/user/namespace combination"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol used for client certificates and keys"
        },
        {
          "term": "HTTPS",
          "tier": 3,
          "reasoning": "Secure HTTP protocol mentioned in TLS verification context"
        },
        {
          "term": "certificate authority",
          "tier": 2,
          "reasoning": "Security concept for certificate validation"
        },
        {
          "term": "client certificate",
          "tier": 2,
          "reasoning": "TLS authentication mechanism for client identity"
        },
        {
          "term": "client key",
          "tier": 2,
          "reasoning": "Private key file used with client certificate for TLS"
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Kubernetes component that receives authentication credentials"
        },
        {
          "term": "basic authentication",
          "tier": 2,
          "reasoning": "Authentication method using username/password for API server"
        },
        {
          "term": "impersonate",
          "tier": 2,
          "reasoning": "Kubernetes authorization concept for acting as another user/group"
        },
        {
          "term": "UID",
          "tier": 3,
          "reasoning": "User identifier that can be impersonated for operations"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling features like KUBECTL_KUBERC"
        },
        {
          "term": "KUBERC",
          "tier": 1,
          "reasoning": "Feature gate name for kuberc functionality"
        },
        {
          "term": "KUBECTL_KUBERC",
          "tier": 1,
          "reasoning": "Environment variable feature gate for kuberc"
        },
        {
          "term": "cache directory",
          "tier": 2,
          "reasoning": "Local storage location for kubectl cached data"
        },
        {
          "term": "response compression",
          "tier": 2,
          "reasoning": "Server optimization feature that can be disabled"
        },
        {
          "term": "server version",
          "tier": 2,
          "reasoning": "Kubernetes server version for compatibility matching"
        },
        {
          "term": "client version",
          "tier": 2,
          "reasoning": "Kubectl client version for compatibility matching"
        },
        {
          "term": "profile",
          "tier": 2,
          "reasoning": "Profiling capability for performance analysis"
        },
        {
          "term": "cpu",
          "tier": 3,
          "reasoning": "Profile type for CPU profiling"
        },
        {
          "term": "heap",
          "tier": 3,
          "reasoning": "Profile type for memory heap profiling"
        },
        {
          "term": "goroutine",
          "tier": 3,
          "reasoning": "Profile type for Go goroutine profiling"
        },
        {
          "term": "threadcreate",
          "tier": 3,
          "reasoning": "Profile type for thread creation profiling"
        },
        {
          "term": "block",
          "tier": 3,
          "reasoning": "Profile type for blocking profiling"
        },
        {
          "term": "mutex",
          "tier": 3,
          "reasoning": "Profile type for mutex contention profiling"
        },
        {
          "term": "trace",
          "tier": 3,
          "reasoning": "Profile type for execution tracing"
        },
        {
          "term": "CLI",
          "tier": 3,
          "reasoning": "Command Line Interface referenced for kubectl requests"
        }
      ],
      "term_count": 49,
      "generated_at": "2026-02-08T22:13:45.521254",
      "elapsed_time": 17.91709041595459
    },
    {
      "chunk_id": "concepts_security__index_sec0",
      "doc_id": "concepts_security__index",
      "heading": "Introduction",
      "source_file": "concepts_security__index.md",
      "content": "---\ntitle: \"Security\"\nweight: 85\ndescription: >\n  Concepts for keeping your cloud-native workload secure.\nsimple_list: true\n---\n\nThis section of the Kubernetes documentation aims to help you learn to run\nworkloads more securely, and about the essential aspects of keeping a\nKubernetes cluster secure.\n\nKubernetes is based on a cloud-native architecture, and draws on advice from the\n{{< glossary_tooltip text=\"CNCF\" term_id=\"cncf\" >}} about good practice for\ncloud native information security.\n\nRead [Cloud Native Security and Kubernetes](/docs/concepts/security/cloud-native-security/)\nfor the broader context about how to secure your cluster and the applications that\nyou're running on it.",
      "terms": [
        {
          "term": "Security",
          "tier": 2,
          "reasoning": "Core domain concept and the main topic of this documentation section"
        },
        {
          "term": "cloud-native",
          "tier": 2,
          "reasoning": "Architectural paradigm describing modern distributed application design patterns"
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes domain term for applications and processes running on the cluster"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core platform and proper noun this documentation describes"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes"
        },
        {
          "term": "cloud native information security",
          "tier": 2,
          "reasoning": "Domain-specific security concept for cloud-native architectures"
        },
        {
          "term": "CNCF",
          "tier": 1,
          "reasoning": "Proper noun acronym for Cloud Native Computing Foundation, the governing body"
        },
        {
          "term": "Cloud Native Security",
          "tier": 2,
          "reasoning": "Specific security domain concept referenced as a documentation topic"
        },
        {
          "term": "applications",
          "tier": 3,
          "reasoning": "Technical term for software running on the cluster in this context"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Plural form of workload, Kubernetes term for running applications"
        },
        {
          "term": "cloud-native architecture",
          "tier": 2,
          "reasoning": "Architectural pattern that Kubernetes is based upon"
        },
        {
          "term": "good practice",
          "tier": 3,
          "reasoning": "Technical term in security context referring to recommended security patterns"
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:13:54.482247",
      "elapsed_time": 7.940618991851807
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec2",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`AuthenticationConfiguration`     {#apiserver-k8s-io-v1beta1-AuthenticationConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "<p>AuthenticationConfiguration provides versioned configuration for authentication.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n<tr><td><code>apiVersion</code><br/>string</td><td><code>apiserver.k8s.io/v1beta1</code></td></tr>\n<tr><td><code>kind</code><br/>string</td><td><code>AuthenticationConfiguration</code></td></tr>\n    \n  \n<tr><td><code>jwt</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-JWTAuthenticator\"><code>[]JWTAuthenticator</code></a>\n</td>\n<td>\n   <p>jwt is a list of authenticator to authenticate Kubernetes users using\nJWT compliant tokens. The authenticator will attempt to parse a raw ID token,\nverify it's been signed by the configured issuer. The public key to verify the\nsignature is discovered from the issuer's public endpoint using OIDC discovery.\nFor an incoming token, each JWT authenticator will be attempted in\nthe order in which it is specified in this list.  Note however that\nother authenticators may run before or after the JWT authenticators.\nThe specific position of JWT authenticators in relation to other\nauthenticators is neither defined nor stable across releases.  Since\neach JWT authenticator must have a unique issuer URL, at most one\nJWT authenticator will attempt to cryptographically validate the token.</p>\n<p>The minimum valid JWT payload must contain the following claims:\n{\n&quot;iss&quot;: &quot;https://issuer.example.com&quot;,\n&quot;aud&quot;: [&quot;audience&quot;],\n&quot;exp&quot;: 1234567890,\n&quot;<!-- raw HTML omitted -->&quot;: &quot;username&quot;\n}</p>\n</td>\n</tr>\n<tr><td><code>anonymous</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-AnonymousAuthConfig\"><code>AnonymousAuthConfig</code></a>\n</td>\n<td>\n   <p>If present --anonymous-auth must not be set</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for configuring authentication settings."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Standard Kubernetes API field specifying the API version of a resource."
        },
        {
          "term": "apiserver.k8s.io/v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version identifier for the apiserver configuration."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Standard Kubernetes API field specifying the type of resource."
        },
        {
          "term": "jwt",
          "tier": 2,
          "reasoning": "Field name and reference to JWT-based authentication mechanism in Kubernetes."
        },
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Kubernetes API type for configuring JWT-based authentication."
        },
        {
          "term": "JWT",
          "tier": 2,
          "reasoning": "JSON Web Token - standard protocol for secure token-based authentication."
        },
        {
          "term": "authenticator",
          "tier": 2,
          "reasoning": "Component responsible for verifying user identity in Kubernetes authentication."
        },
        {
          "term": "Kubernetes users",
          "tier": 2,
          "reasoning": "Domain concept referring to authenticated entities in a Kubernetes cluster."
        },
        {
          "term": "JWT compliant tokens",
          "tier": 2,
          "reasoning": "Tokens that conform to the JWT specification for authentication."
        },
        {
          "term": "ID token",
          "tier": 2,
          "reasoning": "Specific type of token containing identity claims used in OIDC authentication."
        },
        {
          "term": "issuer",
          "tier": 2,
          "reasoning": "Entity that creates and signs tokens in JWT/OIDC authentication flow."
        },
        {
          "term": "public key",
          "tier": 2,
          "reasoning": "Cryptographic key used to verify token signatures."
        },
        {
          "term": "signature",
          "tier": 2,
          "reasoning": "Cryptographic signature used to verify token authenticity."
        },
        {
          "term": "OIDC discovery",
          "tier": 2,
          "reasoning": "OpenID Connect protocol mechanism for discovering issuer configuration."
        },
        {
          "term": "OIDC",
          "tier": 2,
          "reasoning": "OpenID Connect - authentication protocol built on OAuth 2.0."
        },
        {
          "term": "issuer URL",
          "tier": 2,
          "reasoning": "Unique URL identifying the token issuer in OIDC/JWT authentication."
        },
        {
          "term": "JWT authenticator",
          "tier": 2,
          "reasoning": "Specific authenticator type that validates JWT tokens."
        },
        {
          "term": "cryptographically validate",
          "tier": 2,
          "reasoning": "Process of verifying token integrity using cryptographic methods."
        },
        {
          "term": "JWT payload",
          "tier": 2,
          "reasoning": "The claims section of a JWT token containing authentication data."
        },
        {
          "term": "claims",
          "tier": 2,
          "reasoning": "Assertions about the subject contained in a JWT token."
        },
        {
          "term": "iss",
          "tier": 2,
          "reasoning": "Standard JWT claim identifying the token issuer."
        },
        {
          "term": "aud",
          "tier": 2,
          "reasoning": "Standard JWT claim specifying the intended audience for the token."
        },
        {
          "term": "exp",
          "tier": 2,
          "reasoning": "Standard JWT claim specifying token expiration time."
        },
        {
          "term": "username",
          "tier": 2,
          "reasoning": "Identity claim representing the authenticated user's name."
        },
        {
          "term": "anonymous",
          "tier": 2,
          "reasoning": "Field for configuring anonymous authentication in Kubernetes."
        },
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Kubernetes API type for configuring anonymous authentication settings."
        },
        {
          "term": "--anonymous-auth",
          "tier": 1,
          "reasoning": "CLI flag for the Kubernetes API server controlling anonymous authentication."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Core security concept for verifying user identity in Kubernetes."
        },
        {
          "term": "token",
          "tier": 2,
          "reasoning": "Credential used for authentication in Kubernetes."
        },
        {
          "term": "public endpoint",
          "tier": 2,
          "reasoning": "Network endpoint accessible for retrieving issuer configuration."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "Kubernetes API version indicating beta stability level."
        }
      ],
      "term_count": 32,
      "generated_at": "2026-02-08T22:14:11.371544",
      "elapsed_time": 15.86068320274353
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec4",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Think about how your application reacts to disruptions",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "Decide how many instances can be down at the same time for a short period\ndue to a voluntary disruption.\n\n- Stateless frontends:\n  - Concern: don't reduce serving capacity by more than 10%.\n    - Solution: use PDB with minAvailable 90% for example.\n- Single-instance Stateful Application:\n  - Concern: do not terminate this application without talking to me.\n    - Possible Solution 1: Do not use a PDB and tolerate occasional downtime.\n    - Possible Solution 2: Set PDB with maxUnavailable=0. Have an understanding\n      (outside of Kubernetes) that the cluster operator needs to consult you before\n      termination. When the cluster operator contacts you, prepare for downtime,\n      and then delete the PDB to indicate readiness for disruption. Recreate afterwards.\n- Multiple-instance Stateful application such as Consul, ZooKeeper, or etcd:\n  - Concern: Do not reduce number of instances below quorum, otherwise writes fail.\n    - Possible Solution 1: set maxUnavailable to 1 (works with varying scale of application).\n    - Possible Solution 2: set minAvailable to quorum-size (e.g. 3 when scale is 5).\n      (Allows more disruptions at once).\n- Restartable Batch Job:\n  - Concern: Job needs to complete in case of voluntary disruption.\n    - Possible solution: Do not create a PDB. The Job controller will create a replacement pod.\n\n### Rounding logic when specifying percentages\n\nValues for `minAvailable` or `maxUnavailable` can be expressed as integers or as a percentage.\n\n- When you specify an integer, it represents a number of Pods. For instance, if you set\n  `minAvailable` to 10, then 10 Pods must always be available, even during a disruption.\n- When you specify a percentage by setting the value to a string representation of a\n  percentage (eg. `\"50%\"`), it represents a percentage of total Pods. For instance, if\n  you set `minAvailable` to `\"50%\"`, then at least 50% of the Pods remain available\n  during a disruption.\n\nWhen you specify the value as a percentage, it may not map to an exact number of Pods.\nFor example, if you have 7 Pods and you set `minAvailable` to `\"50%\"`, it's not\nimmediately obvious whether that means 3 Pods or 4 Pods must be available. Kubernetes\nrounds up to the nearest integer, so in this case, 4 Pods must be available. When you\nspecify the value `maxUnavailable` as a percentage, Kubernetes rounds up the number of\nPods that may be disrupted. Thereby a disruption can exceed your defined\n`maxUnavailable` percentage. You can examine the\n[code](https://github.com/kubernetes/kubernetes/blob/23be9587a0f8677eb8091464098881df939c44a9/pkg/controller/disruption/disruption.go#L539)\nthat controls this behavior.",
      "terms": [
        {
          "term": "PDB",
          "tier": 1,
          "reasoning": "Abbreviation for PodDisruptionBudget, a core Kubernetes API object for managing voluntary disruptions."
        },
        {
          "term": "Consul",
          "tier": 1,
          "reasoning": "Named distributed system/service mesh tool mentioned as example of stateful application."
        },
        {
          "term": "ZooKeeper",
          "tier": 1,
          "reasoning": "Named distributed coordination service mentioned as example of stateful application."
        },
        {
          "term": "etcd",
          "tier": 1,
          "reasoning": "Named distributed key-value store, core Kubernetes component mentioned as stateful application example."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "Job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running batch workloads to completion."
        },
        {
          "term": "Job controller",
          "tier": 1,
          "reasoning": "Kubernetes controller component that manages Job resources and creates replacement pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the core Kubernetes resource unit."
        },
        {
          "term": "voluntary disruption",
          "tier": 2,
          "reasoning": "Domain concept describing intentional, planned disruptions to workloads."
        },
        {
          "term": "Stateless frontends",
          "tier": 2,
          "reasoning": "Architectural pattern describing frontend services without persistent state."
        },
        {
          "term": "serving capacity",
          "tier": 2,
          "reasoning": "Technical concept referring to the ability to handle incoming requests."
        },
        {
          "term": "minAvailable",
          "tier": 2,
          "reasoning": "PDB configuration parameter specifying minimum available pods during disruption."
        },
        {
          "term": "Single-instance Stateful Application",
          "tier": 2,
          "reasoning": "Application architecture pattern with single replica maintaining state."
        },
        {
          "term": "maxUnavailable",
          "tier": 2,
          "reasoning": "PDB configuration parameter specifying maximum pods that can be unavailable."
        },
        {
          "term": "cluster operator",
          "tier": 2,
          "reasoning": "Role/persona responsible for managing Kubernetes cluster operations."
        },
        {
          "term": "termination",
          "tier": 2,
          "reasoning": "Technical process of stopping/ending a pod or application instance."
        },
        {
          "term": "downtime",
          "tier": 2,
          "reasoning": "Operational concept describing period when service is unavailable."
        },
        {
          "term": "Multiple-instance Stateful application",
          "tier": 2,
          "reasoning": "Application architecture pattern with multiple replicas maintaining distributed state."
        },
        {
          "term": "quorum",
          "tier": 2,
          "reasoning": "Distributed systems concept for minimum nodes needed for consensus operations."
        },
        {
          "term": "writes",
          "tier": 2,
          "reasoning": "Database/storage operation concept in context of quorum requirements."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Technical concept referring to number of application instances/replicas."
        },
        {
          "term": "disruptions",
          "tier": 2,
          "reasoning": "Technical concept describing interruptions to normal pod operation."
        },
        {
          "term": "Restartable Batch Job",
          "tier": 2,
          "reasoning": "Workload pattern describing batch jobs that can be safely restarted."
        },
        {
          "term": "replacement pod",
          "tier": 2,
          "reasoning": "Technical concept of creating new pod to replace terminated one."
        },
        {
          "term": "Rounding logic",
          "tier": 2,
          "reasoning": "Technical behavior describing how percentage values are converted to integers."
        },
        {
          "term": "percentage",
          "tier": 2,
          "reasoning": "Configuration value type for PDB parameters as alternative to integers."
        },
        {
          "term": "integers",
          "tier": 3,
          "reasoning": "Data type used for specifying exact pod counts in PDB configuration."
        },
        {
          "term": "total Pods",
          "tier": 2,
          "reasoning": "Technical concept referring to complete count of pods in a workload."
        },
        {
          "term": "rounds up",
          "tier": 2,
          "reasoning": "Mathematical operation Kubernetes uses when converting percentages to pod counts."
        },
        {
          "term": "nearest integer",
          "tier": 3,
          "reasoning": "Mathematical concept describing rounding behavior in Kubernetes."
        },
        {
          "term": "disruption",
          "tier": 2,
          "reasoning": "Singular form of the core concept describing pod interruption events."
        },
        {
          "term": "instances",
          "tier": 2,
          "reasoning": "Technical term for individual running copies of an application."
        },
        {
          "term": "quorum-size",
          "tier": 2,
          "reasoning": "Configuration value representing minimum nodes for distributed consensus."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "Kubernetes architectural component that manages resource state."
        },
        {
          "term": "string representation",
          "tier": 3,
          "reasoning": "Data format concept for expressing percentage values in configuration."
        }
      ],
      "term_count": 36,
      "generated_at": "2026-02-08T22:14:32.634428",
      "elapsed_time": 20.238314867019653
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_create_kubectl_create_deployment_sec2",
      "doc_id": "reference_kubectl_generated_kubectl_create_kubectl_create_deployment",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_create_kubectl_create_deployment.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--allow-missing-template-keys&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--dry-run string[=\"unchanged\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;none&quot;, &quot;server&quot;, or &quot;client&quot;. If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--field-manager string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"kubectl-create\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the manager used to track field ownership.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for deployment</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Image names to run. A deployment can have multiple images set for multi-container pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-o, --output string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Output format. One of: (json, yaml, kyaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--port int32&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: -1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The containerPort that this deployment exposes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-r, --replicas int32&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Number of replicas to create. Default is 1.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--save-config</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the configuration of current object will be saved in its annotation. Otherwise, the annotation will be unchanged. This flag is useful when you want to perform kubectl apply on this object in the future.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--show-managed-fields</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, keep the managedFields when printing objects in JSON or YAML format.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--template string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--validate string[=\"strict\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"strict\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be one of: strict (or true), warn, ignore (or false). &quot;true&quot; or &quot;strict&quot; will use a schema to validate the input and fail the request if invalid. It will perform server side validation if ServerSideFieldValidation is enabled on the api-server, but will fall back to less reliable client-side validation if not. &quot;warn&quot; will warn about unknown or duplicate fields without blocking the request if server-side field validation is enabled on the API server, and behave as &quot;ignore&quot; otherwise. &quot;false&quot; or &quot;ignore&quot; will not perform any schema validation, silently dropping any unknown or duplicate fields.</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource type for managing containerized applications."
        },
        {
          "term": "kubectl-create",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand identifier used as default field-manager name."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool referenced in field-manager default value."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for declarative resource management mentioned in save-config context."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes resource mentioned in context of multi-container pod deployments."
        },
        {
          "term": "multi-container pod",
          "tier": 1,
          "reasoning": "Kubernetes pattern where a pod contains multiple containers, explicitly mentioned."
        },
        {
          "term": "api-server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that handles API requests and validation."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Alternative form of api-server mentioned in validation context."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Technical concept for output formatting using golang templates."
        },
        {
          "term": "golang templates",
          "tier": 2,
          "reasoning": "Specific templating system used for output formatting in kubectl."
        },
        {
          "term": "jsonpath",
          "tier": 2,
          "reasoning": "Query language/output format for extracting data from JSON structures."
        },
        {
          "term": "dry-run",
          "tier": 2,
          "reasoning": "Technical operation mode that simulates actions without persisting changes."
        },
        {
          "term": "server-side request",
          "tier": 2,
          "reasoning": "Technical concept describing requests processed by the API server."
        },
        {
          "term": "client strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where operations are simulated client-side only."
        },
        {
          "term": "server strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where server processes request without persisting."
        },
        {
          "term": "field-manager",
          "tier": 2,
          "reasoning": "Kubernetes concept for tracking ownership of resource fields."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Server-side apply concept for managing which controller owns which fields."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes concept for number of pod instances in a deployment."
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes specification for ports exposed by containers."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept used to specify what containers run."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for storing configuration data."
        },
        {
          "term": "managedFields",
          "tier": 2,
          "reasoning": "Kubernetes metadata tracking field ownership for server-side apply."
        },
        {
          "term": "schema validation",
          "tier": 2,
          "reasoning": "Process of validating resource definitions against API schemas."
        },
        {
          "term": "server-side field validation",
          "tier": 2,
          "reasoning": "API server feature for validating fields during request processing."
        },
        {
          "term": "ServerSideFieldValidation",
          "tier": 2,
          "reasoning": "Specific feature gate/capability name for server-side validation."
        },
        {
          "term": "client-side validation",
          "tier": 2,
          "reasoning": "Validation performed by kubectl before sending to server."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for API objects that can be created/managed."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical concept for object settings saved in annotations."
        },
        {
          "term": "json",
          "tier": 3,
          "reasoning": "Data format used for output and API communication."
        },
        {
          "term": "yaml",
          "tier": 3,
          "reasoning": "Data format commonly used for Kubernetes resource definitions."
        },
        {
          "term": "kyaml",
          "tier": 3,
          "reasoning": "Kubernetes-specific YAML output format option."
        },
        {
          "term": "go-template",
          "tier": 3,
          "reasoning": "Output format using Go templating language."
        },
        {
          "term": "go-template-file",
          "tier": 3,
          "reasoning": "Output format using Go template from file."
        },
        {
          "term": "jsonpath-as-json",
          "tier": 3,
          "reasoning": "Output format combining jsonpath with JSON output."
        },
        {
          "term": "jsonpath-file",
          "tier": 3,
          "reasoning": "Output format using jsonpath expression from file."
        },
        {
          "term": "map key",
          "tier": 3,
          "reasoning": "Data structure concept relevant to template processing."
        },
        {
          "term": "object",
          "tier": 3,
          "reasoning": "Technical term for Kubernetes resource instances."
        },
        {
          "term": "strict",
          "tier": 3,
          "reasoning": "Validation mode that fails on invalid input."
        },
        {
          "term": "warn",
          "tier": 3,
          "reasoning": "Validation mode that warns but doesn't block requests."
        },
        {
          "term": "ignore",
          "tier": 3,
          "reasoning": "Validation mode that silently drops unknown fields."
        },
        {
          "term": "int32",
          "tier": 3,
          "reasoning": "Data type specification for numeric flag values."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type for flags accepting multiple string values."
        }
      ],
      "term_count": 42,
      "generated_at": "2026-02-08T22:14:59.539581",
      "elapsed_time": 25.885162591934204
    },
    {
      "chunk_id": "reference_kubernetes-api_workload-resources_controller-revision-v1_sec3",
      "doc_id": "reference_kubernetes-api_workload-resources_controller-revision-v1",
      "heading": "Operations {#Operations}",
      "source_file": "reference_kubernetes-api_workload-resources_controller-revision-v1.md",
      "content": "<hr>\n\n\n\n\n\n\n### `get` read the specified ControllerRevision\n\n#### HTTP Request\n\nGET /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n401: Unauthorized\n\n\n### `list` list or watch objects of kind ControllerRevision\n\n#### HTTP Request\n\nGET /apis/apps/v1/namespaces/{namespace}/controllerrevisions\n\n#### Parameters\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **allowWatchBookmarks** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#allowWatchBookmarks\" >}}\">allowWatchBookmarks</a>\n\n\n- **continue** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#continue\" >}}\">continue</a>\n\n\n- **fieldSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldSelector\" >}}\">fieldSelector</a>\n\n\n- **labelSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#labelSelector\" >}}\">labelSelector</a>\n\n\n- **limit** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#limit\" >}}\">limit</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **resourceVersion** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersion\" >}}\">resourceVersion</a>\n\n\n- **resourceVersionMatch** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersionMatch\" >}}\">resourceVersionMatch</a>\n\n\n- **sendInitialEvents** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#sendInitialEvents\" >}}\">sendInitialEvents</a>\n\n\n- **timeoutSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#timeoutSeconds\" >}}\">timeoutSeconds</a>\n\n\n- **watch** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#watch\" >}}\">watch</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevisionList\" >}}\">ControllerRevisionList</a>): OK\n\n401: Unauthorized\n\n\n### `list` list or watch objects of kind ControllerRevision\n\n#### HTTP Request\n\nGET /apis/apps/v1/controllerrevisions\n\n#### Parameters\n\n\n- **allowWatchBookmarks** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#allowWatchBookmarks\" >}}\">allowWatchBookmarks</a>\n\n\n- **continue** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#continue\" >}}\">continue</a>\n\n\n- **fieldSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldSelector\" >}}\">fieldSelector</a>\n\n\n- **labelSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#labelSelector\" >}}\">labelSelector</a>\n\n\n- **limit** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#limit\" >}}\">limit</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **resourceVersion** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersion\" >}}\">resourceVersion</a>\n\n\n- **resourceVersionMatch** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersionMatch\" >}}\">resourceVersionMatch</a>\n\n\n- **sendInitialEvents** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#sendInitialEvents\" >}}\">sendInitialEvents</a>\n\n\n- **timeoutSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#timeoutSeconds\" >}}\">timeoutSeconds</a>\n\n\n- **watch** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#watch\" >}}\">watch</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevisionList\" >}}\">ControllerRevisionList</a>): OK\n\n401: Unauthorized\n\n\n### `create` create a ControllerRevision\n\n#### HTTP Request\n\nPOST /apis/apps/v1/namespaces/{namespace}/controllerrevisions\n\n#### Parameters\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>, required\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldManager** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldManager\" >}}\">fieldManager</a>\n\n\n- **fieldValidation** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldValidation\" >}}\">fieldValidation</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n201 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Created\n\n202 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Accepted\n\n401: Unauthorized\n\n\n### `update` replace the specified ControllerRevision\n\n#### HTTP Request\n\nPUT /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>, required\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldManager** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldManager\" >}}\">fieldManager</a>\n\n\n- **fieldValidation** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldValidation\" >}}\">fieldValidation</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n201 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Created\n\n401: Unauthorized\n\n\n### `patch` partially update the specified ControllerRevision\n\n#### HTTP Request\n\nPATCH /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../common-definitions/patch#Patch\" >}}\">Patch</a>, required\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldManager** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldManager\" >}}\">fieldManager</a>\n\n\n- **fieldValidation** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldValidation\" >}}\">fieldValidation</a>\n\n\n- **force** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#force\" >}}\">force</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n201 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Created\n\n401: Unauthorized\n\n\n### `delete` delete a ControllerRevision\n\n#### HTTP Request\n\nDELETE /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../common-definitions/delete-options#DeleteOptions\" >}}\">DeleteOptions</a>\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **gracePeriodSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#gracePeriodSeconds\" >}}\">gracePeriodSeconds</a>\n\n\n- **ignoreStoreReadErrorWithClusterBreakingPotential** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#ignoreStoreReadErrorWithClusterBreakingPotential\" >}}\">ignoreStoreReadErrorWithClusterBreakingPotential</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **propagationPolicy** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#propagationPolicy\" >}}\">propagationPolicy</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../common-definitions/status#Status\" >}}\">Status</a>): OK\n\n202 (<a href=\"{{< ref \"../common-definitions/status#Status\" >}}\">Status</a>): Accepted\n\n401: Unauthorized\n\n\n### `deletecollection` delete collection of ControllerRevision\n\n#### HTTP Request\n\nDELETE /apis/apps/v1/namespaces/{namespace}/controllerrevisions\n\n#### Parameters\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../common-definitions/delete-options#DeleteOptions\" >}}\">DeleteOptions</a>\n\n  \n\n\n- **continue** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#continue\" >}}\">continue</a>\n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldSelector\" >}}\">fieldSelector</a>\n\n\n- **gracePeriodSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#gracePeriodSeconds\" >}}\">gracePeriodSeconds</a>\n\n\n- **ignoreStoreReadErrorWithClusterBreakingPotential** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#ignoreStoreReadErrorWithClusterBreakingPotential\" >}}\">ignoreStoreReadErrorWithClusterBreakingPotential</a>\n\n\n- **labelSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#labelSelector\" >}}\">labelSelector</a>\n\n\n- **limit** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#limit\" >}}\">limit</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **propagationPolicy** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#propagationPolicy\" >}}\">propagationPolicy</a>\n\n\n- **resourceVersion** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersion\" >}}\">resourceVersion</a>\n\n\n- **resourceVersionMatch** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersionMatch\" >}}\">resourceVersionMatch</a>\n\n\n- **sendInitialEvents** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#sendInitialEvents\" >}}\">sendInitialEvents</a>\n\n\n- **timeoutSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#timeoutSeconds\" >}}\">timeoutSeconds</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../common-definitions/status#Status\" >}}\">Status</a>): OK\n\n401: Unauthorized",
      "terms": [
        {
          "term": "ControllerRevision",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for storing revision history of controllers"
        },
        {
          "term": "ControllerRevisionList",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a list of ControllerRevision resources"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for logical isolation and scoping of resources"
        },
        {
          "term": "HTTP Request",
          "tier": 3,
          "reasoning": "Protocol method used for API communication"
        },
        {
          "term": "GET",
          "tier": 3,
          "reasoning": "HTTP method used for retrieving resources from the API"
        },
        {
          "term": "apps/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for application workload resources"
        },
        {
          "term": "controllerrevisions",
          "tier": 1,
          "reasoning": "API endpoint path for ControllerRevision resources"
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Path parameter identifying a specific resource instance"
        },
        {
          "term": "pretty",
          "tier": 2,
          "reasoning": "Common API query parameter for formatting output"
        },
        {
          "term": "allowWatchBookmarks",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for watch operation optimization"
        },
        {
          "term": "continue",
          "tier": 2,
          "reasoning": "Kubernetes API pagination parameter for list operations"
        },
        {
          "term": "fieldSelector",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for filtering resources by field values"
        },
        {
          "term": "labelSelector",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for filtering resources by labels"
        },
        {
          "term": "limit",
          "tier": 2,
          "reasoning": "Kubernetes API pagination parameter to restrict result count"
        },
        {
          "term": "resourceVersion",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for optimistic concurrency control"
        },
        {
          "term": "resourceVersionMatch",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for specifying resource version matching semantics"
        },
        {
          "term": "sendInitialEvents",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for watch operation behavior"
        },
        {
          "term": "timeoutSeconds",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for request timeout configuration"
        },
        {
          "term": "watch",
          "tier": 2,
          "reasoning": "Kubernetes API parameter enabling real-time resource change notifications"
        },
        {
          "term": "in path",
          "tier": 3,
          "reasoning": "API parameter location specifier for URL path parameters"
        },
        {
          "term": "in query",
          "tier": 3,
          "reasoning": "API parameter location specifier for URL query string parameters"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for API parameters"
        },
        {
          "term": "boolean",
          "tier": 3,
          "reasoning": "Data type specification for API parameters"
        },
        {
          "term": "integer",
          "tier": 3,
          "reasoning": "Data type specification for API parameters"
        },
        {
          "term": "required",
          "tier": 3,
          "reasoning": "Parameter constraint indicating mandatory fields"
        },
        {
          "term": "Response",
          "tier": 3,
          "reasoning": "API response section describing return values"
        },
        {
          "term": "200",
          "tier": 3,
          "reasoning": "HTTP status code indicating successful response"
        },
        {
          "term": "401",
          "tier": 3,
          "reasoning": "HTTP status code indicating unauthorized access"
        },
        {
          "term": "Unauthorized",
          "tier": 2,
          "reasoning": "Authentication/authorization error response status"
        },
        {
          "term": "OK",
          "tier": 3,
          "reasoning": "HTTP response status indicating successful operation"
        },
        {
          "term": "list",
          "tier": 2,
          "reasoning": "Kubernetes API operation for retrieving multiple resources"
        },
        {
          "term": "workload-resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources for running applications"
        },
        {
          "term": "common-parameters",
          "tier": 2,
          "reasoning": "Shared API parameters used across multiple endpoints"
        },
        {
          "term": "apis",
          "tier": 2,
          "reasoning": "Kubernetes API path prefix for API group endpoints"
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T22:15:15.593408",
      "elapsed_time": 15.020176887512207
    },
    {
      "chunk_id": "reference_glossary_operator-pattern_sec0",
      "doc_id": "reference_glossary_operator-pattern",
      "heading": "Introduction",
      "source_file": "reference_glossary_operator-pattern.md",
      "content": "---\ntitle: Operator pattern\nid: operator-pattern\ndate: 2019-05-21\nfull_link: /docs/concepts/extend-kubernetes/operator/\nshort_description: >\n  A specialized controller used to manage a custom resource\n\naka:\ntags:\n- architecture\n---\nThe [operator pattern](/docs/concepts/extend-kubernetes/operator/) is a system\ndesign that links a {{< glossary_tooltip term_id=\"controller\" >}} to one or more custom\nresources.\n\n<!--more-->\n\nYou can extend Kubernetes by adding controllers to your cluster, beyond the built-in\ncontrollers that come as part of Kubernetes itself.\n\nIf a running application acts as a controller and has API access to carry out tasks\nagainst a custom resource that's defined in the control plane, that's an example of\nthe Operator pattern.",
      "terms": [
        {
          "term": "operator pattern",
          "tier": 1,
          "reasoning": "Core Kubernetes architectural pattern that is the main subject of this documentation chunk."
        },
        {
          "term": "controller",
          "tier": 1,
          "reasoning": "Named Kubernetes component that is central to the operator pattern definition."
        },
        {
          "term": "custom resource",
          "tier": 1,
          "reasoning": "Named Kubernetes API object type that operators manage."
        },
        {
          "term": "custom resources",
          "tier": 1,
          "reasoning": "Plural form of the core API object type referenced multiple times in the chunk."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the domain context for this documentation."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept where custom resources are defined."
        },
        {
          "term": "controllers",
          "tier": 1,
          "reasoning": "Plural form of the named Kubernetes component that can be added to extend functionality."
        },
        {
          "term": "Operator",
          "tier": 1,
          "reasoning": "Proper noun referring to the pattern implementation, capitalized in the text."
        },
        {
          "term": "API access",
          "tier": 2,
          "reasoning": "Technical concept describing the capability needed for operators to function."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface, contextually relevant to Kubernetes."
        },
        {
          "term": "application",
          "tier": 3,
          "reasoning": "Technical term describing the running software that acts as a controller in the operator pattern."
        },
        {
          "term": "extend Kubernetes",
          "tier": 2,
          "reasoning": "Domain concept describing the extensibility mechanism that operators provide."
        },
        {
          "term": "tasks",
          "tier": 3,
          "reasoning": "Technical term describing the operations carried out against custom resources."
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T22:15:26.757109",
      "elapsed_time": 10.142327308654785
    }
  ],
  "chunks": [
    {
      "chunk_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions_sec0",
      "doc_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions",
      "heading": "Introduction",
      "source_file": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions.md",
      "content": "---\ntitle: Extend the Kubernetes API with CustomResourceDefinitions\nreviewers:\n- deads2k\n- jpbetz\n- liggitt\n- roycaihw\n- sttts\ncontent_type: task\nmin-kubernetes-server-version: 1.16\nweight: 20\n---\n\n<!-- overview -->\nThis page shows how to install a\n[custom resource](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\ninto the Kubernetes API by creating a\n[CustomResourceDefinition](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#customresourcedefinition-v1-apiextensions-k8s-io).",
      "terms": [
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core Kubernetes component that serves as the primary interface for cluster operations and resource management."
        },
        {
          "term": "CustomResourceDefinitions",
          "tier": 1,
          "reasoning": "Named Kubernetes API object used to extend the API with custom resources."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Singular form of the API object for defining custom resources in Kubernetes."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Domain concept referring to user-defined extensions to the Kubernetes API."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually important for Kubernetes extension."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform that is the subject of this documentation."
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Domain concept referring to the mechanism for extending Kubernetes API capabilities."
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the generated Kubernetes API documentation and specification."
        },
        {
          "term": "apiextensions-k8s-io",
          "tier": 1,
          "reasoning": "API group name for Kubernetes API extensions, specifically for CustomResourceDefinitions."
        },
        {
          "term": "v1",
          "tier": 2,
          "reasoning": "API version indicator representing a stable/GA API version in Kubernetes."
        },
        {
          "term": "kubernetes-server-version",
          "tier": 2,
          "reasoning": "Technical concept referring to the minimum required Kubernetes server version for compatibility."
        },
        {
          "term": "1.16",
          "tier": 3,
          "reasoning": "Specific Kubernetes version number indicating minimum compatibility requirement."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:52:17.770996",
      "elapsed_time": 8.672800064086914
    },
    {
      "chunk_id": "concepts_workloads_management_sec10",
      "doc_id": "concepts_workloads_management",
      "heading": "In-place updates of resources",
      "source_file": "concepts_workloads_management.md",
      "content": "Sometimes it's necessary to make narrow, non-disruptive updates to resources you've created.\n\n### kubectl apply\n\nIt is suggested to maintain a set of configuration files in source control\n(see [configuration as code](https://martinfowler.com/bliki/InfrastructureAsCode.html)),\nso that they can be maintained and versioned along with the code for the resources they configure.\nThen, you can use [`kubectl apply`](/docs/reference/kubectl/generated/kubectl_apply/)\nto push your configuration changes to the cluster.\n\nThis command will compare the version of the configuration that you're pushing with the previous\nversion and apply the changes you've made, without overwriting any automated changes to properties\nyou haven't specified.\n\n```shell\nkubectl apply -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml\n```\n\n```none\ndeployment.apps/my-nginx configured\n```\n\nTo learn more about the underlying mechanism, read [server-side apply](/docs/reference/using-api/server-side-apply/).\n\n### kubectl edit\n\nAlternatively, you may also update resources with [`kubectl edit`](/docs/reference/kubectl/generated/kubectl_edit/):\n\n```shell\nkubectl edit deployment/my-nginx\n```\n\nThis is equivalent to first `get` the resource, edit it in text editor, and then `apply` the\nresource with the updated version:\n\n```shell\nkubectl get deployment my-nginx -o yaml > /tmp/nginx.yaml\nvi /tmp/nginx.yaml",
      "terms": [
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for applying configuration changes to cluster resources."
        },
        {
          "term": "kubectl edit",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI command for editing resources directly."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line tool referenced throughout the documentation."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object/resource type shown in examples (deployment.apps/my-nginx, deployment/my-nginx)."
        },
        {
          "term": "my-nginx",
          "tier": 1,
          "reasoning": "Specific named deployment resource used in the examples."
        },
        {
          "term": "nginx-deployment.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file name referenced in the kubectl apply example."
        },
        {
          "term": "deployment.apps",
          "tier": 1,
          "reasoning": "Kubernetes API group and resource type shown in command output."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes objects that can be created and managed."
        },
        {
          "term": "configuration files",
          "tier": 2,
          "reasoning": "Technical concept for files containing resource definitions and settings."
        },
        {
          "term": "source control",
          "tier": 2,
          "reasoning": "Technical concept for version control systems used to manage configuration."
        },
        {
          "term": "configuration as code",
          "tier": 2,
          "reasoning": "Infrastructure/DevOps concept explicitly referenced with link to Martin Fowler's definition."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "configuration changes",
          "tier": 2,
          "reasoning": "Technical concept describing modifications to resource definitions."
        },
        {
          "term": "server-side apply",
          "tier": 2,
          "reasoning": "Kubernetes-specific mechanism for applying configuration changes mentioned as underlying mechanism."
        },
        {
          "term": "automated changes",
          "tier": 2,
          "reasoning": "Technical concept referring to system-generated modifications to resource properties."
        },
        {
          "term": "properties",
          "tier": 2,
          "reasoning": "Technical term for attributes/fields of Kubernetes resources."
        },
        {
          "term": "text editor",
          "tier": 3,
          "reasoning": "General technical tool referenced in the kubectl edit workflow."
        },
        {
          "term": "yaml",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes configuration files, shown in -o yaml flag."
        },
        {
          "term": "get",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for retrieving resource information."
        },
        {
          "term": "apply",
          "tier": 2,
          "reasoning": "Kubernetes kubectl subcommand for applying configuration, used both as command and concept."
        },
        {
          "term": "-o yaml",
          "tier": 2,
          "reasoning": "kubectl output format flag for YAML serialization."
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Technical concept referring to configuration versions being compared during apply."
        },
        {
          "term": "versioned",
          "tier": 3,
          "reasoning": "Technical concept about maintaining version history of configurations."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Technical context indicator for command-line examples."
        },
        {
          "term": "configured",
          "tier": 2,
          "reasoning": "Kubernetes command output status indicating successful configuration update."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:52:32.539071",
      "elapsed_time": 13.76734185218811
    },
    {
      "chunk_id": "concepts_extend-kubernetes_operator_sec7",
      "doc_id": "concepts_extend-kubernetes_operator",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "concepts_extend-kubernetes_operator.md",
      "content": "* Read the {{< glossary_tooltip text=\"CNCF\" term_id=\"cncf\" >}}\n  [Operator White Paper](https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md).\n* Learn more about [Custom Resources](/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\n* Find ready-made operators on [OperatorHub.io](https://operatorhub.io/) to suit your use case\n* [Publish](https://operatorhub.io/) your operator for other people to use\n* Read [CoreOS' original article](https://web.archive.org/web/20170129131616/https://coreos.com/blog/introducing-operators.html)\n  that introduced the operator pattern (this is an archived version of the original article).\n* Read an [article](https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps)\n  from Google Cloud about best practices for building operators",
      "terms": [
        {
          "term": "CNCF",
          "tier": 1,
          "reasoning": "Cloud Native Computing Foundation - a specific organization and proper noun in the cloud-native ecosystem"
        },
        {
          "term": "Operator",
          "tier": 1,
          "reasoning": "A Kubernetes-specific pattern and resource type for managing applications"
        },
        {
          "term": "operator",
          "tier": 1,
          "reasoning": "Appears in lowercase form throughout the text referring to the Kubernetes operator pattern"
        },
        {
          "term": "operators",
          "tier": 1,
          "reasoning": "Plural form of operator, referring to multiple Kubernetes operator implementations"
        },
        {
          "term": "Custom Resources",
          "tier": 1,
          "reasoning": "A specific Kubernetes API extension mechanism for defining custom API objects"
        },
        {
          "term": "OperatorHub.io",
          "tier": 1,
          "reasoning": "A specific platform/registry for discovering and publishing Kubernetes operators"
        },
        {
          "term": "Operator White Paper",
          "tier": 2,
          "reasoning": "A specific technical document defining the operator pattern standards"
        },
        {
          "term": "operator pattern",
          "tier": 2,
          "reasoning": "A Kubernetes architectural pattern for automating application management"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the core subject of this documentation"
        },
        {
          "term": "stateful apps",
          "tier": 2,
          "reasoning": "Applications that maintain persistent state, a key concept in Kubernetes application management"
        },
        {
          "term": "CoreOS",
          "tier": 1,
          "reasoning": "The company that originally introduced the operator pattern, a proper noun"
        },
        {
          "term": "Google Cloud",
          "tier": 1,
          "reasoning": "A specific cloud provider mentioned as source of best practices"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Fundamental virtualization technology that Kubernetes orchestrates"
        },
        {
          "term": "best practices",
          "tier": 3,
          "reasoning": "Technical guidance term used in the context of building operators"
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in the context of extending Kubernetes APIs"
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Kubernetes concept for extending the API server with custom resources"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:52:42.960362",
      "elapsed_time": 9.420279741287231
    },
    {
      "chunk_id": "reference_glossary_sysctl_sec0",
      "doc_id": "reference_glossary_sysctl",
      "heading": "Introduction",
      "source_file": "reference_glossary_sysctl.md",
      "content": "---\ntitle: sysctl\nid: sysctl\ndate: 2019-02-12\nfull_link: /docs/tasks/administer-cluster/sysctl-cluster/\nshort_description: >\n  An interface for getting and setting Unix kernel parameters\n\naka:\ntags:\n- tool\n---\n `sysctl` is a semi-standardized interface for reading or changing the\n attributes of the running Unix kernel.\n\n<!--more-->\n\nOn Unix-like systems, `sysctl` is both the name of the tool that administrators\nuse to view and modify these settings, and also the system call that the tool\nuses.\n\n{{< glossary_tooltip text=\"Container\" term_id=\"container\" >}} runtimes and\nnetwork plugins may rely on `sysctl` values being set a certain way.",
      "terms": [
        {
          "term": "sysctl",
          "tier": 1,
          "reasoning": "Named Unix tool and system call for kernel parameter management, the primary subject of this documentation."
        },
        {
          "term": "Unix kernel",
          "tier": 2,
          "reasoning": "Core operating system component whose parameters sysctl manages."
        },
        {
          "term": "kernel parameters",
          "tier": 2,
          "reasoning": "Technical concept referring to configurable settings of the Unix kernel."
        },
        {
          "term": "Unix kernel parameters",
          "tier": 2,
          "reasoning": "Compound term describing the specific settings that sysctl reads and modifies."
        },
        {
          "term": "Unix-like systems",
          "tier": 3,
          "reasoning": "Category of operating systems where sysctl operates."
        },
        {
          "term": "system call",
          "tier": 2,
          "reasoning": "Technical concept describing the programmatic interface sysctl uses to interact with the kernel."
        },
        {
          "term": "Container",
          "tier": 2,
          "reasoning": "Core Kubernetes/infrastructure concept; container runtimes depend on sysctl values."
        },
        {
          "term": "network plugins",
          "tier": 2,
          "reasoning": "Infrastructure components that handle networking and may depend on sysctl values."
        },
        {
          "term": "interface",
          "tier": 3,
          "reasoning": "Technical term describing sysctl's role as a standardized access method."
        },
        {
          "term": "attributes",
          "tier": 3,
          "reasoning": "Technical term referring to the kernel properties that can be viewed or modified."
        },
        {
          "term": "running",
          "tier": 3,
          "reasoning": "Technical context indicating the kernel is active/executing when sysctl operates on it."
        },
        {
          "term": "tool",
          "tier": 3,
          "reasoning": "Explicitly tagged as a tool in the metadata; describes sysctl's classification."
        },
        {
          "term": "administrators",
          "tier": 3,
          "reasoning": "Role term describing users who interact with sysctl to manage systems."
        }
      ],
      "term_count": 13,
      "generated_at": "2026-02-08T21:52:54.236888",
      "elapsed_time": 10.275332927703857
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec18",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`TCPTransport`     {#apiserver-k8s-io-v1beta1-TCPTransport}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [Transport](#apiserver-k8s-io-v1beta1-Transport)\n\n\n<p>TCPTransport provides the information to connect to konnectivity server via TCP</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>URL is the location of the konnectivity server to connect to.\nAs an example it might be &quot;https://127.0.0.1:8131&quot;</p>\n</td>\n</tr>\n<tr><td><code>tlsConfig</code><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-TLSConfig\"><code>TLSConfig</code></a>\n</td>\n<td>\n   <p>TLSConfig is the config needed to use TLS when connecting to konnectivity server</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Transport",
          "tier": 1,
          "reasoning": "Kubernetes API object type referenced in the documentation for network transport configuration."
        },
        {
          "term": "TCPTransport",
          "tier": 1,
          "reasoning": "Specific Kubernetes API resource type that provides TCP connection configuration to konnectivity server."
        },
        {
          "term": "konnectivity server",
          "tier": 1,
          "reasoning": "Named Kubernetes infrastructure component for network connectivity between control plane and nodes."
        },
        {
          "term": "TLSConfig",
          "tier": 1,
          "reasoning": "Kubernetes API object type for TLS configuration settings."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-Transport",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the Transport resource."
        },
        {
          "term": "apiserver-k8s-io-v1beta1-TLSConfig",
          "tier": 1,
          "reasoning": "Specific API version and group reference for the TLSConfig resource."
        },
        {
          "term": "TCP",
          "tier": 2,
          "reasoning": "Network protocol used for transport layer communication to konnectivity server."
        },
        {
          "term": "TLS",
          "tier": 2,
          "reasoning": "Transport Layer Security protocol for encrypted connections to konnectivity server."
        },
        {
          "term": "url",
          "tier": 3,
          "reasoning": "Configuration field specifying the location/address of the konnectivity server."
        },
        {
          "term": "tlsConfig",
          "tier": 2,
          "reasoning": "Configuration field name for TLS settings in the TCPTransport specification."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "API version indicating beta maturity level of the Kubernetes API."
        },
        {
          "term": "apiserver",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API server component in the API group naming."
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Protocol shown in the example URL for secure connection to konnectivity server."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing configuration parameters in the API object specification."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the url field in the API object."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T21:53:03.889797",
      "elapsed_time": 8.651746273040771
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec24",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`UserValidationRule`     {#apiserver-config-k8s-io-v1-UserValidationRule}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>UserValidationRule provides the configuration for a single user info validation rule.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>expression</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>expression represents the expression which will be evaluated by CEL.\nMust return true for the validation to pass.</p>\n<p>CEL expressions have access to the contents of UserInfo, organized into CEL variable:</p>\n<ul>\n<li>'user' - authentication.k8s.io/v1, Kind=UserInfo object\nRefer to https://github.com/kubernetes/api/blob/release-1.28/authentication/v1/types.go#L105-L122 for the definition.\nAPI documentation: https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#userinfo-v1-authentication-k8s-io</li>\n</ul>\n<p>Documentation on CEL: https://kubernetes.io/docs/reference/using-api/cel/</p>\n</td>\n</tr>\n<tr><td><code>message</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>message customizes the returned error message when rule returns false.\nmessage is a literal string.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration."
        },
        {
          "term": "UserValidationRule",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration object for user info validation rules."
        },
        {
          "term": "UserInfo",
          "tier": 1,
          "reasoning": "Named Kubernetes API object (authentication.k8s.io/v1, Kind=UserInfo) containing user information."
        },
        {
          "term": "CEL",
          "tier": 2,
          "reasoning": "Common Expression Language - a domain-specific expression language used for validation in Kubernetes."
        },
        {
          "term": "expression",
          "tier": 2,
          "reasoning": "Technical field name representing the CEL expression to be evaluated for validation."
        },
        {
          "term": "validation",
          "tier": 2,
          "reasoning": "Domain concept referring to the process of verifying user information meets specified rules."
        },
        {
          "term": "CEL variable",
          "tier": 2,
          "reasoning": "Technical concept referring to variables accessible within CEL expressions."
        },
        {
          "term": "CEL expressions",
          "tier": 2,
          "reasoning": "Technical term for expressions written in Common Expression Language for evaluation."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Core security concept for verifying user identity in Kubernetes."
        },
        {
          "term": "authentication.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for authentication-related resources."
        },
        {
          "term": "user",
          "tier": 2,
          "reasoning": "CEL variable name providing access to UserInfo object in validation expressions."
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Technical field name for customizing error messages when validation fails."
        },
        {
          "term": "error message",
          "tier": 3,
          "reasoning": "Technical term for the message returned when validation rule returns false."
        },
        {
          "term": "literal string",
          "tier": 3,
          "reasoning": "Technical term describing the type of value the message field accepts."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - referenced in context of Kubernetes API documentation."
        },
        {
          "term": "kubernetes-api",
          "tier": 2,
          "reasoning": "Referenced as part of documentation URL for Kubernetes API specifications."
        },
        {
          "term": "v1.28",
          "tier": 2,
          "reasoning": "Specific Kubernetes version referenced for API definitions."
        },
        {
          "term": "release-1.28",
          "tier": 2,
          "reasoning": "Specific Kubernetes release version referenced for source code."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the expression and message fields."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term referring to configuration fields in the API object specification."
        },
        {
          "term": "rule",
          "tier": 2,
          "reasoning": "Domain concept referring to a single validation condition to be evaluated."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical term for the settings and parameters of the validation rule."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API group reference for API server configuration objects."
        }
      ],
      "term_count": 23,
      "generated_at": "2026-02-08T21:53:19.982247",
      "elapsed_time": 15.091115951538086
    },
    {
      "chunk_id": "reference_access-authn-authz_validating-admission-policy_sec0",
      "doc_id": "reference_access-authn-authz_validating-admission-policy",
      "heading": "Introduction",
      "source_file": "reference_access-authn-authz_validating-admission-policy.md",
      "content": "---\nreviewers:\n- liggitt\n- jpbetz\n- cici37\ntitle: Validating Admission Policy\ncontent_type: concept\n---\n\n<!-- overview -->\n\n{{< feature-state state=\"stable\" for_k8s_version=\"v1.30\" >}}\n\nThis page provides an overview of Validating Admission Policy.\n\n\n<!-- body -->",
      "terms": [
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource and the primary subject of this documentation page."
        },
        {
          "term": "Admission Policy",
          "tier": 2,
          "reasoning": "Domain concept referring to policies that control admission of resources to the cluster."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating the feature has reached production-ready status in Kubernetes."
        },
        {
          "term": "v1.30",
          "tier": 3,
          "reasoning": "Specific Kubernetes version identifier indicating when the feature became stable."
        },
        {
          "term": "feature-state",
          "tier": 3,
          "reasoning": "Kubernetes documentation concept indicating the maturity level of a feature."
        }
      ],
      "term_count": 5,
      "generated_at": "2026-02-08T21:53:25.410278",
      "elapsed_time": 4.42641282081604
    },
    {
      "chunk_id": "concepts_workloads_management_sec0",
      "doc_id": "concepts_workloads_management",
      "heading": "Introduction",
      "source_file": "concepts_workloads_management.md",
      "content": "---\ntitle: Managing Workloads\ncontent_type: concept\nreviewers:\n- janetkuo\nweight: 40\n---\n\n<!-- overview -->\n\nYou've deployed your application and exposed it via a Service. Now what? Kubernetes provides a\nnumber of tools to help you manage your application deployment, including scaling and updating.\n\n<!-- body -->",
      "terms": [
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to applications running on the cluster, appears in title."
        },
        {
          "term": "application",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context referring to deployed software workloads."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource for exposing applications, capitalized indicating the K8s resource type."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary platform/system being documented, proper noun."
        },
        {
          "term": "application deployment",
          "tier": 2,
          "reasoning": "Domain concept describing the process of deploying applications to Kubernetes."
        },
        {
          "term": "scaling",
          "tier": 2,
          "reasoning": "Core Kubernetes operational concept for adjusting application capacity."
        },
        {
          "term": "updating",
          "tier": 2,
          "reasoning": "Technical process in Kubernetes for modifying deployed applications."
        },
        {
          "term": "deployed",
          "tier": 2,
          "reasoning": "Technical term describing the state of an application running in Kubernetes."
        },
        {
          "term": "exposed",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context meaning making a service accessible via networking."
        },
        {
          "term": "Managing Workloads",
          "tier": 2,
          "reasoning": "Compound concept representing the operational practice of administering Kubernetes workloads."
        }
      ],
      "term_count": 10,
      "generated_at": "2026-02-08T21:53:33.539238",
      "elapsed_time": 7.126946926116943
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "How apply calculates differences and merges changes",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "{{< caution >}}\nA *patch* is an update operation that is scoped to specific fields of an object\ninstead of the entire object. This enables updating only a specific set of fields\non an object without reading the object first.\n{{< /caution >}}\n\nWhen `kubectl apply` updates the live configuration for an object,\nit does so by sending a patch request to the API server. The\npatch defines updates scoped to specific fields of the live object\nconfiguration. The `kubectl apply` command calculates this patch request\nusing the configuration file, the live configuration, and the\n`last-applied-configuration` annotation stored in the live configuration.\n\n### Merge patch calculation\n\nThe `kubectl apply` command writes the contents of the configuration file to the\n`kubectl.kubernetes.io/last-applied-configuration` annotation. This\nis used to identify fields that have been removed from the configuration\nfile and need to be cleared from the live configuration. Here are the steps used\nto calculate which fields should be deleted or set:\n\n1. Calculate the fields to delete. These are the fields present in\n   `last-applied-configuration` and missing from the configuration file.\n2. Calculate the fields to add or set. These are the fields present in\n   the configuration file whose values don't match the live configuration.\n\nHere's an example. Suppose this is the configuration file for a Deployment object:\n\n{{% code_sample file=\"application/update_deployment.yaml\" %}}\n\nAlso, suppose this is the live configuration for the same Deployment object:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # note that the annotation does not contain replicas\n    # because it was not updated through apply\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"minReadySeconds\":5,\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.14.2\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n  # ...\nspec:\n  replicas: 2 # written by scale\n  # ...\n  minReadySeconds: 5\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n      # ...\n```\n\nHere are the merge calculations that would be performed by `kubectl apply`:\n\n1. Calculate the fields to delete by reading values from\n   `last-applied-configuration` and comparing them to values in the\n   configuration file.\n   Clear fields explicitly set to null in the local object configuration file\n   regardless of whether they appear in the `last-applied-configuration`.\n   In this example, `minReadySeconds` appears in the\n   `last-applied-configuration` annotation, but does not appear in the configuration file.\n   **Action:** Clear `minReadySeconds` from the live configuration.\n2. Calculate the fields to set by reading values from the configuration\n   file and comparing them to values in the live configuration. In this example,\n   the value of `image` in the configuration file does not match\n   the value in the live configuration. **Action:** Set the value of `image` in the live configuration.\n3. Set the `last-applied-configuration` annotation to match the value\n   of the configuration file.\n4. Merge the results from 1, 2, 3 into a single patch request to the API server.\n\nHere is the live configuration that is the result of the merge:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    # ...\n    # The annotation contains the updated image to nginx 1.16.1,\n    # but does not contain the updated replicas to 2\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\n      \"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"default\"},\n      \"spec\":{\"selector\":{\"matchLabels\":{\"app\":nginx}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"nginx\"}},\n      \"spec\":{\"containers\":[{\"image\":\"nginx:1.16.1\",\"name\":\"nginx\",\n      \"ports\":[{\"containerPort\":80}]}]}}}}\n    # ...\nspec:\n  selector:\n    matchLabels:\n      # ...\n      app: nginx\n  replicas: 2 # Set by `kubectl scale`.  Ignored by `kubectl apply`.\n  # minReadySeconds cleared by `kubectl apply`\n  # ...\n  template:\n    metadata:\n      # ...\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.16.1 # Set by `kubectl apply`\n        # ...\n        name: nginx\n        ports:\n        - containerPort: 80\n        # ...\n      # ...\n    # ...\n  # ...\n```\n\n### How different types of fields are merged\n\nHow a particular field in a configuration file is merged with\nthe live configuration depends on the\ntype of the field. There are several types of fields:\n\n- *primitive*: A field of type string, integer, or boolean.\n  For example, `image` and `replicas` are primitive fields. **Action:** Replace.\n\n- *map*, also called *object*: A field of type map or a complex type that contains subfields. For example, `labels`,\n  `annotations`,`spec` and `metadata` are all maps. **Action:** Merge elements or subfields.\n\n- *list*: A field containing a list of items that can be either primitive types or maps.\n  For example, `containers`, `ports`, and `args` are lists. **Action:** Varies.\n\nWhen `kubectl apply` updates a map or list field, it typically does\nnot replace the entire field, but instead updates the individual subelements.\nFor instance, when merging the `spec` on a Deployment, the entire `spec` is\nnot replaced. Instead the subfields of `spec`, such as `replicas`, are compared\nand merged.\n\n### Merging changes to primitive fields\n\nPrimitive fields are replaced or cleared.\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Field in object configuration file  | Field in live object configuration | Field in last-applied-configuration | Action                                    |\n|-------------------------------------|------------------------------------|-------------------------------------|-------------------------------------------|\n| Yes                                 | Yes                                | -                                   | Set live to configuration file value.  |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.           |\n| No                                  | -                                  | Yes                                 | Clear from live configuration.            |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.             |\n\n### Merging changes to map fields\n\nFields that represent maps are merged by comparing each of the subfields or elements of the map:\n\n{{< note >}}\n`-` is used for \"not applicable\" because the value is not used.\n{{< /note >}}\n\n| Key in object configuration file    | Key in live object configuration   | Field in last-applied-configuration | Action                           |\n|-------------------------------------|------------------------------------|-------------------------------------|----------------------------------|\n| Yes                                 | Yes                                | -                                   | Compare sub fields values.        |\n| Yes                                 | No                                 | -                                   | Set live to local configuration.  |\n| No                                  | -                                  | Yes                                 | Delete from live configuration.   |\n| No                                  | -                                  | No                                  | Do nothing. Keep live value.     |\n\n### Merging changes for fields of type list\n\nMerging changes to a list uses one of three strategies:\n\n* Replace the list if all its elements are primitives.\n* Merge individual elements in a list of complex elements.\n* Merge a list of primitive elements.\n\nThe choice of strategy is made on a per-field basis.\n\n#### Replace the list if all its elements are primitives\n\nTreat the list the same as a primitive field. Replace or delete the\nentire list. This preserves ordering.\n\n**Example:** Use `kubectl apply` to update the `args` field of a Container in a Pod. This sets\nthe value of `args` in the live configuration to the value in the configuration file.\nAny `args` elements that had previously been added to the live configuration are lost.\nThe order of the `args` elements defined in the configuration file is\nretained in the live configuration.\n\n```yaml",
      "terms": [
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Core technical concept describing an update operation scoped to specific fields of an object"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes API objects that can be created and managed"
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for declarative configuration management"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters"
        },
        {
          "term": "live configuration",
          "tier": 2,
          "reasoning": "Domain concept referring to the current state of an object in the cluster"
        },
        {
          "term": "patch request",
          "tier": 2,
          "reasoning": "Technical process describing the API request type sent to update objects"
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes component that exposes the Kubernetes API"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Domain concept for the declarative specification file used with kubectl apply"
        },
        {
          "term": "last-applied-configuration",
          "tier": 1,
          "reasoning": "Specific annotation name used to track previous configuration state"
        },
        {
          "term": "kubectl.kubernetes.io/last-applied-configuration",
          "tier": 1,
          "reasoning": "Full annotation key used by kubectl apply to store configuration history"
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching arbitrary non-identifying metadata to objects"
        },
        {
          "term": "Merge patch calculation",
          "tier": 2,
          "reasoning": "Specific technical process for calculating differences between configurations"
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing stateless applications"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the object"
        },
        {
          "term": "apps/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for apps resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the type of resource"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes object section containing identifying information"
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata field for non-identifying key-value pairs"
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Kubernetes metadata field for the unique identifier within a namespace"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for logical partitioning of cluster resources"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "The default Kubernetes namespace used when none is specified"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes object section defining the desired state"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment spec field controlling the number of pod instances"
        },
        {
          "term": "minReadySeconds",
          "tier": 2,
          "reasoning": "Deployment spec field for minimum seconds a pod must be ready"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for selecting pods based on labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Selector field for exact label matching"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within a Deployment"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for identifying and selecting objects"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod spec field listing container specifications"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container spec field specifying the container image to run"
        },
        {
          "term": "nginx:1.14.2",
          "tier": 3,
          "reasoning": "Specific container image version used in the example"
        },
        {
          "term": "nginx:1.16.1",
          "tier": 3,
          "reasoning": "Updated container image version shown in the merge result"
        },
        {
          "term": "nginx",
          "tier": 3,
          "reasoning": "Container name and application used in the example"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Container spec field for exposing container ports"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Port specification field for container network ports"
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes operation for adjusting replica count"
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific Deployment resource name used in the example"
        },
        {
          "term": "app",
          "tier": 2,
          "reasoning": "Common label key used for application identification"
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term for specific properties within Kubernetes objects"
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T21:53:54.876026",
      "elapsed_time": 20.334879875183105
    },
    {
      "chunk_id": "tasks_administer-cluster_topology-manager_sec3",
      "doc_id": "tasks_administer-cluster_topology-manager",
      "heading": "Topology manager scopes and policies",
      "source_file": "tasks_administer-cluster_topology-manager.md",
      "content": "The Topology Manager currently:\n\n- aligns Pods of all QoS classes.\n- aligns the requested resources that Hint Provider provides topology hints for.\n\nIf these conditions are met, the Topology Manager will align the requested resources.\n\nIn order to customize how this alignment is carried out, the Topology Manager provides two\ndistinct options: `scope` and `policy`.\n\nThe `scope` defines the granularity at which you would like resource alignment to be performed,\nfor example, at the `pod` or `container` level. And the `policy` defines the actual policy used to\ncarry out the alignment, for example, `best-effort`, `restricted`, and `single-numa-node`.\nDetails on the various `scopes` and `policies` available today can be found below.\n\n{{< note >}}\nTo align CPU resources with other requested resources in a Pod spec, the CPU Manager should be\nenabled and proper CPU Manager policy should be configured on a Node.\nSee [Control CPU Management Policies on the Node](/docs/tasks/administer-cluster/cpu-management-policies/).\n{{< /note >}}\n\n{{< note >}}\nTo align memory (and hugepages) resources with other requested resources in a Pod spec, the Memory\nManager should be enabled and proper Memory Manager policy should be configured on a Node. Refer to\n[Memory Manager](/docs/tasks/administer-cluster/memory-manager/) documentation.\n{{< /note >}}",
      "terms": [
        {
          "term": "Topology Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for resource alignment across NUMA nodes."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object and workload unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the fundamental Kubernetes workload unit, referenced in 'pod' scope."
        },
        {
          "term": "QoS classes",
          "tier": 2,
          "reasoning": "Quality of Service classification system for Pods in Kubernetes."
        },
        {
          "term": "Hint Provider",
          "tier": 1,
          "reasoning": "Named component that provides topology hints for resource alignment."
        },
        {
          "term": "topology hints",
          "tier": 2,
          "reasoning": "Domain concept describing hints used for NUMA-aware resource placement."
        },
        {
          "term": "scope",
          "tier": 2,
          "reasoning": "Configuration option defining granularity of resource alignment in Topology Manager."
        },
        {
          "term": "policy",
          "tier": 2,
          "reasoning": "Configuration option defining the alignment strategy used by Topology Manager."
        },
        {
          "term": "resource alignment",
          "tier": 2,
          "reasoning": "Technical process of aligning resources across topology domains."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing the unit of compute within a Pod."
        },
        {
          "term": "best-effort",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for resource alignment."
        },
        {
          "term": "restricted",
          "tier": 2,
          "reasoning": "Named Topology Manager policy option for stricter resource alignment."
        },
        {
          "term": "single-numa-node",
          "tier": 2,
          "reasoning": "Named Topology Manager policy requiring all resources on a single NUMA node."
        },
        {
          "term": "CPU resources",
          "tier": 2,
          "reasoning": "Technical term for compute resources managed by CPU Manager."
        },
        {
          "term": "CPU Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for CPU resource management on nodes."
        },
        {
          "term": "CPU Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for CPU Manager behavior."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "CPU Management Policies",
          "tier": 2,
          "reasoning": "Domain concept for policies controlling CPU allocation on nodes."
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "System resource type managed by Memory Manager."
        },
        {
          "term": "hugepages",
          "tier": 2,
          "reasoning": "Linux memory feature for large memory pages, managed by Memory Manager."
        },
        {
          "term": "Memory Manager",
          "tier": 1,
          "reasoning": "Core Kubernetes component for memory resource management on nodes."
        },
        {
          "term": "Memory Manager policy",
          "tier": 2,
          "reasoning": "Configuration policy for Memory Manager behavior."
        },
        {
          "term": "Pod spec",
          "tier": 2,
          "reasoning": "Technical term for the specification section of a Pod definition."
        },
        {
          "term": "requested resources",
          "tier": 2,
          "reasoning": "Domain concept for resources explicitly requested in Pod specifications."
        },
        {
          "term": "scopes",
          "tier": 2,
          "reasoning": "Plural form referring to available Topology Manager scope options."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Plural form referring to available Topology Manager policy options."
        },
        {
          "term": "Control CPU Management Policies on the Node",
          "tier": 2,
          "reasoning": "Referenced documentation topic for CPU management configuration."
        },
        {
          "term": "administer-cluster",
          "tier": 3,
          "reasoning": "Documentation path segment indicating cluster administration tasks."
        }
      ],
      "term_count": 28,
      "generated_at": "2026-02-08T21:54:09.885159",
      "elapsed_time": 14.007121801376343
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec1",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Terminology",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "For clarity, this guide defines the following terms:\n\n* Node: A worker machine in Kubernetes, part of a cluster.\n* Cluster: A set of Nodes that run containerized applications managed by Kubernetes.\n  For this example, and in most common Kubernetes deployments, nodes in the cluster\n  are not part of the public internet.\n* Edge router: A router that enforces the firewall policy for your cluster. This\n  could be a gateway managed by a cloud provider or a physical piece of hardware.\n* Cluster network: A set of links, logical or physical, that facilitate communication\n  within a cluster according to the Kubernetes [networking model](/docs/concepts/cluster-administration/networking/).\n* Service: A Kubernetes {{< glossary_tooltip term_id=\"service\" >}} that identifies\n  a set of Pods using {{< glossary_tooltip text=\"label\" term_id=\"label\" >}} selectors.\n  Unless mentioned otherwise, Services are assumed to have virtual IPs only routable within the cluster network.",
      "terms": [
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Core Kubernetes resource representing a worker machine in the cluster."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "containerized applications",
          "tier": 2,
          "reasoning": "Domain concept describing applications packaged in containers."
        },
        {
          "term": "Edge router",
          "tier": 2,
          "reasoning": "Network infrastructure component that enforces firewall policy at cluster boundary."
        },
        {
          "term": "router",
          "tier": 3,
          "reasoning": "General networking term with specific meaning in cluster context."
        },
        {
          "term": "firewall policy",
          "tier": 2,
          "reasoning": "Security concept governing network traffic rules for the cluster."
        },
        {
          "term": "gateway",
          "tier": 2,
          "reasoning": "Network component that can serve as edge router in cloud deployments."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Infrastructure concept referring to managed cloud services hosting Kubernetes."
        },
        {
          "term": "Cluster network",
          "tier": 2,
          "reasoning": "Kubernetes networking concept describing internal cluster communication infrastructure."
        },
        {
          "term": "networking model",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept defining how network communication works."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that identifies and exposes a set of Pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing the smallest deployable unit."
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes concept for key-value pairs used to organize and select resources."
        },
        {
          "term": "virtual IPs",
          "tier": 2,
          "reasoning": "Networking concept for IP addresses assigned to Services for internal routing."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Infrastructure term describing the compute resources that run workloads."
        },
        {
          "term": "public internet",
          "tier": 3,
          "reasoning": "Networking context term distinguishing external from internal cluster access."
        },
        {
          "term": "hardware",
          "tier": 3,
          "reasoning": "Infrastructure term referring to physical networking equipment."
        },
        {
          "term": "links",
          "tier": 3,
          "reasoning": "Networking term describing connections within cluster network."
        },
        {
          "term": "communication",
          "tier": 3,
          "reasoning": "Technical term describing data exchange within the cluster network context."
        },
        {
          "term": "routable",
          "tier": 3,
          "reasoning": "Networking term describing whether traffic can reach a destination."
        },
        {
          "term": "selectors",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching resources based on criteria."
        },
        {
          "term": "nodes",
          "tier": 1,
          "reasoning": "Plural form of Node, core Kubernetes worker machine resource."
        },
        {
          "term": "cluster network",
          "tier": 2,
          "reasoning": "Lowercase variant appearing in context of Service routing scope."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:54:23.729709",
      "elapsed_time": 12.8415048122406
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec19",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "You might already have removed the next set",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "kubectl delete configmaps/special-config configmaps/env-config\nkubectl delete configmap -l 'game-config in (config-4,config-5)'\n```\n\nRemove the `kustomization.yaml` file that you used to generate the ConfigMap:\n\n```bash\nrm kustomization.yaml\n```\n\nIf you created a directory `configure-pod-container` and no longer need it, you should remove that too,\nor move it into the trash can / deleted files location.\n\n```bash\nrm -r configure-pod-container\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used for cluster management and resource operations."
        },
        {
          "term": "configmaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing non-confidential configuration data as key-value pairs."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API resource referenced in the context of generation and deletion."
        },
        {
          "term": "special-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "env-config",
          "tier": 1,
          "reasoning": "Named ConfigMap resource being deleted in the example command."
        },
        {
          "term": "game-config",
          "tier": 1,
          "reasoning": "Named label value used for ConfigMap selection in the delete command."
        },
        {
          "term": "config-4",
          "tier": 1,
          "reasoning": "Specific ConfigMap configuration name used in label selector."
        },
        {
          "term": "config-5",
          "tier": 1,
          "reasoning": "Specific ConfigMap configuration name used in label selector."
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Kustomize configuration file used to generate Kubernetes resources including ConfigMaps."
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation/command for removing resources from the cluster."
        },
        {
          "term": "configure-pod-container",
          "tier": 2,
          "reasoning": "Directory name related to pod and container configuration documentation/examples."
        },
        {
          "term": "-l",
          "tier": 3,
          "reasoning": "kubectl flag for label selector, used to filter resources by labels."
        },
        {
          "term": "rm",
          "tier": 3,
          "reasoning": "Unix/Linux command for removing files, used in cleanup operations."
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Shell environment indicated for executing the cleanup commands."
        },
        {
          "term": "pod",
          "tier": 2,
          "reasoning": "Referenced in directory name 'configure-pod-container', fundamental Kubernetes workload unit."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Referenced in directory name 'configure-pod-container', core concept in Kubernetes."
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T21:54:33.771879",
      "elapsed_time": 9.039495944976807
    },
    {
      "chunk_id": "reference_node_node-status_sec6",
      "doc_id": "reference_node_node-status",
      "heading": "Declared features {#declaredfeatures}",
      "source_file": "reference_node_node-status.md",
      "content": "{{< feature-state feature_gate_name=\"NodeDeclaredFeatures\" >}}\n\nThis field lists specific Kubernetes features that are currently enabled on the\nnode's kubelet via [feature gates](/docs/reference/command-line-tools-reference/feature-gates/).\nThe features are reported by the kubelet as a list of strings in the\n`.status.declaredFeatures` field of the Node object.\n\nThis field is intended for newer features under active development; features that\nhave graduated and no longer require a feature gate are considered baseline and\nare not declared in this field. This reflects the enablement of Kubernetes\nfeatures, not the underlying operating system or kernel capabilities of the node.\n\nSee [Node Declared Features](/docs/concepts/scheduling-eviction/node-declared-features/)\nfor more details.",
      "terms": [
        {
          "term": "NodeDeclaredFeatures",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature gate name that controls node feature declaration functionality."
        },
        {
          "term": "feature_gate_name",
          "tier": 2,
          "reasoning": "Technical parameter reference for specifying feature gate identifiers in Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform this documentation describes."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine in the cluster."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages pod lifecycle."
        },
        {
          "term": "feature gates",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": "features",
          "tier": 2,
          "reasoning": "Technical term referring to specific Kubernetes capabilities that can be enabled or disabled."
        },
        {
          "term": ".status.declaredFeatures",
          "tier": 1,
          "reasoning": "Specific API field path in the Node object where declared features are reported."
        },
        {
          "term": "Node object",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a node resource in the cluster."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type used to represent the feature list in the API field."
        },
        {
          "term": "field",
          "tier": 3,
          "reasoning": "Technical term for a property within a Kubernetes API object structure."
        },
        {
          "term": "graduated",
          "tier": 2,
          "reasoning": "Kubernetes feature lifecycle term indicating a feature has moved to stable/GA status."
        },
        {
          "term": "baseline",
          "tier": 2,
          "reasoning": "Technical term describing features that are standard and no longer require explicit enablement."
        },
        {
          "term": "operating system",
          "tier": 3,
          "reasoning": "System software concept distinguished from Kubernetes feature enablement."
        },
        {
          "term": "kernel",
          "tier": 3,
          "reasoning": "Core OS component whose capabilities are distinguished from Kubernetes features."
        },
        {
          "term": "Node Declared Features",
          "tier": 1,
          "reasoning": "Named Kubernetes concept/feature for reporting enabled features on nodes."
        },
        {
          "term": "scheduling-eviction",
          "tier": 2,
          "reasoning": "Kubernetes documentation category related to pod scheduling and eviction processes."
        },
        {
          "term": "enablement",
          "tier": 2,
          "reasoning": "Technical process term describing the activation state of Kubernetes features."
        },
        {
          "term": "capabilities",
          "tier": 2,
          "reasoning": "Technical term for functional abilities of a system or component."
        },
        {
          "term": "active development",
          "tier": 2,
          "reasoning": "Feature lifecycle term indicating features still being developed and refined."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T21:54:46.556410",
      "elapsed_time": 11.781420946121216
    },
    {
      "chunk_id": "concepts_policy__index_sec3",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using ValidatingAdmissionPolicy",
      "source_file": "concepts_policy__index.md",
      "content": "Validating admission policies allow configurable validation checks to be executed in the API server using the Common Expression Language (CEL). For example, a `ValidatingAdmissionPolicy` can be used to disallow use of the `latest` image tag.\n\nA `ValidatingAdmissionPolicy` operates on an API request and can be used to block, audit, and warn users about non-compliant configurations.\n\nDetails on the `ValidatingAdmissionPolicy` API, with examples, are documented in a dedicated section:\n* [Validating Admission Policy](/docs/reference/access-authn-authz/validating-admission-policy/)",
      "terms": [
        {
          "term": "ValidatingAdmissionPolicy",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for configurable validation checks in the API server."
        },
        {
          "term": "Validating admission policies",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for admission control validation."
        },
        {
          "term": "Validating Admission Policy",
          "tier": 1,
          "reasoning": "Proper noun reference to the Kubernetes API resource as it appears in documentation link."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that processes API requests."
        },
        {
          "term": "Common Expression Language",
          "tier": 2,
          "reasoning": "Domain-specific language used for writing validation expressions in Kubernetes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Acronym for Common Expression Language, a technical standard used in validation policies."
        },
        {
          "term": "API request",
          "tier": 2,
          "reasoning": "Technical concept referring to requests made to the Kubernetes API server."
        },
        {
          "term": "validation checks",
          "tier": 2,
          "reasoning": "Domain concept describing the verification process performed by admission policies."
        },
        {
          "term": "configurable validation",
          "tier": 2,
          "reasoning": "Technical concept describing customizable validation behavior."
        },
        {
          "term": "image tag",
          "tier": 2,
          "reasoning": "Container domain concept referring to version identifiers for container images."
        },
        {
          "term": "latest",
          "tier": 2,
          "reasoning": "Specific image tag value with special meaning in container ecosystems, used as example of what to disallow."
        },
        {
          "term": "block",
          "tier": 2,
          "reasoning": "Admission control action that prevents non-compliant configurations."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Admission control action for logging policy violations without blocking."
        },
        {
          "term": "warn",
          "tier": 2,
          "reasoning": "Admission control action that alerts users about non-compliant configurations."
        },
        {
          "term": "non-compliant configurations",
          "tier": 2,
          "reasoning": "Domain concept describing configurations that violate defined policies."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for Application Programming Interface, contextually relevant to Kubernetes."
        },
        {
          "term": "admission",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to the admission control phase of API request processing."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:54:59.104958",
      "elapsed_time": 11.545385837554932
    },
    {
      "chunk_id": "concepts_policy__index_sec1",
      "doc_id": "concepts_policy__index",
      "heading": "Apply policies using API objects",
      "source_file": "concepts_policy__index.md",
      "content": "Some API objects act as policies. Here are some examples:\n* [NetworkPolicies](/docs/concepts/services-networking/network-policies/) can be used to restrict ingress and egress traffic for a workload.\n* [LimitRanges](/docs/concepts/policy/limit-range/) manage resource allocation constraints across different object kinds.\n* [ResourceQuotas](/docs/concepts/policy/resource-quotas/) limit resource consumption for a {{< glossary_tooltip text=\"namespace\" term_id=\"namespace\" >}}.",
      "terms": [
        {
          "term": "API objects",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the persistent entities in the system that represent cluster state."
        },
        {
          "term": "policies",
          "tier": 2,
          "reasoning": "Domain concept describing API objects that enforce rules and constraints on cluster behavior."
        },
        {
          "term": "NetworkPolicies",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource that controls network traffic flow for workloads."
        },
        {
          "term": "ingress",
          "tier": 2,
          "reasoning": "Networking concept referring to incoming traffic to a workload or cluster."
        },
        {
          "term": "egress",
          "tier": 2,
          "reasoning": "Networking concept referring to outgoing traffic from a workload or cluster."
        },
        {
          "term": "traffic",
          "tier": 3,
          "reasoning": "Technical networking term describing data flow in the context of network policies."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running on the cluster."
        },
        {
          "term": "LimitRanges",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource that manages resource allocation constraints."
        },
        {
          "term": "resource allocation",
          "tier": 2,
          "reasoning": "Domain concept describing how compute resources are distributed to objects."
        },
        {
          "term": "constraints",
          "tier": 2,
          "reasoning": "Technical term describing limitations or rules applied to resource usage."
        },
        {
          "term": "object kinds",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the types/categories of API objects."
        },
        {
          "term": "ResourceQuotas",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource that limits resource consumption per namespace."
        },
        {
          "term": "resource consumption",
          "tier": 2,
          "reasoning": "Domain concept describing the usage of compute resources by workloads."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for logical partitioning and isolation of cluster resources."
        },
        {
          "term": "ingress and egress traffic",
          "tier": 2,
          "reasoning": "Compound networking concept describing bidirectional network flow control."
        },
        {
          "term": "restrict",
          "tier": 3,
          "reasoning": "Technical action term in the context of policy enforcement on network traffic."
        },
        {
          "term": "limit",
          "tier": 3,
          "reasoning": "Technical action term describing resource consumption boundaries."
        },
        {
          "term": "manage",
          "tier": 3,
          "reasoning": "Technical action term describing administrative control over resource allocation."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T21:55:10.283284",
      "elapsed_time": 10.175119400024414
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec7",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Types of Ingress",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "### Ingress backed by a single Service {#single-service-ingress}\n\nThere are existing Kubernetes concepts that allow you to expose a single Service\n(see [alternatives](#alternatives)). You can also do this with an Ingress by specifying a\n*default backend* with no rules.\n\n{{% code_sample file=\"service/networking/test-ingress.yaml\" %}}\n\nIf you create it using `kubectl apply -f` you should be able to view the state\nof the Ingress you added:\n\n```bash\nkubectl get ingress test-ingress\n```\n\n```\nNAME           CLASS         HOSTS   ADDRESS         PORTS   AGE\ntest-ingress   external-lb   *       203.0.113.123   80      59s\n```\n\nWhere `203.0.113.123` is the IP allocated by the Ingress controller to satisfy\nthis Ingress.\n\n{{< note >}}\nIngress controllers and load balancers may take a minute or two to allocate an IP address.\nUntil that time, you often see the address listed as `<pending>`.\n{{< /note >}}\n\n### Simple fanout\n\nA fanout configuration routes traffic from a single IP address to more than one Service,\nbased on the HTTP URI being requested. An Ingress allows you to keep the number of load balancers\ndown to a minimum. For example, a setup like:\n\n{{< figure src=\"/docs/images/ingressFanOut.svg\" alt=\"ingress-fanout-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Fan Out\" link=\"https://mermaid.live/edit#pako:eNqNUslOwzAQ_RXLvYCUhMQpUFzUUzkgcUBwbHpw4klr4diR7bCo8O8k2FFbFomLPZq3jP00O1xpDpjijWHtFt09zAuFUCUFKHey8vf6NE7QrdoYsDZumGIb4Oi6NAskNeOoZJKpCgxK4oXwrFVgRyi7nCVXWZKRPMlysv5yD6Q4Xryf1Vq_WzDPooJs9egLNDbolKTpT03JzKgh3zWEztJZ0Niu9L-qZGcdmAMfj4cxvWmreba613z9C0B-AMQD-V_AdA-A4j5QZu0SatRKJhSqhZR0wjmPrDP6CeikrutQxy-Cuy2dtq9RpaU2dJKm6fzI5Glmg0VOLio4_5dLjx27hFSC015KJ2VZHtuQvY2fuHcaE43G0MaCREOow_FV5cMxHZ5-oPX75UM5avuXhXuOI9yAaZjg_aLuBl6B3RYaKDDtSw4166QrcKE-emrXcubghgunDaY1kxYizDqnH99UhakzHYykpWD9hjS--fEJoIELqQ\" >}}\n\nIt would require an Ingress such as:\n\n{{% code_sample file=\"service/networking/simple-fanout-example.yaml\" %}}\n\nWhen you create the Ingress with `kubectl apply -f`:\n\n```shell\nkubectl describe ingress simple-fanout-example\n```\n\n```\nName:             simple-fanout-example\nNamespace:        default\nAddress:          178.91.123.132\nDefault backend:  default-http-backend:80 (10.8.2.3:8080)\nRules:\n  Host         Path  Backends\n  ----         ----  --------\n  foo.bar.com\n               /foo   service1:4200 (10.8.0.90:4200)\n               /bar   service2:8080 (10.8.0.91:8080)\nEvents:\n  Type     Reason  Age                From                     Message\n  ----     ------  ----               ----                     -------\n  Normal   ADD     22s                loadbalancer-controller  default/test\n```\n\nThe Ingress controller provisions an implementation-specific load balancer\nthat satisfies the Ingress, as long as the Services (`service1`, `service2`) exist.\nWhen it has done so, you can see the address of the load balancer at the\nAddress field.\n\n{{< note >}}\nDepending on the [Ingress controller](/docs/concepts/services-networking/ingress-controllers/)\nyou are using, you may need to create a default-http-backend\n[Service](/docs/concepts/services-networking/service/).\n{{< /note >}}\n\n### Name based virtual hosting\n\nName-based virtual hosts support routing HTTP traffic to multiple host names at the same IP address.\n\n{{< figure src=\"/docs/images/ingressNameBased.svg\" alt=\"ingress-namebase-diagram\" class=\"diagram-large\" caption=\"Figure. Ingress Name Based Virtual hosting\" link=\"https://mermaid.live/edit#pako:eNqNkl9PwyAUxb8KYS-atM1Kp05m9qSJJj4Y97jugcLtRqTQAPVPdN_dVlq3qUt8gZt7zvkBN7xjbgRgiteW1Rt0_zjLNUJcSdD-ZBn21WmcoDu9tuBcXDHN1iDQVWHnSBkmUMEU0xwsSuK5DK5l745QejFNLtMkJVmSZmT1Re9NcTz_uDXOU1QakxTMJtxUHw7ss-SQLhehQEODTsdH4l20Q-zFyc84-Y67pghv5apxHuweMuj9eS2_NiJdPhix-kMgvwQShOyYMNkJoEUYM3PuGkpUKyY1KqVSdCSEiJy35gnoqCzLvo5fpPAbOqlfI26UsXQ0Ho9nB5CnqesRGTnncPYvSqsdUvqp9KRdlI6KojjEkB0mnLgjDRONhqENBYm6oXbLV5V1y6S7-l42_LowlIN2uFm_twqOcAW2YlK0H_i9c-bYb6CCHNO2FFCyRvkc53rbWptaMA83QnpjMS2ZchBh1nizeNMcU28bGEzXkrV_pArN7Sc0rBTu\" >}}\n\nThe following Ingress tells the backing load balancer to route requests based on\nthe [Host header](https://tools.ietf.org/html/rfc7230#section-5.4).\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress.yaml\" %}}\n\nIf you create an Ingress resource without any hosts defined in the rules, then any\nweb traffic to the IP address of your Ingress controller can be matched without a name based\nvirtual host being required.\n\nFor example, the following Ingress routes traffic\nrequested for `first.bar.com` to `service1`, `second.bar.com` to `service2`,\nand any traffic whose request host header doesn't match `first.bar.com`\nand `second.bar.com` to `service3`.\n\n{{% code_sample file=\"service/networking/name-virtual-host-ingress-no-third-host.yaml\" %}}\n\n### TLS\n\nYou can secure an Ingress by specifying a {{< glossary_tooltip term_id=\"secret\" >}}\nthat contains a TLS private key and certificate. The Ingress resource only\nsupports a single TLS port, 443, and assumes TLS termination at the ingress point\n(traffic to the Service and its Pods is in plaintext).\nIf the TLS configuration section in an Ingress specifies different hosts, they are\nmultiplexed on the same port according to the hostname specified through the\nSNI TLS extension (provided the Ingress controller supports SNI). The TLS secret\nmust contain keys named `tls.crt` and `tls.key` that contain the certificate\nand private key to use for TLS. For example:\n\n```yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: testsecret-tls\n  namespace: default\ndata:\n  tls.crt: base64 encoded cert\n  tls.key: base64 encoded key\ntype: kubernetes.io/tls\n```\n\nReferencing this secret in an Ingress tells the Ingress controller to\nsecure the channel from the client to the load balancer using TLS. You need to make\nsure the TLS secret you created came from a certificate that contains a Common\nName (CN), also known as a Fully Qualified Domain Name (FQDN) for `https-example.foo.com`.\n\n{{< note >}}\nKeep in mind that TLS will not work on the default rule because the\ncertificates would have to be issued for all the possible sub-domains. Therefore,\n`hosts` in the `tls` section need to explicitly match the `host` in the `rules`\nsection.\n{{< /note >}}\n\n{{% code_sample file=\"service/networking/tls-example-ingress.yaml\" %}}\n\n{{< note >}}\nThere is a gap between TLS features supported by various ingress controllers.\nYou should refer to the documentation for the ingress controller(s) you've chosen to\nunderstand how TLS works in your environment.\n{{< /note >}}\n\n### Load balancing {#load-balancing}\n\nAn Ingress controller is bootstrapped with some load balancing policy settings\nthat it applies to all Ingress, such as the load balancing algorithm, backend\nweight scheme, and others. More advanced load balancing concepts\n(e.g. persistent sessions, dynamic weights) are not yet exposed through the\nIngress. You can instead get these features through the load balancer used for\na Service.\n\nIt's also worth noting that even though health checks are not exposed directly\nthrough the Ingress, there exist parallel concepts in Kubernetes such as\n[readiness probes](/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)\nthat allow you to achieve the same end result. Please review the controller\nspecific documentation to see how they handle health checks.",
      "terms": [
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing external access to services in a cluster."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object that exposes applications running on pods."
        },
        {
          "term": "default backend",
          "tier": 2,
          "reasoning": "Ingress configuration concept specifying where traffic goes when no rules match."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used for cluster management."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for applying configuration to resources."
        },
        {
          "term": "kubectl get ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for retrieving Ingress resources."
        },
        {
          "term": "kubectl describe ingress",
          "tier": 1,
          "reasoning": "Specific kubectl command for detailed Ingress information."
        },
        {
          "term": "Ingress controller",
          "tier": 1,
          "reasoning": "Kubernetes component that implements Ingress resources and manages load balancing."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Infrastructure component that distributes network traffic across services."
        },
        {
          "term": "IP address",
          "tier": 3,
          "reasoning": "Network addressing concept essential for Ingress routing."
        },
        {
          "term": "fanout",
          "tier": 2,
          "reasoning": "Ingress configuration pattern routing traffic from single IP to multiple services."
        },
        {
          "term": "HTTP URI",
          "tier": 3,
          "reasoning": "Protocol-specific identifier used for routing decisions in Ingress."
        },
        {
          "term": "Address",
          "tier": 2,
          "reasoning": "Ingress field showing the allocated IP for the load balancer."
        },
        {
          "term": "Name based virtual hosting",
          "tier": 2,
          "reasoning": "Ingress routing pattern supporting multiple hostnames at same IP."
        },
        {
          "term": "virtual hosting",
          "tier": 2,
          "reasoning": "Networking concept for hosting multiple domains on single IP."
        },
        {
          "term": "HTTP traffic",
          "tier": 3,
          "reasoning": "Protocol-specific network traffic that Ingress routes."
        },
        {
          "term": "host names",
          "tier": 2,
          "reasoning": "DNS names used for name-based virtual hosting routing."
        },
        {
          "term": "Namespace",
          "tier": 1,
          "reasoning": "Kubernetes resource for organizing and isolating cluster resources."
        },
        {
          "term": "default-http-backend",
          "tier": 1,
          "reasoning": "Specific Service name required by some Ingress controllers."
        },
        {
          "term": "Backends",
          "tier": 2,
          "reasoning": "Ingress concept referring to target Services for routing."
        },
        {
          "term": "Rules",
          "tier": 2,
          "reasoning": "Ingress configuration element defining routing logic."
        },
        {
          "term": "Host",
          "tier": 2,
          "reasoning": "Ingress rule field specifying hostname for routing."
        },
        {
          "term": "Path",
          "tier": 2,
          "reasoning": "Ingress rule field specifying URL path for routing."
        },
        {
          "term": "PORTS",
          "tier": 2,
          "reasoning": "Network ports exposed by the Ingress resource."
        },
        {
          "term": "CLASS",
          "tier": 2,
          "reasoning": "Ingress field specifying which controller should implement it."
        },
        {
          "term": "external-lb",
          "tier": 1,
          "reasoning": "Specific Ingress class name shown in the example."
        },
        {
          "term": "service1",
          "tier": 1,
          "reasoning": "Named Service resource in the fanout example."
        },
        {
          "term": "service2",
          "tier": 1,
          "reasoning": "Named Service resource in the fanout example."
        },
        {
          "term": "test-ingress",
          "tier": 1,
          "reasoning": "Named Ingress resource in the single-service example."
        },
        {
          "term": "simple-fanout-example",
          "tier": 1,
          "reasoning": "Named Ingress resource demonstrating fanout configuration."
        },
        {
          "term": "foo.bar.com",
          "tier": 2,
          "reasoning": "Example hostname used in Ingress routing rules."
        },
        {
          "term": "Events",
          "tier": 2,
          "reasoning": "Kubernetes resource field showing cluster events related to the resource."
        },
        {
          "term": "loadbalancer-controller",
          "tier": 1,
          "reasoning": "Component name shown in Events generating Ingress-related messages."
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "Kubernetes namespace name where resources are created."
        },
        {
          "term": "-f",
          "tier": 3,
          "reasoning": "kubectl flag for specifying file input."
        }
      ],
      "term_count": 35,
      "generated_at": "2026-02-08T21:55:30.425499",
      "elapsed_time": 19.13832187652588
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec19",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Key`     {#apiserver-config-k8s-io-v1-Key}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [AESConfiguration](#apiserver-config-k8s-io-v1-AESConfiguration)\n\n- [SecretboxConfiguration](#apiserver-config-k8s-io-v1-SecretboxConfiguration)\n\n\n<p>Key contains name and secret of the provided key for a transformer.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>name</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>name is the name of the key to be used while storing data to disk.</p>\n</td>\n</tr>\n<tr><td><code>secret</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>secret is the actual key, encoded in base64.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for AES encryption settings."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for Secretbox encryption settings."
        },
        {
          "term": "Key",
          "tier": 1,
          "reasoning": "Named API object/struct that contains name and secret for a transformer."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept referring to a component that transforms/encrypts data in Kubernetes."
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Required field identifier used for storing data to disk, carries technical meaning in this API context."
        },
        {
          "term": "secret",
          "tier": 2,
          "reasoning": "Technical term referring to the actual encryption key value, core security concept."
        },
        {
          "term": "base64",
          "tier": 3,
          "reasoning": "Encoding standard used for representing the secret key data."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the field values in the API object."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "API group and version identifier for Kubernetes API server configuration."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing a property/attribute in the API object schema."
        },
        {
          "term": "disk",
          "tier": 3,
          "reasoning": "Storage medium referenced in context of data persistence."
        },
        {
          "term": "encoded",
          "tier": 3,
          "reasoning": "Technical process term describing how the secret key is represented."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:55:39.744741",
      "elapsed_time": 8.31572151184082
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec6",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`AnonymousAuthCondition`     {#apiserver-k8s-io-v1beta1-AnonymousAuthCondition}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [AnonymousAuthConfig](#apiserver-k8s-io-v1beta1-AnonymousAuthConfig)\n\n\n<p>AnonymousAuthCondition describes the condition under which anonymous auth\nshould be enabled.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>path</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>Path for which anonymous auth is enabled.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for anonymous authentication settings."
        },
        {
          "term": "AnonymousAuthCondition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type that describes conditions for anonymous authentication."
        },
        {
          "term": "apiserver-k8s-io-v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version identifier for the apiserver configuration."
        },
        {
          "term": "anonymous auth",
          "tier": 2,
          "reasoning": "Domain concept referring to authentication mechanism allowing unauthenticated access."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Technical field specifying the URL path for which anonymous authentication applies."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term describing a configuration property in the API object schema."
        },
        {
          "term": "condition",
          "tier": 2,
          "reasoning": "Domain concept describing a state or requirement that must be met for a feature to be enabled."
        },
        {
          "term": "enabled",
          "tier": 3,
          "reasoning": "Technical state indicating a feature or configuration is active."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the path field in the API schema."
        }
      ],
      "term_count": 9,
      "generated_at": "2026-02-08T21:55:46.876831",
      "elapsed_time": 6.128656387329102
    },
    {
      "chunk_id": "tasks_administer-cluster_coredns_sec3",
      "doc_id": "tasks_administer-cluster_coredns",
      "heading": "Upgrading CoreDNS",
      "source_file": "tasks_administer-cluster_coredns.md",
      "content": "You can check the version of CoreDNS that kubeadm installs for each version of\nKubernetes in the page\n[CoreDNS version in Kubernetes](https://github.com/coredns/deployment/blob/master/kubernetes/CoreDNS-k8s_version.md).\n\nCoreDNS can be upgraded manually in case you want to only upgrade CoreDNS\nor use your own custom image.\nThere is a helpful [guideline and walkthrough](https://github.com/coredns/deployment/blob/master/kubernetes/Upgrading_CoreDNS.md)\navailable to ensure a smooth upgrade.\nMake sure the existing CoreDNS configuration (\"Corefile\") is retained when\nupgrading your cluster.\n\nIf you are upgrading your cluster using the `kubeadm` tool, `kubeadm`\ncan take care of retaining the existing CoreDNS configuration automatically.",
      "terms": [
        {
          "term": "CoreDNS",
          "tier": 1,
          "reasoning": "Core Kubernetes DNS component and proper noun, a specific infrastructure component"
        },
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster bootstrapping and management"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform this documentation describes"
        },
        {
          "term": "Corefile",
          "tier": 1,
          "reasoning": "CoreDNS-specific configuration file name, a proper noun for the configuration resource"
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Technical term referring to software versioning in the context of CoreDNS and Kubernetes releases"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process term for updating software components to newer versions"
        },
        {
          "term": "upgraded",
          "tier": 2,
          "reasoning": "Past tense form of upgrade process appearing in the text"
        },
        {
          "term": "upgrading",
          "tier": 2,
          "reasoning": "Gerund form of the upgrade process, used multiple times in context"
        },
        {
          "term": "custom image",
          "tier": 2,
          "reasoning": "Container/Kubernetes concept referring to user-defined container images"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept, fundamental to Kubernetes workloads"
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical term for system settings and parameters, specifically CoreDNS configuration"
        },
        {
          "term": "CoreDNS configuration",
          "tier": 2,
          "reasoning": "Compound term referring to the specific configuration of the CoreDNS component"
        },
        {
          "term": "CoreDNS version",
          "tier": 2,
          "reasoning": "Compound term referring to specific releases of the CoreDNS component"
        },
        {
          "term": "installs",
          "tier": 3,
          "reasoning": "Technical action term for deploying software components"
        },
        {
          "term": "manually",
          "tier": 3,
          "reasoning": "Operational term contrasting with automated processes in cluster management"
        },
        {
          "term": "tool",
          "tier": 3,
          "reasoning": "Technical term referring to CLI utilities like kubeadm"
        },
        {
          "term": "retained",
          "tier": 3,
          "reasoning": "Technical term for preserving configuration during upgrade processes"
        },
        {
          "term": "automatically",
          "tier": 3,
          "reasoning": "Operational term describing kubeadm's behavior in managing configurations"
        }
      ],
      "term_count": 19,
      "generated_at": "2026-02-08T21:55:59.593692",
      "elapsed_time": 11.71185302734375
    },
    {
      "chunk_id": "tasks_debug_debug-application_debug-statefulset_sec1",
      "doc_id": "tasks_debug_debug-application_debug-statefulset",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_debug_debug-application_debug-statefulset.md",
      "content": "* You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with your cluster.\n* You should have a StatefulSet running that you want to investigate.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes cluster",
          "tier": 1,
          "reasoning": "Core infrastructure resource - a complete Kubernetes deployment environment"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster management and communication"
        },
        {
          "term": "command-line tool",
          "tier": 2,
          "reasoning": "Technical term describing the type of interface kubectl provides"
        },
        {
          "term": "configured",
          "tier": 3,
          "reasoning": "Technical process term referring to setting up tool parameters for cluster communication"
        },
        {
          "term": "communicate",
          "tier": 3,
          "reasoning": "Technical term in context referring to API communication between kubectl and cluster"
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/workload resource for managing stateful applications"
        },
        {
          "term": "running",
          "tier": 3,
          "reasoning": "Technical state term describing an active workload in Kubernetes context"
        }
      ],
      "term_count": 9,
      "generated_at": "2026-02-08T21:56:07.693260",
      "elapsed_time": 7.0959837436676025
    },
    {
      "chunk_id": "concepts_overview_working-with-objects_annotations_sec1",
      "doc_id": "concepts_overview_working-with-objects_annotations",
      "heading": "Attaching metadata to objects",
      "source_file": "concepts_overview_working-with-objects_annotations.md",
      "content": "You can use either labels or annotations to attach metadata to Kubernetes\nobjects. Labels can be used to select objects and to find\ncollections of objects that satisfy certain conditions. In contrast, annotations\nare not used to identify and select objects. The metadata\nin an annotation can be small or large, structured or unstructured, and can\ninclude characters not permitted by labels. It is possible to use labels as \nwell as annotations in the metadata of the same object.\n\nAnnotations, like labels, are key/value maps:\n\n```json\n\"metadata\": {\n  \"annotations\": {\n    \"key1\" : \"value1\",\n    \"key2\" : \"value2\"\n  }\n}\n```\n\n{{<note>}}\nThe keys and the values in the map must be strings. In other words, you cannot use\nnumeric, boolean, list or other types for either the keys or the values.\n{{</note>}}\n\nHere are some examples of information that could be recorded in annotations:\n\n* Fields managed by a declarative configuration layer. Attaching these fields\n  as annotations distinguishes them from default values set by clients or\n  servers, and from auto-generated fields and fields set by\n  auto-sizing or auto-scaling systems.\n\n* Build, release, or image information like timestamps, release IDs, git branch,\n  PR numbers, image hashes, and registry address.\n\n* Pointers to logging, monitoring, analytics, or audit repositories.\n\n* Client library or tool information that can be used for debugging purposes:\n  for example, name, version, and build information.\n\n* User or tool/system provenance information, such as URLs of related objects\n  from other ecosystem components.\n\n* Lightweight rollout tool metadata: for example, config or checkpoints.\n\n* Phone or pager numbers of persons responsible, or directory entries that\n  specify where that information can be found, such as a team web site.\n\n* Directives from the end-user to the implementations to modify behavior or\n  engage non-standard features.\n\nInstead of using annotations, you could store this type of information in an\nexternal database or directory, but that would make it much harder to produce\nshared client libraries and tools for deployment, management, introspection,\nand the like.",
      "terms": [
        {
          "term": "labels",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for selecting and identifying objects."
        },
        {
          "term": "annotations",
          "tier": 1,
          "reasoning": "Core Kubernetes metadata mechanism for attaching non-identifying information to objects."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The primary container orchestration platform being documented."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Technical concept referring to data attached to Kubernetes objects for identification and description."
        },
        {
          "term": "objects",
          "tier": 2,
          "reasoning": "Domain concept referring to Kubernetes API resources and entities."
        },
        {
          "term": "key/value maps",
          "tier": 2,
          "reasoning": "Data structure concept describing how annotations and labels store information."
        },
        {
          "term": "keys",
          "tier": 3,
          "reasoning": "Technical term for the identifier portion of key/value pairs in metadata."
        },
        {
          "term": "values",
          "tier": 3,
          "reasoning": "Technical term for the data portion of key/value pairs in metadata."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type constraint for annotation and label keys and values."
        },
        {
          "term": "declarative configuration layer",
          "tier": 2,
          "reasoning": "Architectural concept describing configuration management approach in Kubernetes."
        },
        {
          "term": "clients",
          "tier": 2,
          "reasoning": "Technical term for applications or tools that interact with Kubernetes API."
        },
        {
          "term": "servers",
          "tier": 2,
          "reasoning": "Technical term for Kubernetes API server components that process requests."
        },
        {
          "term": "auto-generated fields",
          "tier": 2,
          "reasoning": "Domain concept for fields automatically populated by Kubernetes systems."
        },
        {
          "term": "auto-sizing",
          "tier": 2,
          "reasoning": "Technical process for automatic resource adjustment in Kubernetes."
        },
        {
          "term": "auto-scaling systems",
          "tier": 2,
          "reasoning": "Domain concept for systems that automatically scale workloads."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept used in build and release metadata context."
        },
        {
          "term": "timestamps",
          "tier": 3,
          "reasoning": "Technical metadata element for recording time information."
        },
        {
          "term": "release IDs",
          "tier": 3,
          "reasoning": "Technical metadata for identifying software releases."
        },
        {
          "term": "git branch",
          "tier": 3,
          "reasoning": "Version control concept used in build metadata."
        },
        {
          "term": "PR numbers",
          "tier": 3,
          "reasoning": "Pull request identifiers used in build metadata tracking."
        },
        {
          "term": "image hashes",
          "tier": 2,
          "reasoning": "Container image identification mechanism using cryptographic hashes."
        },
        {
          "term": "registry address",
          "tier": 2,
          "reasoning": "Container registry location information for image storage."
        },
        {
          "term": "logging",
          "tier": 2,
          "reasoning": "Observability concept for recording system events and data."
        },
        {
          "term": "monitoring",
          "tier": 2,
          "reasoning": "Observability concept for tracking system health and metrics."
        },
        {
          "term": "analytics",
          "tier": 2,
          "reasoning": "Technical concept for data analysis and insights."
        },
        {
          "term": "audit",
          "tier": 2,
          "reasoning": "Security and compliance concept for tracking system actions."
        },
        {
          "term": "repositories",
          "tier": 3,
          "reasoning": "Storage locations for code, logs, or other data."
        },
        {
          "term": "client library",
          "tier": 2,
          "reasoning": "Software development concept for API interaction libraries."
        },
        {
          "term": "debugging",
          "tier": 3,
          "reasoning": "Technical process for troubleshooting and fixing issues."
        },
        {
          "term": "provenance information",
          "tier": 2,
          "reasoning": "Technical concept for tracking origin and history of resources."
        },
        {
          "term": "ecosystem components",
          "tier": 2,
          "reasoning": "Architectural term for related tools and systems in Kubernetes ecosystem."
        },
        {
          "term": "rollout tool",
          "tier": 2,
          "reasoning": "Deployment tooling concept for managing application updates."
        },
        {
          "term": "config",
          "tier": 2,
          "reasoning": "Configuration data used in deployment and management."
        },
        {
          "term": "checkpoints",
          "tier": 2,
          "reasoning": "Technical concept for saving state during rollout processes."
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Domain concept for releasing and managing applications."
        },
        {
          "term": "management",
          "tier": 2,
          "reasoning": "Operational concept for administering Kubernetes resources."
        },
        {
          "term": "introspection",
          "tier": 2,
          "reasoning": "Technical capability for examining system state and configuration."
        },
        {
          "term": "external database",
          "tier": 3,
          "reasoning": "Alternative storage mechanism mentioned for metadata."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "Storage or organizational structure for information."
        },
        {
          "term": "shared client libraries",
          "tier": 2,
          "reasoning": "Reusable software components for Kubernetes API interaction."
        },
        {
          "term": "tools",
          "tier": 3,
          "reasoning": "Software utilities for Kubernetes operations and management."
        }
      ],
      "term_count": 41,
      "generated_at": "2026-02-08T21:56:27.995248",
      "elapsed_time": 19.2979154586792
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster_sec7",
      "doc_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster.md",
      "content": "* [Learn more about DRA](/docs/concepts/scheduling-eviction/dynamic-resource-allocation)\n* [Allocate Devices to Workloads with DRA](/docs/tasks/configure-pod-container/assign-resources/allocate-devices-dra)",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Abbreviation for Dynamic Resource Allocation, a specific Kubernetes feature/API for resource management."
        },
        {
          "term": "Dynamic Resource Allocation",
          "tier": 1,
          "reasoning": "Implied by the DRA abbreviation in the URL path, this is a core Kubernetes scheduling feature."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Domain concept appearing in the URL path 'scheduling-eviction', referring to the Kubernetes scheduling process."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Domain concept appearing in the URL path 'scheduling-eviction', referring to the process of removing pods from nodes."
        },
        {
          "term": "Devices",
          "tier": 2,
          "reasoning": "Technical term in Kubernetes context referring to hardware resources that can be allocated to workloads."
        },
        {
          "term": "Workloads",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to applications running in the cluster (Pods, Deployments, etc.)."
        },
        {
          "term": "Allocate",
          "tier": 2,
          "reasoning": "Technical process term describing the assignment of resources to workloads in Kubernetes."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to compute resources (CPU, memory, devices) that can be requested and allocated."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Implied by 'configure-pod-container' in the URL path, Pod is a core Kubernetes API object."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Appears in URL path 'configure-pod-container', fundamental Kubernetes concept for running applications."
        },
        {
          "term": "assign-resources",
          "tier": 2,
          "reasoning": "Technical process appearing in URL path describing the action of assigning resources to pods/containers."
        },
        {
          "term": "allocate-devices-dra",
          "tier": 2,
          "reasoning": "Task/process name appearing in URL describing the specific operation of allocating devices using DRA."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T21:56:39.190401",
      "elapsed_time": 10.190244674682617
    },
    {
      "chunk_id": "reference_config-api_apiserver-admission.v1_sec2",
      "doc_id": "reference_config-api_apiserver-admission.v1",
      "heading": "`AdmissionResponse`     {#admission-k8s-io-v1-AdmissionResponse}",
      "source_file": "reference_config-api_apiserver-admission.v1.md",
      "content": "**Appears in:**\n\n- [AdmissionReview](#admission-k8s-io-v1-AdmissionReview)\n\n\n<p>AdmissionResponse describes an admission response.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>uid</code> <B>[Required]</B><br/>\n<a href=\"https://pkg.go.dev/k8s.io/apimachinery/pkg/types#UID\"><code>k8s.io/apimachinery/pkg/types.UID</code></a>\n</td>\n<td>\n   <p>uid is an identifier for the individual request/response.\nThis must be copied over from the corresponding AdmissionRequest.</p>\n</td>\n</tr>\n<tr><td><code>allowed</code> <B>[Required]</B><br/>\n<code>bool</code>\n</td>\n<td>\n   <p>allowed indicates whether or not the admission request was permitted.</p>\n</td>\n</tr>\n<tr><td><code>status</code><br/>\n<a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.35/#status-v1-meta\"><code>meta/v1.Status</code></a>\n</td>\n<td>\n   <p>status is the result contains extra details into why an admission request was denied.\nThis field IS NOT consulted in any way if &quot;Allowed&quot; is &quot;true&quot;.</p>\n</td>\n</tr>\n<tr><td><code>patch</code><br/>\n<code>[]byte</code>\n</td>\n<td>\n   <p>patch is the patch body. Currently we only support &quot;JSONPatch&quot; which implements RFC 6902.</p>\n</td>\n</tr>\n<tr><td><code>patchType</code><br/>\n<a href=\"#admission-k8s-io-v1-PatchType\"><code>PatchType</code></a>\n</td>\n<td>\n   <p>patchType is the type of Patch. Currently we only allow &quot;JSONPatch&quot;.</p>\n</td>\n</tr>\n<tr><td><code>auditAnnotations</code><br/>\n<code>map[string]string</code>\n</td>\n<td>\n   <p>auditAnnotations is an unstructured key value map set by remote admission controller (e.g. error=image-blacklisted).\nMutatingAdmissionWebhook and ValidatingAdmissionWebhook admission controller will prefix the keys with\nadmission webhook name (e.g. imagepolicy.example.com/error=image-blacklisted). AuditAnnotations will be provided by\nthe admission webhook to add additional context to the audit log for this request.</p>\n</td>\n</tr>\n<tr><td><code>warnings</code><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>warnings is a list of warning messages to return to the requesting API client.\nWarning messages describe a problem the client making the API request should correct or be aware of.\nLimit warnings to 120 characters if possible.\nWarnings over 256 characters and large numbers of warnings may be truncated.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AdmissionReview",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for admission control review requests and responses."
        },
        {
          "term": "AdmissionResponse",
          "tier": 1,
          "reasoning": "Core Kubernetes API object that describes an admission response structure."
        },
        {
          "term": "AdmissionRequest",
          "tier": 1,
          "reasoning": "Core Kubernetes API object referenced as the source for copying uid field."
        },
        {
          "term": "uid",
          "tier": 2,
          "reasoning": "Technical field identifier for individual request/response tracking in admission control."
        },
        {
          "term": "UID",
          "tier": 2,
          "reasoning": "Kubernetes type from apimachinery package for unique identifiers."
        },
        {
          "term": "k8s.io/apimachinery/pkg/types.UID",
          "tier": 1,
          "reasoning": "Specific Kubernetes Go package type reference for unique identifiers."
        },
        {
          "term": "allowed",
          "tier": 2,
          "reasoning": "Technical field indicating whether an admission request was permitted."
        },
        {
          "term": "admission request",
          "tier": 2,
          "reasoning": "Domain concept describing a request to the admission control system."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Technical field containing result details for denied admission requests."
        },
        {
          "term": "meta/v1.Status",
          "tier": 1,
          "reasoning": "Kubernetes API type reference for status information in meta/v1 API group."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Technical field containing the patch body for mutating admission responses."
        },
        {
          "term": "JSONPatch",
          "tier": 2,
          "reasoning": "Specific patch format implementing RFC 6902 for JSON document modifications."
        },
        {
          "term": "RFC 6902",
          "tier": 3,
          "reasoning": "Technical standard specification for JSON Patch operations."
        },
        {
          "term": "patchType",
          "tier": 2,
          "reasoning": "Technical field specifying the type of patch being applied."
        },
        {
          "term": "PatchType",
          "tier": 1,
          "reasoning": "Kubernetes API type for specifying patch format in admission responses."
        },
        {
          "term": "auditAnnotations",
          "tier": 2,
          "reasoning": "Technical field for key-value annotations added by admission controllers for audit logging."
        },
        {
          "term": "remote admission controller",
          "tier": 2,
          "reasoning": "Domain concept describing external admission control webhooks."
        },
        {
          "term": "MutatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Core Kubernetes admission controller type that can modify resources."
        },
        {
          "term": "ValidatingAdmissionWebhook",
          "tier": 1,
          "reasoning": "Core Kubernetes admission controller type that validates resources."
        },
        {
          "term": "admission webhook",
          "tier": 2,
          "reasoning": "Domain concept for webhook-based admission control mechanisms."
        },
        {
          "term": "audit log",
          "tier": 2,
          "reasoning": "Technical concept for logging system recording admission decisions and context."
        },
        {
          "term": "warnings",
          "tier": 2,
          "reasoning": "Technical field containing warning messages returned to API clients."
        },
        {
          "term": "API client",
          "tier": 2,
          "reasoning": "Technical term for clients making requests to the Kubernetes API."
        },
        {
          "term": "admission controller",
          "tier": 2,
          "reasoning": "Domain concept for components that intercept and process admission requests."
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "Go programming language boolean type used in field definitions."
        },
        {
          "term": "[]byte",
          "tier": 3,
          "reasoning": "Go programming language byte slice type for patch body data."
        },
        {
          "term": "map[string]string",
          "tier": 3,
          "reasoning": "Go programming language map type for key-value audit annotations."
        },
        {
          "term": "[]string",
          "tier": 3,
          "reasoning": "Go programming language string slice type for warnings list."
        },
        {
          "term": "request/response",
          "tier": 2,
          "reasoning": "Technical pattern describing the admission control communication model."
        }
      ],
      "term_count": 29,
      "generated_at": "2026-02-08T21:56:56.765033",
      "elapsed_time": 16.5705885887146
    },
    {
      "chunk_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information_sec2",
      "doc_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information",
      "heading": "Store container fields",
      "source_file": "tasks_inject-data-application_downward-api-volume-expose-pod-information.md",
      "content": "The preceding exercise, you made Pod-level fields accessible using the\ndownward API.\nIn this next exercise, you are going to pass fields that are part of the Pod\ndefinition, but taken from the specific\n[container](/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container)\nrather than from the Pod overall. Here is a manifest for a Pod that again has\njust one container:\n\n{{% code_sample file=\"pods/inject/dapi-volume-resources.yaml\" %}}\n\nIn the manifest, you can see that the Pod has a\n[`downwardAPI` volume](/docs/concepts/storage/volumes/#downwardapi),\nand that the single container in that Pod mounts the volume at `/etc/podinfo`.\n\nLook at the `items` array under `downwardAPI`. Each element of the array\ndefines a file in the downward API volume.\n\nThe first element specifies that in the container named `client-container`,\nthe value of the `limits.cpu` field in the format specified by `1m` should be\npublished as a file named `cpu_limit`. The `divisor` field is optional and has the\ndefault value of `1`. A divisor of 1 means cores for `cpu` resources, or\nbytes for `memory` resources.\n\nCreate the Pod:\n\n```shell\nkubectl apply -f https://k8s.io/examples/pods/inject/dapi-volume-resources.yaml\n```\n\nGet a shell into the container that is running in your Pod:\n\n```shell\nkubectl exec -it kubernetes-downwardapi-volume-example-2 -- sh\n```\n\nIn your shell, view the `cpu_limit` file:\n\n```shell",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and workload resource explicitly discussed throughout the chunk."
        },
        {
          "term": "downward API",
          "tier": 1,
          "reasoning": "Specific Kubernetes feature for exposing Pod and container information to containers."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing the runtime unit within a Pod."
        },
        {
          "term": "Pod-level fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata and spec fields defined at the Pod scope."
        },
        {
          "term": "manifest",
          "tier": 2,
          "reasoning": "Technical term for the YAML/JSON file defining Kubernetes resources."
        },
        {
          "term": "downwardAPI volume",
          "tier": 1,
          "reasoning": "Specific Kubernetes volume type for exposing downward API data as files."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Core Kubernetes storage concept for providing data to containers."
        },
        {
          "term": "mounts",
          "tier": 2,
          "reasoning": "Technical process of attaching a volume to a container filesystem path."
        },
        {
          "term": "client-container",
          "tier": 1,
          "reasoning": "Specific named container referenced in the example manifest."
        },
        {
          "term": "limits.cpu",
          "tier": 2,
          "reasoning": "Kubernetes resource field specifying CPU resource limits for a container."
        },
        {
          "term": "divisor",
          "tier": 2,
          "reasoning": "Configuration field in downward API that controls unit formatting of resource values."
        },
        {
          "term": "cores",
          "tier": 3,
          "reasoning": "Unit of measurement for CPU resources in Kubernetes."
        },
        {
          "term": "bytes",
          "tier": 3,
          "reasoning": "Unit of measurement for memory resources in Kubernetes."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for creating or updating resources declaratively."
        },
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for executing commands inside a container."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes command-line interface tool."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface environment used to interact with containers."
        },
        {
          "term": "sh",
          "tier": 3,
          "reasoning": "Shell executable used when accessing container command line."
        },
        {
          "term": "cpu_limit",
          "tier": 2,
          "reasoning": "File name in the downward API volume containing CPU limit value."
        },
        {
          "term": "kubernetes-downwardapi-volume-example-2",
          "tier": 1,
          "reasoning": "Specific Pod name used in the example commands."
        },
        {
          "term": "dapi-volume-resources.yaml",
          "tier": 1,
          "reasoning": "Specific manifest filename referenced for the example Pod definition."
        },
        {
          "term": "/etc/podinfo",
          "tier": 2,
          "reasoning": "Mount path where the downward API volume is attached in the container."
        },
        {
          "term": "1m",
          "tier": 2,
          "reasoning": "Format specifier for CPU resource values (millicores notation)."
        },
        {
          "term": "file",
          "tier": 3,
          "reasoning": "Technical concept for how downward API data is exposed within the volume."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T21:57:12.905436",
      "elapsed_time": 15.136048793792725
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec10",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a deployment.yaml file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF > deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx\n        ports:\n        - containerPort: 80\nEOF",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource for managing replicated applications"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployment resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field that specifies the type of resource being defined"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section containing resource identification information"
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Kubernetes metadata field for resource identification"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section defining the desired state specification"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching and selecting resources based on labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector field for exact label matching"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes Deployment field specifying the number of Pod instances to run"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Kubernetes Pod template specification within a Deployment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes spec field defining container configurations within a Pod"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core virtualization concept - isolated runtime environment for applications"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image reference specifying the container runtime artifact"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container image name - popular web server/reverse proxy software"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Kubernetes container spec field for network port configuration"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes field specifying the port exposed by a container"
        },
        {
          "term": "EOF",
          "tier": 3,
          "reasoning": "Shell heredoc delimiter used in command-line operations"
        },
        {
          "term": "cat",
          "tier": 3,
          "reasoning": "Unix/Linux command used here for file creation via heredoc"
        },
        {
          "term": "deployment.yaml",
          "tier": 3,
          "reasoning": "YAML manifest filename for Kubernetes Deployment configuration"
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes manifests (implied by .yaml extension)"
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T21:57:24.855511",
      "elapsed_time": 10.94538950920105
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec8",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Arbitrary workloads and arbitrary selectors {#arbitrary-controllers-and-selectors}",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "You can skip this section if you only use PDBs with the built-in\nworkload resources (Deployment, ReplicaSet, StatefulSet and ReplicationController)\nor with {{< glossary_tooltip term_id=\"CustomResourceDefinition\" text=\"custom resources\" >}}\nthat implement a `scale` [subresource](/docs/concepts/extend-kubernetes/api-extension/custom-resources/#advanced-features-and-flexibility),\nand where the PDB selector exactly matches the selector of the Pod's owning resource.\n\nYou can use a PDB with pods controlled by another resource, by an\n\"operator\", or bare pods, but with these restrictions:\n\n- only `.spec.minAvailable` can be used, not `.spec.maxUnavailable`.\n- only an integer value can be used with `.spec.minAvailable`, not a percentage.\n\nIt is not possible to use other availability configurations,\nbecause Kubernetes cannot derive a total number of pods without a supported owning resource.\n\nYou can use a selector which selects a subset or superset of the pods belonging to a\nworkload resource. The eviction API will disallow eviction of any pod covered by multiple PDBs,\nso most users will want to avoid overlapping selectors. One reasonable use of overlapping\nPDBs is when pods are being transitioned from one PDB to another.",
      "terms": [
        {
          "term": "PDBs",
          "tier": 1,
          "reasoning": "Abbreviation for PodDisruptionBudget, a core Kubernetes API resource for managing pod availability during disruptions."
        },
        {
          "term": "PDB",
          "tier": 1,
          "reasoning": "Singular form of PodDisruptionBudget, a named Kubernetes API object."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource for managing stateless applications."
        },
        {
          "term": "ReplicaSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource that maintains a stable set of replica pods."
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload resource for managing stateful applications."
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Legacy Kubernetes workload resource for maintaining pod replicas."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Kubernetes API extension mechanism for defining custom resources."
        },
        {
          "term": "custom resources",
          "tier": 1,
          "reasoning": "User-defined Kubernetes API objects extending the platform's capabilities."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes workload unit representing one or more containers."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, the basic schedulable unit in Kubernetes."
        },
        {
          "term": "eviction API",
          "tier": 1,
          "reasoning": "Specific Kubernetes API for gracefully removing pods from nodes."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes subresource enabling scaling operations on workload resources."
        },
        {
          "term": "subresource",
          "tier": 2,
          "reasoning": "Technical concept referring to a secondary API endpoint on a Kubernetes resource."
        },
        {
          "term": "workload resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources that manage pod lifecycles."
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for matching and selecting resources based on labels."
        },
        {
          "term": "owning resource",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the parent resource that controls child objects."
        },
        {
          "term": "operator",
          "tier": 2,
          "reasoning": "Kubernetes pattern for extending cluster behavior with custom controllers."
        },
        {
          "term": "bare pods",
          "tier": 2,
          "reasoning": "Pods created directly without a controlling workload resource."
        },
        {
          "term": ".spec.minAvailable",
          "tier": 2,
          "reasoning": "PDB specification field defining minimum available pods during disruption."
        },
        {
          "term": ".spec.maxUnavailable",
          "tier": 2,
          "reasoning": "PDB specification field defining maximum unavailable pods during disruption."
        },
        {
          "term": "integer value",
          "tier": 3,
          "reasoning": "Technical constraint on PDB configuration for bare pods."
        },
        {
          "term": "percentage",
          "tier": 3,
          "reasoning": "Alternative value type for PDB configuration not available for bare pods."
        },
        {
          "term": "availability configurations",
          "tier": 2,
          "reasoning": "Settings controlling pod availability guarantees during disruptions."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Kubernetes process of gracefully terminating pods from nodes."
        },
        {
          "term": "overlapping selectors",
          "tier": 2,
          "reasoning": "Configuration where multiple PDBs select the same pods."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in context of Kubernetes eviction API."
        },
        {
          "term": "api-extension",
          "tier": 2,
          "reasoning": "Kubernetes concept for extending the API with custom resources."
        }
      ],
      "term_count": 27,
      "generated_at": "2026-02-08T21:57:40.524005",
      "elapsed_time": 14.663658380508423
    },
    {
      "chunk_id": "reference_node_node-status_sec3",
      "doc_id": "reference_node_node-status",
      "heading": "Conditions {#condition}",
      "source_file": "reference_node_node-status.md",
      "content": "The `conditions` field describes the status of all `Running` nodes. Examples of conditions include:\n\n{{< table caption = \"Node conditions, and a description of when each condition applies.\" >}}\n| Node Condition       | Description |\n|----------------------|-------------|\n| `Ready`              | `True` if the node is healthy and ready to accept pods, `False` if the node is not healthy and is not accepting pods, and `Unknown` if the node controller has not heard from the node in the last `node-monitor-grace-period` (default is 50 seconds) |\n| `DiskPressure`       | `True` if pressure exists on the disk size\u2014that is, if the disk capacity is low; otherwise `False` |\n| `MemoryPressure`     | `True` if pressure exists on the node memory\u2014that is, if the node memory is low; otherwise `False` |\n| `PIDPressure`        | `True` if pressure exists on the processes\u2014that is, if there are too many processes on the node; otherwise `False` |\n| `NetworkUnavailable` | `True` if the network for the node is not correctly configured, otherwise `False` |\n{{< /table >}}\n\n{{< note >}}\nIf you use command-line tools to print details of a cordoned Node, the Condition includes\n`SchedulingDisabled`. `SchedulingDisabled` is not a Condition in the Kubernetes API; instead,\ncordoned nodes are marked Unschedulable in their spec.\n{{< /note >}}\n\nIn the Kubernetes API, a node's condition is represented as part of the `.status`\nof the Node resource. For example, the following JSON structure describes a healthy node:\n\n```json\n\"conditions\": [\n  {\n    \"type\": \"Ready\",\n    \"status\": \"True\",\n    \"reason\": \"KubeletReady\",\n    \"message\": \"kubelet is posting ready status\",\n    \"lastHeartbeatTime\": \"2019-06-05T18:38:35Z\",\n    \"lastTransitionTime\": \"2019-06-05T11:41:27Z\"\n  }\n]\n```\n\nWhen problems occur on nodes, the Kubernetes control plane automatically creates\n[taints](/docs/concepts/scheduling-eviction/taint-and-toleration/) that match the conditions\naffecting the node. An example of this is when the `status` of the Ready condition\nremains `Unknown` or `False` for longer than the kube-controller-manager's `NodeMonitorGracePeriod`,\nwhich defaults to 50 seconds. This will cause either an `node.kubernetes.io/unreachable` taint, for an `Unknown` status,\nor a `node.kubernetes.io/not-ready` taint, for a `False` status, to be added to the Node.\n\nThese taints affect pending pods as the scheduler takes the Node's taints into consideration when\nassigning a pod to a Node. Existing pods scheduled to the node may be evicted due to the application\nof `NoExecute` taints. Pods may also have {{< glossary_tooltip text=\"tolerations\" term_id=\"toleration\" >}} that let\nthem schedule to and continue running on a Node even though it has a specific taint.\n\nSee [Taint Based Evictions](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-based-evictions) and\n[Taint Nodes by Condition](/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-nodes-by-condition)\nfor more details.",
      "terms": [
        {
          "term": "conditions",
          "tier": 2,
          "reasoning": "Domain concept describing the status field of node resources in Kubernetes API"
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "Node status state indicating operational nodes"
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing worker machines in a cluster"
        },
        {
          "term": "Node Condition",
          "tier": 2,
          "reasoning": "Specific Kubernetes concept for describing node health states"
        },
        {
          "term": "Ready",
          "tier": 1,
          "reasoning": "Named node condition type in Kubernetes API"
        },
        {
          "term": "DiskPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low disk capacity"
        },
        {
          "term": "MemoryPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating low node memory"
        },
        {
          "term": "PIDPressure",
          "tier": 1,
          "reasoning": "Named node condition type indicating too many processes"
        },
        {
          "term": "NetworkUnavailable",
          "tier": 1,
          "reasoning": "Named node condition type indicating network misconfiguration"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource representing deployable units"
        },
        {
          "term": "node controller",
          "tier": 1,
          "reasoning": "Kubernetes control plane component managing node lifecycle"
        },
        {
          "term": "node-monitor-grace-period",
          "tier": 1,
          "reasoning": "Specific configuration parameter for node monitoring timeout"
        },
        {
          "term": "disk capacity",
          "tier": 3,
          "reasoning": "Technical term for storage space relevant to DiskPressure condition"
        },
        {
          "term": "node memory",
          "tier": 2,
          "reasoning": "Technical concept for memory resources on a node"
        },
        {
          "term": "processes",
          "tier": 3,
          "reasoning": "OS-level concept relevant to PIDPressure condition"
        },
        {
          "term": "network",
          "tier": 3,
          "reasoning": "Infrastructure concept relevant to NetworkUnavailable condition"
        },
        {
          "term": "cordoned Node",
          "tier": 2,
          "reasoning": "Kubernetes operational concept for nodes marked to prevent new pod scheduling"
        },
        {
          "term": "SchedulingDisabled",
          "tier": 1,
          "reasoning": "Condition label shown in CLI for cordoned nodes"
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for interacting with Kubernetes resources"
        },
        {
          "term": "Unschedulable",
          "tier": 2,
          "reasoning": "Node spec field indicating scheduling is disabled"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes resource specification field"
        },
        {
          "term": ".status",
          "tier": 2,
          "reasoning": "Kubernetes resource status field path notation"
        },
        {
          "term": "Node resource",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a node"
        },
        {
          "term": "type",
          "tier": 2,
          "reasoning": "Field in condition structure specifying condition type"
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Field in condition structure indicating True/False/Unknown"
        },
        {
          "term": "reason",
          "tier": 2,
          "reasoning": "Field in condition structure providing machine-readable reason"
        },
        {
          "term": "message",
          "tier": 2,
          "reasoning": "Field in condition structure providing human-readable description"
        },
        {
          "term": "lastHeartbeatTime",
          "tier": 2,
          "reasoning": "Condition field tracking last heartbeat timestamp"
        },
        {
          "term": "lastTransitionTime",
          "tier": 2,
          "reasoning": "Condition field tracking last state change timestamp"
        },
        {
          "term": "KubeletReady",
          "tier": 1,
          "reasoning": "Specific reason value indicating kubelet is ready"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component"
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept for management components"
        },
        {
          "term": "taints",
          "tier": 2,
          "reasoning": "Kubernetes scheduling mechanism to repel pods from nodes"
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component"
        },
        {
          "term": "NodeMonitorGracePeriod",
          "tier": 1,
          "reasoning": "Specific configuration parameter for node monitoring"
        },
        {
          "term": "node.kubernetes.io/unreachable",
          "tier": 1,
          "reasoning": "Specific taint key applied to unreachable nodes"
        },
        {
          "term": "node.kubernetes.io/not-ready",
          "tier": 1,
          "reasoning": "Specific taint key applied to not-ready nodes"
        },
        {
          "term": "scheduler",
          "tier": 1,
          "reasoning": "Kubernetes control plane component for pod placement"
        },
        {
          "term": "pending pods",
          "tier": 2,
          "reasoning": "Pods waiting to be scheduled to a node"
        },
        {
          "term": "evicted",
          "tier": 2,
          "reasoning": "Process of removing pods from nodes"
        },
        {
          "term": "NoExecute",
          "tier": 1,
          "reasoning": "Specific taint effect that evicts existing pods"
        },
        {
          "term": "tolerations",
          "tier": 2,
          "reasoning": "Kubernetes mechanism allowing pods to schedule on tainted nodes"
        },
        {
          "term": "Taint Based Evictions",
          "tier": 2,
          "reasoning": "Kubernetes concept for evicting pods based on taints"
        },
        {
          "term": "Taint Nodes by Condition",
          "tier": 2,
          "reasoning": "Kubernetes feature for automatically tainting nodes based on conditions"
        },
        {
          "term": "Unknown",
          "tier": 2,
          "reasoning": "Condition status value indicating uncertain state"
        },
        {
          "term": "True",
          "tier": 3,
          "reasoning": "Condition status value indicating positive state"
        },
        {
          "term": "False",
          "tier": 3,
          "reasoning": "Condition status value indicating negative state"
        }
      ],
      "term_count": 47,
      "generated_at": "2026-02-08T21:58:01.907161",
      "elapsed_time": 20.37715244293213
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec21",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`ProviderConfiguration`     {#apiserver-config-k8s-io-v1-ProviderConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [ResourceConfiguration](#apiserver-config-k8s-io-v1-ResourceConfiguration)\n\n\n<p>ProviderConfiguration stores the provided configuration for an encryption provider.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>aesgcm</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aesgcm is the configuration for the AES-GCM transformer.</p>\n</td>\n</tr>\n<tr><td><code>aescbc</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AESConfiguration\"><code>AESConfiguration</code></a>\n</td>\n<td>\n   <p>aescbc is the configuration for the AES-CBC transformer.</p>\n</td>\n</tr>\n<tr><td><code>secretbox</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-SecretboxConfiguration\"><code>SecretboxConfiguration</code></a>\n</td>\n<td>\n   <p>secretbox is the configuration for the Secretbox based transformer.</p>\n</td>\n</tr>\n<tr><td><code>identity</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-IdentityConfiguration\"><code>IdentityConfiguration</code></a>\n</td>\n<td>\n   <p>identity is the (empty) configuration for the identity transformer.</p>\n</td>\n</tr>\n<tr><td><code>kms</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-KMSConfiguration\"><code>KMSConfiguration</code></a>\n</td>\n<td>\n   <p>kms contains the name, cache size and path to configuration file for a KMS based envelope transformer.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "ResourceConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for resource settings."
        },
        {
          "term": "ProviderConfiguration",
          "tier": 1,
          "reasoning": "Named configuration structure that stores encryption provider settings."
        },
        {
          "term": "AESConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for AES-based encryption transformers."
        },
        {
          "term": "SecretboxConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for Secretbox-based encryption transformer."
        },
        {
          "term": "IdentityConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for the identity transformer."
        },
        {
          "term": "KMSConfiguration",
          "tier": 1,
          "reasoning": "Named configuration type for KMS-based envelope transformer."
        },
        {
          "term": "encryption provider",
          "tier": 2,
          "reasoning": "Domain concept referring to a component that provides encryption capabilities."
        },
        {
          "term": "aesgcm",
          "tier": 2,
          "reasoning": "Configuration field name for AES-GCM transformer, a specific encryption mode."
        },
        {
          "term": "AES-GCM transformer",
          "tier": 2,
          "reasoning": "Encryption component using AES in Galois/Counter Mode for data transformation."
        },
        {
          "term": "aescbc",
          "tier": 2,
          "reasoning": "Configuration field name for AES-CBC transformer, a specific encryption mode."
        },
        {
          "term": "AES-CBC transformer",
          "tier": 2,
          "reasoning": "Encryption component using AES in Cipher Block Chaining mode for data transformation."
        },
        {
          "term": "secretbox",
          "tier": 2,
          "reasoning": "Configuration field for Secretbox-based encryption transformer."
        },
        {
          "term": "Secretbox based transformer",
          "tier": 2,
          "reasoning": "Encryption component using NaCl Secretbox for authenticated encryption."
        },
        {
          "term": "identity",
          "tier": 2,
          "reasoning": "Configuration field for identity transformer that performs no encryption."
        },
        {
          "term": "identity transformer",
          "tier": 2,
          "reasoning": "A transformer that passes data through unchanged without encryption."
        },
        {
          "term": "kms",
          "tier": 2,
          "reasoning": "Configuration field for Key Management Service based encryption."
        },
        {
          "term": "KMS based envelope transformer",
          "tier": 2,
          "reasoning": "Encryption component using external KMS for envelope encryption."
        },
        {
          "term": "envelope transformer",
          "tier": 2,
          "reasoning": "Encryption pattern where data encryption keys are wrapped by a master key."
        },
        {
          "term": "transformer",
          "tier": 2,
          "reasoning": "Domain concept for components that transform/encrypt data at rest."
        },
        {
          "term": "cache size",
          "tier": 3,
          "reasoning": "Technical parameter for KMS configuration affecting performance."
        },
        {
          "term": "configuration file",
          "tier": 3,
          "reasoning": "Technical term for file containing KMS transformer settings."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "API group and version identifier for Kubernetes API server configuration."
        },
        {
          "term": "AES-GCM",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Galois/Counter Mode, a cryptographic algorithm."
        },
        {
          "term": "AES-CBC",
          "tier": 3,
          "reasoning": "Advanced Encryption Standard in Cipher Block Chaining mode, a cryptographic algorithm."
        },
        {
          "term": "KMS",
          "tier": 2,
          "reasoning": "Key Management Service, external service for managing encryption keys."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T21:58:14.624220",
      "elapsed_time": 11.71132779121399
    },
    {
      "chunk_id": "reference_setup-tools_kubeadm_kubeadm-upgrade_sec1",
      "doc_id": "reference_setup-tools_kubeadm_kubeadm-upgrade",
      "heading": "kubeadm upgrade guidance",
      "source_file": "reference_setup-tools_kubeadm_kubeadm-upgrade.md",
      "content": "The steps for performing an upgrade using kubeadm are outlined in [this document](/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/).\nFor older versions of kubeadm, please refer to older documentation sets of the Kubernetes website.\n\nYou can use `kubeadm upgrade diff` to see the changes that would be applied to static pod manifests.\n\nIn Kubernetes v1.15.0 and later, `kubeadm upgrade apply` and `kubeadm upgrade node` will also\nautomatically renew the kubeadm managed certificates on this node, including those stored in kubeconfig files.\nTo opt-out, it is possible to pass the flag `--certificate-renewal=false`. For more details about certificate\nrenewal see the [certificate management documentation](/docs/tasks/administer-cluster/kubeadm/kubeadm-certs).\n\n{{< note >}}\nThe commands `kubeadm upgrade apply` and `kubeadm upgrade plan` have a legacy `--config`\nflag which makes it possible to reconfigure the cluster, while performing planning or upgrade of that particular\ncontrol-plane node. Please be aware that the upgrade workflow was not designed for this scenario and there are\nreports of unexpected results.\n{{</ note >}}",
      "terms": [
        {
          "term": "kubeadm",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI tool for cluster bootstrapping and management"
        },
        {
          "term": "kubeadm upgrade",
          "tier": 1,
          "reasoning": "Specific kubeadm subcommand for performing cluster upgrades"
        },
        {
          "term": "kubeadm upgrade diff",
          "tier": 1,
          "reasoning": "Specific kubeadm command to preview changes to static pod manifests"
        },
        {
          "term": "kubeadm upgrade apply",
          "tier": 1,
          "reasoning": "Specific kubeadm command to apply cluster upgrades"
        },
        {
          "term": "kubeadm upgrade node",
          "tier": 1,
          "reasoning": "Specific kubeadm command to upgrade a node"
        },
        {
          "term": "kubeadm upgrade plan",
          "tier": 1,
          "reasoning": "Specific kubeadm command for planning upgrades"
        },
        {
          "term": "static pod manifests",
          "tier": 2,
          "reasoning": "Domain concept referring to pod definitions managed directly by kubelet"
        },
        {
          "term": "static pod",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for pods managed directly by kubelet without API server"
        },
        {
          "term": "manifests",
          "tier": 2,
          "reasoning": "Technical term for Kubernetes resource definition files"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented"
        },
        {
          "term": "certificates",
          "tier": 2,
          "reasoning": "Security concept for TLS/PKI certificates used in cluster authentication"
        },
        {
          "term": "certificate renewal",
          "tier": 2,
          "reasoning": "Process of renewing expiring certificates in the cluster"
        },
        {
          "term": "kubeconfig files",
          "tier": 1,
          "reasoning": "Configuration files containing cluster access credentials and settings"
        },
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Core Kubernetes configuration file format for cluster access"
        },
        {
          "term": "--certificate-renewal=false",
          "tier": 1,
          "reasoning": "CLI flag to disable automatic certificate renewal"
        },
        {
          "term": "--config",
          "tier": 1,
          "reasoning": "CLI flag for specifying configuration during upgrade operations"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept referring to the set of nodes running workloads"
        },
        {
          "term": "control-plane node",
          "tier": 2,
          "reasoning": "Node running control plane components that manage the cluster"
        },
        {
          "term": "control-plane",
          "tier": 2,
          "reasoning": "Architectural component containing cluster management services"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for a worker machine in the cluster"
        },
        {
          "term": "upgrade",
          "tier": 2,
          "reasoning": "Technical process of updating Kubernetes version or components"
        },
        {
          "term": "upgrade workflow",
          "tier": 2,
          "reasoning": "The defined process and steps for performing cluster upgrades"
        },
        {
          "term": "certificate management",
          "tier": 2,
          "reasoning": "Domain concept for handling PKI certificates in the cluster"
        },
        {
          "term": "reconfigure",
          "tier": 2,
          "reasoning": "Technical operation of changing cluster configuration"
        },
        {
          "term": "v1.15.0",
          "tier": 3,
          "reasoning": "Specific Kubernetes version reference indicating feature availability"
        },
        {
          "term": "flag",
          "tier": 3,
          "reasoning": "CLI concept for command-line options passed to tools"
        }
      ],
      "term_count": 26,
      "generated_at": "2026-02-08T21:58:29.512782",
      "elapsed_time": 13.881198167800903
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec18",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "{{% heading \"cleanup\" %}}",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "Delete the ConfigMaps and Pods that you made:\n\n```bash\nkubectl delete configmaps/game-config configmaps/game-config-2 configmaps/game-config-3 \\\n               configmaps/game-config-env-file\nkubectl delete pod dapi-test-pod --now",
      "terms": [
        {
          "term": "ConfigMaps",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data as key-value pairs, explicitly named in the delete command."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit, explicitly mentioned in the section header."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used to interact with the cluster, shown executing delete commands."
        },
        {
          "term": "kubectl delete",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for removing Kubernetes resources from the cluster."
        },
        {
          "term": "configmaps/game-config",
          "tier": 1,
          "reasoning": "Specific ConfigMap resource reference using type/name notation in kubectl command."
        },
        {
          "term": "configmaps/game-config-2",
          "tier": 1,
          "reasoning": "Specific ConfigMap resource reference demonstrating multiple resource deletion."
        },
        {
          "term": "configmaps/game-config-3",
          "tier": 1,
          "reasoning": "Specific ConfigMap resource reference in the batch delete operation."
        },
        {
          "term": "configmaps/game-config-env-file",
          "tier": 1,
          "reasoning": "ConfigMap resource created from environment file, indicated by naming convention."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Kubernetes resource type specified in the delete command for dapi-test-pod."
        },
        {
          "term": "dapi-test-pod",
          "tier": 1,
          "reasoning": "Specific named Pod resource being deleted, likely used for Downward API testing based on naming."
        },
        {
          "term": "game-config",
          "tier": 2,
          "reasoning": "ConfigMap name representing a configuration resource for a game application example."
        },
        {
          "term": "game-config-2",
          "tier": 2,
          "reasoning": "Second ConfigMap variant in the tutorial example series."
        },
        {
          "term": "game-config-3",
          "tier": 2,
          "reasoning": "Third ConfigMap variant in the tutorial example series."
        },
        {
          "term": "game-config-env-file",
          "tier": 2,
          "reasoning": "ConfigMap created from an environment file, demonstrating env-file creation pattern."
        },
        {
          "term": "--now",
          "tier": 2,
          "reasoning": "kubectl flag that forces immediate deletion without waiting for graceful termination."
        },
        {
          "term": "delete",
          "tier": 2,
          "reasoning": "Kubernetes operation for removing resources from the cluster."
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Shell environment indicated for executing the kubectl commands."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T21:58:41.518149",
      "elapsed_time": 10.999773502349854
    },
    {
      "chunk_id": "reference_instrumentation_node-metrics_sec0",
      "doc_id": "reference_instrumentation_node-metrics",
      "heading": "Introduction",
      "source_file": "reference_instrumentation_node-metrics.md",
      "content": "---\ntitle: Node metrics data\ncontent_type: reference\nweight: 50\ndescription: >-\n  Mechanisms for accessing metrics at node, volume, pod and container level,\n  as seen by the kubelet.\n---\n\nThe [kubelet](/docs/reference/command-line-tools-reference/kubelet/)\ngathers metric statistics at the node, volume, pod and container level,\nand emits this information in the\n[Summary API](/docs/reference/config-api/kubelet-stats.v1alpha1/).\n\nYou can send a proxied request to the stats summary API via the\nKubernetes API server.\n\nHere is an example of a Summary API request for a node named `minikube`:\n\n```shell\nkubectl get --raw \"/api/v1/nodes/minikube/proxy/stats/summary\"\n```\n\nHere is the same API call using `curl`:\n\n```shell",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for node-level operations, explicitly referenced and linked in the documentation."
        },
        {
          "term": "Summary API",
          "tier": 1,
          "reasoning": "Specific Kubernetes API for accessing kubelet statistics, a named API endpoint."
        },
        {
          "term": "Kubernetes API server",
          "tier": 1,
          "reasoning": "Core control plane component that proxies requests to the stats summary API."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used in the example command."
        },
        {
          "term": "minikube",
          "tier": 1,
          "reasoning": "Named Kubernetes distribution/tool used as the example node name."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept representing a worker machine where pods run."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Kubernetes storage abstraction, one of the levels at which metrics are gathered."
        },
        {
          "term": "pod",
          "tier": 2,
          "reasoning": "Core Kubernetes workload unit, one of the levels at which metrics are gathered."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental unit of containerized applications, one of the levels at which metrics are gathered."
        },
        {
          "term": "metric statistics",
          "tier": 2,
          "reasoning": "Domain concept referring to the performance and resource usage data collected by kubelet."
        },
        {
          "term": "Node metrics data",
          "tier": 2,
          "reasoning": "The main topic of this documentation, referring to metrics collected at the node level."
        },
        {
          "term": "stats summary API",
          "tier": 2,
          "reasoning": "Alternative reference to the Summary API endpoint for statistics."
        },
        {
          "term": "proxied request",
          "tier": 2,
          "reasoning": "Technical concept describing how requests are forwarded through the API server."
        },
        {
          "term": "container level",
          "tier": 2,
          "reasoning": "Architectural concept indicating the granularity of metrics collection."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface, used in context of Kubernetes APIs."
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool for making HTTP requests, shown as alternative to kubectl."
        },
        {
          "term": "kubectl get",
          "tier": 2,
          "reasoning": "Specific kubectl subcommand used to retrieve resources and API data."
        },
        {
          "term": "--raw",
          "tier": 2,
          "reasoning": "kubectl flag that allows raw API requests to be made directly."
        },
        {
          "term": "proxy",
          "tier": 2,
          "reasoning": "Technical concept for forwarding requests, used in the API path structure."
        }
      ],
      "term_count": 19,
      "generated_at": "2026-02-08T21:58:54.633688",
      "elapsed_time": 12.109588146209717
    },
    {
      "chunk_id": "concepts_cluster-administration_system-logs_sec1",
      "doc_id": "concepts_cluster-administration_system-logs",
      "heading": "Klog",
      "source_file": "concepts_cluster-administration_system-logs.md",
      "content": "klog is the Kubernetes logging library. [klog](https://github.com/kubernetes/klog)\ngenerates log messages for the Kubernetes system components.\n\nKubernetes is in the process of simplifying logging in its components.\nThe following klog command line flags\n[are deprecated](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/2845-deprecate-klog-specific-flags-in-k8s-components)\nstarting with Kubernetes v1.23 and removed in Kubernetes v1.26:\n\n- `--add-dir-header`\n- `--alsologtostderr`\n- `--log-backtrace-at`\n- `--log-dir`\n- `--log-file`\n- `--log-file-max-size`\n- `--logtostderr`\n- `--one-output`\n- `--skip-headers`\n- `--skip-log-headers`\n- `--stderrthreshold`\n\nOutput will always be written to stderr, regardless of the output format. Output redirection is\nexpected to be handled by the component which invokes a Kubernetes component. This can be a POSIX\nshell or a tool like systemd.\n\nIn some cases, for example a distroless container or a Windows system service, those options are\nnot available. Then the\n[`kube-log-runner`](https://github.com/kubernetes/kubernetes/blob/d2a8a81639fcff8d1221b900f66d28361a170654/staging/src/k8s.io/component-base/logs/kube-log-runner/README.md)\nbinary can be used as wrapper around a Kubernetes component to redirect\noutput. A prebuilt binary is included in several Kubernetes base images under\nits traditional name as `/go-runner` and as `kube-log-runner` in server and\nnode release archives.\n\nThis table shows how `kube-log-runner` invocations correspond to shell redirection:\n\n| Usage                                    | POSIX shell (such as bash) | `kube-log-runner <options> <cmd>`                           |\n| -----------------------------------------|----------------------------|-------------------------------------------------------------|\n| Merge stderr and stdout, write to stdout | `2>&1`                     | `kube-log-runner` (default behavior)                        |\n| Redirect both into log file              | `1>>/tmp/log 2>&1`         | `kube-log-runner -log-file=/tmp/log`                        |\n| Copy into log file and to stdout         | `2>&1 \\| tee -a /tmp/log`  | `kube-log-runner -log-file=/tmp/log -also-stdout`           |\n| Redirect only stdout into log file       | `>/tmp/log`                | `kube-log-runner -log-file=/tmp/log -redirect-stderr=false` |\n\n### Klog output\n\nAn example of the traditional klog native format:\n\n```\nI1025 00:15:15.525108       1 httplog.go:79] GET /api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-57c75779f-9p8wg: (1.512ms) 200 [pod_nanny/v0.0.0 (linux/amd64) kubernetes/$Format 10.56.1.19:51756]\n```\n\nThe message string may contain line breaks:\n\n```\nI1025 00:15:15.525108       1 example.go:79] This is a message\nwhich has a line break.\n```\n\n### Structured Logging\n\n{{< feature-state for_k8s_version=\"v1.23\" state=\"beta\" >}}\n\n{{< warning >}}\nMigration to structured log messages is an ongoing process. Not all log messages are structured in\nthis version. When parsing log files, you must also handle unstructured log messages.\n\nLog formatting and value serialization are subject to change.\n{{< /warning>}}\n\nStructured logging introduces a uniform structure in log messages allowing for programmatic\nextraction of information. You can store and process structured logs with less effort and cost.\nThe code which generates a log message determines whether it uses the traditional unstructured\nklog output or structured logging.\n\nThe default formatting of structured log messages is as text, with a format that is backward\ncompatible with traditional klog:\n\n```\n<klog header> \"<message>\" <key1>=\"<value1>\" <key2>=\"<value2>\" ...\n```\n\nExample:\n\n```\nI1025 00:15:15.525108       1 controller_utils.go:116] \"Pod status updated\" pod=\"kube-system/kubedns\" status=\"ready\"\n```\n\nStrings are quoted. Other values are formatted with\n[`%+v`](https://pkg.go.dev/fmt#hdr-Printing), which may cause log messages to\ncontinue on the next line [depending on the data](https://github.com/kubernetes/kubernetes/issues/106428).\n\n```\nI1025 00:15:15.525108       1 example.go:116] \"Example\" data=\"This is text with a line break\\nand \\\"quotation marks\\\".\" someInt=1 someFloat=0.1 someStruct={StringField: First line,\nsecond line.}\n```\n\n### Contextual Logging\n\n{{< feature-state for_k8s_version=\"v1.30\" state=\"beta\" >}}\n\nContextual logging builds on top of structured logging. It is primarily about\nhow developers use logging calls: code based on that concept is more flexible\nand supports additional use cases as described in the [Contextual Logging\nKEP](https://github.com/kubernetes/enhancements/tree/master/keps/sig-instrumentation/3077-contextual-logging).\n\nIf developers use additional functions like `WithValues` or `WithName` in\ntheir components, then log entries contain additional information that gets\npassed into functions by their caller.\n\nFor Kubernetes {{< skew currentVersion >}}, this is gated behind the `ContextualLogging`\n[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) and is\nenabled by default. The infrastructure for this was added in 1.24 without\nmodifying components. The\n[`component-base/logs/example`](https://github.com/kubernetes/kubernetes/blob/v1.24.0-beta.0/staging/src/k8s.io/component-base/logs/example/cmd/logger.go)\ncommand demonstrates how to use the new logging calls and how a component\nbehaves that supports contextual logging.\n\n```console\n$ cd $GOPATH/src/k8s.io/kubernetes/staging/src/k8s.io/component-base/logs/example/cmd/\n$ go run . --help\n...\n      --feature-gates mapStringBool  A set of key=value pairs that describe feature gates for alpha/experimental features. Options are:\n                                     AllAlpha=true|false (ALPHA - default=false)\n                                     AllBeta=true|false (BETA - default=false)\n                                     ContextualLogging=true|false (BETA - default=true)\n$ go run . --feature-gates ContextualLogging=true\n...\nI0222 15:13:31.645988  197901 example.go:54] \"runtime\" logger=\"example.myname\" foo=\"bar\" duration=\"1m0s\"\nI0222 15:13:31.646007  197901 example.go:55] \"another runtime\" logger=\"example\" foo=\"bar\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\nThe `logger` key and `foo=\"bar\"` were added by the caller of the function\nwhich logs the `runtime` message and `duration=\"1m0s\"` value, without having to\nmodify that function.\n\nWith contextual logging disable, `WithValues` and `WithName` do nothing and log\ncalls go through the global klog logger. Therefore this additional information\nis not in the log output anymore:\n\n```console\n$ go run . --feature-gates ContextualLogging=false\n...\nI0222 15:14:40.497333  198174 example.go:54] \"runtime\" duration=\"1m0s\"\nI0222 15:14:40.497346  198174 example.go:55] \"another runtime\" duration=\"1h0m0s\" duration=\"1m0s\"\n```\n\n### JSON log format\n\n{{< feature-state for_k8s_version=\"v1.19\" state=\"alpha\" >}}\n\n{{<warning >}}\nJSON output does not support many standard klog flags. For list of unsupported klog flags, see the\n[Command line tool reference](/docs/reference/command-line-tools-reference/).\n\nNot all logs are guaranteed to be written in JSON format (for example, during process start).\nIf you intend to parse logs, make sure you can handle log lines that are not JSON as well.\n\nField names and JSON serialization are subject to change.\n{{< /warning >}}\n\nThe `--logging-format=json` flag changes the format of logs from klog native format to JSON format.\nExample of JSON log format (pretty printed):\n\n```json\n{\n   \"ts\": 1580306777.04728,\n   \"v\": 4,\n   \"msg\": \"Pod status updated\",\n   \"pod\":{\n      \"name\": \"nginx-1\",\n      \"namespace\": \"default\"\n   },\n   \"status\": \"ready\"\n}\n```\n\nKeys with special meaning:\n\n* `ts` - timestamp as Unix time (required, float)\n* `v` - verbosity (only for info and not for error messages, int)\n* `err` - error string (optional, string)\n* `msg` - message (required, string)\n\nList of components currently supporting JSON format:\n\n* {{< glossary_tooltip term_id=\"kube-controller-manager\" text=\"kube-controller-manager\" >}}\n* {{< glossary_tooltip term_id=\"kube-apiserver\" text=\"kube-apiserver\" >}}\n* {{< glossary_tooltip term_id=\"kube-scheduler\" text=\"kube-scheduler\" >}}\n* {{< glossary_tooltip term_id=\"kubelet\" text=\"kubelet\" >}}\n\n### Log verbosity level\n\nThe `-v` flag controls log verbosity. Increasing the value increases the number of logged events.\nDecreasing the value decreases the number of logged events.  Increasing verbosity settings logs\nincreasingly less severe events. A verbosity setting of 0 logs only critical events.\n\n### Log location\n\nThere are two types of system components: those that run in a container and those\nthat do not run in a container. For example:\n\n* The Kubernetes scheduler and kube-proxy run in a container.\n* The kubelet and {{<glossary_tooltip term_id=\"container-runtime\" text=\"container runtime\">}}\n  do not run in containers.\n\nOn machines with systemd, the kubelet and container runtime write to journald.\nOtherwise, they write to `.log` files in the `/var/log` directory.\nSystem components inside containers always write to `.log` files in the `/var/log` directory,\nbypassing the default logging mechanism.\nSimilar to the container logs, you should rotate system component logs in the `/var/log` directory.\nIn Kubernetes clusters created by the `kube-up.sh` script, log rotation is configured by the `logrotate` tool.\nThe `logrotate` tool rotates logs daily, or once the log size is greater than 100MB.",
      "terms": [
        {
          "term": "klog",
          "tier": 1,
          "reasoning": "The Kubernetes logging library, a core component for system logging."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "log messages",
          "tier": 2,
          "reasoning": "Technical concept referring to the output generated by logging systems."
        },
        {
          "term": "system components",
          "tier": 2,
          "reasoning": "Refers to the various parts that make up the Kubernetes system."
        },
        {
          "term": "klog command line flags",
          "tier": 2,
          "reasoning": "Configuration options passed to klog via command line interface."
        },
        {
          "term": "--add-dir-header",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for logging configuration."
        },
        {
          "term": "--alsologtostderr",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for stderr logging."
        },
        {
          "term": "--log-backtrace-at",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for backtrace logging."
        },
        {
          "term": "--log-dir",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for log directory specification."
        },
        {
          "term": "--log-file",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for log file specification."
        },
        {
          "term": "--log-file-max-size",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for maximum log file size."
        },
        {
          "term": "--logtostderr",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for logging to stderr."
        },
        {
          "term": "--one-output",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for output configuration."
        },
        {
          "term": "--skip-headers",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for header handling."
        },
        {
          "term": "--skip-log-headers",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for log header handling."
        },
        {
          "term": "--stderrthreshold",
          "tier": 3,
          "reasoning": "Deprecated klog CLI flag for stderr threshold configuration."
        },
        {
          "term": "stderr",
          "tier": 3,
          "reasoning": "Standard error output stream, a fundamental OS concept for output handling."
        },
        {
          "term": "stdout",
          "tier": 3,
          "reasoning": "Standard output stream, a fundamental OS concept for output handling."
        },
        {
          "term": "output format",
          "tier": 2,
          "reasoning": "Technical concept describing how log data is structured and presented."
        },
        {
          "term": "output redirection",
          "tier": 2,
          "reasoning": "Technical process of directing output to different destinations."
        },
        {
          "term": "Kubernetes component",
          "tier": 2,
          "reasoning": "Any of the individual parts that make up the Kubernetes system."
        },
        {
          "term": "POSIX shell",
          "tier": 3,
          "reasoning": "Standard shell interface specification relevant to output handling."
        },
        {
          "term": "systemd",
          "tier": 3,
          "reasoning": "Linux system and service manager used for component invocation."
        },
        {
          "term": "distroless container",
          "tier": 2,
          "reasoning": "Minimal container image type without shell or package manager."
        },
        {
          "term": "Windows system service",
          "tier": 3,
          "reasoning": "Windows service context where standard shell options are unavailable."
        },
        {
          "term": "kube-log-runner",
          "tier": 1,
          "reasoning": "Kubernetes binary wrapper for output redirection in restricted environments."
        },
        {
          "term": "/go-runner",
          "tier": 1,
          "reasoning": "Traditional name for the kube-log-runner binary in base images."
        },
        {
          "term": "Kubernetes base images",
          "tier": 2,
          "reasoning": "Foundation container images used for Kubernetes components."
        },
        {
          "term": "-log-file",
          "tier": 3,
          "reasoning": "kube-log-runner option for specifying log file destination."
        },
        {
          "term": "-also-stdout",
          "tier": 3,
          "reasoning": "kube-log-runner option for copying output to stdout."
        },
        {
          "term": "-redirect-stderr",
          "tier": 3,
          "reasoning": "kube-log-runner option for controlling stderr redirection."
        },
        {
          "term": "klog native format",
          "tier": 2,
          "reasoning": "The traditional output format used by klog for log messages."
        },
        {
          "term": "Structured Logging",
          "tier": 2,
          "reasoning": "Logging approach that introduces uniform structure for programmatic extraction."
        },
        {
          "term": "structured log messages",
          "tier": 2,
          "reasoning": "Log messages with consistent, parseable structure."
        },
        {
          "term": "unstructured log messages",
          "tier": 2,
          "reasoning": "Traditional log messages without uniform structure."
        },
        {
          "term": "log formatting",
          "tier": 2,
          "reasoning": "The process of structuring log output in a specific format."
        },
        {
          "term": "value serialization",
          "tier": 2,
          "reasoning": "Process of converting values to string representation in logs."
        },
        {
          "term": "klog header",
          "tier": 2,
          "reasoning": "The prefix portion of klog output containing metadata."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object shown in log message examples."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Kubernetes workload resource referenced in structured log examples."
        },
        {
          "term": "namespaces",
          "tier": 2,
          "reasoning": "Kubernetes resource for organizing and isolating cluster resources."
        },
        {
          "term": "kube-system",
          "tier": 1,
          "reasoning": "System namespace for Kubernetes core components."
        },
        {
          "term": "metrics-server",
          "tier": 1,
          "reasoning": "Kubernetes component for resource metrics collection."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating the maturity level of Structured Logging."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in log example paths."
        },
        {
          "term": "linux/amd64",
          "tier": 3,
          "reasoning": "Platform identifier indicating operating system and architecture."
        }
      ],
      "term_count": 46,
      "generated_at": "2026-02-08T21:59:19.379833",
      "elapsed_time": 23.73857569694519
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DefaultHostNetworkHostPortsInPodTemplates.md",
      "content": "---\ntitle: DefaultHostNetworkHostPortsInPodTemplates\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: deprecated\n    defaultValue: false\n    fromVersion: \"1.28\"\n    toVersion: \"1.30\"\n\nremoved: true\n---\nThis feature gate controls the point at which a default value for\n`.spec.containers[*].ports[*].hostPort`\nis assigned, for Pods using `hostNetwork: true`. The default since Kubernetes v1.28 is to only set a default\nvalue in Pods.\n\nEnabling this means a default will be assigned even to the `.spec` of an embedded\n[PodTemplate](/docs/concepts/workloads/pods/#pod-templates) (for example, in a Deployment),\nwhich is the way that older releases of Kubernetes worked.\nYou should migrate your code so that it does not rely on the legacy behavior.",
      "terms": [
        {
          "term": "DefaultHostNetworkHostPortsInPodTemplates",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling experimental or optional features."
        },
        {
          "term": "feature gate",
          "tier": 1,
          "reasoning": "Alternative form of the feature gate concept appearing in the documentation."
        },
        {
          "term": ".spec.containers[*].ports[*].hostPort",
          "tier": 1,
          "reasoning": "A specific API field path in the Pod specification for container port configuration."
        },
        {
          "term": "hostPort",
          "tier": 2,
          "reasoning": "A Kubernetes networking concept specifying which port on the host node to expose."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "hostNetwork",
          "tier": 2,
          "reasoning": "A Pod networking configuration option that uses the host's network namespace."
        },
        {
          "term": ".spec",
          "tier": 2,
          "reasoning": "The specification section of a Kubernetes resource definition."
        },
        {
          "term": "PodTemplate",
          "tier": 1,
          "reasoning": "A Kubernetes API object that defines a template for creating Pods."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "A core Kubernetes workload resource for managing replicated applications."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": "deprecated",
          "tier": 2,
          "reasoning": "A lifecycle stage indicating a feature is no longer recommended for use."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "A configuration property indicating the default state of a feature gate."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "The fundamental unit of application packaging in Kubernetes."
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Network port configuration for containers in Kubernetes."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "A Kubernetes concept category for applications running on the cluster."
        },
        {
          "term": "embedded",
          "tier": 3,
          "reasoning": "Technical term describing PodTemplates nested within other resources."
        },
        {
          "term": "default value",
          "tier": 2,
          "reasoning": "A configuration concept for automatic value assignment."
        },
        {
          "term": "stages",
          "tier": 2,
          "reasoning": "Feature gate lifecycle phases in Kubernetes."
        },
        {
          "term": "removed",
          "tier": 2,
          "reasoning": "A lifecycle state indicating the feature gate has been eliminated from Kubernetes."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T21:59:31.417594",
      "elapsed_time": 11.026712417602539
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec6",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a password.txt file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF >./password.txt\nusername=admin\npassword=secret\nEOF\n\ncat <<EOF >deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  labels:\n    app: my-app\nspec:\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: app\n        image: my-app\n        volumeMounts:\n        - name: password\n          mountPath: /secrets\n      volumes:\n      - name: password\n        secret:\n          secretName: example-secret-1\nEOF\n\ncat <<EOF >./kustomization.yaml\nresources:\n- deployment.yaml\nsecretGenerator:\n- name: example-secret-1\n  files:\n  - password.txt\nEOF\n```\n\n#### generatorOptions\n\nThe generated ConfigMaps and Secrets have a content hash suffix appended. This ensures that\na new ConfigMap or Secret is generated when the contents are changed. To disable the behavior\nof appending a suffix, one can use `generatorOptions`. Besides that, it is also possible to\nspecify cross-cutting options for generated ConfigMaps and Secrets.\n\n```shell\ncat <<EOF >./kustomization.yaml\nconfigMapGenerator:\n- name: example-configmap-3\n  literals:\n  - FOO=Bar\ngeneratorOptions:\n  disableNameSuffixHash: true\n  labels:\n    type: generated\n  annotations:\n    note: generated\nEOF\n```\n\nRun`kubectl kustomize ./` to view the generated ConfigMap:\n\n```yaml\napiVersion: v1\ndata:\n  FOO: Bar\nkind: ConfigMap\nmetadata:\n  annotations:\n    note: generated\n  labels:\n    type: generated\n  name: example-configmap-3\n```\n\n### Setting cross-cutting fields\n\nIt is quite common to set cross-cutting fields for all Kubernetes resources in a project.\nSome use cases for setting cross-cutting fields:\n\n* setting the same namespace for all resources\n* adding the same name prefix or suffix\n* adding the same set of labels\n* adding the same set of annotations\n\nHere is an example:\n\n```shell",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing application deployments"
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing configuration data"
        },
        {
          "term": "Secret",
          "tier": 1,
          "reasoning": "Kubernetes API object for storing sensitive data like passwords"
        },
        {
          "term": "secretGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating Secret resources"
        },
        {
          "term": "configMapGenerator",
          "tier": 1,
          "reasoning": "Kustomize feature for generating ConfigMap resources"
        },
        {
          "term": "generatorOptions",
          "tier": 1,
          "reasoning": "Kustomize configuration block for controlling generator behavior"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "kustomize",
          "tier": 1,
          "reasoning": "Kubernetes configuration management tool referenced via kubectl kustomize"
        },
        {
          "term": "kubectl kustomize",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for running kustomize"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying API version"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API version for apps resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying resource type"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource metadata"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes manifest section for resource specification"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for matching resources by labels"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector mechanism for label matching"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for organizing and selecting resources"
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata for attaching non-identifying information"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within Deployment"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Kubernetes spec field defining container configurations"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image specification in Kubernetes"
        },
        {
          "term": "volumeMounts",
          "tier": 2,
          "reasoning": "Kubernetes field for mounting volumes into containers"
        },
        {
          "term": "mountPath",
          "tier": 2,
          "reasoning": "Filesystem path where volume is mounted in container"
        },
        {
          "term": "volumes",
          "tier": 2,
          "reasoning": "Kubernetes field for defining storage volumes"
        },
        {
          "term": "secretName",
          "tier": 2,
          "reasoning": "Reference to a Secret resource by name"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kustomization field listing Kubernetes resource files"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes isolation mechanism for resources"
        },
        {
          "term": "name prefix",
          "tier": 2,
          "reasoning": "Kustomize feature for adding prefix to resource names"
        },
        {
          "term": "content hash suffix",
          "tier": 2,
          "reasoning": "Auto-generated suffix based on content for ConfigMaps/Secrets"
        },
        {
          "term": "disableNameSuffixHash",
          "tier": 2,
          "reasoning": "Kustomize option to disable automatic hash suffix"
        },
        {
          "term": "cross-cutting fields",
          "tier": 2,
          "reasoning": "Configuration applied uniformly across multiple resources"
        },
        {
          "term": "literals",
          "tier": 2,
          "reasoning": "Kustomize field for inline key-value configuration data"
        },
        {
          "term": "files",
          "tier": 2,
          "reasoning": "Kustomize field for referencing external files as data sources"
        },
        {
          "term": "kustomization.yaml",
          "tier": 3,
          "reasoning": "Configuration file for Kustomize"
        },
        {
          "term": "deployment.yaml",
          "tier": 3,
          "reasoning": "YAML file containing Deployment resource definition"
        },
        {
          "term": "password.txt",
          "tier": 3,
          "reasoning": "Example file used as secret data source"
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "Kubernetes core API version"
        }
      ],
      "term_count": 37,
      "generated_at": "2026-02-08T21:59:47.201418",
      "elapsed_time": 14.774433612823486
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec5",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Specifying a PodDisruptionBudget",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "A `PodDisruptionBudget` has three fields:\n\n- A label selector `.spec.selector` to specify the set of\n  pods to which it applies. This field is required.\n- `.spec.minAvailable` which is a description of the number of pods from that\n  set that must still be available after the eviction, even in the absence\n  of the evicted pod. `minAvailable` can be either an absolute number or a percentage.\n- `.spec.maxUnavailable` (available in Kubernetes 1.7 and higher) which is a description\n  of the number of pods from that set that can be unavailable after the eviction.\n  It can be either an absolute number or a percentage.\n\n{{< note >}}\nThe behavior for an empty selector differs between the policy/v1beta1 and policy/v1 APIs for\nPodDisruptionBudgets. For policy/v1beta1 an empty selector matches zero pods, while\nfor policy/v1 an empty selector matches every pod in the namespace.\n{{< /note >}}\n\nYou can specify only one of `maxUnavailable` and `minAvailable` in a single `PodDisruptionBudget`.\n`maxUnavailable` can only be used to control the eviction of pods\nthat all have the same associated controller managing them. In the examples below, \"desired replicas\"\nis the `scale` of the controller managing the pods being selected by the\n`PodDisruptionBudget`.\n\nExample 1: With a `minAvailable` of 5, evictions are allowed as long as they leave behind\n5 or more [healthy](#healthiness-of-a-pod) pods among those selected by the PodDisruptionBudget's `selector`.\n\nExample 2: With a `minAvailable` of 30%, evictions are allowed as long as at least 30%\nof the number of desired replicas are healthy.\n\nExample 3: With a `maxUnavailable` of 5, evictions are allowed as long as there are at most 5\nunhealthy replicas among the total number of desired replicas.\n\nExample 4: With a `maxUnavailable` of 30%, evictions are allowed as long as the number of \nunhealthy replicas does not exceed 30% of the total number of desired replica rounded up to \nthe nearest integer. If the total number of desired replicas is just one, that single replica\nis still allowed for disruption, leading to an effective unavailability of 100%.\n\nIn typical usage, a single budget would be used for a collection of pods managed by\na controller\u2014for example, the pods in a single ReplicaSet or StatefulSet.\n\n{{< note >}}\nA disruption budget does not truly guarantee that the specified\nnumber/percentage of pods will always be up. For example, a node that hosts a\npod from the collection may fail when the collection is at the minimum size\nspecified in the budget, thus bringing the number of available pods from the\ncollection below the specified size. The budget can only protect against\nvoluntary evictions, not all causes of unavailability.\n{{< /note >}}\n\nIf you set `maxUnavailable` to 0% or 0, or you set `minAvailable` to 100% or the number of replicas,\nyou are requiring zero voluntary evictions. When you set zero voluntary evictions for a workload\nobject such as ReplicaSet, then you cannot successfully drain a Node running one of those Pods.\nIf you try to drain a Node where an unevictable Pod is running, the drain never completes.\nThis is permitted as per the semantics of `PodDisruptionBudget`.\n\nYou can find examples of pod disruption budgets defined below. They match pods with the label\n`app: zookeeper`.\n\nExample PDB Using minAvailable:\n\n{{% code_sample file=\"policy/zookeeper-pod-disruption-budget-minavailable.yaml\" %}}\n\nExample PDB Using maxUnavailable:\n\n{{% code_sample file=\"policy/zookeeper-pod-disruption-budget-maxunavailable.yaml\" %}}\n\nFor example, if the above `zk-pdb` object selects the pods of a StatefulSet of size 3, both\nspecifications have the exact same meaning. The use of `maxUnavailable` is recommended as it\nautomatically responds to changes in the number of replicas of the corresponding controller.",
      "terms": [
        {
          "term": "PodDisruptionBudget",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing pod disruption policies."
        },
        {
          "term": "label selector",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for selecting resources based on labels."
        },
        {
          "term": ".spec.selector",
          "tier": 1,
          "reasoning": "Specific API field path for the PodDisruptionBudget selector configuration."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes resource unit being managed by the disruption budget."
        },
        {
          "term": ".spec.minAvailable",
          "tier": 1,
          "reasoning": "Specific API field for configuring minimum available pods in PDB."
        },
        {
          "term": "eviction",
          "tier": 2,
          "reasoning": "Kubernetes process of removing pods from nodes."
        },
        {
          "term": "minAvailable",
          "tier": 1,
          "reasoning": "PodDisruptionBudget configuration parameter for minimum pod availability."
        },
        {
          "term": ".spec.maxUnavailable",
          "tier": 1,
          "reasoning": "Specific API field for configuring maximum unavailable pods in PDB."
        },
        {
          "term": "maxUnavailable",
          "tier": 1,
          "reasoning": "PodDisruptionBudget configuration parameter for maximum pod unavailability."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform being documented."
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes concept for matching resources based on criteria."
        },
        {
          "term": "policy/v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API version for PodDisruptionBudget."
        },
        {
          "term": "policy/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API version for PodDisruptionBudget."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes isolation mechanism for resources."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "Kubernetes component that manages the lifecycle of resources."
        },
        {
          "term": "desired replicas",
          "tier": 2,
          "reasoning": "Target number of pod instances specified in a controller."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes concept for the number of replicas of a workload."
        },
        {
          "term": "healthy",
          "tier": 2,
          "reasoning": "Pod health status concept in Kubernetes disruption context."
        },
        {
          "term": "unhealthy replicas",
          "tier": 2,
          "reasoning": "Pods not meeting health criteria in the context of disruption budgets."
        },
        {
          "term": "ReplicaSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload controller that maintains pod replicas."
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Core Kubernetes workload controller for stateful applications."
        },
        {
          "term": "disruption budget",
          "tier": 2,
          "reasoning": "Kubernetes concept for controlling voluntary pod disruptions."
        },
        {
          "term": "node",
          "tier": 1,
          "reasoning": "Kubernetes worker machine that runs pods."
        },
        {
          "term": "voluntary evictions",
          "tier": 2,
          "reasoning": "Intentional pod removals that can be controlled by PDB."
        },
        {
          "term": "unavailability",
          "tier": 2,
          "reasoning": "State of pods not being available in the cluster."
        },
        {
          "term": "zero voluntary evictions",
          "tier": 2,
          "reasoning": "Configuration preventing any intentional pod disruptions."
        },
        {
          "term": "drain",
          "tier": 2,
          "reasoning": "Kubernetes operation to safely remove pods from a node."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Kubernetes cluster component that hosts pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes resource (capitalized form as proper noun)."
        },
        {
          "term": "unevictable Pod",
          "tier": 2,
          "reasoning": "Pod protected from eviction by disruption budget settings."
        },
        {
          "term": "pod disruption budgets",
          "tier": 2,
          "reasoning": "Plural form of the PDB concept for managing disruptions."
        },
        {
          "term": "app: zookeeper",
          "tier": 2,
          "reasoning": "Example label selector value used in PDB configuration."
        },
        {
          "term": "PDB",
          "tier": 1,
          "reasoning": "Abbreviation for PodDisruptionBudget API object."
        },
        {
          "term": "zk-pdb",
          "tier": 1,
          "reasoning": "Example PodDisruptionBudget object name in documentation."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Number of pod instances managed by a controller."
        },
        {
          "term": "percentage",
          "tier": 3,
          "reasoning": "Value type for minAvailable/maxUnavailable configuration."
        },
        {
          "term": "absolute number",
          "tier": 3,
          "reasoning": "Value type for minAvailable/maxUnavailable configuration."
        },
        {
          "term": "evicted pod",
          "tier": 2,
          "reasoning": "Pod that has been removed through the eviction process."
        }
      ],
      "term_count": 38,
      "generated_at": "2026-02-08T22:00:09.994065",
      "elapsed_time": 21.785396575927734
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_options__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_options__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_options__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for options</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "-h",
          "tier": 1,
          "reasoning": "CLI flag shorthand for help option, a specific command-line interface element."
        },
        {
          "term": "--help",
          "tier": 1,
          "reasoning": "CLI flag for displaying help information, a standard command-line option."
        },
        {
          "term": "help",
          "tier": 3,
          "reasoning": "In CLI context, 'help' refers to the built-in documentation/usage information system."
        },
        {
          "term": "options",
          "tier": 3,
          "reasoning": "In CLI context, 'options' refers to command-line flags and parameters that modify command behavior."
        }
      ],
      "term_count": 4,
      "generated_at": "2026-02-08T22:00:15.446049",
      "elapsed_time": 4.4418535232543945
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec11",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create another patch set_memory.yaml",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF > set_memory.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  template:\n    spec:\n      containers:\n      - name: my-nginx\n        resources:\n          limits:\n            memory: 512Mi\nEOF\n\ncat <<EOF >./kustomization.yaml\nresources:\n- deployment.yaml\npatches:\n  - path: increase_replicas.yaml\n  - path: set_memory.yaml\nEOF\n```\n\nRun `kubectl kustomize ./` to view the Deployment:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      run: my-nginx\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - image: nginx\n        name: my-nginx\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            memory: 512Mi\n```\n\nNot all resources or fields support `strategicMerge` patches. To support modifying arbitrary fields in arbitrary resources,\nKustomize offers applying [JSON patch](https://tools.ietf.org/html/rfc6902) through `Json6902`.\nTo find the correct Resource for a `Json6902` patch, it is mandatory to specify the `target` field in `kustomization.yaml`.\n\nFor example, increasing the replica number of a Deployment object can also be done through `Json6902` patch. The target resource\nis matched using `group`, `version`, `kind`, and `name` from the `target` field.\n\n```shell",
      "terms": [
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing replicated applications"
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file name for Kustomize tool"
        },
        {
          "term": "Kustomize",
          "tier": 1,
          "reasoning": "Named Kubernetes configuration management tool"
        },
        {
          "term": "kubectl kustomize",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for running Kustomize"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "Json6902",
          "tier": 1,
          "reasoning": "Specific Kustomize patch type named after RFC 6902"
        },
        {
          "term": "JSON patch",
          "tier": 2,
          "reasoning": "Technical patching mechanism based on RFC 6902 standard"
        },
        {
          "term": "strategicMerge",
          "tier": 2,
          "reasoning": "Kubernetes-specific merge strategy for patches"
        },
        {
          "term": "patches",
          "tier": 2,
          "reasoning": "Kustomize concept for modifying base resources"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Kustomize field specifying base Kubernetes resources to manage"
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes deployment configuration for pod count"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod specification field defining container configurations"
        },
        {
          "term": "selector",
          "tier": 2,
          "reasoning": "Kubernetes field for matching pods to controllers"
        },
        {
          "term": "matchLabels",
          "tier": 2,
          "reasoning": "Kubernetes selector type for label-based matching"
        },
        {
          "term": "labels",
          "tier": 2,
          "reasoning": "Kubernetes metadata for organizing and selecting resources"
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Pod template specification within Deployment"
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes resource specification field"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes resource metadata section"
        },
        {
          "term": "limits",
          "tier": 2,
          "reasoning": "Resource constraints specification in Kubernetes"
        },
        {
          "term": "memory",
          "tier": 3,
          "reasoning": "Resource type being limited in container specification"
        },
        {
          "term": "target",
          "tier": 2,
          "reasoning": "Kustomize field for specifying which resource to patch"
        },
        {
          "term": "group",
          "tier": 2,
          "reasoning": "Kubernetes API group identifier for resource targeting"
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Kubernetes API version for resource targeting"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes resource type identifier"
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Kubernetes resource identifier field"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying API version"
        },
        {
          "term": "apps/v1",
          "tier": 2,
          "reasoning": "Specific Kubernetes API group and version for Deployments"
        },
        {
          "term": "nginx",
          "tier": 3,
          "reasoning": "Container image being deployed in the example"
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container specification field for container image"
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes field specifying exposed container port"
        },
        {
          "term": "ports",
          "tier": 2,
          "reasoning": "Container specification for network port configuration"
        },
        {
          "term": "path",
          "tier": 2,
          "reasoning": "Kustomize patches field specifying patch file location"
        },
        {
          "term": "Resource",
          "tier": 2,
          "reasoning": "Generic term for Kubernetes API objects in Kustomize context"
        },
        {
          "term": "512Mi",
          "tier": 3,
          "reasoning": "Kubernetes memory quantity notation (mebibytes)"
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T22:00:31.615971",
      "elapsed_time": 15.162225723266602
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_CronJobsScheduledAnnotation.md",
      "content": "---\ntitle: CronJobsScheduledAnnotation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.28\"\n    toVersion: \"1.31\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.32\"\n\n---\nSet the scheduled job time as an\n{{< glossary_tooltip text=\"annotation\" term_id=\"annotation\" >}} on Jobs that were created\non behalf of a CronJob.",
      "terms": [
        {
          "term": "CronJobsScheduledAnnotation",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configuration option."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "A Kubernetes mechanism for enabling/disabling optional features, appearing as the content_type."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "A Kubernetes concept for attaching non-identifying metadata to objects."
        },
        {
          "term": "Jobs",
          "tier": 1,
          "reasoning": "A Kubernetes API object/resource that runs tasks to completion."
        },
        {
          "term": "CronJob",
          "tier": 1,
          "reasoning": "A Kubernetes API object that creates Jobs on a time-based schedule."
        },
        {
          "term": "scheduled job time",
          "tier": 2,
          "reasoning": "A domain concept referring to the time when a job is scheduled to run."
        },
        {
          "term": "beta",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is well-tested but not yet stable."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "A feature lifecycle stage in Kubernetes indicating the feature is production-ready and enabled by default."
        },
        {
          "term": "stage",
          "tier": 3,
          "reasoning": "Technical term describing the maturity phase of a feature gate in Kubernetes."
        },
        {
          "term": "defaultValue",
          "tier": 3,
          "reasoning": "A configuration property indicating whether a feature gate is enabled by default."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Technical metadata indicating the Kubernetes version when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Technical metadata indicating the Kubernetes version when a feature stage ends."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:00:40.211906",
      "elapsed_time": 7.588131904602051
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec16",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`Issuer`     {#apiserver-config-k8s-io-v1-Issuer}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [JWTAuthenticator](#apiserver-config-k8s-io-v1-JWTAuthenticator)\n\n\n<p>Issuer provides the configuration for an external provider's specific settings.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>url</code> <B>[Required]</B><br/>\n<code>string</code>\n</td>\n<td>\n   <p>url points to the issuer URL in a format https://url or https://url/path.\nThis must match the &quot;iss&quot; claim in the presented JWT, and the issuer returned from discovery.\nSame value as the --oidc-issuer-url flag.\nDiscovery information is fetched from &quot;{url}/.well-known/openid-configuration&quot; unless overridden by discoveryURL.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>discoveryURL</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>discoveryURL, if specified, overrides the URL used to fetch discovery\ninformation instead of using &quot;{url}/.well-known/openid-configuration&quot;.\nThe exact value specified is used, so &quot;/.well-known/openid-configuration&quot;\nmust be included in discoveryURL if needed.</p>\n<p>The &quot;issuer&quot; field in the fetched discovery information must match the &quot;issuer.url&quot; field\nin the AuthenticationConfiguration and will be used to validate the &quot;iss&quot; claim in the presented JWT.\nThis is for scenarios where the well-known and jwks endpoints are hosted at a different\nlocation than the issuer (such as locally in the cluster).</p>\n<p>Example:\nA discovery url that is exposed using kubernetes service 'oidc' in namespace 'oidc-namespace'\nand discovery information is available at '/.well-known/openid-configuration'.\ndiscoveryURL: &quot;https://oidc.oidc-namespace/.well-known/openid-configuration&quot;\ncertificateAuthority is used to verify the TLS connection and the hostname on the leaf certificate\nmust be set to 'oidc.oidc-namespace'.</p>\n<p>curl https://oidc.oidc-namespace/.well-known/openid-configuration (.discoveryURL field)\n{\nissuer: &quot;https://oidc.example.com&quot; (.url field)\n}</p>\n<p>discoveryURL must be different from url.\nRequired to be unique across all JWT authenticators.\nNote that egress selection configuration is not used for this network connection.</p>\n</td>\n</tr>\n<tr><td><code>certificateAuthority</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>certificateAuthority contains PEM-encoded certificate authority certificates\nused to validate the connection when fetching discovery information.\nIf unset, the system verifier is used.\nSame value as the content of the file referenced by the --oidc-ca-file flag.</p>\n</td>\n</tr>\n<tr><td><code>audiences</code> <B>[Required]</B><br/>\n<code>[]string</code>\n</td>\n<td>\n   <p>audiences is the set of acceptable audiences the JWT must be issued to.\nAt least one of the entries must match the &quot;aud&quot; claim in presented JWTs.\nSame value as the --oidc-client-id flag (though this field supports an array).\nRequired to be non-empty.</p>\n</td>\n</tr>\n<tr><td><code>audienceMatchPolicy</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AudienceMatchPolicyType\"><code>AudienceMatchPolicyType</code></a>\n</td>\n<td>\n   <p>audienceMatchPolicy defines how the &quot;audiences&quot; field is used to match the &quot;aud&quot; claim in the presented JWT.\nAllowed values are:</p>\n<ol>\n<li>&quot;MatchAny&quot; when multiple audiences are specified and</li>\n<li>empty (or unset) or &quot;MatchAny&quot; when a single audience is specified.</li>\n</ol>\n<ul>\n<li>\n<p>MatchAny: the &quot;aud&quot; claim in the presented JWT must match at least one of the entries in the &quot;audiences&quot; field.\nFor example, if &quot;audiences&quot; is [&quot;foo&quot;, &quot;bar&quot;], the &quot;aud&quot; claim in the presented JWT must contain either &quot;foo&quot; or &quot;bar&quot; (and may contain both).</p>\n</li>\n<li>\n<p>&quot;&quot;: The match policy can be empty (or unset) when a single audience is specified in the &quot;audiences&quot; field. The &quot;aud&quot; claim in the presented JWT must contain the single audience (and may contain others).</p>\n</li>\n</ul>\n<p>For more nuanced audience validation, use claimValidationRules.\nexample: claimValidationRule[].expression: 'sets.equivalent(claims.aud, [&quot;bar&quot;, &quot;foo&quot;, &quot;baz&quot;])' to require an exact match.</p>\n</td>\n</tr>\n<tr><td><code>egressSelectorType</code><br/>\n<a href=\"#apiserver-config-k8s-io-v1-EgressSelectorType\"><code>EgressSelectorType</code></a>\n</td>\n<td>\n   <p>egressSelectorType is an indicator of which egress selection should be used for sending all traffic related\nto this issuer (discovery, JWKS, distributed claims, etc).  If unspecified, no custom dialer is used.\nWhen specified, the valid choices are &quot;controlplane&quot; and &quot;cluster&quot;.  These correspond to the associated\nvalues in the --egress-selector-config-file.</p>\n<ul>\n<li>\n<p>controlplane: for traffic intended to go to the control plane.</p>\n</li>\n<li>\n<p>cluster: for traffic intended to go to the system being managed by Kubernetes.</p>\n</li>\n</ul>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for JWT-based authentication configuration"
        },
        {
          "term": "Issuer",
          "tier": 1,
          "reasoning": "Named configuration component for external identity provider settings"
        },
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for authentication settings"
        },
        {
          "term": "AudienceMatchPolicyType",
          "tier": 1,
          "reasoning": "Named Kubernetes API type for audience matching policy configuration"
        },
        {
          "term": "JWT",
          "tier": 2,
          "reasoning": "JSON Web Token - core authentication token format used throughout the document"
        },
        {
          "term": "JWT authenticators",
          "tier": 2,
          "reasoning": "Domain concept referring to authentication components that validate JWTs"
        },
        {
          "term": "url",
          "tier": 2,
          "reasoning": "Configuration field pointing to the issuer URL for JWT validation"
        },
        {
          "term": "discoveryURL",
          "tier": 2,
          "reasoning": "Configuration field that overrides the default OIDC discovery endpoint"
        },
        {
          "term": "certificateAuthority",
          "tier": 2,
          "reasoning": "Configuration field containing PEM-encoded CA certificates for TLS validation"
        },
        {
          "term": "audiences",
          "tier": 2,
          "reasoning": "Configuration field specifying acceptable JWT audience values"
        },
        {
          "term": "audienceMatchPolicy",
          "tier": 2,
          "reasoning": "Configuration field defining how audience claims are matched"
        },
        {
          "term": "iss",
          "tier": 2,
          "reasoning": "JWT claim field representing the token issuer"
        },
        {
          "term": "aud",
          "tier": 2,
          "reasoning": "JWT claim field representing the token audience"
        },
        {
          "term": "issuer",
          "tier": 2,
          "reasoning": "Identity provider that issues JWTs, referenced in discovery information"
        },
        {
          "term": "discovery information",
          "tier": 2,
          "reasoning": "OIDC metadata fetched from well-known endpoint for authentication configuration"
        },
        {
          "term": "openid-configuration",
          "tier": 2,
          "reasoning": "Standard OIDC discovery endpoint path for provider metadata"
        },
        {
          "term": ".well-known/openid-configuration",
          "tier": 2,
          "reasoning": "Standard well-known path for OIDC discovery endpoint"
        },
        {
          "term": "OIDC",
          "tier": 2,
          "reasoning": "OpenID Connect - authentication protocol referenced via flags and discovery"
        },
        {
          "term": "--oidc-issuer-url",
          "tier": 1,
          "reasoning": "CLI flag for configuring the OIDC issuer URL"
        },
        {
          "term": "--oidc-ca-file",
          "tier": 1,
          "reasoning": "CLI flag for specifying the OIDC CA certificate file"
        },
        {
          "term": "--oidc-client-id",
          "tier": 1,
          "reasoning": "CLI flag for configuring the OIDC client ID"
        },
        {
          "term": "egress selection configuration",
          "tier": 2,
          "reasoning": "Kubernetes network configuration concept for outbound connections"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol used for secure connections"
        },
        {
          "term": "TLS connection",
          "tier": 2,
          "reasoning": "Secure connection verified using certificate authority"
        },
        {
          "term": "PEM-encoded",
          "tier": 3,
          "reasoning": "Certificate encoding format for certificate authority data"
        },
        {
          "term": "certificate authority certificates",
          "tier": 2,
          "reasoning": "CA certificates used to validate TLS connections"
        },
        {
          "term": "leaf certificate",
          "tier": 2,
          "reasoning": "End-entity certificate whose hostname is validated"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Network identifier validated on leaf certificates"
        },
        {
          "term": "jwks endpoints",
          "tier": 2,
          "reasoning": "JSON Web Key Set endpoints for retrieving public keys"
        },
        {
          "term": "kubernetes service",
          "tier": 1,
          "reasoning": "Named Kubernetes resource type for service discovery"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes isolation concept referenced in service example"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster context where services are hosted"
        },
        {
          "term": "MatchAny",
          "tier": 2,
          "reasoning": "Specific audience match policy value for JWT validation"
        },
        {
          "term": "system verifier",
          "tier": 2,
          "reasoning": "Default certificate verification mechanism when CA is unset"
        },
        {
          "term": "https",
          "tier": 3,
          "reasoning": "Secure HTTP protocol required for issuer URLs"
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "Command-line tool referenced in discovery URL example"
        }
      ],
      "term_count": 36,
      "generated_at": "2026-02-08T22:01:01.684018",
      "elapsed_time": 20.460999250411987
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_logs__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_logs__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_logs__index.md",
      "content": "```\n  # Return snapshot logs from pod nginx with only one container\n  kubectl logs nginx\n  \n  # Return snapshot logs from pod nginx, prefixing each line with the source pod and container name\n  kubectl logs nginx --prefix\n  \n  # Return snapshot logs from pod nginx, limiting output to 500 bytes\n  kubectl logs nginx --limit-bytes=500\n  \n  # Return snapshot logs from pod nginx, waiting up to 20 seconds for it to start running.\n  kubectl logs nginx --pod-running-timeout=20s\n  \n  # Return snapshot logs from pod nginx with multi containers\n  kubectl logs nginx --all-containers=true\n  \n  # Return snapshot logs from all pods in the deployment nginx\n  kubectl logs deployment/nginx --all-pods=true\n  \n  # Return snapshot logs from all containers in pods defined by label app=nginx\n  kubectl logs -l app=nginx --all-containers=true\n  \n  # Return snapshot logs from all pods defined by label app=nginx, limiting concurrent log requests to 10 pods\n  kubectl logs -l app=nginx --max-log-requests=10\n  \n  # Return snapshot of previous terminated ruby container logs from pod web-1\n  kubectl logs -p -c ruby web-1\n  \n  # Begin streaming the logs from pod nginx, continuing even if errors occur\n  kubectl logs nginx -f --ignore-errors=true\n  \n  # Begin streaming the logs of the ruby container in pod web-1\n  kubectl logs -f -c ruby web-1\n  \n  # Begin streaming the logs from all containers in pods defined by label app=nginx\n  kubectl logs -f -l app=nginx --all-containers=true\n  \n  # Display only the most recent 20 lines of output in pod nginx\n  kubectl logs --tail=20 nginx\n  \n  # Show all logs from pod nginx written in the last hour\n  kubectl logs --since=1h nginx\n  \n  # Show all logs with timestamps from pod nginx starting from August 30, 2024, at 06:00:00 UTC\n  kubectl logs nginx --since-time=2024-08-30T06:00:00Z --timestamps=true\n  \n  # Show logs from a kubelet with an expired serving certificate\n  kubectl logs --insecure-skip-tls-verify-backend nginx\n  \n  # Return snapshot logs from first container of a job named hello\n  kubectl logs job/hello\n  \n  # Return snapshot logs from container nginx-1 of a deployment named nginx\n  kubectl logs deployment/nginx -c nginx-1\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout all examples"
        },
        {
          "term": "logs",
          "tier": 2,
          "reasoning": "Kubernetes subcommand for retrieving container/pod log output"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental unit of deployment"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container/pod name used as example, represents a well-known web server"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept - isolated runtime unit within pods"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form used in --all-containers flag context"
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing replicated applications"
        },
        {
          "term": "deployment/nginx",
          "tier": 1,
          "reasoning": "Resource reference syntax for Kubernetes deployments"
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources"
        },
        {
          "term": "app=nginx",
          "tier": 2,
          "reasoning": "Label selector syntax used to filter pods"
        },
        {
          "term": "ruby",
          "tier": 1,
          "reasoning": "Specific container name referenced in multi-container pod examples"
        },
        {
          "term": "web-1",
          "tier": 1,
          "reasoning": "Specific pod name used in examples"
        },
        {
          "term": "job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running batch workloads"
        },
        {
          "term": "job/hello",
          "tier": 1,
          "reasoning": "Resource reference syntax for Kubernetes jobs"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component mentioned in TLS context"
        },
        {
          "term": "--prefix",
          "tier": 2,
          "reasoning": "kubectl logs flag for prefixing output with source information"
        },
        {
          "term": "--limit-bytes",
          "tier": 2,
          "reasoning": "kubectl logs flag for limiting log output size"
        },
        {
          "term": "--pod-running-timeout",
          "tier": 2,
          "reasoning": "kubectl logs flag for waiting on pod startup"
        },
        {
          "term": "--all-containers",
          "tier": 2,
          "reasoning": "kubectl logs flag for retrieving logs from all containers"
        },
        {
          "term": "--all-pods",
          "tier": 2,
          "reasoning": "kubectl logs flag for retrieving logs from all pods in a resource"
        },
        {
          "term": "-l",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for label selector"
        },
        {
          "term": "--max-log-requests",
          "tier": 2,
          "reasoning": "kubectl logs flag for limiting concurrent log requests"
        },
        {
          "term": "-p",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for previous terminated container logs"
        },
        {
          "term": "-c",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for specifying container name"
        },
        {
          "term": "-f",
          "tier": 2,
          "reasoning": "kubectl shorthand flag for following/streaming logs"
        },
        {
          "term": "--ignore-errors",
          "tier": 2,
          "reasoning": "kubectl logs flag for continuing despite errors"
        },
        {
          "term": "--tail",
          "tier": 2,
          "reasoning": "kubectl logs flag for limiting output to recent lines"
        },
        {
          "term": "--since",
          "tier": 2,
          "reasoning": "kubectl logs flag for time-based log filtering"
        },
        {
          "term": "--since-time",
          "tier": 2,
          "reasoning": "kubectl logs flag for absolute timestamp filtering"
        },
        {
          "term": "--timestamps",
          "tier": 2,
          "reasoning": "kubectl logs flag for including timestamps in output"
        },
        {
          "term": "--insecure-skip-tls-verify-backend",
          "tier": 2,
          "reasoning": "kubectl logs flag for bypassing TLS verification"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol referenced in certificate context"
        },
        {
          "term": "serving certificate",
          "tier": 2,
          "reasoning": "TLS certificate used by kubelet for serving requests"
        },
        {
          "term": "streaming",
          "tier": 2,
          "reasoning": "Technical concept for continuous real-time log output"
        },
        {
          "term": "snapshot logs",
          "tier": 2,
          "reasoning": "Point-in-time log retrieval as opposed to streaming"
        },
        {
          "term": "terminated",
          "tier": 2,
          "reasoning": "Container lifecycle state - previously stopped container"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of core Kubernetes resource used throughout"
        },
        {
          "term": "nginx-1",
          "tier": 1,
          "reasoning": "Specific container name in deployment example"
        },
        {
          "term": "UTC",
          "tier": 3,
          "reasoning": "Coordinated Universal Time - timestamp timezone reference"
        },
        {
          "term": "bytes",
          "tier": 3,
          "reasoning": "Unit of data measurement for log size limiting"
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:01:20.647765",
      "elapsed_time": 17.9552743434906
    },
    {
      "chunk_id": "tasks_tls_certificate-rotation_sec1",
      "doc_id": "tasks_tls_certificate-rotation",
      "heading": "Overview",
      "source_file": "tasks_tls_certificate-rotation.md",
      "content": "The kubelet uses certificates for authenticating to the Kubernetes API.  By\ndefault, these certificates are issued with one year expiration so that they do\nnot need to be renewed too frequently.\n\nKubernetes contains [kubelet certificate\nrotation](/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/),\nthat will automatically generate a new key and request a new certificate from\nthe Kubernetes API as the current certificate approaches expiration. Once the\nnew certificate is available, it will be used for authenticating connections to\nthe Kubernetes API.",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for managing pods on a node."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "The primary interface for interacting with Kubernetes clusters, a core infrastructure component."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "certificates",
          "tier": 2,
          "reasoning": "Security credentials used for authentication in the Kubernetes context."
        },
        {
          "term": "authenticating",
          "tier": 2,
          "reasoning": "Security process of verifying identity, a key domain concept in Kubernetes security."
        },
        {
          "term": "certificate",
          "tier": 2,
          "reasoning": "Individual security credential used for TLS/authentication purposes."
        },
        {
          "term": "expiration",
          "tier": 2,
          "reasoning": "Technical concept related to certificate lifecycle management."
        },
        {
          "term": "key",
          "tier": 2,
          "reasoning": "Cryptographic key used in certificate-based authentication."
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Referenced in the linked documentation path (kubelet-tls-bootstrapping), indicating Transport Layer Security protocol."
        },
        {
          "term": "bootstrapping",
          "tier": 2,
          "reasoning": "Referenced in the documentation path, describes the initial setup process for kubelet TLS."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, general technical term used in context of Kubernetes API."
        },
        {
          "term": "connections",
          "tier": 3,
          "reasoning": "Network connections being authenticated, relevant in the context of API communication."
        },
        {
          "term": "access-authn-authz",
          "tier": 2,
          "reasoning": "Path component indicating access, authentication, and authorization domain concepts."
        },
        {
          "term": "authn",
          "tier": 2,
          "reasoning": "Abbreviation for authentication appearing in the documentation path."
        },
        {
          "term": "authz",
          "tier": 2,
          "reasoning": "Abbreviation for authorization appearing in the documentation path."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T22:01:32.473051",
      "elapsed_time": 10.816485166549683
    },
    {
      "chunk_id": "concepts_services-networking_ingress_sec6",
      "doc_id": "concepts_services-networking_ingress",
      "heading": "Ingress class",
      "source_file": "concepts_services-networking_ingress.md",
      "content": "Ingresses can be implemented by different controllers, often with different\nconfiguration. Each Ingress should specify a class, a reference to an\nIngressClass resource that contains additional configuration including the name\nof the controller that should implement the class.\n\n{{% code_sample file=\"service/networking/external-lb.yaml\" %}}\n\nThe `.spec.parameters` field of an IngressClass lets you reference another\nresource that provides configuration related to that IngressClass.\n\nThe specific type of parameters to use depends on the ingress controller\nthat you specify in the `.spec.controller` field of the IngressClass.\n\n### IngressClass scope\n\nDepending on your ingress controller, you may be able to use parameters\nthat you set cluster-wide, or just for one namespace.\n\n{{< tabs name=\"tabs_ingressclass_parameter_scope\" >}}\n{{% tab name=\"Cluster\" %}}\nThe default scope for IngressClass parameters is cluster-wide.\n\nIf you set the `.spec.parameters` field and don't set\n`.spec.parameters.scope`, or if you set `.spec.parameters.scope` to\n`Cluster`, then the IngressClass refers to a cluster-scoped resource.\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a cluster-scoped API (possibly a custom resource), and\nthe `name` of the parameters identifies a specific cluster scoped\nresource for that API.\n\nFor example:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-1\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in a\n    # ClusterIngressParameter (API group k8s.example.net) named\n    # \"external-config-1\". This definition tells Kubernetes to\n    # look for a cluster-scoped parameter resource.\n    scope: Cluster\n    apiGroup: k8s.example.net\n    kind: ClusterIngressParameter\n    name: external-config-1\n```\n\n{{% /tab %}}\n{{% tab name=\"Namespaced\" %}}\n{{< feature-state for_k8s_version=\"v1.23\" state=\"stable\" >}}\n\nIf you set the `.spec.parameters` field and set\n`.spec.parameters.scope` to `Namespace`, then the IngressClass refers\nto a namespaced-scoped resource. You must also set the `namespace`\nfield within `.spec.parameters` to the namespace that contains\nthe parameters you want to use.\n\nThe `kind` (in combination the `apiGroup`) of the parameters\nrefers to a namespaced API (for example: ConfigMap), and\nthe `name` of the parameters identifies a specific resource\nin the namespace you specified in `namespace`.\n\nNamespace-scoped parameters help the cluster operator delegate control over the\nconfiguration (for example: load balancer settings, API gateway definition)\nthat is used for a workload. If you used a cluster-scoped parameter then either:\n\n- the cluster operator team needs to approve a different team's changes every\n  time there's a new configuration change being applied.\n- the cluster operator must define specific access controls, such as\n  [RBAC](/docs/reference/access-authn-authz/rbac/) roles and bindings, that let\n  the application team make changes to the cluster-scoped parameters resource.\n\nThe IngressClass API itself is always cluster-scoped.\n\nHere is an example of an IngressClass that refers to parameters that are\nnamespaced:\n\n```yaml\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: external-lb-2\nspec:\n  controller: example.com/ingress-controller\n  parameters:\n    # The parameters for this IngressClass are specified in an\n    # IngressParameter (API group k8s.example.com) named \"external-config\",\n    # that's in the \"external-configuration\" namespace.\n    scope: Namespace\n    apiGroup: k8s.example.com\n    kind: IngressParameter\n    namespace: external-configuration\n    name: external-config\n```\n\n{{% /tab %}}\n{{< /tabs >}}\n\n### Deprecated annotation\n\nBefore the IngressClass resource and `ingressClassName` field were added in\nKubernetes 1.18, Ingress classes were specified with a\n`kubernetes.io/ingress.class` annotation on the Ingress. This annotation was\nnever formally defined, but was widely supported by Ingress controllers.\n\nThe newer `ingressClassName` field on Ingresses is a replacement for that\nannotation, but is not a direct equivalent. While the annotation was generally\nused to reference the name of the Ingress controller that should implement the\nIngress, the field is a reference to an IngressClass resource that contains\nadditional Ingress configuration, including the name of the Ingress controller.\n\n### Default IngressClass {#default-ingress-class}\n\nYou can mark a particular IngressClass as default for your cluster. Setting the\n`ingressclass.kubernetes.io/is-default-class` annotation to `true` on an\nIngressClass resource will ensure that new Ingresses without an\n`ingressClassName` field specified will be assigned this default IngressClass.\n\n{{< caution >}}\nIf you have more than one IngressClass marked as the default for your cluster,\nthe admission controller prevents creating new Ingress objects that don't have\nan `ingressClassName` specified. You can resolve this by ensuring that at most 1\nIngressClass is marked as default in your cluster.\n{{< /caution >}}\n\nStart by defining a\ndefault IngressClass. It is recommended though, to specify the default\nIngressClass:\n\n{{% code_sample file=\"service/networking/default-ingressclass.yaml\" %}}",
      "terms": [
        {
          "term": "Ingresses",
          "tier": 1,
          "reasoning": "Kubernetes API resource for managing external access to services in a cluster."
        },
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Kubernetes API object that manages external access to services, typically HTTP."
        },
        {
          "term": "controllers",
          "tier": 2,
          "reasoning": "Components that implement the control loop pattern to manage Kubernetes resources."
        },
        {
          "term": "IngressClass",
          "tier": 1,
          "reasoning": "Kubernetes API resource that contains configuration for Ingress controllers."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "A component that watches the state of the cluster and makes changes to move toward desired state."
        },
        {
          "term": ".spec.parameters",
          "tier": 1,
          "reasoning": "Specific field path in IngressClass resource for referencing configuration parameters."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "A Kubernetes API object that represents cluster state."
        },
        {
          "term": "ingress controller",
          "tier": 1,
          "reasoning": "A specialized controller that implements the Ingress specification."
        },
        {
          "term": ".spec.controller",
          "tier": 1,
          "reasoning": "Field in IngressClass that specifies which controller should implement the class."
        },
        {
          "term": "IngressClass scope",
          "tier": 2,
          "reasoning": "Concept describing whether IngressClass parameters apply cluster-wide or per-namespace."
        },
        {
          "term": "cluster-wide",
          "tier": 2,
          "reasoning": "Scope indicating resources or settings that apply across the entire cluster."
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for isolating groups of resources within a cluster."
        },
        {
          "term": "cluster-scoped",
          "tier": 2,
          "reasoning": "Resources that exist at the cluster level rather than within a namespace."
        },
        {
          "term": ".spec.parameters.scope",
          "tier": 1,
          "reasoning": "Field that determines whether IngressClass parameters are cluster or namespace scoped."
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Scope value indicating cluster-wide parameter applicability."
        },
        {
          "term": "apiGroup",
          "tier": 1,
          "reasoning": "Kubernetes API field specifying the API group of a referenced resource."
        },
        {
          "term": "kind",
          "tier": 1,
          "reasoning": "Kubernetes API field specifying the type of resource being referenced."
        },
        {
          "term": "custom resource",
          "tier": 2,
          "reasoning": "Extension of the Kubernetes API that allows users to define their own resource types."
        },
        {
          "term": "ClusterIngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for cluster-scoped Ingress parameters."
        },
        {
          "term": "apiVersion",
          "tier": 1,
          "reasoning": "Kubernetes manifest field specifying the API version of the resource."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for networking resources including Ingress."
        },
        {
          "term": "metadata",
          "tier": 1,
          "reasoning": "Kubernetes resource field containing identifying information like name and labels."
        },
        {
          "term": "spec",
          "tier": 1,
          "reasoning": "Kubernetes resource field containing the desired state specification."
        },
        {
          "term": "Namespace",
          "tier": 2,
          "reasoning": "Scope value indicating namespace-level parameter applicability."
        },
        {
          "term": "namespaced-scoped",
          "tier": 2,
          "reasoning": "Resources that exist within a specific namespace."
        },
        {
          "term": "namespaced API",
          "tier": 2,
          "reasoning": "Kubernetes APIs for resources that are scoped to a namespace."
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Kubernetes API object used to store non-confidential configuration data."
        },
        {
          "term": "cluster operator",
          "tier": 2,
          "reasoning": "Role responsible for managing and maintaining Kubernetes cluster infrastructure."
        },
        {
          "term": "load balancer",
          "tier": 2,
          "reasoning": "Component that distributes network traffic across multiple backend services."
        },
        {
          "term": "API gateway",
          "tier": 2,
          "reasoning": "Service that manages API traffic, routing, and policies."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Applications running on Kubernetes, typically as Pods."
        },
        {
          "term": "RBAC",
          "tier": 1,
          "reasoning": "Role-Based Access Control - Kubernetes authorization mechanism."
        },
        {
          "term": "roles",
          "tier": 2,
          "reasoning": "RBAC resources that define permissions within a namespace."
        },
        {
          "term": "bindings",
          "tier": 2,
          "reasoning": "RBAC resources that associate roles with users or service accounts."
        },
        {
          "term": "IngressClass API",
          "tier": 1,
          "reasoning": "The Kubernetes API for managing IngressClass resources."
        },
        {
          "term": "IngressParameter",
          "tier": 1,
          "reasoning": "Example custom resource kind for namespace-scoped Ingress parameters."
        },
        {
          "term": "ingressClassName",
          "tier": 1,
          "reasoning": "Field on Ingress resources that references an IngressClass."
        },
        {
          "term": "kubernetes.io/ingress.class",
          "tier": 1,
          "reasoning": "Deprecated annotation used to specify Ingress class before IngressClass resource existed."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for attaching arbitrary non-identifying information to objects."
        },
        {
          "term": "Kubernetes 1.18",
          "tier": 2,
          "reasoning": "Specific Kubernetes version when IngressClass resource was introduced."
        },
        {
          "term": "v1.23",
          "tier": 2,
          "reasoning": "Kubernetes version when namespace-scoped IngressClass parameters became stable."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready functionality."
        },
        {
          "term": "access controls",
          "tier": 2,
          "reasoning": "Mechanisms for restricting who can perform actions on resources."
        }
      ],
      "term_count": 43,
      "generated_at": "2026-02-08T22:01:56.216513",
      "elapsed_time": 22.734813690185547
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec3",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "JSONSchemaProps {#JSONSchemaProps}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "JSONSchemaProps is a JSON-Schema following Specification Draft 4 (http://json-schema.org/).\n\n<hr>\n\n- **$ref** (string)\n\n\n- **$schema** (string)\n\n\n- **additionalItems** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **additionalProperties** (JSONSchemaPropsOrBool)\n\n\n  <a name=\"JSONSchemaPropsOrBool\"></a>\n  *JSONSchemaPropsOrBool represents JSONSchemaProps or a boolean value. Defaults to true for the boolean property.*\n\n- **allOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **anyOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **default** (JSON)\n\n  default is a default value for undefined object fields. Defaulting is a beta feature under the CustomResourceDefaulting feature gate. Defaulting requires spec.preserveUnknownFields to be false.\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **definitions** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **dependencies** (map[string]JSONSchemaPropsOrStringArray)\n\n\n  <a name=\"JSONSchemaPropsOrStringArray\"></a>\n  *JSONSchemaPropsOrStringArray represents a JSONSchemaProps or a string array.*\n\n- **description** (string)\n\n\n- **enum** ([]JSON)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **example** (JSON)\n\n\n  <a name=\"JSON\"></a>\n  *JSON represents any valid JSON value. These types are supported: bool, int64, float64, string, []interface{}, map[string]interface{} and nil.*\n\n- **exclusiveMaximum** (boolean)\n\n\n- **exclusiveMinimum** (boolean)\n\n\n- **externalDocs** (ExternalDocumentation)\n\n\n  <a name=\"ExternalDocumentation\"></a>\n  *ExternalDocumentation allows referencing an external resource for extended documentation.*\n\n  - **externalDocs.description** (string)\n\n\n  - **externalDocs.url** (string)\n\n\n- **format** (string)\n\n  format is an OpenAPI v3 format string. Unknown formats are ignored. The following formats are validated:\n  \n  - bsonobjectid: a bson object ID, i.e. a 24 characters hex string - uri: an URI as parsed by Golang net/url.ParseRequestURI - email: an email address as parsed by Golang net/mail.ParseAddress - hostname: a valid representation for an Internet host name, as defined by RFC 1034, section 3.1 [RFC1034]. - ipv4: an IPv4 IP as parsed by Golang net.ParseIP - ipv6: an IPv6 IP as parsed by Golang net.ParseIP - cidr: a CIDR as parsed by Golang net.ParseCIDR - mac: a MAC address as parsed by Golang net.ParseMAC - uuid: an UUID that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid3: an UUID3 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?3[0-9a-f]{3}-?[0-9a-f]{4}-?[0-9a-f]{12}$ - uuid4: an UUID4 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?4[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - uuid5: an UUID5 that allows uppercase defined by the regex (?i)^[0-9a-f]{8}-?[0-9a-f]{4}-?5[0-9a-f]{3}-?[89ab][0-9a-f]{3}-?[0-9a-f]{12}$ - isbn: an ISBN10 or ISBN13 number string like \"0321751043\" or \"978-0321751041\" - isbn10: an ISBN10 number string like \"0321751043\" - isbn13: an ISBN13 number string like \"978-0321751041\" - creditcard: a credit card number defined by the regex ^(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|6(?:011|5[0-9][0-9])[0-9]{12}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|(?:2131|1800|35\\\\d{3})\\\\d{11})$ with any non digit characters mixed in - ssn: a U.S. social security number following the regex ^\\\\d{3}[- ]?\\\\d{2}[- ]?\\\\d{4}$ - hexcolor: an hexadecimal color code like \"#FFFFFF: following the regex ^#?([0-9a-fA-F]{3}|[0-9a-fA-F]{6})$ - rgbcolor: an RGB color code like rgb like \"rgb(255,255,2559\" - byte: base64 encoded binary data - password: any kind of string - date: a date string like \"2006-01-02\" as defined by full-date in RFC3339 - duration: a duration string like \"22 ns\" as parsed by Golang time.ParseDuration or compatible with Scala duration format - datetime: a date time string like \"2014-12-15T19:30:20.000Z\" as defined by date-time in RFC3339.\n\n- **id** (string)\n\n\n- **items** (JSONSchemaPropsOrArray)\n\n\n  <a name=\"JSONSchemaPropsOrArray\"></a>\n  *JSONSchemaPropsOrArray represents a value that can either be a JSONSchemaProps or an array of JSONSchemaProps. Mainly here for serialization purposes.*\n\n- **maxItems** (int64)\n\n\n- **maxLength** (int64)\n\n\n- **maxProperties** (int64)\n\n\n- **maximum** (double)\n\n\n- **minItems** (int64)\n\n\n- **minLength** (int64)\n\n\n- **minProperties** (int64)\n\n\n- **minimum** (double)\n\n\n- **multipleOf** (double)\n\n\n- **not** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **nullable** (boolean)\n\n\n- **oneOf** ([]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **pattern** (string)\n\n\n- **patternProperties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **properties** (map[string]<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n\n- **required** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  \n\n- **title** (string)\n\n\n- **type** (string)\n\n\n- **uniqueItems** (boolean)\n\n\n- **x-kubernetes-embedded-resource** (boolean)\n\n  x-kubernetes-embedded-resource defines that the value is an embedded Kubernetes runtime.Object, with TypeMeta and ObjectMeta. The type must be object. It is allowed to further restrict the embedded object. kind, apiVersion and metadata are validated automatically. x-kubernetes-preserve-unknown-fields is allowed to be true, but does not have to be if the object is fully specified (up to kind, apiVersion, metadata).\n\n- **x-kubernetes-int-or-string** (boolean)\n\n  x-kubernetes-int-or-string specifies that this value is either an integer or a string. If this is true, an empty type is allowed and type as child of anyOf is permitted if following one of the following patterns:\n  \n  1) anyOf:\n     - type: integer\n     - type: string\n  2) allOf:\n     - anyOf:\n       - type: integer\n       - type: string\n     - ... zero or more\n\n- **x-kubernetes-list-map-keys** ([]string)\n\n  *Atomic: will be replaced during a merge*\n  \n  x-kubernetes-list-map-keys annotates an array with the x-kubernetes-list-type `map` by specifying the keys used as the index of the map.\n  \n  This tag MUST only be used on lists that have the \"x-kubernetes-list-type\" extension set to \"map\". Also, the values specified for this attribute must be a scalar typed field of the child structure (no nesting is supported).\n  \n  The properties specified must either be required or have a default value, to ensure those properties are present for all list items.\n\n- **x-kubernetes-list-type** (string)\n\n  x-kubernetes-list-type annotates an array to further describe its topology. This extension must only be used on lists and may have 3 possible values:\n  \n  1) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic lists will be entirely replaced when updated. This extension\n       may be used on any type of list (struct, scalar, ...).\n  2) `set`:\n       Sets are lists that must not have multiple items with the same value. Each\n       value must be a scalar, an object with x-kubernetes-map-type `atomic` or an\n       array with x-kubernetes-list-type `atomic`.\n  3) `map`:\n       These lists are like maps in that their elements have a non-index key\n       used to identify them. Order is preserved upon merge. The map tag\n       must only be used on a list with elements of type object.\n  Defaults to atomic for arrays.\n\n- **x-kubernetes-map-type** (string)\n\n  x-kubernetes-map-type annotates an object to further describe its topology. This extension must only be used when type is object and may have 2 possible values:\n  \n  1) `granular`:\n       These maps are actual maps (key-value pairs) and each fields are independent\n       from each other (they can each be manipulated by separate actors). This is\n       the default behaviour for all maps.\n  2) `atomic`: the list is treated as a single entity, like a scalar.\n       Atomic maps will be entirely replaced when updated.\n\n- **x-kubernetes-preserve-unknown-fields** (boolean)\n\n  x-kubernetes-preserve-unknown-fields stops the API server decoding step from pruning fields which are not specified in the validation schema. This affects fields recursively, but switches back to normal pruning behaviour if nested properties or additionalProperties are specified in the schema. This can either be true or undefined. False is forbidden.\n\n- **x-kubernetes-validations** ([]ValidationRule)\n\n  *Patch strategy: merge on key `rule`*\n  \n  *Map: unique values on key rule will be kept during a merge*\n  \n  x-kubernetes-validations describes a list of validation rules written in the CEL expression language.\n\n  <a name=\"ValidationRule\"></a>\n  *ValidationRule describes a validation rule written in the CEL expression language.*\n\n  - **x-kubernetes-validations.rule** (string), required\n\n    Rule represents the expression which will be evaluated by CEL. ref: https://github.com/google/cel-spec The Rule is scoped to the location of the x-kubernetes-validations extension in the schema. The `self` variable in the CEL expression is bound to the scoped value. Example: - Rule scoped to the root of a resource with a status subresource: {\"rule\": \"self.status.actual \\<= self.spec.maxDesired\"}\n    \n    If the Rule is scoped to an object with properties, the accessible properties of the object are field selectable via `self.field` and field presence can be checked via `has(self.field)`. Null valued fields are treated as absent fields in CEL expressions. If the Rule is scoped to an object with additionalProperties (i.e. a map) the value of the map are accessible via `self[mapKey]`, map containment can be checked via `mapKey in self` and all entries of the map are accessible via CEL macros and functions such as `self.all(...)`. If the Rule is scoped to an array, the elements of the array are accessible via `self[i]` and also by macros and functions. If the Rule is scoped to a scalar, `self` is bound to the scalar value. Examples: - Rule scoped to a map of objects: {\"rule\": \"self.components['Widget'].priority \\< 10\"} - Rule scoped to a list of integers: {\"rule\": \"self.values.all(value, value >= 0 && value \\< 100)\"} - Rule scoped to a string value: {\"rule\": \"self.startsWith('kube')\"}\n    \n    The `apiVersion`, `kind`, `metadata.name` and `metadata.generateName` are always accessible from the root of the object and from any x-kubernetes-embedded-resource annotated objects. No other metadata properties are accessible.\n    \n    Unknown data preserved in custom resources via x-kubernetes-preserve-unknown-fields is not accessible in CEL expressions. This includes: - Unknown field values that are preserved by object schemas with x-kubernetes-preserve-unknown-fields. - Object properties where the property schema is of an \"unknown type\". An \"unknown type\" is recursively defined as:\n      - A schema with no type and x-kubernetes-preserve-unknown-fields set to true\n      - An array where the items schema is of an \"unknown type\"\n      - An object where the additionalProperties schema is of an \"unknown type\"\n    \n    Only property names of the form `[a-zA-Z_.-/][a-zA-Z0-9_.-/]*` are accessible. Accessible property names are escaped according to the following rules when accessed in the expression: - '__' escapes to '__underscores__' - '.' escapes to '__dot__' - '-' escapes to '__dash__' - '/' escapes to '__slash__' - Property names that exactly match a CEL RESERVED keyword escape to '__{keyword}__'. The keywords are:\n    \t  \"true\", \"false\", \"null\", \"in\", \"as\", \"break\", \"const\", \"continue\", \"else\", \"for\", \"function\", \"if\",\n    \t  \"import\", \"let\", \"loop\", \"package\", \"namespace\", \"return\".\n    Examples:\n      - Rule accessing a property named \"namespace\": {\"rule\": \"self.__namespace__ > 0\"}\n      - Rule accessing a property named \"x-prop\": {\"rule\": \"self.x__dash__prop > 0\"}\n      - Rule accessing a property named \"redact__d\": {\"rule\": \"self.redact__underscores__d > 0\"}\n    \n    Equality on arrays with x-kubernetes-list-type of 'set' or 'map' ignores element order, i.e. [1, 2] == [2, 1]. Concatenation on arrays with x-kubernetes-list-type use the semantics of the list type:\n      - 'set': `X + Y` performs a union where the array positions of all elements in `X` are preserved and\n        non-intersecting elements in `Y` are appended, retaining their partial order.\n      - 'map': `X + Y` performs a merge where the array positions of all keys in `X` are preserved but the values\n        are overwritten by values in `Y` when the key sets of `X` and `Y` intersect. Elements in `Y` with\n        non-intersecting keys are appended, retaining their partial order.\n    \n    If `rule` makes use of the `oldSelf` variable it is implicitly a `transition rule`.\n    \n    By default, the `oldSelf` variable is the same type as `self`. When `optionalOldSelf` is true, the `oldSelf` variable is a CEL optional\n     variable whose value() is the same type as `self`.\n    See the documentation for the `optionalOldSelf` field for details.\n    \n    Transition rules by default are applied only on UPDATE requests and are skipped if an old value could not be found. You can opt a transition rule into unconditional evaluation by setting `optionalOldSelf` to true.\n\n  - **x-kubernetes-validations.fieldPath** (string)\n\n    fieldPath represents the field path returned when the validation fails. It must be a relative JSON path (i.e. with array notation) scoped to the location of this x-kubernetes-validations extension in the schema and refer to an existing field. e.g. when validation checks if a specific attribute `foo` under a map `testMap`, the fieldPath could be set to `.testMap.foo` If the validation checks two lists must have unique attributes, the fieldPath could be set to either of the list: e.g. `.testList` It does not support list numeric index. It supports child operation to refer to an existing field currently. Refer to [JSONPath support in Kubernetes](https://kubernetes.io/docs/reference/kubectl/jsonpath/) for more info. Numeric index of array is not supported. For field name which contains special characters, use `['specialName']` to refer the field name. e.g. for attribute `foo.34$` appears in a list `testList`, the fieldPath could be set to `.testList['foo.34$']`\n\n  - **x-kubernetes-validations.message** (string)\n\n    Message represents the message displayed when validation fails. The message is required if the Rule contains line breaks. The message must not contain line breaks. If unset, the message is \"failed rule: {Rule}\". e.g. \"must be a URL with the host matching spec.host\"\n\n  - **x-kubernetes-validations.messageExpression** (string)\n\n    MessageExpression declares a CEL expression that evaluates to the validation failure message that is returned when this rule fails. Since messageExpression is used as a failure message, it must evaluate to a string. If both message and messageExpression are present on a rule, then messageExpression will be used if validation fails. If messageExpression results in a runtime error, the runtime error is logged, and the validation failure message is produced as if the messageExpression field were unset. If messageExpression evaluates to an empty string, a string with only spaces, or a string that contains line breaks, then the validation failure message will also be produced as if the messageExpression field were unset, and the fact that messageExpression produced an empty string/string with only spaces/string with line breaks will be logged. messageExpression has access to all the same variables as the rule; the only difference is the return type. Example: \"x must be less than max (\"+string(self.max)+\")\"\n\n  - **x-kubernetes-validations.optionalOldSelf** (boolean)\n\n    optionalOldSelf is used to opt a transition rule into evaluation even when the object is first created, or if the old object is missing the value.\n    \n    When enabled `oldSelf` will be a CEL optional whose value will be `None` if there is no old value, or when the object is initially created.\n    \n    You may check for presence of oldSelf using `oldSelf.hasValue()` and unwrap it after checking using `oldSelf.value()`. Check the CEL documentation for Optional types for more information: https://pkg.go.dev/github.com/google/cel-go/cel#OptionalTypes\n    \n    May not be set unless `oldSelf` is used in `rule`.\n\n  - **x-kubernetes-validations.reason** (string)\n\n    reason provides a machine-readable validation failure reason that is returned to the caller when a request fails this validation rule. The HTTP status code returned to the caller will match the reason of the reason of the first failed validation rule. The currently supported reasons are: \"FieldValueInvalid\", \"FieldValueForbidden\", \"FieldValueRequired\", \"FieldValueDuplicate\". If not set, default to use \"FieldValueInvalid\". All future added reasons must be accepted by clients when reading this value and unknown reasons should be treated as FieldValueInvalid.\n    \n    Possible enum values:\n     - `\"FieldValueDuplicate\"` is used to report collisions of values that must be unique (e.g. unique IDs).\n     - `\"FieldValueForbidden\"` is used to report valid (as per formatting rules) values which would be accepted under some conditions, but which are not permitted by the current conditions (such as security policy).\n     - `\"FieldValueInvalid\"` is used to report malformed values (e.g. failed regex match, too long, out of bounds).\n     - `\"FieldValueRequired\"` is used to report required values that are not provided (e.g. empty strings, null values, or empty arrays).",
      "terms": [
        {
          "term": "JSONSchemaProps",
          "tier": 1,
          "reasoning": "Core API type representing JSON Schema properties in Kubernetes CRD definitions"
        },
        {
          "term": "JSON-Schema",
          "tier": 2,
          "reasoning": "Domain standard specification that JSONSchemaProps follows"
        },
        {
          "term": "Specification Draft 4",
          "tier": 2,
          "reasoning": "Specific version of JSON Schema specification referenced"
        },
        {
          "term": "$ref",
          "tier": 3,
          "reasoning": "JSON Schema keyword for referencing other schemas"
        },
        {
          "term": "$schema",
          "tier": 3,
          "reasoning": "JSON Schema keyword for declaring schema version"
        },
        {
          "term": "additionalItems",
          "tier": 2,
          "reasoning": "JSON Schema property controlling validation of additional array items"
        },
        {
          "term": "JSONSchemaPropsOrBool",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or boolean value"
        },
        {
          "term": "additionalProperties",
          "tier": 2,
          "reasoning": "JSON Schema property controlling validation of additional object properties"
        },
        {
          "term": "allOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical AND"
        },
        {
          "term": "Atomic",
          "tier": 2,
          "reasoning": "Kubernetes merge strategy indicating field will be replaced during merge"
        },
        {
          "term": "anyOf",
          "tier": 2,
          "reasoning": "JSON Schema keyword for combining schemas with logical OR"
        },
        {
          "term": "default",
          "tier": 2,
          "reasoning": "JSON Schema property for specifying default values for undefined fields"
        },
        {
          "term": "CustomResourceDefaulting",
          "tier": 1,
          "reasoning": "Kubernetes feature gate controlling defaulting behavior for custom resources"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling features"
        },
        {
          "term": "spec.preserveUnknownFields",
          "tier": 1,
          "reasoning": "CRD spec field controlling preservation of unknown fields"
        },
        {
          "term": "JSON",
          "tier": 2,
          "reasoning": "Data format type representing valid JSON values in Kubernetes"
        },
        {
          "term": "definitions",
          "tier": 2,
          "reasoning": "JSON Schema keyword for reusable schema definitions"
        },
        {
          "term": "dependencies",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining property dependencies"
        },
        {
          "term": "JSONSchemaPropsOrStringArray",
          "tier": 1,
          "reasoning": "Kubernetes-specific type representing either JSONSchemaProps or string array"
        },
        {
          "term": "description",
          "tier": 3,
          "reasoning": "JSON Schema property for human-readable descriptions"
        },
        {
          "term": "enum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for defining allowed values"
        },
        {
          "term": "example",
          "tier": 3,
          "reasoning": "JSON Schema property for providing example values"
        },
        {
          "term": "exclusiveMaximum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive upper bound validation"
        },
        {
          "term": "exclusiveMinimum",
          "tier": 2,
          "reasoning": "JSON Schema keyword for exclusive lower bound validation"
        },
        {
          "term": "externalDocs",
          "tier": 2,
          "reasoning": "OpenAPI/JSON Schema property for external documentation references"
        },
        {
          "term": "ExternalDocumentation",
          "tier": 1,
          "reasoning": "Kubernetes type for referencing external documentation resources"
        },
        {
          "term": "format",
          "tier": 2,
          "reasoning": "JSON Schema/OpenAPI property for string format validation"
        },
        {
          "term": "OpenAPI v3",
          "tier": 2,
          "reasoning": "API specification standard used by Kubernetes"
        },
        {
          "term": "bsonobjectid",
          "tier": 3,
          "reasoning": "Format string for BSON object ID validation"
        },
        {
          "term": "uri",
          "tier": 3,
          "reasoning": "Format string for URI validation"
        },
        {
          "term": "email",
          "tier": 3,
          "reasoning": "Format string for email address validation"
        },
        {
          "term": "hostname",
          "tier": 3,
          "reasoning": "Format string for hostname validation per RFC 1034"
        },
        {
          "term": "RFC 1034",
          "tier": 3,
          "reasoning": "Internet standard defining hostname format"
        },
        {
          "term": "ipv4",
          "tier": 3,
          "reasoning": "Format string for IPv4 address validation"
        },
        {
          "term": "ipv6",
          "tier": 3,
          "reasoning": "Format string for IPv6 address validation"
        },
        {
          "term": "cidr",
          "tier": 3,
          "reasoning": "Format string for CIDR notation validation"
        },
        {
          "term": "mac",
          "tier": 3,
          "reasoning": "Format string for MAC address validation"
        },
        {
          "term": "uuid",
          "tier": 3,
          "reasoning": "Format string for UUID validation"
        },
        {
          "term": "uuid3",
          "tier": 3,
          "reasoning": "Format string for UUID version 3 validation"
        },
        {
          "term": "uuid4",
          "tier": 3,
          "reasoning": "Format string for UUID version 4 validation"
        },
        {
          "term": "uuid5",
          "tier": 3,
          "reasoning": "Format string for UUID version 5 validation"
        },
        {
          "term": "isbn",
          "tier": 3,
          "reasoning": "Format string for ISBN number validation"
        },
        {
          "term": "isbn10",
          "tier": 3,
          "reasoning": "Format string for ISBN-10 validation"
        },
        {
          "term": "isbn13",
          "tier": 3,
          "reasoning": "Format string for ISBN-13 validation"
        },
        {
          "term": "creditcard",
          "tier": 3,
          "reasoning": "Format string for credit card number validation"
        },
        {
          "term": "custom-resource-definition-v1",
          "tier": 1,
          "reasoning": "Kubernetes API resource version reference for CRDs"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Kubernetes feature lifecycle stage indicating maturing feature"
        },
        {
          "term": "regex",
          "tier": 3,
          "reasoning": "Regular expression pattern used for format validation"
        },
        {
          "term": "Golang",
          "tier": 3,
          "reasoning": "Programming language used for parsing and validation implementations"
        },
        {
          "term": "net/url.ParseRequestURI",
          "tier": 3,
          "reasoning": "Go standard library function for URI parsing"
        },
        {
          "term": "net/mail.ParseAddress",
          "tier": 3,
          "reasoning": "Go standard library function for email parsing"
        },
        {
          "term": "net.ParseIP",
          "tier": 3,
          "reasoning": "Go standard library function for IP address parsing"
        },
        {
          "term": "net.ParseCIDR",
          "tier": 3,
          "reasoning": "Go standard library function for CIDR parsing"
        },
        {
          "term": "net.ParseMAC",
          "tier": 3,
          "reasoning": "Go standard library function for MAC address parsing"
        }
      ],
      "term_count": 54,
      "generated_at": "2026-02-08T22:02:18.898567",
      "elapsed_time": 21.672163248062134
    },
    {
      "chunk_id": "concepts_storage_volume-pvc-datasource_sec0",
      "doc_id": "concepts_storage_volume-pvc-datasource",
      "heading": "Introduction",
      "source_file": "concepts_storage_volume-pvc-datasource.md",
      "content": "---\nreviewers:\n- jsafrane\n- saad-ali\n- thockin\n- msau42\ntitle: CSI Volume Cloning\ncontent_type: concept\nweight: 70\n---\n\n<!-- overview -->\n\nThis document describes the concept of cloning existing CSI Volumes in Kubernetes.\nFamiliarity with [Volumes](/docs/concepts/storage/volumes) is suggested.\n\n<!-- body -->",
      "terms": [
        {
          "term": "CSI",
          "tier": 1,
          "reasoning": "Container Storage Interface - a core Kubernetes storage standard/protocol for volume plugins."
        },
        {
          "term": "CSI Volumes",
          "tier": 1,
          "reasoning": "Specific Kubernetes storage resource type using the Container Storage Interface."
        },
        {
          "term": "CSI Volume Cloning",
          "tier": 2,
          "reasoning": "A specific Kubernetes storage feature/process for duplicating CSI-based volumes."
        },
        {
          "term": "Volumes",
          "tier": 1,
          "reasoning": "Core Kubernetes storage API object/resource for persistent data."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "cloning",
          "tier": 2,
          "reasoning": "Technical process of duplicating storage volumes in the Kubernetes context."
        }
      ],
      "term_count": 6,
      "generated_at": "2026-02-08T22:02:24.887183",
      "elapsed_time": 4.97821044921875
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_run__index_sec3",
      "doc_id": "reference_kubectl_generated_kubectl_run__index",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_run__index.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--allow-missing-template-keys&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--annotations strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Annotations to apply to the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--attach</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for the Pod to start running, and then attach to the Pod as if 'kubectl attach ...' were called.  Default false, unless '-i/--stdin' is set, in which case the default is true. With '--restart=Never' the exit code of the container process is returned.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cascade string[=\"background\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"background\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;background&quot;, &quot;orphan&quot;, or &quot;foreground&quot;. Selects the deletion cascading strategy for the dependents (e.g. Pods created by a ReplicationController). Defaults to background.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--command</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true and extra arguments are present, use them as the 'command' field in the container, rather than the 'args' field which is the default.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--dry-run string[=\"unchanged\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;none&quot;, &quot;server&quot;, or &quot;client&quot;. If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--env strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Environment variables to set in the container.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--expose --port</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, create a ClusterIP service associated with the pod.  Requires --port.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--field-manager string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"kubectl-run\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the manager used to track field ownership.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-f, --filename strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>to use to replace the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--force</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, immediately remove resources from API and bypass graceful deletion. Note that immediate deletion of some resources may result in inconsistency or data loss and requires confirmation.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--grace-period int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: -1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Period of time in seconds given to the resource to terminate gracefully. Ignored if negative. Set to 1 for immediate shutdown. Can only be set to 0 when --force is true (force deletion).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for run</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image for the container to run.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image-pull-policy string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The image pull policy for the container.  If left empty, this value will not be specified by the client and defaulted by the server.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-k, --kustomize string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process a kustomization directory. This flag can't be used together with -f or -R.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-l, --labels string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Comma separated labels to apply to the pod. Will override previous values.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--leave-stdin-open</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If the pod is started in interactive mode or with stdin, leave stdin open after the first attach completes. By default, stdin will be closed after the first attach completes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-o, --output string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Output format. One of: (json, yaml, kyaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--override-type string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"merge\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The method used to override the generated object: json, merge, or strategic.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--overrides string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>An inline JSON override for the generated object. If this is non-empty, it is used to override the generated object. Requires that the object supply a valid apiVersion field.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--pod-running-timeout duration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1m0s</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time (like 5s, 2m, or 3h, higher than zero) to wait until at least one pod is running</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--port string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The port that this container exposes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--privileged</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, run the container in privileged mode.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-q, --quiet</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, suppress prompt messages.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-R, --recursive</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--restart string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"Always\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The restart policy for this Pod.  Legal values [Always, OnFailure, Never].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--rm</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, delete the pod after it exits.  Only valid when attaching to the container, e.g. with '--attach' or with '-i/--stdin'.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--save-config</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the configuration of current object will be saved in its annotation. Otherwise, the annotation will be unchanged. This flag is useful when you want to perform kubectl apply on this object in the future.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--show-managed-fields</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, keep the managedFields when printing objects in JSON or YAML format.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-i, --stdin</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Keep stdin open on the container in the pod, even if nothing is attached.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--template string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--timeout duration</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time to wait before giving up on a delete, zero means determine a timeout from the size of the object</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-t, --tty</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Allocate a TTY for the container in the pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--wait</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, wait for resources to be gone before returning. This waits for finalizers.</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Kubernetes API object that ensures a specified number of pod replicas are running."
        },
        {
          "term": "ClusterIP service",
          "tier": 1,
          "reasoning": "Specific Kubernetes Service type that exposes the service on a cluster-internal IP."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool, referenced as 'kubectl attach' and 'kubectl-run'."
        },
        {
          "term": "kubectl attach",
          "tier": 1,
          "reasoning": "Specific kubectl command for attaching to a running container."
        },
        {
          "term": "kubectl-run",
          "tier": 1,
          "reasoning": "Field manager name for the kubectl run command."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept representing an isolated runtime environment for applications."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Technical concept for output formatting in golang and jsonpath contexts."
        },
        {
          "term": "golang",
          "tier": 3,
          "reasoning": "Programming language referenced as an output format type."
        },
        {
          "term": "jsonpath",
          "tier": 2,
          "reasoning": "Query language for JSON used as an output format in kubectl."
        },
        {
          "term": "annotations",
          "tier": 2,
          "reasoning": "Kubernetes metadata concept for attaching non-identifying information to objects."
        },
        {
          "term": "stdin",
          "tier": 3,
          "reasoning": "Standard input stream, referenced as -i/--stdin flag behavior."
        },
        {
          "term": "exit code",
          "tier": 3,
          "reasoning": "Technical concept for process termination status returned by container."
        },
        {
          "term": "cascade",
          "tier": 2,
          "reasoning": "Deletion strategy concept for handling dependent resources."
        },
        {
          "term": "deletion cascading strategy",
          "tier": 2,
          "reasoning": "Technical process for managing dependent resource deletion."
        },
        {
          "term": "dependents",
          "tier": 2,
          "reasoning": "Kubernetes concept for resources owned by or dependent on other resources."
        },
        {
          "term": "background",
          "tier": 2,
          "reasoning": "Cascade deletion mode where deletion happens asynchronously."
        },
        {
          "term": "orphan",
          "tier": 2,
          "reasoning": "Cascade deletion mode where dependents are left without owner references."
        },
        {
          "term": "foreground",
          "tier": 2,
          "reasoning": "Cascade deletion mode where owner waits for dependents to be deleted."
        },
        {
          "term": "command",
          "tier": 2,
          "reasoning": "Container specification field that overrides the container entrypoint."
        },
        {
          "term": "args",
          "tier": 2,
          "reasoning": "Container specification field for arguments passed to the entrypoint."
        },
        {
          "term": "dry-run",
          "tier": 2,
          "reasoning": "Operational mode for testing changes without persisting them."
        },
        {
          "term": "server-side request",
          "tier": 2,
          "reasoning": "API request processed by the Kubernetes API server."
        },
        {
          "term": "client strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where object is only printed locally."
        },
        {
          "term": "server strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where request is submitted but not persisted."
        },
        {
          "term": "environment variables",
          "tier": 2,
          "reasoning": "Configuration mechanism for passing values to containers."
        },
        {
          "term": "field manager",
          "tier": 2,
          "reasoning": "Server-side apply concept for tracking field ownership."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Kubernetes concept for tracking which manager controls which fields."
        },
        {
          "term": "--port",
          "tier": 2,
          "reasoning": "CLI flag for specifying port configuration."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "General Kubernetes term for API objects that can be created/managed."
        },
        {
          "term": "graceful deletion",
          "tier": 2,
          "reasoning": "Process allowing resources time to terminate cleanly."
        },
        {
          "term": "grace-period",
          "tier": 2,
          "reasoning": "Time period for graceful termination of resources."
        },
        {
          "term": "immediate deletion",
          "tier": 2,
          "reasoning": "Forced removal of resources without waiting for graceful shutdown."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, referenced in context of resource removal."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image used to run containers in pods."
        },
        {
          "term": "image-pull-policy",
          "tier": 2,
          "reasoning": "Kubernetes configuration for when to pull container images."
        },
        {
          "term": "attach",
          "tier": 2,
          "reasoning": "Operation to connect to a running container's stdin/stdout."
        },
        {
          "term": "--restart=Never",
          "tier": 2,
          "reasoning": "Pod restart policy option indicating no automatic restarts."
        },
        {
          "term": "container process",
          "tier": 2,
          "reasoning": "The main process running inside a container."
        }
      ],
      "term_count": 39,
      "generated_at": "2026-02-08T22:02:47.589850",
      "elapsed_time": 21.691736936569214
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_patch__index_sec2",
      "doc_id": "reference_kubectl_generated_kubectl_patch__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_patch__index.md",
      "content": "```\n  # Partially update a node using a strategic merge patch, specifying the patch as JSON\n  kubectl patch node k8s-node-1 -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Partially update a node using a strategic merge patch, specifying the patch as YAML\n  kubectl patch node k8s-node-1 -p $'spec:\\n unschedulable: true'\n  \n  # Partially update a node identified by the type and name specified in \"node.json\" using strategic merge patch\n  kubectl patch -f node.json -p '{\"spec\":{\"unschedulable\":true}}'\n  \n  # Update a container's image; spec.containers[*].name is required because it's a merge key\n  kubectl patch pod valid-pod -p '{\"spec\":{\"containers\":[{\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"}]}}'\n  \n  # Update a container's image using a JSON patch with positional arrays\n  kubectl patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"}]'\n  \n  # Update a deployment's replicas through the 'scale' subresource using a merge patch\n  kubectl patch deployment nginx-deployment --subresource='scale' --type='merge' -p '{\"spec\":{\"replicas\":2}}'\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout the documentation chunk."
        },
        {
          "term": "node",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing a worker machine in the cluster."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing replicated applications."
        },
        {
          "term": "k8s-node-1",
          "tier": 1,
          "reasoning": "Specific node name used as an example in the commands."
        },
        {
          "term": "valid-pod",
          "tier": 1,
          "reasoning": "Specific pod name used as an example in the commands."
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific deployment name used as an example in the commands."
        },
        {
          "term": "kubernetes-serve-hostname",
          "tier": 1,
          "reasoning": "Specific container name used as an example in the patch command."
        },
        {
          "term": "patch",
          "tier": 2,
          "reasoning": "Kubernetes operation for partially updating resources without replacing them entirely."
        },
        {
          "term": "strategic merge patch",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch strategy that understands the schema of Kubernetes objects."
        },
        {
          "term": "JSON patch",
          "tier": 2,
          "reasoning": "RFC 6902 standard patch format supported by Kubernetes for precise updates."
        },
        {
          "term": "merge patch",
          "tier": 2,
          "reasoning": "Patch type that merges the provided fields with existing object fields."
        },
        {
          "term": "subresource",
          "tier": 2,
          "reasoning": "Kubernetes concept for accessing specific aspects of a resource like scale or status."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Kubernetes subresource for adjusting the number of replicas."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes object field containing the desired state specification."
        },
        {
          "term": "unschedulable",
          "tier": 2,
          "reasoning": "Node spec field that prevents new pods from being scheduled on the node."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Pod spec field containing the list of container definitions."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental unit of deployment within a pod."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container specification field defining the container image to run."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Deployment/scale spec field defining the desired number of pod instances."
        },
        {
          "term": "merge key",
          "tier": 2,
          "reasoning": "Field used by strategic merge patch to identify list items for merging."
        },
        {
          "term": "positional arrays",
          "tier": 2,
          "reasoning": "JSON patch technique for addressing array elements by index position."
        },
        {
          "term": "JSON",
          "tier": 3,
          "reasoning": "Data format used for specifying patches in kubectl commands."
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data format alternative to JSON for specifying patches."
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Required container field that serves as the merge key for strategic merge patch."
        },
        {
          "term": "node.json",
          "tier": 2,
          "reasoning": "File reference for specifying resource type and name in patch operations."
        },
        {
          "term": "-p",
          "tier": 2,
          "reasoning": "kubectl patch flag for specifying the patch content."
        },
        {
          "term": "-f",
          "tier": 2,
          "reasoning": "kubectl flag for specifying a file containing resource definition."
        },
        {
          "term": "--type",
          "tier": 2,
          "reasoning": "kubectl patch flag for specifying the patch type (json, merge, strategic)."
        },
        {
          "term": "--subresource",
          "tier": 2,
          "reasoning": "kubectl flag for targeting a specific subresource of an object."
        },
        {
          "term": "op",
          "tier": 3,
          "reasoning": "JSON patch operation field specifying the action (replace, add, remove)."
        },
        {
          "term": "replace",
          "tier": 3,
          "reasoning": "JSON patch operation that replaces a value at a specified path."
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "JSON patch field specifying the location in the object to modify."
        },
        {
          "term": "value",
          "tier": 3,
          "reasoning": "JSON patch field specifying the new value to set."
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T22:03:05.676438",
      "elapsed_time": 17.076692819595337
    },
    {
      "chunk_id": "tasks_debug_debug-application_get-shell-running-container_sec0",
      "doc_id": "tasks_debug_debug-application_get-shell-running-container",
      "heading": "Introduction",
      "source_file": "tasks_debug_debug-application_get-shell-running-container.md",
      "content": "---\nreviewers:\n- caesarxuchao\n- mikedanese\ntitle: Get a Shell to a Running Container\ncontent_type: task\n---\n\n<!-- overview -->\n\nThis page shows how to use `kubectl exec` to get a shell to a\nrunning container.",
      "terms": [
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for executing commands in containers, a core Kubernetes CLI operation."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool, a core CLI component."
        },
        {
          "term": "exec",
          "tier": 2,
          "reasoning": "A specific kubectl command/operation for executing commands inside containers."
        },
        {
          "term": "shell",
          "tier": 2,
          "reasoning": "Technical term referring to command-line interface access to a container's environment."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes/containerization concept representing an isolated runtime environment."
        },
        {
          "term": "running container",
          "tier": 2,
          "reasoning": "Domain-specific phrase describing a container in active execution state."
        },
        {
          "term": "task",
          "tier": 3,
          "reasoning": "Content type classification indicating procedural documentation in Kubernetes docs."
        }
      ],
      "term_count": 7,
      "generated_at": "2026-02-08T22:03:12.833014",
      "elapsed_time": 6.143071413040161
    },
    {
      "chunk_id": "reference_glossary_host-aliases_sec0",
      "doc_id": "reference_glossary_host-aliases",
      "heading": "Introduction",
      "source_file": "reference_glossary_host-aliases.md",
      "content": "---\ntitle: HostAliases\nid: HostAliases\ndate: 2019-01-31\nfull_link: /docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core\nshort_description: >\n  A HostAliases is a mapping between the IP address and hostname to be injected into a Pod's hosts file.\n\naka:\ntags:\n- operation\n---\n A HostAliases is a mapping between the IP address and hostname to be injected into a {{< glossary_tooltip text=\"Pod\" term_id=\"pod\" >}}'s hosts file.\n\n<!--more-->\n\n[HostAliases](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#hostalias-v1-core) is an optional list of hostnames and IP addresses that will be injected into the Pod's hosts file if specified. This is only valid for non-hostNetwork Pods.",
      "terms": [
        {
          "term": "HostAliases",
          "tier": 1,
          "reasoning": "Named Kubernetes API object for mapping IP addresses to hostnames in Pod hosts files"
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource that HostAliases is injected into"
        },
        {
          "term": "IP address",
          "tier": 2,
          "reasoning": "Network addressing concept that is one half of the HostAliases mapping"
        },
        {
          "term": "hostname",
          "tier": 2,
          "reasoning": "Network naming concept that is the other half of the HostAliases mapping"
        },
        {
          "term": "hosts file",
          "tier": 3,
          "reasoning": "Operating system file that maps hostnames to IP addresses, target of HostAliases injection"
        },
        {
          "term": "hostNetwork",
          "tier": 2,
          "reasoning": "Kubernetes Pod networking mode that affects HostAliases validity"
        },
        {
          "term": "non-hostNetwork Pods",
          "tier": 2,
          "reasoning": "Specific Pod configuration context where HostAliases is valid"
        },
        {
          "term": "mapping",
          "tier": 3,
          "reasoning": "Technical concept describing the relationship between IP and hostname in HostAliases"
        },
        {
          "term": "injected",
          "tier": 3,
          "reasoning": "Technical process term describing how HostAliases entries are added to the hosts file"
        },
        {
          "term": "hostalias-v1-core",
          "tier": 1,
          "reasoning": "Kubernetes API reference identifier for the HostAlias resource in core v1 API"
        },
        {
          "term": "kubernetes-api",
          "tier": 1,
          "reasoning": "Reference to the Kubernetes API documentation and specification"
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T22:03:21.913143",
      "elapsed_time": 8.069787502288818
    },
    {
      "chunk_id": "concepts_scheduling-eviction_dynamic-resource-allocation_sec1",
      "doc_id": "concepts_scheduling-eviction_dynamic-resource-allocation",
      "heading": "About DRA {#about-dra}",
      "source_file": "concepts_scheduling-eviction_dynamic-resource-allocation.md",
      "content": "{{< glossary_definition prepend=\"DRA is\" term_id=\"dra\" length=\"all\" >}}\n\nAllocating resources with DRA is a similar experience to\n[dynamic volume provisioning](/docs/concepts/storage/dynamic-provisioning/), in\nwhich you use PersistentVolumeClaims to claim storage capacity from storage\nclasses and request the claimed capacity in your Pods.\n\n### Benefits of DRA {#dra-benefits}\n\nDRA provides a flexible way to categorize, request, and use devices in your\ncluster. Using DRA provides benefits like the following:\n\n* **Flexible device filtering**: use common expression language (CEL) to perform\n  fine-grained filtering for specific device attributes.\n* **Device sharing**: share the same resource with multiple containers or Pods\n  by referencing the corresponding resource claim.\n* **Centralized device categorization**: device drivers and cluster admins can\n  use device classes to provide app operators with hardware categories that are\n  optimized for various use cases. For example, you can create a cost-optimized\n  device class for general-purpose workloads, and a high-performance device\n  class for critical jobs.\n* **Simplified Pod requests**: with DRA, app operators don't need to specify\n  device quantities in Pod resource requests. Instead, the Pod references a\n  resource claim, and the device configuration in that claim applies to the Pod.\n\nThese benefits provide significant improvements in the device allocation\nworkflow when compared to\n[device plugins](/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/),\nwhich require per-container device requests, don't support device sharing, and\ndon't support expression-based device filtering.\n\n### Types of DRA users {#dra-user-types}\n\nThe workflow of using DRA to allocate devices involves the following types of\nusers:\n\n* **Device owner**: responsible for devices. Device owners might be commercial\n  vendors, the cluster operator, or another entity. To use DRA, devices must\n  have DRA-compatible drivers that do the following:\n\n  * Create ResourceSlices that provide Kubernetes with information about\n    nodes and resources.\n  * Update ResourceSlices when resource capacity in the cluster changes.\n  * Optionally, create DeviceClasses that workload operators can use to\n    claim devices.\n\n* **Cluster admin**: responsible for configuring clusters and nodes,\n  attaching devices, installing drivers, and similar tasks. To use DRA,\n  cluster admins do the following:\n\n  * Attach devices to nodes.\n  * Install device drivers that support DRA.\n  * Optionally, create DeviceClasses that workload operators can use to claim\n    devices.\n\n* **Workload operator**: responsible for deploying and managing workloads in the\n  cluster. To use DRA to allocate devices to Pods, workload operators do the\n  following:\n\n  * Create ResourceClaims or ResourceClaimTemplates to request specific\n    configurations within DeviceClasses.\n  * Deploy workloads that use specific ResourceClaims or ResourceClaimTemplates.",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Core Kubernetes feature/API for Dynamic Resource Allocation, the main subject of this documentation."
        },
        {
          "term": "dynamic volume provisioning",
          "tier": 2,
          "reasoning": "Kubernetes concept for automatically provisioning storage volumes."
        },
        {
          "term": "PersistentVolumeClaims",
          "tier": 1,
          "reasoning": "Kubernetes API object for claiming persistent storage capacity."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "CEL",
          "tier": 3,
          "reasoning": "Common Expression Language, a protocol/standard used for device filtering in DRA."
        },
        {
          "term": "common expression language",
          "tier": 2,
          "reasoning": "The full name of CEL, a domain-specific language for expressions."
        },
        {
          "term": "device filtering",
          "tier": 2,
          "reasoning": "Technical process for selecting devices based on attributes."
        },
        {
          "term": "device attributes",
          "tier": 2,
          "reasoning": "Technical concept describing properties of devices in DRA."
        },
        {
          "term": "resource claim",
          "tier": 2,
          "reasoning": "DRA concept for requesting device resources."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core Kubernetes/container orchestration concept for isolated runtime environments."
        },
        {
          "term": "device classes",
          "tier": 1,
          "reasoning": "DRA API object for categorizing devices by use case."
        },
        {
          "term": "DeviceClasses",
          "tier": 1,
          "reasoning": "Kubernetes API object name for device categorization in DRA."
        },
        {
          "term": "device drivers",
          "tier": 2,
          "reasoning": "Software components that enable device communication with Kubernetes."
        },
        {
          "term": "Pod resource requests",
          "tier": 2,
          "reasoning": "Kubernetes concept for specifying resource requirements in Pod specs."
        },
        {
          "term": "device allocation",
          "tier": 2,
          "reasoning": "Technical process of assigning devices to workloads."
        },
        {
          "term": "device plugins",
          "tier": 1,
          "reasoning": "Kubernetes extension mechanism for advertising device resources to nodes."
        },
        {
          "term": "ResourceSlices",
          "tier": 1,
          "reasoning": "DRA API object providing Kubernetes with node and resource information."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept representing worker machines in a cluster."
        },
        {
          "term": "resource capacity",
          "tier": 2,
          "reasoning": "Technical concept describing available resources in a cluster."
        },
        {
          "term": "ResourceClaims",
          "tier": 1,
          "reasoning": "DRA API object for requesting specific device configurations."
        },
        {
          "term": "ResourceClaimTemplates",
          "tier": 1,
          "reasoning": "DRA API object template for creating ResourceClaims."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes concept for applications running in the cluster."
        },
        {
          "term": "device owner",
          "tier": 2,
          "reasoning": "DRA user role responsible for devices and drivers."
        },
        {
          "term": "cluster admin",
          "tier": 2,
          "reasoning": "DRA user role responsible for cluster and node configuration."
        },
        {
          "term": "workload operator",
          "tier": 2,
          "reasoning": "DRA user role responsible for deploying and managing workloads."
        },
        {
          "term": "DRA-compatible drivers",
          "tier": 2,
          "reasoning": "Technical requirement for device drivers to work with DRA."
        },
        {
          "term": "device sharing",
          "tier": 2,
          "reasoning": "DRA capability allowing multiple containers/Pods to use the same device."
        },
        {
          "term": "expression-based device filtering",
          "tier": 2,
          "reasoning": "DRA capability for filtering devices using expressions like CEL."
        },
        {
          "term": "storage capacity",
          "tier": 2,
          "reasoning": "Technical concept for available storage in the cluster."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of core Kubernetes API object appearing in text."
        }
      ],
      "term_count": 31,
      "generated_at": "2026-02-08T22:03:40.500291",
      "elapsed_time": 17.5769464969635
    },
    {
      "chunk_id": "reference_using-api_server-side-apply_sec4",
      "doc_id": "reference_using-api_server-side-apply",
      "heading": "Merge strategy",
      "source_file": "reference_using-api_server-side-apply.md",
      "content": "The merging strategy, implemented with Server-Side Apply, provides a generally\nmore stable object lifecycle. Server-Side Apply tries to merge fields based on\nthe actor who manages them instead of overruling based on values. This way\nmultiple actors can update the same object without causing unexpected interference.\n\nWhen a user sends a _fully-specified intent_ object to the Server-Side Apply\nendpoint, the server merges it with the live object favoring the value from the\nrequest body if it is specified in both places. If the set of items present in\nthe applied config is not a superset of the items applied by the same user last\ntime, each missing item not managed by any other appliers is removed. For\nmore information about how an object's schema is used to make decisions when\nmerging, see\n[sigs.k8s.io/structured-merge-diff](https://sigs.k8s.io/structured-merge-diff).\n\nThe Kubernetes API (and the Go code that implements that API for Kubernetes) allows\ndefining _merge strategy markers_. These markers describe the merge strategy supported\nfor fields within Kubernetes objects.\nFor a {{< glossary_tooltip term_id=\"CustomResourceDefinition\" text=\"CustomResourceDefinition\" >}},\nyou can set these markers when you define the custom resource.\n\n| Golang marker   | OpenAPI extension            | Possible values                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| --------------- | ---------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `//+listType`   | `x-kubernetes-list-type`     | `atomic`/`set`/`map`                             | Applicable to lists. `set` applies to lists that include only scalar elements. These elements must be unique. `map` applies to lists of nested types only. The key values (see `listMapKey`) must be unique in the list. `atomic` can apply to any list. If configured as `atomic`, the entire list is replaced during merge. At any point in time, a single manager owns the list. If `set` or `map`, different managers can manage entries separately. |\n| `//+listMapKey` | `x-kubernetes-list-map-keys` | List of field names, e.g. `[\"port\", \"protocol\"]` | Only applicable when `+listType=map`. A list of field names whose values uniquely identify entries in the list. While there can be multiple keys, `listMapKey` is singular because keys need to be specified individually in the Go type. The key fields must be scalars.                                                                                                                                                                                |\n| `//+mapType`    | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to maps. `atomic` means that the map can only be entirely replaced by a single manager. `granular` means that the map supports separate managers updating individual fields.                                                                                                                                                                                                                                                                  |\n| `//+structType` | `x-kubernetes-map-type`      | `atomic`/`granular`                              | Applicable to structs; otherwise same usage and OpenAPI annotation as `//+mapType`.                                                                                                                                                                                                                                                                                                                                                                      |\n\nIf `listType` is missing, the API server interprets a\n`patchStrategy=merge` marker as a `listType=map` and the\ncorresponding `patchMergeKey` marker as a `listMapKey`.\n\nThe `atomic` list type is recursive.\n\n(In the [Go](https://go.dev/) code for Kubernetes, these markers are specified as\ncomments and code authors need not repeat them as field tags).",
      "terms": [
        {
          "term": "Server-Side Apply",
          "tier": 1,
          "reasoning": "Core Kubernetes API mechanism for applying configuration changes with field ownership tracking."
        },
        {
          "term": "merging strategy",
          "tier": 2,
          "reasoning": "Technical concept describing how object fields are combined during updates."
        },
        {
          "term": "object lifecycle",
          "tier": 2,
          "reasoning": "Domain concept referring to the stages and management of Kubernetes objects over time."
        },
        {
          "term": "actor",
          "tier": 2,
          "reasoning": "Technical term referring to an entity (user/controller) that manages fields in Server-Side Apply."
        },
        {
          "term": "fully-specified intent",
          "tier": 2,
          "reasoning": "Domain-specific concept describing a complete object specification sent to the API."
        },
        {
          "term": "live object",
          "tier": 2,
          "reasoning": "Technical term for the current state of an object in the Kubernetes API server."
        },
        {
          "term": "request body",
          "tier": 3,
          "reasoning": "API/HTTP concept referring to the payload sent in an API request."
        },
        {
          "term": "applied config",
          "tier": 2,
          "reasoning": "Technical term for the configuration that has been applied to an object."
        },
        {
          "term": "appliers",
          "tier": 2,
          "reasoning": "Domain term for actors/managers that apply configurations to objects."
        },
        {
          "term": "schema",
          "tier": 3,
          "reasoning": "Technical term for the structure definition used in merge decisions."
        },
        {
          "term": "structured-merge-diff",
          "tier": 1,
          "reasoning": "Specific library/project name for implementing structured merging in Kubernetes."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core component name for the API that exposes Kubernetes functionality."
        },
        {
          "term": "merge strategy markers",
          "tier": 2,
          "reasoning": "Domain-specific concept for annotations that define how fields should be merged."
        },
        {
          "term": "Kubernetes objects",
          "tier": 2,
          "reasoning": "Core domain concept referring to resources managed by Kubernetes."
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for defining custom resources."
        },
        {
          "term": "custom resource",
          "tier": 1,
          "reasoning": "Core Kubernetes concept for user-defined API extensions."
        },
        {
          "term": "Golang marker",
          "tier": 2,
          "reasoning": "Technical term for Go code annotations used to define merge behavior."
        },
        {
          "term": "OpenAPI extension",
          "tier": 2,
          "reasoning": "Technical concept for custom extensions to OpenAPI specifications."
        },
        {
          "term": "listType",
          "tier": 1,
          "reasoning": "Specific merge strategy marker name for defining list merge behavior."
        },
        {
          "term": "x-kubernetes-list-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension name for Kubernetes list type definitions."
        },
        {
          "term": "atomic",
          "tier": 2,
          "reasoning": "Merge strategy value indicating entire field replacement during merge."
        },
        {
          "term": "set",
          "tier": 2,
          "reasoning": "Merge strategy value for lists containing unique scalar elements."
        },
        {
          "term": "map",
          "tier": 2,
          "reasoning": "Merge strategy value for lists of nested types with unique keys."
        },
        {
          "term": "listMapKey",
          "tier": 1,
          "reasoning": "Specific merge strategy marker for defining unique key fields in map-type lists."
        },
        {
          "term": "x-kubernetes-list-map-keys",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for defining list map keys."
        },
        {
          "term": "mapType",
          "tier": 1,
          "reasoning": "Specific merge strategy marker for defining map merge behavior."
        },
        {
          "term": "x-kubernetes-map-type",
          "tier": 1,
          "reasoning": "Specific OpenAPI extension for Kubernetes map type definitions."
        },
        {
          "term": "granular",
          "tier": 2,
          "reasoning": "Merge strategy value allowing separate managers to update individual map fields."
        },
        {
          "term": "structType",
          "tier": 1,
          "reasoning": "Specific merge strategy marker for defining struct merge behavior."
        },
        {
          "term": "scalar elements",
          "tier": 2,
          "reasoning": "Technical term for simple/primitive values in lists."
        },
        {
          "term": "nested types",
          "tier": 2,
          "reasoning": "Technical term for complex/compound data structures within lists."
        },
        {
          "term": "key fields",
          "tier": 2,
          "reasoning": "Technical term for fields that uniquely identify entries in a list."
        },
        {
          "term": "manager",
          "tier": 2,
          "reasoning": "Domain term for an entity that owns and manages specific fields in an object."
        },
        {
          "term": "Go type",
          "tier": 3,
          "reasoning": "Programming language concept relevant to how markers are specified in Kubernetes code."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "API/networking term for the Server-Side Apply API location."
        },
        {
          "term": "fields",
          "tier": 2,
          "reasoning": "Technical term for individual properties within Kubernetes objects that can be managed."
        }
      ],
      "term_count": 36,
      "generated_at": "2026-02-08T22:04:02.759350",
      "elapsed_time": 21.24813437461853
    },
    {
      "chunk_id": "tasks_administer-cluster_kubelet-in-userns_sec6",
      "doc_id": "tasks_administer-cluster_kubelet-in-userns",
      "heading": "(unless you run another systemd in the namespace)",
      "source_file": "tasks_administer-cluster_kubelet-in-userns.md",
      "content": "SystemdCgroup = false\n```\n\nThe default path of the configuration file is `/etc/containerd/config.toml`.\nThe path can be specified with `containerd -c /path/to/containerd/config.toml`.\n\n{{% /tab %}}\n{{% tab name=\"CRI-O\" %}}\n\nRunning CRI-O in a user namespace is supported since CRI-O 1.22.\n\nCRI-O requires an environment variable `_CRIO_ROOTLESS=1` to be set.\n\nThe following configurations are also recommended:\n\n```toml\n[crio]\n  storage_driver = \"overlay\"",
      "terms": [
        {
          "term": "SystemdCgroup",
          "tier": 1,
          "reasoning": "Configuration parameter for container runtime cgroup management"
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Core container runtime component used in Kubernetes infrastructure"
        },
        {
          "term": "CRI-O",
          "tier": 1,
          "reasoning": "Container Runtime Interface implementation, a core Kubernetes container runtime"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "Technical concept referring to system configuration storage"
        },
        {
          "term": "/etc/containerd/config.toml",
          "tier": 1,
          "reasoning": "Specific filesystem path for containerd configuration"
        },
        {
          "term": "config.toml",
          "tier": 2,
          "reasoning": "Configuration file format used by container runtimes"
        },
        {
          "term": "user namespace",
          "tier": 2,
          "reasoning": "Linux kernel namespace concept for user isolation, critical for rootless containers"
        },
        {
          "term": "_CRIO_ROOTLESS",
          "tier": 1,
          "reasoning": "Specific environment variable required for CRI-O rootless operation"
        },
        {
          "term": "environment variable",
          "tier": 2,
          "reasoning": "Technical concept for passing configuration to processes"
        },
        {
          "term": "storage_driver",
          "tier": 1,
          "reasoning": "Configuration parameter specifying container storage backend"
        },
        {
          "term": "overlay",
          "tier": 2,
          "reasoning": "Specific storage driver type using overlay filesystem"
        },
        {
          "term": "crio",
          "tier": 1,
          "reasoning": "Configuration section identifier for CRI-O settings"
        },
        {
          "term": "toml",
          "tier": 3,
          "reasoning": "Configuration file format used by container runtimes"
        },
        {
          "term": "rootless",
          "tier": 2,
          "reasoning": "Container execution mode without root privileges, security concept"
        },
        {
          "term": "path",
          "tier": 3,
          "reasoning": "Filesystem path concept relevant to configuration location"
        },
        {
          "term": "-c",
          "tier": 1,
          "reasoning": "CLI flag for specifying containerd configuration file path"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T22:04:12.537870",
      "elapsed_time": 8.76627516746521
    },
    {
      "chunk_id": "reference_access-authn-authz_kubelet-authn-authz_sec0",
      "doc_id": "reference_access-authn-authz_kubelet-authn-authz",
      "heading": "Overview",
      "source_file": "reference_access-authn-authz_kubelet-authn-authz.md",
      "content": "A kubelet's HTTPS endpoint exposes APIs which give access to data of varying sensitivity,\nand allow you to perform operations with varying levels of power on the node and within containers.\n\nThis document describes how to authenticate and authorize access to the kubelet's HTTPS endpoint.",
      "terms": [
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes component that runs on each node and manages containers."
        },
        {
          "term": "HTTPS endpoint",
          "tier": 2,
          "reasoning": "Technical concept describing the secure API access point exposed by the kubelet."
        },
        {
          "term": "HTTPS",
          "tier": 3,
          "reasoning": "Protocol standard for secure HTTP communication used by the kubelet's endpoint."
        },
        {
          "term": "endpoint",
          "tier": 3,
          "reasoning": "Technical networking term referring to an accessible API interface."
        },
        {
          "term": "APIs",
          "tier": 2,
          "reasoning": "Application Programming Interfaces exposed by the kubelet for programmatic access."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to a worker machine in the cluster."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core domain concept for isolated runtime environments managed by Kubernetes."
        },
        {
          "term": "authenticate",
          "tier": 2,
          "reasoning": "Security process concept for verifying identity when accessing the kubelet API."
        },
        {
          "term": "authorize",
          "tier": 2,
          "reasoning": "Security process concept for determining permissions after authentication."
        },
        {
          "term": "access",
          "tier": 3,
          "reasoning": "Technical term in security context referring to the ability to interact with resources."
        },
        {
          "term": "data",
          "tier": 3,
          "reasoning": "Technical term referring to information exposed through the kubelet APIs."
        },
        {
          "term": "sensitivity",
          "tier": 3,
          "reasoning": "Security-related term describing the classification level of exposed data."
        },
        {
          "term": "operations",
          "tier": 3,
          "reasoning": "Technical term referring to actions that can be performed via the kubelet API."
        }
      ],
      "term_count": 13,
      "generated_at": "2026-02-08T22:04:21.654121",
      "elapsed_time": 8.097816467285156
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec1",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "CustomResourceDefinition {#CustomResourceDefinition}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "CustomResourceDefinition represents a resource that should be exposed on the API server.  Its name MUST be in the format \\<.spec.name>.\\<.spec.group>.\n\n<hr>\n\n- **apiVersion**: apiextensions.k8s.io/v1\n\n\n- **kind**: CustomResourceDefinition\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/object-meta#ObjectMeta\" >}}\">ObjectMeta</a>)\n\n  Standard object's metadata More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **spec** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#CustomResourceDefinitionSpec\" >}}\">CustomResourceDefinitionSpec</a>), required\n\n  spec describes how the user wants the resources to appear\n\n- **status** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#CustomResourceDefinitionStatus\" >}}\">CustomResourceDefinitionStatus</a>)\n\n  status indicates the actual state of the CustomResourceDefinition",
      "terms": [
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for extending the API server with custom resources."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that exposes the Kubernetes API."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the version of the API schema for an object."
        },
        {
          "term": "apiextensions.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific API group and version for CustomResourceDefinition resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Standard Kubernetes object field containing identifying information like name and labels."
        },
        {
          "term": "ObjectMeta",
          "tier": 1,
          "reasoning": "Kubernetes API type that defines the standard metadata structure for all objects."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes API field that describes the desired state of a resource."
        },
        {
          "term": "CustomResourceDefinitionSpec",
          "tier": 1,
          "reasoning": "Specific Kubernetes type defining the specification structure for CRDs."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API field that indicates the current observed state of a resource."
        },
        {
          "term": "CustomResourceDefinitionStatus",
          "tier": 1,
          "reasoning": "Specific Kubernetes type defining the status structure for CRDs."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to API objects that can be created and managed."
        },
        {
          "term": ".spec.name",
          "tier": 2,
          "reasoning": "Field path reference indicating the name field within the spec of a CRD."
        },
        {
          "term": ".spec.group",
          "tier": 2,
          "reasoning": "Field path reference indicating the API group field within the spec of a CRD."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Reference to Kubernetes API design conventions documentation."
        },
        {
          "term": "extend-resources",
          "tier": 2,
          "reasoning": "Kubernetes documentation category for resource extension mechanisms."
        },
        {
          "term": "common-definitions",
          "tier": 2,
          "reasoning": "Kubernetes documentation category for shared API type definitions."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T22:04:32.550043",
      "elapsed_time": 9.885009527206421
    },
    {
      "chunk_id": "concepts_security_security-checklist_sec1",
      "doc_id": "concepts_security_security-checklist",
      "heading": "Authentication & Authorization",
      "source_file": "concepts_security_security-checklist.md",
      "content": "- [ ] `system:masters` group is not used for user or component authentication after bootstrapping.\n- [ ] The kube-controller-manager is running with `--use-service-account-credentials`\n  enabled.\n- [ ] The root certificate is protected (either an offline CA, or a managed\n  online CA with effective access controls).\n- [ ] Intermediate and leaf certificates have an expiry date no more than 3\n  years in the future.\n- [ ] A process exists for periodic access review, and reviews occur no more\n  than 24 months apart.\n- [ ] The [Role Based Access Control Good Practices](/docs/concepts/security/rbac-good-practices/)\n  are followed for guidance related to authentication and authorization.\n\nAfter bootstrapping, neither users nor components should authenticate to the\nKubernetes API as `system:masters`. Similarly, running all of\nkube-controller-manager as `system:masters` should be avoided. In fact,\n`system:masters` should only be used as a break-glass mechanism, as opposed to\nan admin user.",
      "terms": [
        {
          "term": "system:masters",
          "tier": 1,
          "reasoning": "Kubernetes built-in group with superuser privileges, a specific named security principal."
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that runs controller processes."
        },
        {
          "term": "--use-service-account-credentials",
          "tier": 1,
          "reasoning": "CLI flag for kube-controller-manager configuration."
        },
        {
          "term": "root certificate",
          "tier": 2,
          "reasoning": "PKI/security concept referring to the top-level certificate authority."
        },
        {
          "term": "offline CA",
          "tier": 2,
          "reasoning": "Security architecture pattern for certificate authority management."
        },
        {
          "term": "CA",
          "tier": 2,
          "reasoning": "Abbreviation for Certificate Authority, a core PKI security concept."
        },
        {
          "term": "Intermediate and leaf certificates",
          "tier": 2,
          "reasoning": "PKI hierarchy concepts for certificate chain structure."
        },
        {
          "term": "Intermediate",
          "tier": 3,
          "reasoning": "Part of certificate hierarchy between root and leaf certificates."
        },
        {
          "term": "leaf certificates",
          "tier": 2,
          "reasoning": "End-entity certificates in PKI hierarchy."
        },
        {
          "term": "expiry date",
          "tier": 3,
          "reasoning": "Certificate lifecycle management concept."
        },
        {
          "term": "access review",
          "tier": 2,
          "reasoning": "Security compliance process for auditing permissions."
        },
        {
          "term": "Role Based Access Control",
          "tier": 2,
          "reasoning": "Authorization mechanism for controlling access based on roles."
        },
        {
          "term": "RBAC",
          "tier": 2,
          "reasoning": "Abbreviation visible in URL path, standard Kubernetes authorization mode."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Security concept for verifying identity of users and components."
        },
        {
          "term": "authorization",
          "tier": 2,
          "reasoning": "Security concept for determining permitted actions after authentication."
        },
        {
          "term": "bootstrapping",
          "tier": 2,
          "reasoning": "Cluster initialization process for setting up initial configuration."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for all Kubernetes operations and resource management."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface, general technical term used in Kubernetes context."
        },
        {
          "term": "access controls",
          "tier": 2,
          "reasoning": "Security mechanisms for restricting resource access."
        },
        {
          "term": "user",
          "tier": 3,
          "reasoning": "Identity type in Kubernetes authentication context."
        },
        {
          "term": "component",
          "tier": 3,
          "reasoning": "Kubernetes system component in authentication context."
        },
        {
          "term": "admin user",
          "tier": 2,
          "reasoning": "Administrative identity role in Kubernetes security model."
        },
        {
          "term": "break-glass mechanism",
          "tier": 2,
          "reasoning": "Emergency access pattern for exceptional administrative situations."
        },
        {
          "term": "service account",
          "tier": 2,
          "reasoning": "Kubernetes identity type for workloads, referenced in the flag name."
        },
        {
          "term": "Good Practices",
          "tier": 3,
          "reasoning": "Part of the referenced documentation title for security guidance."
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T22:04:47.089557",
      "elapsed_time": 13.528335809707642
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-pods-nodes_sec1",
      "doc_id": "tasks_configure-pod-container_assign-pods-nodes",
      "heading": "Create a pod that gets scheduled to your chosen node",
      "source_file": "tasks_configure-pod-container_assign-pods-nodes.md",
      "content": "This pod configuration file describes a pod that has a node selector,\n`disktype: ssd`. This means that the pod will get scheduled on a node that has\na `disktype=ssd` label.\n\n{{% code_sample file=\"pods/pod-nginx.yaml\" %}}\n\n1. Use the configuration file to create a pod that will get scheduled on your\n   chosen node:\n    \n    ```shell\n    kubectl apply -f https://k8s.io/examples/pods/pod-nginx.yaml\n    ```\n\n1. Verify that the pod is running on your chosen node:\n\n    ```shell\n    kubectl get pods --output=wide\n    ```\n\n    The output is similar to this:\n    \n    ```shell\n    NAME     READY     STATUS    RESTARTS   AGE    IP           NODE\n    nginx    1/1       Running   0          13s    10.200.0.4   worker0\n    ```",
      "terms": [
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit"
        },
        {
          "term": "node selector",
          "tier": 2,
          "reasoning": "Kubernetes scheduling mechanism that constrains pods to nodes with specific labels"
        },
        {
          "term": "disktype: ssd",
          "tier": 2,
          "reasoning": "Specific label key-value pair used for node selection criteria"
        },
        {
          "term": "disktype=ssd",
          "tier": 2,
          "reasoning": "Label selector syntax variant showing the node label requirement"
        },
        {
          "term": "label",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for organizing and selecting resources"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Kubernetes worker machine that runs pods"
        },
        {
          "term": "scheduled",
          "tier": 2,
          "reasoning": "Kubernetes scheduling process of assigning pods to nodes"
        },
        {
          "term": "configuration file",
          "tier": 2,
          "reasoning": "YAML/JSON file defining Kubernetes resource specifications"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for cluster management"
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubectl command for declarative resource creation/updates"
        },
        {
          "term": "kubectl get pods",
          "tier": 1,
          "reasoning": "Kubectl command for listing pod resources"
        },
        {
          "term": "--output=wide",
          "tier": 2,
          "reasoning": "Kubectl flag for extended output format showing additional columns"
        },
        {
          "term": "pods/pod-nginx.yaml",
          "tier": 2,
          "reasoning": "Example configuration file path for nginx pod definition"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Specific container image/application name used in the pod example"
        },
        {
          "term": "READY",
          "tier": 2,
          "reasoning": "Pod status field indicating container readiness state"
        },
        {
          "term": "STATUS",
          "tier": 2,
          "reasoning": "Pod lifecycle state indicator in kubectl output"
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "Pod phase indicating containers are executing"
        },
        {
          "term": "RESTARTS",
          "tier": 2,
          "reasoning": "Pod metric showing container restart count"
        },
        {
          "term": "AGE",
          "tier": 2,
          "reasoning": "Pod metadata showing time since creation"
        },
        {
          "term": "IP",
          "tier": 2,
          "reasoning": "Pod network address assigned within the cluster"
        },
        {
          "term": "NODE",
          "tier": 2,
          "reasoning": "Output column showing which node the pod is scheduled on"
        },
        {
          "term": "worker0",
          "tier": 2,
          "reasoning": "Example worker node name in the cluster"
        },
        {
          "term": "pod configuration file",
          "tier": 2,
          "reasoning": "Compound term for YAML file defining pod specifications"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for executing kubectl commands"
        },
        {
          "term": "1/1",
          "tier": 2,
          "reasoning": "Ready container count format showing running vs total containers"
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T22:05:01.068765",
      "elapsed_time": 12.96739912033081
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_config__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_config__index",
      "heading": "{{% heading \"synopsis\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_config__index.md",
      "content": "Modify kubeconfig files using subcommands like \"kubectl config set current-context my-context\".\n\n The loading order follows these rules:\n\n  1.  If the --kubeconfig flag is set, then only that file is loaded. The flag may only be set once and no merging takes place.\n  2.  If $KUBECONFIG environment variable is set, then it is used as a list of paths (normal path delimiting rules for your system). These paths are merged. When a value is modified, it is modified in the file that defines the stanza. When a value is created, it is created in the first file that exists. If no files in the chain exist, then it creates the last file in the list.\n  3.  Otherwise, ${HOME}/.kube/config is used and no merging takes place.\n\n```\nkubectl config SUBCOMMAND\n```",
      "terms": [
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Core Kubernetes configuration file type that stores cluster access credentials and context information."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool used to interact with clusters."
        },
        {
          "term": "kubectl config",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for managing kubeconfig files."
        },
        {
          "term": "--kubeconfig",
          "tier": 1,
          "reasoning": "CLI flag used to specify a custom kubeconfig file path."
        },
        {
          "term": "$KUBECONFIG",
          "tier": 1,
          "reasoning": "Environment variable that specifies kubeconfig file paths for Kubernetes CLI tools."
        },
        {
          "term": "KUBECONFIG",
          "tier": 1,
          "reasoning": "Environment variable name referenced for configuring kubeconfig file locations."
        },
        {
          "term": "current-context",
          "tier": 2,
          "reasoning": "Kubernetes configuration concept referring to the active cluster/user/namespace combination."
        },
        {
          "term": "context",
          "tier": 2,
          "reasoning": "Kubernetes concept representing a cluster, user, and namespace combination in kubeconfig."
        },
        {
          "term": "set current-context",
          "tier": 2,
          "reasoning": "Kubectl config operation to change the active context."
        },
        {
          "term": "SUBCOMMAND",
          "tier": 3,
          "reasoning": "Technical term describing secondary commands under a main CLI command."
        },
        {
          "term": "flag",
          "tier": 3,
          "reasoning": "CLI concept for command-line options that modify behavior."
        },
        {
          "term": "environment variable",
          "tier": 3,
          "reasoning": "OS-level concept for storing configuration values accessible to processes."
        },
        {
          "term": "paths",
          "tier": 3,
          "reasoning": "Technical term for file system locations used in configuration."
        },
        {
          "term": "merged",
          "tier": 2,
          "reasoning": "Technical process describing how multiple kubeconfig files are combined."
        },
        {
          "term": "merging",
          "tier": 2,
          "reasoning": "Configuration management concept for combining multiple config sources."
        },
        {
          "term": "stanza",
          "tier": 2,
          "reasoning": "Technical term for a distinct section or block within a configuration file."
        },
        {
          "term": "file",
          "tier": 3,
          "reasoning": "Basic technical term for data storage unit, contextually relevant to config files."
        },
        {
          "term": "${HOME}/.kube/config",
          "tier": 1,
          "reasoning": "Default kubeconfig file path location in Kubernetes installations."
        },
        {
          "term": ".kube/config",
          "tier": 1,
          "reasoning": "Standard kubeconfig file path relative to user home directory."
        },
        {
          "term": "${HOME}",
          "tier": 3,
          "reasoning": "Environment variable representing user's home directory path."
        },
        {
          "term": "loading order",
          "tier": 2,
          "reasoning": "Technical concept describing the precedence of configuration file processing."
        },
        {
          "term": "path delimiting rules",
          "tier": 3,
          "reasoning": "System-specific rules for separating multiple paths in environment variables."
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T22:05:15.701395",
      "elapsed_time": 13.620336055755615
    },
    {
      "chunk_id": "tasks_debug_debug-cluster_topology_sec2",
      "doc_id": "tasks_debug_debug-cluster_topology",
      "heading": "Troubleshoot `TopologyAffinityError` {#TopologyAffinityError}",
      "source_file": "tasks_debug_debug-cluster_topology.md",
      "content": "This error typically occurs in the following situations:\n\n* a node has not enough resources available to satisfy the pod's request\n* the pod's request is rejected due to particular Topology Manager policy constraints\n\nThe error appears in the status of a pod:\n\n```shell\nkubectl get pods\n```\n\n```none\nNAME         READY   STATUS                  RESTARTS   AGE\nguaranteed   0/1     TopologyAffinityError   0          113s\n```\n\nUse `kubectl describe pod <id>` or `kubectl events` to obtain a detailed error message:\n\n```none\nWarning  TopologyAffinityError  10m   kubelet, dell8  Resources cannot be allocated with Topology locality\n```",
      "terms": [
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to a worker machine in the cluster"
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Technical term referring to compute resources (CPU, memory) that can be requested by pods"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental deployable unit"
        },
        {
          "term": "request",
          "tier": 2,
          "reasoning": "Kubernetes resource management concept specifying minimum resources needed"
        },
        {
          "term": "Topology Manager",
          "tier": 1,
          "reasoning": "Specific Kubernetes component that manages NUMA topology-aware resource allocation"
        },
        {
          "term": "policy constraints",
          "tier": 2,
          "reasoning": "Technical concept referring to rules that govern resource allocation behavior"
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API field that describes the current state of an object"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters"
        },
        {
          "term": "kubectl get pods",
          "tier": 1,
          "reasoning": "Specific kubectl command to list pod resources"
        },
        {
          "term": "kubectl describe pod",
          "tier": 1,
          "reasoning": "Specific kubectl command to show detailed pod information"
        },
        {
          "term": "kubectl events",
          "tier": 1,
          "reasoning": "Specific kubectl command to view cluster events"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Plural form of pod, core Kubernetes API object"
        },
        {
          "term": "READY",
          "tier": 2,
          "reasoning": "Pod status field indicating container readiness state"
        },
        {
          "term": "STATUS",
          "tier": 2,
          "reasoning": "Pod status field showing current phase or error condition"
        },
        {
          "term": "RESTARTS",
          "tier": 2,
          "reasoning": "Pod status field tracking container restart count"
        },
        {
          "term": "AGE",
          "tier": 2,
          "reasoning": "Pod status field showing time since creation"
        },
        {
          "term": "TopologyAffinityError",
          "tier": 1,
          "reasoning": "Specific Kubernetes error status indicating topology-based scheduling failure"
        },
        {
          "term": "guaranteed",
          "tier": 2,
          "reasoning": "Kubernetes QoS class name indicating pods with equal requests and limits"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for pod lifecycle"
        },
        {
          "term": "Warning",
          "tier": 2,
          "reasoning": "Kubernetes event type indicating a non-fatal issue"
        },
        {
          "term": "Topology locality",
          "tier": 2,
          "reasoning": "Concept referring to NUMA-aware resource placement on nodes"
        },
        {
          "term": "error",
          "tier": 3,
          "reasoning": "Technical term describing failure conditions in system operations"
        },
        {
          "term": "error message",
          "tier": 3,
          "reasoning": "Technical output providing details about failure conditions"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for executing kubectl commands"
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T22:05:27.604739",
      "elapsed_time": 10.891401529312134
    },
    {
      "chunk_id": "tasks_debug_debug-cluster_kubectl-node-debug_sec2",
      "doc_id": "tasks_debug_debug-cluster_kubectl-node-debug",
      "heading": "Debugging a Node using `kubectl debug node`",
      "source_file": "tasks_debug_debug-cluster_kubectl-node-debug.md",
      "content": "Use the `kubectl debug node` command to deploy a Pod to a Node that you want to troubleshoot.\nThis command is helpful in scenarios where you can't access your Node by using an SSH connection.\nWhen the Pod is created, the Pod opens an interactive shell on the Node.\nTo create an interactive shell on a Node named \u201cmynode\u201d, run:\n\n```shell\nkubectl debug node/mynode -it --image=ubuntu\n```\n\n```console\nCreating debugging pod node-debugger-mynode-pdx84 with container debugger on node mynode.\nIf you don't see a command prompt, try pressing enter.\nroot@mynode:/#\n```\n\nThe debug command helps to gather information and troubleshoot issues. Commands \nthat you might use include `ip`, `ifconfig`, `nc`, `ping`, and `ps` and so on. You can also\ninstall other tools, such as `mtr`, `tcpdump`, and `curl`, from the respective package manager.\n\n{{< note >}}\n\nThe debug commands may differ based on the image the debugging pod is using and\nthese commands might need to be installed.\n\n{{< /note >}}\n\nThe debugging Pod can access the root filesystem of the Node, mounted at `/host` in the Pod.\nIf you run your kubelet in a filesystem namespace,\nthe debugging Pod sees the root for that namespace, not for the entire node. For a typical Linux node,\nyou can look at the following paths to find relevant logs:\n\n`/host/var/log/kubelet.log`\n: Logs from the `kubelet`, responsible for running containers on the node.\n\n`/host/var/log/kube-proxy.log`\n: Logs from `kube-proxy`, which is responsible for directing traffic to Service endpoints.\n\n`/host/var/log/containerd.log`\n: Logs from the `containerd` process running on the node.\n\n`/host/var/log/syslog`\n: Shows general messages and information regarding the system.\n\n`/host/var/log/kern.log`\n: Shows kernel logs.\n\nWhen creating a debugging session on a Node, keep in mind that:\n\n* `kubectl debug` automatically generates the name of the new pod, based on\n  the name of the node.\n* The root filesystem of the Node will be mounted at `/host`.\n* Although the container runs in the host IPC, Network, and PID namespaces,\n  the pod isn't privileged. This means that reading some process information might fail\n  because access to that information is restricted to superusers. For example, `chroot /host` will fail.\n  If you need a privileged pod, create it manually or use the `--profile=sysadmin` flag.\n* By applying [Debugging Profiles](/docs/tasks/debug/debug-application/debug-running-pod/#debugging-profiles), you can set specific properties such as [securityContext](/docs/tasks/configure-pod-container/security-context/) to a debugging Pod.",
      "terms": [
        {
          "term": "kubectl debug node",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for node debugging operations."
        },
        {
          "term": "kubectl debug",
          "tier": 1,
          "reasoning": "Core kubectl command for debugging resources."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and workload unit."
        },
        {
          "term": "Node",
          "tier": 1,
          "reasoning": "Core Kubernetes resource representing a worker machine."
        },
        {
          "term": "debugging pod",
          "tier": 1,
          "reasoning": "Specific type of Pod created for troubleshooting purposes."
        },
        {
          "term": "debugging Pod",
          "tier": 1,
          "reasoning": "Variant capitalization of debugging pod as used in the text."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for running containers."
        },
        {
          "term": "kube-proxy",
          "tier": 1,
          "reasoning": "Kubernetes network proxy component for Service traffic routing."
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Container runtime process running on nodes."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Kubernetes API object for network service abstraction."
        },
        {
          "term": "securityContext",
          "tier": 1,
          "reasoning": "Kubernetes Pod/container security configuration field."
        },
        {
          "term": "Debugging Profiles",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for configuring debug pod properties."
        },
        {
          "term": "--profile=sysadmin",
          "tier": 1,
          "reasoning": "Specific CLI flag for creating privileged debugging pods."
        },
        {
          "term": "--image",
          "tier": 1,
          "reasoning": "CLI flag specifying container image for debugging pod."
        },
        {
          "term": "SSH",
          "tier": 2,
          "reasoning": "Secure Shell protocol for remote node access."
        },
        {
          "term": "interactive shell",
          "tier": 2,
          "reasoning": "Terminal session concept for node troubleshooting."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core containerization concept for running workloads."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form of container as used in context."
        },
        {
          "term": "root filesystem",
          "tier": 2,
          "reasoning": "Linux filesystem concept relevant to node debugging access."
        },
        {
          "term": "filesystem namespace",
          "tier": 2,
          "reasoning": "Linux namespace type for filesystem isolation."
        },
        {
          "term": "host IPC",
          "tier": 2,
          "reasoning": "Inter-process communication namespace sharing with host."
        },
        {
          "term": "Network",
          "tier": 2,
          "reasoning": "Network namespace context for pod isolation."
        },
        {
          "term": "PID namespaces",
          "tier": 2,
          "reasoning": "Process ID namespace for container isolation."
        },
        {
          "term": "namespaces",
          "tier": 2,
          "reasoning": "Linux kernel isolation mechanism used by containers."
        },
        {
          "term": "privileged",
          "tier": 2,
          "reasoning": "Security context mode granting elevated container permissions."
        },
        {
          "term": "privileged pod",
          "tier": 2,
          "reasoning": "Pod with elevated security privileges."
        },
        {
          "term": "Service endpoints",
          "tier": 2,
          "reasoning": "Network destinations for Kubernetes Service traffic."
        },
        {
          "term": "traffic",
          "tier": 2,
          "reasoning": "Network traffic concept in context of kube-proxy routing."
        },
        {
          "term": "process information",
          "tier": 2,
          "reasoning": "System process data relevant to debugging."
        },
        {
          "term": "superusers",
          "tier": 2,
          "reasoning": "Privileged user access level for system operations."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image used for debugging pod."
        },
        {
          "term": "package manager",
          "tier": 2,
          "reasoning": "System tool for installing debugging utilities."
        },
        {
          "term": "ip",
          "tier": 3,
          "reasoning": "Linux networking command for troubleshooting."
        },
        {
          "term": "ifconfig",
          "tier": 3,
          "reasoning": "Network interface configuration command."
        },
        {
          "term": "nc",
          "tier": 3,
          "reasoning": "Netcat utility for network debugging."
        },
        {
          "term": "ping",
          "tier": 3,
          "reasoning": "Network connectivity testing command."
        },
        {
          "term": "ps",
          "tier": 3,
          "reasoning": "Process status command for debugging."
        },
        {
          "term": "mtr",
          "tier": 3,
          "reasoning": "Network diagnostic tool combining ping and traceroute."
        },
        {
          "term": "tcpdump",
          "tier": 3,
          "reasoning": "Packet capture tool for network troubleshooting."
        },
        {
          "term": "curl",
          "tier": 3,
          "reasoning": "HTTP client tool for testing endpoints."
        },
        {
          "term": "chroot",
          "tier": 3,
          "reasoning": "Linux command to change root directory."
        },
        {
          "term": "/host",
          "tier": 3,
          "reasoning": "Mount path for node root filesystem in debugging pod."
        },
        {
          "term": "/host/var/log/kubelet.log",
          "tier": 3,
          "reasoning": "Specific log file path for kubelet logs."
        },
        {
          "term": "/host/var/log/kube-proxy.log",
          "tier": 3,
          "reasoning": "Specific log file path for kube-proxy logs."
        },
        {
          "term": "/host/var/log/containerd.log",
          "tier": 3,
          "reasoning": "Specific log file path for containerd logs."
        },
        {
          "term": "/host/var/log/syslog",
          "tier": 3,
          "reasoning": "System log file path for general messages."
        },
        {
          "term": "/host/var/log/kern.log",
          "tier": 3,
          "reasoning": "Kernel log file path."
        },
        {
          "term": "kernel logs",
          "tier": 3,
          "reasoning": "Linux kernel logging output."
        },
        {
          "term": "syslog",
          "tier": 3,
          "reasoning": "System logging facility."
        },
        {
          "term": "ubuntu",
          "tier": 3,
          "reasoning": "Linux distribution used as debugging container image."
        },
        {
          "term": "Linux",
          "tier": 3,
          "reasoning": "Operating system context for node debugging."
        },
        {
          "term": "logs",
          "tier": 3,
          "reasoning": "Log files for troubleshooting node issues."
        }
      ],
      "term_count": 53,
      "generated_at": "2026-02-08T22:05:51.790696",
      "elapsed_time": 23.17345929145813
    },
    {
      "chunk_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1_sec1",
      "doc_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1",
      "heading": "ServiceCIDR {#ServiceCIDR}",
      "source_file": "reference_kubernetes-api_cluster-resources_service-cidr-v1.md",
      "content": "ServiceCIDR defines a range of IP addresses using CIDR format (e.g. 192.168.0.0/24 or 2001:db2::/64). This range is used to allocate ClusterIPs to Service objects.\n\n<hr>\n\n- **apiVersion**: networking.k8s.io/v1\n\n\n- **kind**: ServiceCIDR\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/object-meta#ObjectMeta\" >}}\">ObjectMeta</a>)\n\n  Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **spec** (<a href=\"{{< ref \"../cluster-resources/service-cidr-v1#ServiceCIDRSpec\" >}}\">ServiceCIDRSpec</a>)\n\n  spec is the desired state of the ServiceCIDR. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\n- **status** (<a href=\"{{< ref \"../cluster-resources/service-cidr-v1#ServiceCIDRStatus\" >}}\">ServiceCIDRStatus</a>)\n\n  status represents the current state of the ServiceCIDR. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status",
      "terms": [
        {
          "term": "ServiceCIDR",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for defining IP address ranges for Service allocation."
        },
        {
          "term": "CIDR",
          "tier": 2,
          "reasoning": "Domain-specific networking notation format for specifying IP address ranges."
        },
        {
          "term": "IP addresses",
          "tier": 3,
          "reasoning": "Fundamental networking concept used in the context of service allocation."
        },
        {
          "term": "ClusterIPs",
          "tier": 1,
          "reasoning": "Kubernetes-specific IP type allocated to Service objects within a cluster."
        },
        {
          "term": "Service",
          "tier": 1,
          "reasoning": "Core Kubernetes API object that receives ClusterIP allocations."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the API group and version for a resource."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for networking resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes API field containing standard object metadata like name and labels."
        },
        {
          "term": "ObjectMeta",
          "tier": 1,
          "reasoning": "Kubernetes API type that defines the structure of object metadata."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes API field representing the desired state specification of a resource."
        },
        {
          "term": "ServiceCIDRSpec",
          "tier": 1,
          "reasoning": "Kubernetes API type defining the specification structure for ServiceCIDR resources."
        },
        {
          "term": "status",
          "tier": 2,
          "reasoning": "Kubernetes API field representing the current observed state of a resource."
        },
        {
          "term": "ServiceCIDRStatus",
          "tier": 1,
          "reasoning": "Kubernetes API type defining the status structure for ServiceCIDR resources."
        },
        {
          "term": "desired state",
          "tier": 2,
          "reasoning": "Core Kubernetes concept describing the intended configuration of a resource."
        },
        {
          "term": "current state",
          "tier": 2,
          "reasoning": "Core Kubernetes concept describing the actual observed state of a resource."
        },
        {
          "term": "cluster-resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources that operate at cluster scope."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Kubernetes development standards referenced for metadata, spec, and status patterns."
        },
        {
          "term": "networking.k8s.io",
          "tier": 1,
          "reasoning": "Kubernetes API group for networking-related resources."
        },
        {
          "term": "192.168.0.0/24",
          "tier": 3,
          "reasoning": "Example IPv4 CIDR notation demonstrating the format used by ServiceCIDR."
        },
        {
          "term": "2001:db2::/64",
          "tier": 3,
          "reasoning": "Example IPv6 CIDR notation demonstrating dual-stack support in ServiceCIDR."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:06:03.727126",
      "elapsed_time": 10.921918630599976
    },
    {
      "chunk_id": "tasks_configure-pod-container_configure-pod-configmap_sec6",
      "doc_id": "tasks_configure-pod-container_configure-pod-configmap",
      "heading": "This comment and the empty line above it are ignored",
      "source_file": "tasks_configure-pod-container_configure-pod-configmap.md",
      "content": "```\n\n```shell\nkubectl create configmap game-config-env-file \\\n       --from-env-file=configure-pod-container/configmap/game-env-file.properties\n```\n\nwould produce a ConfigMap. View the ConfigMap:\n\n```shell\nkubectl get configmap game-config-env-file -o yaml\n```\n\nthe output is similar to:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2019-12-27T18:36:28Z\n  name: game-config-env-file\n  namespace: default\n  resourceVersion: \"809965\"\n  uid: d9d1ca5b-eb34-11e7-887b-42010a8002b8\ndata:\n  allowed: '\"true\"'\n  enemies: aliens\n  lives: \"3\"\n```\n\nStarting with Kubernetes v1.23, `kubectl` supports the `--from-env-file` argument to be\nspecified multiple times to create a ConfigMap from multiple data sources.\n\n```shell\nkubectl create configmap config-multi-env-files \\\n        --from-env-file=configure-pod-container/configmap/game-env-file.properties \\\n        --from-env-file=configure-pod-container/configmap/ui-env-file.properties\n```\n\nwould produce the following ConfigMap:\n\n```shell\nkubectl get configmap config-multi-env-files -o yaml\n```\n\nwhere the output is similar to this:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2019-12-27T18:38:34Z\n  name: config-multi-env-files\n  namespace: default\n  resourceVersion: \"810136\"\n  uid: 252c4572-eb35-11e7-887b-42010a8002b8\ndata:\n  allowed: '\"true\"'\n  color: purple\n  enemies: aliens\n  how: fairlyNice\n  lives: \"3\"\n  textmode: \"true\"\n```\n\n#### Define the key to use when creating a ConfigMap from a file\n\nYou can define a key other than the file name to use in the `data` section of your ConfigMap\nwhen using the `--from-file` argument:\n\n```shell\nkubectl create configmap game-config-3 --from-file=<my-key-name>=<path-to-file>\n```\n\nwhere `<my-key-name>` is the key you want to use in the ConfigMap and `<path-to-file>` is the\nlocation of the data source file you want the key to represent.\n\nFor example:\n\n```shell\nkubectl create configmap game-config-3 --from-file=game-special-key=configure-pod-container/configmap/game.properties\n```\n\nwould produce the following ConfigMap:\n```\nkubectl get configmaps game-config-3 -o yaml\n```\n\nwhere the output is similar to this:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2022-02-18T18:54:22Z\n  name: game-config-3\n  namespace: default\n  resourceVersion: \"530\"\n  uid: 05f8da22-d671-11e5-8cd0-68f728db1985\ndata:\n  game-special-key: |\n    enemies=aliens\n    lives=3\n    enemies.cheat=true\n    enemies.cheat.level=noGoodRotten\n    secret.code.passphrase=UUDDLRLRBABAS\n    secret.code.allowed=true\n    secret.code.lives=30\n```\n\n#### Create ConfigMaps from literal values\n\nYou can use `kubectl create configmap` with the `--from-literal` argument to define a literal\nvalue from the command line:\n\n```shell\nkubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm\n```\n\nYou can pass in multiple key-value pairs. Each pair provided on the command line is represented\nas a separate entry in the `data` section of the ConfigMap.\n\n```shell\nkubectl get configmaps special-config -o yaml\n```\n\nThe output is similar to this:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  creationTimestamp: 2022-02-18T19:14:38Z\n  name: special-config\n  namespace: default\n  resourceVersion: \"651\"\n  uid: dadce046-d673-11e5-8cd0-68f728db1985\ndata:\n  special.how: very\n  special.type: charm\n```\n\n### Create a ConfigMap from generator\n\nYou can also create a ConfigMap from generators and then apply it to create the object\nin the cluster's API server.\nYou should specify the generators in a `kustomization.yaml` file within a directory.\n\n#### Generate ConfigMaps from files\n\nFor example, to generate a ConfigMap from files `configure-pod-container/configmap/game.properties`\n\n```shell",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Core Kubernetes CLI tool used throughout for creating and managing ConfigMaps"
        },
        {
          "term": "ConfigMap",
          "tier": 1,
          "reasoning": "Primary Kubernetes API object being created and configured throughout the documentation"
        },
        {
          "term": "configmap",
          "tier": 1,
          "reasoning": "Lowercase variant of ConfigMap used in kubectl commands"
        },
        {
          "term": "game-config-env-file",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource created in the example"
        },
        {
          "term": "config-multi-env-files",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource for multiple env files example"
        },
        {
          "term": "game-config-3",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource with custom key example"
        },
        {
          "term": "special-config",
          "tier": 1,
          "reasoning": "Specific named ConfigMap resource created from literal values"
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Specific configuration file used for Kustomize generators"
        },
        {
          "term": "--from-env-file",
          "tier": 2,
          "reasoning": "kubectl flag for creating ConfigMaps from environment file properties"
        },
        {
          "term": "--from-file",
          "tier": 2,
          "reasoning": "kubectl flag for creating ConfigMaps from files with custom keys"
        },
        {
          "term": "--from-literal",
          "tier": 2,
          "reasoning": "kubectl flag for defining literal values in ConfigMap creation"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes namespace concept shown in ConfigMap metadata"
        },
        {
          "term": "data",
          "tier": 2,
          "reasoning": "ConfigMap data section containing key-value configuration pairs"
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes object metadata section containing name, namespace, uid"
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API version field in resource definitions"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes resource type identifier in YAML definitions"
        },
        {
          "term": "resourceVersion",
          "tier": 2,
          "reasoning": "Kubernetes internal version tracking for resources"
        },
        {
          "term": "uid",
          "tier": 2,
          "reasoning": "Unique identifier for Kubernetes objects"
        },
        {
          "term": "creationTimestamp",
          "tier": 2,
          "reasoning": "Kubernetes metadata field showing resource creation time"
        },
        {
          "term": "generators",
          "tier": 2,
          "reasoning": "Kustomize feature for generating ConfigMaps programmatically"
        },
        {
          "term": "key-value pairs",
          "tier": 2,
          "reasoning": "Data structure concept for ConfigMap entries"
        },
        {
          "term": "API server",
          "tier": 2,
          "reasoning": "Kubernetes cluster component that receives generated ConfigMaps"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster where ConfigMaps are applied"
        },
        {
          "term": "Kubernetes",
          "tier": 2,
          "reasoning": "Container orchestration platform context for all operations"
        },
        {
          "term": "v1.23",
          "tier": 2,
          "reasoning": "Specific Kubernetes version introducing multiple --from-env-file support"
        },
        {
          "term": "v1",
          "tier": 2,
          "reasoning": "API version for ConfigMap resources"
        },
        {
          "term": "-o yaml",
          "tier": 3,
          "reasoning": "kubectl output format flag for YAML representation"
        },
        {
          "term": "default",
          "tier": 3,
          "reasoning": "Default namespace name in Kubernetes"
        },
        {
          "term": "properties",
          "tier": 3,
          "reasoning": "File format type for configuration properties files"
        },
        {
          "term": "data source file",
          "tier": 3,
          "reasoning": "Source file from which ConfigMap data is read"
        },
        {
          "term": "command line",
          "tier": 3,
          "reasoning": "Interface context for kubectl operations"
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "File system location for kustomization.yaml files"
        }
      ],
      "term_count": 32,
      "generated_at": "2026-02-08T22:06:19.798635",
      "elapsed_time": 15.05581021308899
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_UnauthenticatedHTTP2DOSMitigation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_UnauthenticatedHTTP2DOSMitigation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_UnauthenticatedHTTP2DOSMitigation.md",
      "content": "---\ntitle: UnauthenticatedHTTP2DOSMitigation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n \nstages:\n  - stage: beta\n    defaultValue: false\n    fromVersion: \"1.28\"\n    toVersion: \"1.28\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.29\" \n---\nEnables HTTP/2 Denial of Service (DoS) mitigations for unauthenticated clients.\nKubernetes v1.28.0 through v1.28.2 do not include this feature gate.",
      "terms": [
        {
          "term": "UnauthenticatedHTTP2DOSMitigation",
          "tier": 1,
          "reasoning": "This is a specific Kubernetes feature gate name, a proper noun identifying a configurable feature."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "Kubernetes-specific mechanism for enabling/disabling optional features in the cluster."
        },
        {
          "term": "HTTP/2",
          "tier": 3,
          "reasoning": "A specific network protocol version relevant to the security mitigation being described."
        },
        {
          "term": "Denial of Service",
          "tier": 2,
          "reasoning": "A security concept describing a type of attack that this feature mitigates."
        },
        {
          "term": "DoS",
          "tier": 2,
          "reasoning": "Standard abbreviation for Denial of Service, a security attack vector."
        },
        {
          "term": "mitigations",
          "tier": 2,
          "reasoning": "Security domain term referring to measures taken to reduce risk or impact of attacks."
        },
        {
          "term": "unauthenticated clients",
          "tier": 2,
          "reasoning": "Security concept referring to clients that have not proven their identity."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform this documentation describes."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating a feature that is tested but not yet stable."
        },
        {
          "term": "stage",
          "tier": 2,
          "reasoning": "Technical term describing the maturity level of a feature gate in Kubernetes."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Configuration term indicating the default state of a feature gate."
        },
        {
          "term": "fromVersion",
          "tier": 2,
          "reasoning": "Version specification term indicating when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 2,
          "reasoning": "Version specification term indicating when a feature stage ends."
        },
        {
          "term": "v1.28",
          "tier": 2,
          "reasoning": "Specific Kubernetes version identifier relevant to feature availability."
        },
        {
          "term": "v1.28.0",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch version where the feature gate is absent."
        },
        {
          "term": "v1.28.2",
          "tier": 2,
          "reasoning": "Specific Kubernetes patch version marking the end of versions without this feature gate."
        },
        {
          "term": "HTTP/2 Denial of Service",
          "tier": 2,
          "reasoning": "Compound security term describing the specific attack type this feature addresses."
        },
        {
          "term": "clients",
          "tier": 3,
          "reasoning": "Technical term for entities making requests to a server/API in this context."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T22:06:31.823898",
      "elapsed_time": 11.009517192840576
    },
    {
      "chunk_id": "concepts_security_hardening-guide_authentication-mechanisms_sec9",
      "doc_id": "concepts_security_hardening-guide_authentication-mechanisms",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "concepts_security_hardening-guide_authentication-mechanisms.md",
      "content": "- [User Authentication](/docs/reference/access-authn-authz/authentication/)\n- [Authenticating with Bootstrap Tokens](/docs/reference/access-authn-authz/bootstrap-tokens/)\n- [kubelet Authentication](/docs/reference/access-authn-authz/kubelet-authn-authz/#kubelet-authentication)\n- [Authenticating with Service Account Tokens](/docs/reference/access-authn-authz/service-accounts-admin/#bound-service-account-tokens)",
      "terms": [
        {
          "term": "User Authentication",
          "tier": 2,
          "reasoning": "Domain concept referring to the process of verifying user identity in Kubernetes."
        },
        {
          "term": "Authentication",
          "tier": 2,
          "reasoning": "Core security concept for verifying identity of users or services."
        },
        {
          "term": "Bootstrap Tokens",
          "tier": 1,
          "reasoning": "Specific Kubernetes authentication mechanism used during cluster bootstrapping."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component responsible for managing pods on a node."
        },
        {
          "term": "kubelet Authentication",
          "tier": 2,
          "reasoning": "Specific authentication process for the kubelet component."
        },
        {
          "term": "Service Account Tokens",
          "tier": 1,
          "reasoning": "Kubernetes API object tokens used for authenticating service accounts."
        },
        {
          "term": "Service Account",
          "tier": 1,
          "reasoning": "Kubernetes API resource providing identity for processes running in pods."
        },
        {
          "term": "Tokens",
          "tier": 2,
          "reasoning": "Security credentials used for authentication in Kubernetes context."
        },
        {
          "term": "Bound Service Account Tokens",
          "tier": 1,
          "reasoning": "Specific type of service account tokens that are bound to specific pods and have expiration."
        },
        {
          "term": "access-authn-authz",
          "tier": 2,
          "reasoning": "Kubernetes documentation category covering access control, authentication, and authorization."
        },
        {
          "term": "authn",
          "tier": 2,
          "reasoning": "Abbreviation for authentication commonly used in Kubernetes security context."
        },
        {
          "term": "authz",
          "tier": 2,
          "reasoning": "Abbreviation for authorization commonly used in Kubernetes security context."
        },
        {
          "term": "kubelet-authn-authz",
          "tier": 2,
          "reasoning": "Reference to kubelet's authentication and authorization configuration."
        },
        {
          "term": "service-accounts-admin",
          "tier": 2,
          "reasoning": "Administrative configuration reference for service accounts in Kubernetes."
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T22:06:41.102043",
      "elapsed_time": 8.26522421836853
    },
    {
      "chunk_id": "concepts_scheduling-eviction_dynamic-resource-allocation_sec3",
      "doc_id": "concepts_scheduling-eviction_dynamic-resource-allocation",
      "heading": "How resource allocation with DRA works {#how-it-works}",
      "source_file": "concepts_scheduling-eviction_dynamic-resource-allocation.md",
      "content": "The following sections describe the workflow for the various\n[types of DRA users](#dra-user-types) and for the Kubernetes system during\ndynamic resource allocation.\n\n### Workflow for users {#user-workflow}\n\n1. **Driver creation**: device owners or third-party entities create drivers\n   that can create and manage ResourceSlices in the cluster. These drivers\n   optionally also create DeviceClasses that define a category of devices and\n   how to request them.\n1. **Cluster configuration**: cluster admins create clusters, attach devices to\n   nodes, and install the DRA device drivers. Cluster admins optionally create\n   DeviceClasses that define categories of devices and how to request them.\n1. **Resource claims**: workload operators create ResourceClaimTemplates or\n   ResourceClaims that request specific device configurations within a\n   DeviceClass. In the same step, workload operators modify their Kubernetes\n   manifests to request those ResourceClaimTemplates or ResourceClaims.\n\n### Workflow for Kubernetes {#kubernetes-workflow}\n\n1. **ResourceSlice creation**: drivers in the cluster create ResourceSlices that\n   represent one or more devices in a managed pool of similar devices.\n1. **Workload creation**: the cluster control plane checks new workloads for\n   references to ResourceClaimTemplates or to specific ResourceClaims.\n\n   * If the workload uses a ResourceClaimTemplate, a controller named the\n     `resourceclaim-controller` generates ResourceClaims for every Pod in the\n     workload.\n   * If the workload uses a specific ResourceClaim, Kubernetes checks whether\n     that ResourceClaim exists in the cluster. If the ResourceClaim doesn't\n     exist, the Pods won't deploy.\n\n1. **ResourceSlice filtering**: for every Pod, Kubernetes checks the\n   ResourceSlices in the cluster to find a device that satisfies all of the\n   following criteria:\n\n   * The nodes that can access the resources are eligible to run the Pod.\n   * The ResourceSlice has unallocated resources that match the requirements of\n     the Pod's ResourceClaim.\n\n1. **Resource allocation**: after finding an eligible ResourceSlice for a\n   Pod's ResourceClaim, the Kubernetes scheduler updates the ResourceClaim\n   with the allocation details.\n1. **Pod scheduling**: when resource allocation is complete, the scheduler\n   places the Pod on a node that can access the allocated resource. The device\n   driver and the kubelet on that node configure the device and the Pod's access\n   to the device.",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Abbreviation for Dynamic Resource Allocation, a core Kubernetes feature being documented."
        },
        {
          "term": "dynamic resource allocation",
          "tier": 2,
          "reasoning": "The main domain concept this documentation describes, a Kubernetes resource management process."
        },
        {
          "term": "DRA user types",
          "tier": 2,
          "reasoning": "Specific categorization of users within the DRA system."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented."
        },
        {
          "term": "ResourceSlices",
          "tier": 1,
          "reasoning": "A Kubernetes API object representing devices in a managed pool."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to a set of nodes."
        },
        {
          "term": "drivers",
          "tier": 2,
          "reasoning": "Software components that create and manage ResourceSlices in DRA context."
        },
        {
          "term": "DeviceClasses",
          "tier": 1,
          "reasoning": "Kubernetes API object that defines categories of devices and how to request them."
        },
        {
          "term": "device drivers",
          "tier": 2,
          "reasoning": "DRA-specific drivers that manage device resources in the cluster."
        },
        {
          "term": "DRA device drivers",
          "tier": 1,
          "reasoning": "Specific component name for drivers in the Dynamic Resource Allocation system."
        },
        {
          "term": "cluster admins",
          "tier": 2,
          "reasoning": "Role/persona responsible for cluster configuration in Kubernetes."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing worker machines in a cluster."
        },
        {
          "term": "workload operators",
          "tier": 2,
          "reasoning": "Role/persona responsible for creating and managing workloads."
        },
        {
          "term": "ResourceClaimTemplates",
          "tier": 1,
          "reasoning": "Kubernetes API object used to template resource claims for workloads."
        },
        {
          "term": "ResourceClaims",
          "tier": 1,
          "reasoning": "Kubernetes API object that requests specific device configurations."
        },
        {
          "term": "device configurations",
          "tier": 2,
          "reasoning": "Technical concept describing how devices are configured within DeviceClasses."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural component that manages cluster state."
        },
        {
          "term": "cluster control plane",
          "tier": 2,
          "reasoning": "Specific reference to the control plane managing the cluster."
        },
        {
          "term": "resourceclaim-controller",
          "tier": 1,
          "reasoning": "Named Kubernetes controller component that generates ResourceClaims."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "Kubernetes architectural pattern for managing resource state."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, frequently used in the documentation."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Technical concept for applications running in Kubernetes."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Plural form referring to multiple applications in the cluster."
        },
        {
          "term": "resource allocation",
          "tier": 2,
          "reasoning": "Core process in DRA where resources are assigned to claims."
        },
        {
          "term": "scheduler",
          "tier": 1,
          "reasoning": "Core Kubernetes component responsible for placing Pods on nodes."
        },
        {
          "term": "Kubernetes scheduler",
          "tier": 1,
          "reasoning": "Specific named component that handles Pod scheduling."
        },
        {
          "term": "allocation details",
          "tier": 2,
          "reasoning": "Technical information about how resources are allocated to claims."
        },
        {
          "term": "Pod scheduling",
          "tier": 2,
          "reasoning": "The process of placing Pods on appropriate nodes."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent that manages Pod lifecycle."
        },
        {
          "term": "device",
          "tier": 2,
          "reasoning": "Hardware resource managed through DRA in Kubernetes."
        },
        {
          "term": "devices",
          "tier": 2,
          "reasoning": "Plural form of device, representing hardware resources."
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Individual worker machine in a Kubernetes cluster."
        },
        {
          "term": "pool",
          "tier": 2,
          "reasoning": "Collection of similar devices managed together in DRA."
        },
        {
          "term": "managed pool",
          "tier": 2,
          "reasoning": "Specific concept of a pool of devices under driver management."
        },
        {
          "term": "unallocated resources",
          "tier": 2,
          "reasoning": "Resources in a ResourceSlice not yet assigned to claims."
        },
        {
          "term": "allocated resource",
          "tier": 2,
          "reasoning": "Resource that has been assigned to a Pod's claim."
        },
        {
          "term": "ResourceSlice filtering",
          "tier": 2,
          "reasoning": "Process of finding suitable ResourceSlices for Pod requirements."
        }
      ],
      "term_count": 38,
      "generated_at": "2026-02-08T22:07:03.127661",
      "elapsed_time": 21.011798620224
    },
    {
      "chunk_id": "tasks_job_coarse-parallel-processing-work-queue_sec10",
      "doc_id": "tasks_job_coarse-parallel-processing-work-queue",
      "heading": "Run this on your computer, not in the Pod",
      "source_file": "tasks_job_coarse-parallel-processing-work-queue.md",
      "content": "/usr/bin/amqp-declare-queue --url=$BROKER_URL -q job1  -d\n```\n```\njob1\n```\nAdd items to the queue:\n```shell\nfor f in apple banana cherry date fig grape lemon melon\ndo\n  /usr/bin/amqp-publish --url=$BROKER_URL -r job1 -p -b $f\ndone\n```\n\nYou added 8 messages to the queue.",
      "terms": [
        {
          "term": "amqp-declare-queue",
          "tier": 1,
          "reasoning": "CLI tool/command for declaring AMQP message queues"
        },
        {
          "term": "BROKER_URL",
          "tier": 2,
          "reasoning": "Environment variable representing the message broker connection URL"
        },
        {
          "term": "queue",
          "tier": 2,
          "reasoning": "Core messaging concept - a data structure for storing messages in order"
        },
        {
          "term": "job1",
          "tier": 1,
          "reasoning": "Named queue resource identifier in this messaging context"
        },
        {
          "term": "amqp-publish",
          "tier": 1,
          "reasoning": "CLI tool/command for publishing messages to AMQP queues"
        },
        {
          "term": "-q",
          "tier": 3,
          "reasoning": "CLI flag for specifying queue name"
        },
        {
          "term": "-d",
          "tier": 3,
          "reasoning": "CLI flag likely for durable queue declaration"
        },
        {
          "term": "-r",
          "tier": 3,
          "reasoning": "CLI flag for specifying routing key"
        },
        {
          "term": "-p",
          "tier": 3,
          "reasoning": "CLI flag for persistent message delivery"
        },
        {
          "term": "-b",
          "tier": 3,
          "reasoning": "CLI flag for specifying message body"
        },
        {
          "term": "--url",
          "tier": 3,
          "reasoning": "CLI flag for specifying broker URL connection string"
        },
        {
          "term": "messages",
          "tier": 2,
          "reasoning": "Core messaging concept - units of data transmitted through the queue"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interpreter environment context"
        },
        {
          "term": "/usr/bin",
          "tier": 3,
          "reasoning": "Standard Unix/Linux binary executable path"
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T22:07:11.230555",
      "elapsed_time": 7.087721109390259
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec1",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`TracingConfiguration`     {#TracingConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "**Appears in:**\n\n- [KubeletConfiguration](#kubelet-config-k8s-io-v1beta1-KubeletConfiguration)\n\n- [TracingConfiguration](#apiserver-k8s-io-v1alpha1-TracingConfiguration)\n\n- [TracingConfiguration](#apiserver-k8s-io-v1beta1-TracingConfiguration)\n\n\n<p>TracingConfiguration provides versioned configuration for OpenTelemetry tracing clients.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>endpoint</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>Endpoint of the collector this component will report traces to.\nThe connection is insecure, and does not currently support TLS.\nRecommended is unset, and endpoint is the otlp grpc default, localhost:4317.</p>\n</td>\n</tr>\n<tr><td><code>samplingRatePerMillion</code><br/>\n<code>int32</code>\n</td>\n<td>\n   <p>SamplingRatePerMillion is the number of samples to collect per million spans.\nRecommended is unset. If unset, sampler respects its parent span's sampling\nrate, but otherwise never samples.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "KubeletConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for the kubelet component"
        },
        {
          "term": "TracingConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for tracing settings"
        },
        {
          "term": "OpenTelemetry",
          "tier": 1,
          "reasoning": "Specific observability framework/standard for distributed tracing"
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Core Kubernetes node agent component (referenced via KubeletConfiguration)"
        },
        {
          "term": "apiserver",
          "tier": 1,
          "reasoning": "Core Kubernetes API server component referenced in configuration paths"
        },
        {
          "term": "endpoint",
          "tier": 2,
          "reasoning": "Technical field name specifying the collector connection target"
        },
        {
          "term": "collector",
          "tier": 2,
          "reasoning": "Component that receives and processes trace data in observability systems"
        },
        {
          "term": "traces",
          "tier": 2,
          "reasoning": "Distributed tracing data units used for observability"
        },
        {
          "term": "tracing",
          "tier": 2,
          "reasoning": "Observability concept for tracking requests across distributed systems"
        },
        {
          "term": "tracing clients",
          "tier": 2,
          "reasoning": "Components that generate and send trace data to collectors"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol mentioned as not currently supported"
        },
        {
          "term": "otlp",
          "tier": 2,
          "reasoning": "OpenTelemetry Protocol - standard protocol for transmitting telemetry data"
        },
        {
          "term": "grpc",
          "tier": 3,
          "reasoning": "Remote procedure call protocol used as default transport for OTLP"
        },
        {
          "term": "samplingRatePerMillion",
          "tier": 2,
          "reasoning": "Configuration field controlling trace sampling frequency"
        },
        {
          "term": "sampler",
          "tier": 2,
          "reasoning": "Component that decides which spans to collect based on sampling rate"
        },
        {
          "term": "spans",
          "tier": 2,
          "reasoning": "Individual units of work in distributed tracing representing operations"
        },
        {
          "term": "parent span",
          "tier": 2,
          "reasoning": "Hierarchical tracing concept where spans can have parent-child relationships"
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "Kubernetes API version indicating beta stability level"
        },
        {
          "term": "v1alpha1",
          "tier": 2,
          "reasoning": "Kubernetes API version indicating alpha stability level"
        },
        {
          "term": "localhost:4317",
          "tier": 3,
          "reasoning": "Default OTLP gRPC endpoint address for trace collection"
        },
        {
          "term": "int32",
          "tier": 3,
          "reasoning": "Data type specification for the sampling rate field"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the endpoint field"
        },
        {
          "term": "connection",
          "tier": 3,
          "reasoning": "Network connection concept relevant to collector communication"
        },
        {
          "term": "insecure",
          "tier": 3,
          "reasoning": "Security term describing the connection type without TLS"
        },
        {
          "term": "component",
          "tier": 3,
          "reasoning": "Technical term referring to Kubernetes system parts that report traces"
        }
      ],
      "term_count": 25,
      "generated_at": "2026-02-08T22:07:24.429834",
      "elapsed_time": 12.183044195175171
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_attach__index_sec1",
      "doc_id": "reference_kubectl_generated_kubectl_attach__index",
      "heading": "{{% heading \"examples\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_attach__index.md",
      "content": "```\n  # Get output from running pod mypod; use the 'kubectl.kubernetes.io/default-container' annotation\n  # for selecting the container to be attached or the first container in the pod will be chosen\n  kubectl attach mypod\n  \n  # Get output from ruby-container from pod mypod\n  kubectl attach mypod -c ruby-container\n  \n  # Switch to raw terminal mode; sends stdin to 'bash' in ruby-container from pod mypod\n  # and sends stdout/stderr from 'bash' back to the client\n  kubectl attach mypod -c ruby-container -i -t\n  \n  # Get output from the first pod of a replica set named nginx\n  kubectl attach rs/nginx\n```",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool used throughout the examples"
        },
        {
          "term": "kubectl attach",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for attaching to running containers"
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and resource type referenced multiple times"
        },
        {
          "term": "mypod",
          "tier": 1,
          "reasoning": "Example pod name used in the documentation examples"
        },
        {
          "term": "ruby-container",
          "tier": 1,
          "reasoning": "Example container name used in the documentation"
        },
        {
          "term": "replica set",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing pod replicas, referenced as rs/nginx"
        },
        {
          "term": "rs/nginx",
          "tier": 1,
          "reasoning": "Specific resource reference syntax for a replica set named nginx"
        },
        {
          "term": "nginx",
          "tier": 1,
          "reasoning": "Named replica set resource in the example"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes concept - the unit being attached to within a pod"
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism used for default container selection"
        },
        {
          "term": "kubectl.kubernetes.io/default-container",
          "tier": 1,
          "reasoning": "Specific Kubernetes annotation for selecting default container"
        },
        {
          "term": "stdin",
          "tier": 3,
          "reasoning": "Standard input stream - Linux/OS concept used in terminal attachment"
        },
        {
          "term": "stdout",
          "tier": 3,
          "reasoning": "Standard output stream - Linux/OS concept for receiving container output"
        },
        {
          "term": "stderr",
          "tier": 3,
          "reasoning": "Standard error stream - Linux/OS concept for receiving container errors"
        },
        {
          "term": "bash",
          "tier": 3,
          "reasoning": "Shell program running inside the container being attached to"
        },
        {
          "term": "raw terminal mode",
          "tier": 2,
          "reasoning": "Terminal mode concept for direct I/O with container processes"
        },
        {
          "term": "client",
          "tier": 2,
          "reasoning": "Technical term referring to the kubectl client receiving output"
        },
        {
          "term": "-c",
          "tier": 2,
          "reasoning": "CLI flag for specifying container name in kubectl commands"
        },
        {
          "term": "-i",
          "tier": 2,
          "reasoning": "CLI flag for interactive mode, passing stdin to container"
        },
        {
          "term": "-t",
          "tier": 2,
          "reasoning": "CLI flag for TTY allocation in terminal mode"
        },
        {
          "term": "attach",
          "tier": 2,
          "reasoning": "Technical operation for connecting to a running container's process"
        },
        {
          "term": "output",
          "tier": 2,
          "reasoning": "Technical term for data streams from container processes"
        }
      ],
      "term_count": 22,
      "generated_at": "2026-02-08T22:07:36.338860",
      "elapsed_time": 10.89553952217102
    },
    {
      "chunk_id": "concepts_security_security-checklist_sec2",
      "doc_id": "concepts_security_security-checklist",
      "heading": "Network security",
      "source_file": "concepts_security_security-checklist.md",
      "content": "- [ ] CNI plugins in use support network policies.\n- [ ] Ingress and egress network policies are applied to all workloads in the\n  cluster.\n- [ ] Default network policies within each namespace, selecting all pods, denying\n  everything, are in place.\n- [ ] If appropriate, a service mesh is used to encrypt all communications inside of the cluster.\n- [ ] The Kubernetes API, kubelet API and etcd are not exposed publicly on Internet.\n- [ ] Access from the workloads to the cloud metadata API is filtered.\n- [ ] Use of LoadBalancer and ExternalIPs is restricted.\n\nA number of [Container Network Interface (CNI) plugins](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)\nplugins provide the functionality to\nrestrict network resources that pods may communicate with. This is most commonly done\nthrough [Network Policies](/docs/concepts/services-networking/network-policies/)\nwhich provide a namespaced resource to define rules. Default network policies\nthat block all egress and ingress, in each namespace, selecting all pods, can be\nuseful to adopt an allow list approach to ensure that no workloads are missed.\n\nNot all CNI plugins provide encryption in transit. If the chosen plugin lacks this\nfeature, an alternative solution could be to use a service mesh to provide that\nfunctionality.\n\nThe etcd datastore of the control plane should have controls to limit access and\nnot be publicly exposed on the Internet. Furthermore, mutual TLS (mTLS) should\nbe used to communicate securely with it. The certificate authority for this\nshould be unique to etcd.\n\nExternal Internet access to the Kubernetes API server should be restricted to\nnot expose the API publicly. Be careful, as many managed Kubernetes distributions\nare publicly exposing the API server by default. You can then use a bastion host\nto access the server.\n\nThe [kubelet](/docs/reference/command-line-tools-reference/kubelet/) API access\nshould be restricted and not exposed publicly, the default authentication and\nauthorization settings, when no configuration file specified with the `--config`\nflag, are overly permissive.\n\nIf a cloud provider is used for hosting Kubernetes, the access from pods to the cloud\nmetadata API `169.254.169.254` should also be restricted or blocked if not needed\nbecause it may leak information.\n\nFor restricted LoadBalancer and ExternalIPs use, see\n[CVE-2020-8554: Man in the middle using LoadBalancer or ExternalIPs](https://github.com/kubernetes/kubernetes/issues/97076)\nand the [DenyServiceExternalIPs admission controller](/docs/reference/access-authn-authz/admission-controllers/#denyserviceexternalips)\nfor further information.",
      "terms": [
        {
          "term": "CNI plugins",
          "tier": 1,
          "reasoning": "Container Network Interface plugins are specific Kubernetes networking components."
        },
        {
          "term": "Container Network Interface",
          "tier": 1,
          "reasoning": "Full name of CNI, a core Kubernetes networking standard."
        },
        {
          "term": "network policies",
          "tier": 1,
          "reasoning": "Kubernetes API resource for controlling pod network traffic."
        },
        {
          "term": "Network Policies",
          "tier": 1,
          "reasoning": "Capitalized reference to the Kubernetes API object."
        },
        {
          "term": "Ingress",
          "tier": 1,
          "reasoning": "Kubernetes concept for inbound network traffic control."
        },
        {
          "term": "egress",
          "tier": 2,
          "reasoning": "Kubernetes networking concept for outbound traffic."
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes term for applications running in the cluster."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept for a set of nodes."
        },
        {
          "term": "namespace",
          "tier": 1,
          "reasoning": "Kubernetes API object for resource isolation and organization."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes workload resource unit."
        },
        {
          "term": "service mesh",
          "tier": 2,
          "reasoning": "Infrastructure layer concept for service-to-service communication."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Core interface for interacting with Kubernetes control plane."
        },
        {
          "term": "kubelet API",
          "tier": 1,
          "reasoning": "API exposed by the kubelet node agent component."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Primary node agent that runs on each Kubernetes node."
        },
        {
          "term": "etcd",
          "tier": 1,
          "reasoning": "Distributed key-value store used as Kubernetes backing store."
        },
        {
          "term": "cloud metadata API",
          "tier": 2,
          "reasoning": "Cloud provider service endpoint for instance metadata."
        },
        {
          "term": "LoadBalancer",
          "tier": 1,
          "reasoning": "Kubernetes Service type for external load balancing."
        },
        {
          "term": "ExternalIPs",
          "tier": 1,
          "reasoning": "Kubernetes Service field for external IP addresses."
        },
        {
          "term": "network resources",
          "tier": 2,
          "reasoning": "Technical term for network-related Kubernetes resources."
        },
        {
          "term": "namespaced resource",
          "tier": 2,
          "reasoning": "Kubernetes concept for resources scoped to a namespace."
        },
        {
          "term": "allow list",
          "tier": 2,
          "reasoning": "Security concept for explicitly permitted access."
        },
        {
          "term": "encryption in transit",
          "tier": 2,
          "reasoning": "Security concept for protecting data during transmission."
        },
        {
          "term": "etcd datastore",
          "tier": 1,
          "reasoning": "Specific reference to etcd as the control plane data store."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Kubernetes architectural component managing cluster state."
        },
        {
          "term": "mutual TLS",
          "tier": 2,
          "reasoning": "Security protocol for bidirectional certificate authentication."
        },
        {
          "term": "mTLS",
          "tier": 2,
          "reasoning": "Abbreviation for mutual TLS, common security term."
        },
        {
          "term": "certificate authority",
          "tier": 2,
          "reasoning": "PKI concept for issuing and managing certificates."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component (kube-apiserver)."
        },
        {
          "term": "bastion host",
          "tier": 2,
          "reasoning": "Security architecture term for a hardened access point."
        },
        {
          "term": "managed Kubernetes distributions",
          "tier": 2,
          "reasoning": "Cloud provider Kubernetes offerings concept."
        },
        {
          "term": "--config",
          "tier": 1,
          "reasoning": "CLI flag for kubelet configuration file specification."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Security concept for identity verification."
        },
        {
          "term": "authorization",
          "tier": 2,
          "reasoning": "Security concept for access control decisions."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Kubernetes integration concept for cloud infrastructure."
        },
        {
          "term": "169.254.169.254",
          "tier": 3,
          "reasoning": "Specific IP address for cloud metadata API endpoint."
        },
        {
          "term": "CVE-2020-8554",
          "tier": 1,
          "reasoning": "Specific security vulnerability identifier referenced."
        },
        {
          "term": "DenyServiceExternalIPs admission controller",
          "tier": 1,
          "reasoning": "Specific Kubernetes admission controller component."
        },
        {
          "term": "admission controller",
          "tier": 1,
          "reasoning": "Kubernetes component that intercepts API requests."
        },
        {
          "term": "default network policies",
          "tier": 2,
          "reasoning": "Kubernetes security pattern for baseline network rules."
        },
        {
          "term": "Internet",
          "tier": 3,
          "reasoning": "Network context term for external public network access."
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:07:56.041461",
      "elapsed_time": 18.688344955444336
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec0",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Introduction",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "---\ntitle: Specifying a Disruption Budget for your Application\ncontent_type: task\nweight: 110\nmin-kubernetes-server-version: v1.21\n---\n\n<!-- overview -->\n\n{{< feature-state for_k8s_version=\"v1.21\" state=\"stable\" >}}\n\nThis page shows how to limit the number of concurrent disruptions\nthat your application experiences, allowing for higher availability\nwhile permitting the cluster administrator to manage the clusters\nnodes.",
      "terms": [
        {
          "term": "Disruption Budget",
          "tier": 1,
          "reasoning": "Core Kubernetes API object (PodDisruptionBudget) referenced in the title for managing pod disruptions."
        },
        {
          "term": "Application",
          "tier": 2,
          "reasoning": "Domain concept referring to workloads running on Kubernetes that the disruption budget protects."
        },
        {
          "term": "concurrent disruptions",
          "tier": 2,
          "reasoning": "Technical concept describing simultaneous pod terminations that disruption budgets limit."
        },
        {
          "term": "disruptions",
          "tier": 2,
          "reasoning": "Domain concept referring to voluntary or involuntary pod terminations in Kubernetes."
        },
        {
          "term": "availability",
          "tier": 2,
          "reasoning": "Architectural term describing the operational uptime goal that disruption budgets help maintain."
        },
        {
          "term": "higher availability",
          "tier": 2,
          "reasoning": "Architectural concept describing improved uptime through controlled disruption management."
        },
        {
          "term": "cluster administrator",
          "tier": 2,
          "reasoning": "Domain role responsible for managing Kubernetes cluster infrastructure and nodes."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "nodes",
          "tier": 2,
          "reasoning": "Core Kubernetes resource representing worker machines in the cluster."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle state indicating the feature has graduated to production-ready status in Kubernetes."
        },
        {
          "term": "v1.21",
          "tier": 3,
          "reasoning": "Kubernetes API version indicating when this feature became stable."
        },
        {
          "term": "min-kubernetes-server-version",
          "tier": 3,
          "reasoning": "Metadata field specifying minimum Kubernetes version requirement for the feature."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:08:05.956809",
      "elapsed_time": 8.896676301956177
    },
    {
      "chunk_id": "concepts_workloads_controllers__index_sec0",
      "doc_id": "concepts_workloads_controllers__index",
      "heading": "Introduction",
      "source_file": "concepts_workloads_controllers__index.md",
      "content": "---\ntitle: \"Workload Management\"\nweight: 20\nsimple_list: true\n---\n\nKubernetes provides several built-in APIs for declarative management of your\n{{< glossary_tooltip text=\"workloads\" term_id=\"workload\" >}}\nand the components of those workloads.\n\nUltimately, your applications run as containers inside\n{{< glossary_tooltip term_id=\"Pod\" text=\"Pods\" >}}; however, managing individual\nPods would be a lot of effort. For example, if a Pod fails, you probably want to\nrun a new Pod to replace it. Kubernetes can do that for you.\n\nYou use the Kubernetes API to create a workload\n{{< glossary_tooltip text=\"object\" term_id=\"object\" >}} that represents a higher abstraction level\nthan a Pod, and then the Kubernetes\n{{< glossary_tooltip text=\"control plane\" term_id=\"control-plane\" >}} automatically manages\nPod objects on your behalf, based on the specification for the workload object you defined.\n\nThe built-in APIs for managing workloads are:\n\n[Deployment](/docs/concepts/workloads/controllers/deployment/) (and, indirectly, [ReplicaSet](/docs/concepts/workloads/controllers/replicaset/)),\nthe most common way to run an application on your cluster.\nDeployment is a good fit for managing a stateless application workload on your cluster, where\nany Pod in the Deployment is interchangeable and can be replaced if needed.\n(Deployments are a replacement for the legacy\n{{< glossary_tooltip text=\"ReplicationController\" term_id=\"replication-controller\" >}} API).\n\nA [StatefulSet](/docs/concepts/workloads/controllers/statefulset/) lets you\nmanage one or more Pods \u2013 all running the same application code \u2013 where the Pods rely\non having a distinct identity. This is different from a Deployment where the Pods are\nexpected to be interchangeable.\nThe most common use for a StatefulSet is to be able to make a link between its Pods and\ntheir persistent storage. For example, you can run a StatefulSet that associates each Pod\nwith a [PersistentVolume](/docs/concepts/storage/persistent-volumes/). If one of the Pods\nin the StatefulSet fails, Kubernetes makes a replacement Pod that is connected to the\nsame PersistentVolume.\n\nA [DaemonSet](/docs/concepts/workloads/controllers/daemonset/) defines Pods that provide\nfacilities that are local to a specific {{< glossary_tooltip text=\"node\" term_id=\"node\" >}};\nfor example, a driver that lets containers on that node access a storage system. You use a DaemonSet\nwhen the driver, or other node-level service, has to run on the node where it's useful.\nEach Pod in a DaemonSet performs a role similar to a system daemon on a classic Unix / POSIX\nserver.\nA DaemonSet might be fundamental to the operation of your cluster,\nsuch as a plugin to let that node access\n[cluster networking](/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-network-model),\nit might help you to manage the node,\nor it could provide less essential facilities that enhance the container platform you are running.\nYou can run DaemonSets (and their pods) across every node in your cluster, or across just a subset (for example,\nonly install the GPU accelerator driver on nodes that have a GPU installed).\n\nYou can use a [Job](/docs/concepts/workloads/controllers/job/) and / or\na [CronJob](/docs/concepts/workloads/controllers/cron-jobs/) to\ndefine tasks that run to completion and then stop. A Job represents a one-off task,\nwhereas each CronJob repeats according to a schedule.\n\nOther topics in this section:\n<!-- relies on simple_list: true in the front matter -->",
      "terms": [
        {
          "term": "Workload Management",
          "tier": 2,
          "reasoning": "Title concept describing the management of workloads in Kubernetes"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core platform/system name that is the subject of the documentation"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Domain concept referring to applications and their components running on Kubernetes"
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental unit of deployment"
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Plural form of Pod, frequently used throughout the document"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core concept - the runtime units that applications run inside"
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "The API interface for interacting with Kubernetes resources"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Kubernetes domain term for API resources/entities"
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core architectural concept - the brain of Kubernetes that manages cluster state"
        },
        {
          "term": "Pod objects",
          "tier": 1,
          "reasoning": "Specific reference to Pod as an API object type"
        },
        {
          "term": "workload object",
          "tier": 2,
          "reasoning": "Higher-level abstraction representing workloads in Kubernetes"
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing stateless applications"
        },
        {
          "term": "ReplicaSet",
          "tier": 1,
          "reasoning": "Kubernetes API object that Deployment manages indirectly"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept - a set of nodes running containerized applications"
        },
        {
          "term": "stateless application",
          "tier": 2,
          "reasoning": "Application architecture concept where pods are interchangeable"
        },
        {
          "term": "ReplicationController",
          "tier": 1,
          "reasoning": "Legacy Kubernetes API object replaced by Deployment"
        },
        {
          "term": "StatefulSet",
          "tier": 1,
          "reasoning": "Kubernetes API object for managing stateful applications with distinct identities"
        },
        {
          "term": "persistent storage",
          "tier": 2,
          "reasoning": "Storage concept for data that persists beyond pod lifecycle"
        },
        {
          "term": "PersistentVolume",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a piece of storage in the cluster"
        },
        {
          "term": "DaemonSet",
          "tier": 1,
          "reasoning": "Kubernetes API object ensuring pods run on specific nodes"
        },
        {
          "term": "node",
          "tier": 2,
          "reasoning": "Core Kubernetes concept - a worker machine in the cluster"
        },
        {
          "term": "driver",
          "tier": 2,
          "reasoning": "Technical term for software enabling access to hardware/systems"
        },
        {
          "term": "storage system",
          "tier": 2,
          "reasoning": "Infrastructure concept for persistent data storage"
        },
        {
          "term": "node-level service",
          "tier": 2,
          "reasoning": "Service concept specific to individual nodes"
        },
        {
          "term": "system daemon",
          "tier": 2,
          "reasoning": "Unix/POSIX concept for background services, analogous to DaemonSet pods"
        },
        {
          "term": "Unix",
          "tier": 3,
          "reasoning": "Operating system family referenced for daemon concept"
        },
        {
          "term": "POSIX",
          "tier": 3,
          "reasoning": "Standard referenced for daemon concept"
        },
        {
          "term": "plugin",
          "tier": 2,
          "reasoning": "Extensibility concept for adding functionality"
        },
        {
          "term": "cluster networking",
          "tier": 2,
          "reasoning": "Networking concept specific to Kubernetes clusters"
        },
        {
          "term": "container platform",
          "tier": 2,
          "reasoning": "Infrastructure concept for running containerized applications"
        },
        {
          "term": "GPU",
          "tier": 3,
          "reasoning": "Hardware component referenced in context of node-specific drivers"
        },
        {
          "term": "GPU accelerator driver",
          "tier": 2,
          "reasoning": "Specific driver type for GPU hardware acceleration"
        },
        {
          "term": "Job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running tasks to completion"
        },
        {
          "term": "CronJob",
          "tier": 1,
          "reasoning": "Kubernetes API object for scheduled recurring tasks"
        },
        {
          "term": "tasks",
          "tier": 2,
          "reasoning": "Workload concept for discrete units of work"
        },
        {
          "term": "schedule",
          "tier": 2,
          "reasoning": "Timing concept for CronJob execution"
        },
        {
          "term": "distinct identity",
          "tier": 2,
          "reasoning": "StatefulSet concept where each pod has unique, stable identity"
        },
        {
          "term": "interchangeable",
          "tier": 2,
          "reasoning": "Deployment concept where pods can replace each other"
        },
        {
          "term": "APIs",
          "tier": 3,
          "reasoning": "General technical term for programmatic interfaces"
        },
        {
          "term": "declarative management",
          "tier": 2,
          "reasoning": "Kubernetes operational pattern for defining desired state"
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:08:25.433670",
      "elapsed_time": 18.462199211120605
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec21",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "{{% heading \"whatsnext\" %}}",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "* [Managing Kubernetes Objects Using Imperative Commands](/docs/tasks/manage-kubernetes-objects/imperative-command/)\n* [Imperative Management of Kubernetes Objects Using Configuration Files](/docs/tasks/manage-kubernetes-objects/imperative-config/)\n* [Kubectl Command Reference](/docs/reference/generated/kubectl/kubectl-commands/)\n* [Kubernetes API Reference](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/)",
      "terms": [
        {
          "term": "Kubernetes Objects",
          "tier": 1,
          "reasoning": "Core API resources that represent the state of a Kubernetes cluster."
        },
        {
          "term": "Imperative Commands",
          "tier": 2,
          "reasoning": "A management approach where users directly specify operations to perform on cluster resources."
        },
        {
          "term": "Imperative Management",
          "tier": 2,
          "reasoning": "A paradigm for managing Kubernetes resources through direct commands rather than declarative configuration."
        },
        {
          "term": "Configuration Files",
          "tier": 2,
          "reasoning": "Files used to define and manage Kubernetes resource specifications."
        },
        {
          "term": "Kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool for interacting with clusters."
        },
        {
          "term": "kubectl-commands",
          "tier": 1,
          "reasoning": "Reference to the set of commands available in the kubectl CLI tool."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "The primary interface for interacting with Kubernetes clusters programmatically."
        },
        {
          "term": "API Reference",
          "tier": 2,
          "reasoning": "Documentation describing the Kubernetes API endpoints and resources."
        },
        {
          "term": "Command Reference",
          "tier": 2,
          "reasoning": "Documentation describing available CLI commands and their usage."
        },
        {
          "term": "Managing",
          "tier": 2,
          "reasoning": "Technical process of creating, updating, and deleting Kubernetes resources."
        },
        {
          "term": "Imperative",
          "tier": 2,
          "reasoning": "A resource management paradigm in Kubernetes contrasted with declarative approaches."
        },
        {
          "term": "version",
          "tier": 3,
          "reasoning": "Refers to API versioning in Kubernetes, a key concept for API stability and compatibility."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:08:35.985150",
      "elapsed_time": 9.53627347946167
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_kustomization_sec5",
      "doc_id": "tasks_manage-kubernetes-objects_kustomization",
      "heading": "Create a password.txt file",
      "source_file": "tasks_manage-kubernetes-objects_kustomization.md",
      "content": "cat <<EOF >./password.txt\nusername=admin\npassword=secret\nEOF\n\ncat <<EOF >./kustomization.yaml\nsecretGenerator:\n- name: example-secret-1\n  files:\n  - password.txt\nEOF\n```\n\nThe generated Secret is as follows:\n\n```yaml\napiVersion: v1\ndata:\n  password.txt: dXNlcm5hbWU9YWRtaW4KcGFzc3dvcmQ9c2VjcmV0Cg==\nkind: Secret\nmetadata:\n  name: example-secret-1-t2kt65hgtb\ntype: Opaque\n```\n\nTo generate a Secret from a literal key-value pair, add an entry to `literals` list\nin `secretGenerator`. Here is an example of generating a Secret with a data item from a key-value pair:\n\n```shell\ncat <<EOF >./kustomization.yaml\nsecretGenerator:\n- name: example-secret-2\n  literals:\n  - username=admin\n  - password=secret\nEOF\n```\n\nThe generated Secret is as follows:\n\n```yaml\napiVersion: v1\ndata:\n  password: c2VjcmV0\n  username: YWRtaW4=\nkind: Secret\nmetadata:\n  name: example-secret-2-t52t6g96d8\ntype: Opaque\n```\n\nLike ConfigMaps, generated Secrets can be used in Deployments by referring to the name of the secretGenerator:\n\n```shell",
      "terms": [
        {
          "term": "Secret",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for storing sensitive data like passwords and tokens."
        },
        {
          "term": "secretGenerator",
          "tier": 1,
          "reasoning": "Kustomize-specific resource generator for creating Secret objects."
        },
        {
          "term": "ConfigMaps",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for storing non-sensitive configuration data."
        },
        {
          "term": "Deployments",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for managing replicated applications."
        },
        {
          "term": "kustomization.yaml",
          "tier": 1,
          "reasoning": "Configuration file used by Kustomize to define resource customizations."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the API version for the resource."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes manifest field specifying the type of resource being defined."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes manifest section containing resource identification information."
        },
        {
          "term": "data",
          "tier": 2,
          "reasoning": "Field in Secret/ConfigMap resources containing the actual stored values."
        },
        {
          "term": "type",
          "tier": 2,
          "reasoning": "Field in Secret resources specifying the secret type classification."
        },
        {
          "term": "Opaque",
          "tier": 2,
          "reasoning": "Default Secret type in Kubernetes for arbitrary user-defined data."
        },
        {
          "term": "literals",
          "tier": 2,
          "reasoning": "Kustomize secretGenerator field for specifying inline key-value pairs."
        },
        {
          "term": "files",
          "tier": 2,
          "reasoning": "Kustomize secretGenerator field for specifying file-based secret sources."
        },
        {
          "term": "name",
          "tier": 2,
          "reasoning": "Kubernetes metadata field identifying the resource within a namespace."
        },
        {
          "term": "key-value pair",
          "tier": 2,
          "reasoning": "Data structure concept used for storing secret literals."
        },
        {
          "term": "generated Secret",
          "tier": 2,
          "reasoning": "Secret resource created by Kustomize's secretGenerator."
        },
        {
          "term": "v1",
          "tier": 3,
          "reasoning": "Kubernetes core API version identifier."
        },
        {
          "term": "password.txt",
          "tier": 3,
          "reasoning": "Example file used as source for secret data in the documentation."
        },
        {
          "term": "username",
          "tier": 3,
          "reasoning": "Key name used in the secret data examples."
        },
        {
          "term": "password",
          "tier": 3,
          "reasoning": "Key name used in the secret data examples."
        },
        {
          "term": "cat",
          "tier": 3,
          "reasoning": "Shell command used to create files in the examples."
        },
        {
          "term": "EOF",
          "tier": 3,
          "reasoning": "Here-document delimiter used in shell examples."
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Command-line interface context for the examples."
        },
        {
          "term": "YAML",
          "tier": 3,
          "reasoning": "Data serialization format used for Kubernetes manifests."
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T22:08:49.821377",
      "elapsed_time": 12.820742130279541
    },
    {
      "chunk_id": "reference_using-api_deprecation-policy_sec4",
      "doc_id": "reference_using-api_deprecation-policy",
      "heading": "Deprecating a metric",
      "source_file": "reference_using-api_deprecation-policy.md",
      "content": "Each component of the Kubernetes control-plane exposes metrics (usually the\n`/metrics` endpoint), which are typically ingested by cluster administrators.\nNot all metrics are the same: some metrics are commonly used as SLIs or used\nto determine SLOs, these tend to have greater import. Other metrics are more\nexperimental in nature or are used primarily in the Kubernetes development\nprocess.\n\nAccordingly, metrics fall under three stability classes (`ALPHA`, `BETA` `STABLE`);\nthis impacts removal of a metric during a Kubernetes release. These classes\nare determined by the perceived importance of the metric. The rules for\ndeprecating and removing a metric are as follows:\n\n**Rule #11a: Metrics, for the corresponding stability class, must function for no less than:**\n\n* **STABLE: 4 releases or 12 months (whichever is longer)**\n* **BETA: 2 releases or 8 months (whichever is longer)**\n* **ALPHA: 0 releases**\n\n**Rule #11b: Metrics, after their _announced deprecation_, must function for no less than:**\n\n* **STABLE: 3 releases or 9 months (whichever is longer)**\n* **BETA: 1 releases or 4 months (whichever is longer)**\n* **ALPHA: 0 releases**\n\nDeprecated metrics will have their description text prefixed with a deprecation notice\nstring '(Deprecated from x.y)' and a warning log will be emitted during metric\nregistration. Like their stable undeprecated counterparts, deprecated metrics will\nbe automatically registered to the metrics endpoint and therefore visible.\n\nOn a subsequent release (when the metric's `deprecatedVersion` is equal to\n_current_kubernetes_version - 3_), a deprecated metric will become a _hidden_ metric.\n**_Unlike_** their deprecated counterparts, hidden metrics will _no longer_ be\nautomatically registered to the metrics endpoint (hence hidden). However, they\ncan be explicitly enabled through a command line flag on the binary\n(`--show-hidden-metrics-for-version=`). This provides cluster admins an\nescape hatch to properly migrate off of a deprecated metric, if they were not\nable to react to the earlier deprecation warnings. Hidden metrics should be\ndeleted after one release.",
      "terms": [
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core platform name, the primary subject of this documentation."
        },
        {
          "term": "control-plane",
          "tier": 1,
          "reasoning": "Named Kubernetes architectural component that manages the cluster."
        },
        {
          "term": "metrics",
          "tier": 2,
          "reasoning": "Core domain concept referring to quantitative measurements exposed by components."
        },
        {
          "term": "/metrics",
          "tier": 1,
          "reasoning": "Specific API endpoint path for accessing metrics data."
        },
        {
          "term": "endpoint",
          "tier": 2,
          "reasoning": "Technical networking concept referring to an accessible URL/path."
        },
        {
          "term": "cluster administrators",
          "tier": 2,
          "reasoning": "Domain-specific role responsible for managing Kubernetes clusters."
        },
        {
          "term": "SLIs",
          "tier": 2,
          "reasoning": "Service Level Indicators - key reliability engineering concept for measuring service performance."
        },
        {
          "term": "SLOs",
          "tier": 2,
          "reasoning": "Service Level Objectives - reliability engineering concept for defining performance targets."
        },
        {
          "term": "stability classes",
          "tier": 2,
          "reasoning": "Domain concept describing the maturity classification system for metrics."
        },
        {
          "term": "ALPHA",
          "tier": 2,
          "reasoning": "Stability class designation indicating experimental/early-stage features."
        },
        {
          "term": "BETA",
          "tier": 2,
          "reasoning": "Stability class designation indicating pre-stable features with some guarantees."
        },
        {
          "term": "STABLE",
          "tier": 2,
          "reasoning": "Stability class designation indicating production-ready features with strong guarantees."
        },
        {
          "term": "Kubernetes release",
          "tier": 2,
          "reasoning": "Domain concept referring to versioned releases of the Kubernetes platform."
        },
        {
          "term": "deprecating",
          "tier": 2,
          "reasoning": "Technical process of marking features/metrics for future removal."
        },
        {
          "term": "deprecation",
          "tier": 2,
          "reasoning": "Technical lifecycle concept for phasing out features."
        },
        {
          "term": "releases",
          "tier": 2,
          "reasoning": "Technical concept referring to software version releases."
        },
        {
          "term": "announced deprecation",
          "tier": 2,
          "reasoning": "Specific lifecycle phase when deprecation is formally communicated."
        },
        {
          "term": "deprecated metrics",
          "tier": 2,
          "reasoning": "Metrics that have been marked for future removal."
        },
        {
          "term": "deprecation notice",
          "tier": 2,
          "reasoning": "Formal notification string indicating a metric is deprecated."
        },
        {
          "term": "warning log",
          "tier": 2,
          "reasoning": "Logging mechanism for alerting about deprecated functionality."
        },
        {
          "term": "metrics endpoint",
          "tier": 2,
          "reasoning": "The API endpoint where metrics are exposed for collection."
        },
        {
          "term": "deprecatedVersion",
          "tier": 1,
          "reasoning": "Specific field/attribute tracking when a metric was deprecated."
        },
        {
          "term": "current_kubernetes_version",
          "tier": 2,
          "reasoning": "Variable representing the current running Kubernetes version."
        },
        {
          "term": "hidden metric",
          "tier": 2,
          "reasoning": "Specific metric state where metrics are not automatically registered."
        },
        {
          "term": "hidden metrics",
          "tier": 2,
          "reasoning": "Plural form of hidden metric, metrics no longer auto-registered."
        },
        {
          "term": "command line flag",
          "tier": 2,
          "reasoning": "CLI configuration mechanism for binary execution options."
        },
        {
          "term": "binary",
          "tier": 3,
          "reasoning": "Executable program file in the context of Kubernetes components."
        },
        {
          "term": "--show-hidden-metrics-for-version=",
          "tier": 1,
          "reasoning": "Specific CLI flag for enabling hidden metrics visibility."
        },
        {
          "term": "cluster admins",
          "tier": 2,
          "reasoning": "Shortened form of cluster administrators role."
        },
        {
          "term": "escape hatch",
          "tier": 2,
          "reasoning": "Technical pattern providing fallback mechanism for migration."
        },
        {
          "term": "deprecation warnings",
          "tier": 2,
          "reasoning": "Alert messages about deprecated functionality."
        }
      ],
      "term_count": 31,
      "generated_at": "2026-02-08T22:09:07.404595",
      "elapsed_time": 16.56701946258545
    },
    {
      "chunk_id": "tasks_extend-kubernetes_configure-aggregation-layer_sec1",
      "doc_id": "tasks_extend-kubernetes_configure-aggregation-layer",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_extend-kubernetes_configure-aggregation-layer.md",
      "content": "{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\n\n{{< note >}}\nThere are a few setup requirements for getting the aggregation layer working in\nyour environment to support mutual TLS auth between the proxy and extension apiservers.\nKubernetes and the kube-apiserver have multiple CAs, so make sure that the proxy is\nsigned by the aggregation layer CA and not by something else, like the Kubernetes general CA.\n{{< /note >}}\n\n{{< caution >}}\nReusing the same CA for different client types can negatively impact the cluster's\nability to function. For more information, see [CA Reusage and Conflicts](#ca-reusage-and-conflicts).\n{{< /caution >}}\n\n<!-- steps -->",
      "terms": [
        {
          "term": "aggregation layer",
          "tier": 1,
          "reasoning": "Core Kubernetes component that enables extending the API server with additional APIs."
        },
        {
          "term": "mutual TLS auth",
          "tier": 2,
          "reasoning": "Security concept describing bidirectional TLS authentication between components."
        },
        {
          "term": "mutual TLS",
          "tier": 2,
          "reasoning": "Abbreviated form of the authentication mechanism referenced in the chunk."
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol, foundational security concept."
        },
        {
          "term": "proxy",
          "tier": 2,
          "reasoning": "Technical component that intermediates requests between API server and extensions."
        },
        {
          "term": "extension apiservers",
          "tier": 1,
          "reasoning": "Kubernetes component that extends the main API server with custom APIs."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented."
        },
        {
          "term": "kube-apiserver",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that exposes the Kubernetes API."
        },
        {
          "term": "CA",
          "tier": 2,
          "reasoning": "Certificate Authority - cryptographic concept for signing certificates."
        },
        {
          "term": "CAs",
          "tier": 2,
          "reasoning": "Plural form of Certificate Authority as used in the text."
        },
        {
          "term": "aggregation layer CA",
          "tier": 1,
          "reasoning": "Specific Certificate Authority used for signing aggregation layer components."
        },
        {
          "term": "Kubernetes general CA",
          "tier": 1,
          "reasoning": "The main Certificate Authority used by Kubernetes for general purposes."
        },
        {
          "term": "client types",
          "tier": 2,
          "reasoning": "Technical concept referring to different categories of API clients."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept representing a set of nodes."
        },
        {
          "term": "CA Reusage and Conflicts",
          "tier": 2,
          "reasoning": "Named section/concept describing certificate authority management issues."
        },
        {
          "term": "auth",
          "tier": 3,
          "reasoning": "Abbreviation for authentication used in technical context."
        },
        {
          "term": "signed",
          "tier": 3,
          "reasoning": "Cryptographic operation relevant to certificate management."
        },
        {
          "term": "environment",
          "tier": 3,
          "reasoning": "Technical context referring to the deployment/runtime environment."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T22:09:18.388763",
      "elapsed_time": 9.968626022338867
    },
    {
      "chunk_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1_sec4",
      "doc_id": "reference_kubernetes-api_cluster-resources_service-cidr-v1",
      "heading": "ServiceCIDRList {#ServiceCIDRList}",
      "source_file": "reference_kubernetes-api_cluster-resources_service-cidr-v1.md",
      "content": "ServiceCIDRList contains a list of ServiceCIDR objects.\n\n<hr>\n\n- **apiVersion**: networking.k8s.io/v1\n\n\n- **kind**: ServiceCIDRList\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/list-meta#ListMeta\" >}}\">ListMeta</a>)\n\n  Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **items** ([]<a href=\"{{< ref \"../cluster-resources/service-cidr-v1#ServiceCIDR\" >}}\">ServiceCIDR</a>), required\n\n  items is the list of ServiceCIDRs.",
      "terms": [
        {
          "term": "ServiceCIDRList",
          "tier": 1,
          "reasoning": "Named Kubernetes API object that contains a list of ServiceCIDR objects."
        },
        {
          "term": "ServiceCIDR",
          "tier": 1,
          "reasoning": "Named Kubernetes API resource referenced as items in the list."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the version of the API schema."
        },
        {
          "term": "networking.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for networking resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes API field containing standard object metadata."
        },
        {
          "term": "ListMeta",
          "tier": 1,
          "reasoning": "Named Kubernetes common definition type for list metadata."
        },
        {
          "term": "items",
          "tier": 2,
          "reasoning": "Kubernetes API field containing the array of resources in a list."
        },
        {
          "term": "CIDR",
          "tier": 2,
          "reasoning": "Networking concept (Classless Inter-Domain Routing) embedded in the resource name."
        },
        {
          "term": "object",
          "tier": 3,
          "reasoning": "Technical term referring to Kubernetes API objects/resources."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Technical acronym for Application Programming Interface, fundamental to Kubernetes."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Reference to Kubernetes API conventions documentation for metadata standards."
        },
        {
          "term": "cluster-resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources that are cluster-scoped."
        },
        {
          "term": "networking.k8s.io",
          "tier": 1,
          "reasoning": "Kubernetes API group for networking-related resources."
        },
        {
          "term": "required",
          "tier": 3,
          "reasoning": "API field validation term indicating mandatory fields in Kubernetes specs."
        }
      ],
      "term_count": 15,
      "generated_at": "2026-02-08T22:09:28.752498",
      "elapsed_time": 9.345441341400146
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DisableCloudProviders_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DisableCloudProviders",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DisableCloudProviders.md",
      "content": "---\ntitle: DisableCloudProviders\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha\n    defaultValue: false\n    fromVersion: \"1.22\"\n    toVersion: \"1.28\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.29\"\n    toVersion: \"1.30\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.31\"\n    toVersion: \"1.32\"\n\nremoved: true\n---\nEnabling this feature gate deactivated functionality in `kube-apiserver`,\n`kube-controller-manager` and `kubelet` that related to the `--cloud-provider`\ncommand line argument.\n\nIn Kubernetes v1.31 and later, the only valid values for `--cloud-provider`\nare the empty string (no cloud provider integration), or \"external\"\n(integration via a separate cloud-controller-manager).",
      "terms": [
        {
          "term": "DisableCloudProviders",
          "tier": 1,
          "reasoning": "Named feature gate in Kubernetes that controls cloud provider functionality."
        },
        {
          "term": "feature_gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling optional features."
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating experimental status in Kubernetes."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating pre-stable testing phase in Kubernetes."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready status in Kubernetes."
        },
        {
          "term": "kube-apiserver",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that exposes the Kubernetes API."
        },
        {
          "term": "kube-controller-manager",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that runs controller processes."
        },
        {
          "term": "kubelet",
          "tier": 1,
          "reasoning": "Primary node agent that runs on each node in the cluster."
        },
        {
          "term": "--cloud-provider",
          "tier": 1,
          "reasoning": "CLI flag/command line argument for configuring cloud provider integration."
        },
        {
          "term": "command line argument",
          "tier": 3,
          "reasoning": "Technical term for parameters passed to executables at runtime."
        },
        {
          "term": "cloud provider",
          "tier": 2,
          "reasoning": "Domain concept referring to infrastructure providers integrated with Kubernetes."
        },
        {
          "term": "cloud provider integration",
          "tier": 2,
          "reasoning": "Technical concept describing how Kubernetes connects with cloud infrastructure."
        },
        {
          "term": "cloud-controller-manager",
          "tier": 1,
          "reasoning": "Kubernetes component that embeds cloud-specific control logic."
        },
        {
          "term": "external",
          "tier": 2,
          "reasoning": "Valid configuration value for --cloud-provider indicating out-of-tree cloud controller."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": "v1.31",
          "tier": 2,
          "reasoning": "Specific Kubernetes version referenced for feature behavior."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Configuration property indicating the default state of a feature gate."
        },
        {
          "term": "fromVersion",
          "tier": 2,
          "reasoning": "Configuration property indicating when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 2,
          "reasoning": "Configuration property indicating when a feature stage ends."
        },
        {
          "term": "stage",
          "tier": 2,
          "reasoning": "Technical term describing feature maturity level in Kubernetes lifecycle."
        },
        {
          "term": "removed",
          "tier": 2,
          "reasoning": "Feature gate status indicating the gate has been removed from Kubernetes."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:09:41.997774",
      "elapsed_time": 12.229445219039917
    },
    {
      "chunk_id": "reference_kubernetes-api_config-and-storage-resources_volume-attributes-class-v1_sec1",
      "doc_id": "reference_kubernetes-api_config-and-storage-resources_volume-attributes-class-v1",
      "heading": "VolumeAttributesClass {#VolumeAttributesClass}",
      "source_file": "reference_kubernetes-api_config-and-storage-resources_volume-attributes-class-v1.md",
      "content": "VolumeAttributesClass represents a specification of mutable volume attributes defined by the CSI driver. The class can be specified during dynamic provisioning of PersistentVolumeClaims, and changed in the PersistentVolumeClaim spec after provisioning.\n\n<hr>\n\n- **apiVersion**: storage.k8s.io/v1\n\n\n- **kind**: VolumeAttributesClass\n\n\n- **metadata** (<a href=\"{{< ref \"../common-definitions/object-meta#ObjectMeta\" >}}\">ObjectMeta</a>)\n\n  Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n- **driverName** (string), required\n\n  Name of the CSI driver This field is immutable.\n\n- **parameters** (map[string]string)\n\n  parameters hold volume attributes defined by the CSI driver. These values are opaque to the Kubernetes and are passed directly to the CSI driver. The underlying storage provider supports changing these attributes on an existing volume, however the parameters field itself is immutable. To invoke a volume update, a new VolumeAttributesClass should be created with new parameters, and the PersistentVolumeClaim should be updated to reference the new VolumeAttributesClass.\n  \n  This field is required and must contain at least one key/value pair. The keys cannot be empty, and the maximum number of parameters is 512, with a cumulative max size of 256K. If the CSI driver rejects invalid parameters, the target PersistentVolumeClaim will be set to an \"Infeasible\" state in the modifyVolumeStatus field.",
      "terms": [
        {
          "term": "VolumeAttributesClass",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for specifying mutable volume attributes defined by CSI driver."
        },
        {
          "term": "CSI driver",
          "tier": 1,
          "reasoning": "Named infrastructure component - Container Storage Interface driver that manages storage operations."
        },
        {
          "term": "PersistentVolumeClaims",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for requesting persistent storage."
        },
        {
          "term": "PersistentVolumeClaim",
          "tier": 1,
          "reasoning": "Singular form of the core Kubernetes storage API resource."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Kubernetes API field that specifies the version of the API schema."
        },
        {
          "term": "storage.k8s.io/v1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version for storage resources."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes API field that identifies the type of resource."
        },
        {
          "term": "metadata",
          "tier": 2,
          "reasoning": "Kubernetes API field containing object identification and management data."
        },
        {
          "term": "ObjectMeta",
          "tier": 1,
          "reasoning": "Kubernetes API type that defines standard object metadata structure."
        },
        {
          "term": "driverName",
          "tier": 2,
          "reasoning": "Required field specifying the name of the CSI driver for the volume class."
        },
        {
          "term": "parameters",
          "tier": 2,
          "reasoning": "Field holding volume attributes as key/value pairs passed to CSI driver."
        },
        {
          "term": "dynamic provisioning",
          "tier": 2,
          "reasoning": "Kubernetes storage concept for automatically creating volumes on demand."
        },
        {
          "term": "immutable",
          "tier": 2,
          "reasoning": "Technical property indicating a field cannot be changed after creation."
        },
        {
          "term": "volume attributes",
          "tier": 2,
          "reasoning": "Domain concept referring to configurable properties of storage volumes."
        },
        {
          "term": "mutable volume attributes",
          "tier": 2,
          "reasoning": "Volume properties that can be changed after initial provisioning."
        },
        {
          "term": "storage provider",
          "tier": 2,
          "reasoning": "Infrastructure concept referring to the underlying storage system."
        },
        {
          "term": "volume update",
          "tier": 2,
          "reasoning": "Process of modifying volume attributes on an existing volume."
        },
        {
          "term": "modifyVolumeStatus",
          "tier": 2,
          "reasoning": "Kubernetes field tracking the status of volume modification operations."
        },
        {
          "term": "Infeasible",
          "tier": 2,
          "reasoning": "Specific status value indicating CSI driver rejected invalid parameters."
        },
        {
          "term": "CSI",
          "tier": 1,
          "reasoning": "Container Storage Interface - standard protocol for storage integration in Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform this documentation describes."
        },
        {
          "term": "spec",
          "tier": 2,
          "reasoning": "Kubernetes API concept referring to the desired state specification of a resource."
        },
        {
          "term": "provisioning",
          "tier": 2,
          "reasoning": "Process of creating and configuring storage resources."
        },
        {
          "term": "key/value pair",
          "tier": 3,
          "reasoning": "Data structure format used for parameters passed to CSI driver."
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the driverName field."
        },
        {
          "term": "map[string]string",
          "tier": 3,
          "reasoning": "Go-style type notation indicating a string-to-string mapping for parameters."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - referenced in context of Kubernetes conventions."
        },
        {
          "term": "api-conventions",
          "tier": 2,
          "reasoning": "Kubernetes documentation reference for API design standards."
        }
      ],
      "term_count": 28,
      "generated_at": "2026-02-08T22:09:57.652185",
      "elapsed_time": 14.633269309997559
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_rollout__index_sec4",
      "doc_id": "reference_kubectl_generated_kubectl_rollout__index",
      "heading": "{{% heading \"seealso\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_rollout__index.md",
      "content": "* [kubectl](../kubectl/)\t - kubectl controls the Kubernetes cluster manager\n* [kubectl rollout history](kubectl_rollout_history/)\t - View rollout history\n* [kubectl rollout pause](kubectl_rollout_pause/)\t - Mark the provided resource as paused\n* [kubectl rollout restart](kubectl_rollout_restart/)\t - Restart a resource\n* [kubectl rollout resume](kubectl_rollout_resume/)\t - Resume a paused resource\n* [kubectl rollout status](kubectl_rollout_status/)\t - Show the status of the rollout\n* [kubectl rollout undo](kubectl_rollout_undo/)\t - Undo a previous rollout",
      "terms": [
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Primary Kubernetes CLI tool, a core named component for cluster management."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that kubectl controls."
        },
        {
          "term": "cluster manager",
          "tier": 2,
          "reasoning": "Domain concept describing the role of managing a Kubernetes cluster."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept representing a set of nodes running containerized applications."
        },
        {
          "term": "kubectl rollout",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for managing rollouts of resources."
        },
        {
          "term": "kubectl rollout history",
          "tier": 1,
          "reasoning": "Specific kubectl command to view rollout history."
        },
        {
          "term": "kubectl rollout pause",
          "tier": 1,
          "reasoning": "Specific kubectl command to pause a rollout."
        },
        {
          "term": "kubectl rollout restart",
          "tier": 1,
          "reasoning": "Specific kubectl command to restart a resource's rollout."
        },
        {
          "term": "kubectl rollout resume",
          "tier": 1,
          "reasoning": "Specific kubectl command to resume a paused rollout."
        },
        {
          "term": "kubectl rollout status",
          "tier": 1,
          "reasoning": "Specific kubectl command to show rollout status."
        },
        {
          "term": "kubectl rollout undo",
          "tier": 1,
          "reasoning": "Specific kubectl command to undo a previous rollout."
        },
        {
          "term": "rollout",
          "tier": 2,
          "reasoning": "Core Kubernetes deployment concept describing the process of updating resources."
        },
        {
          "term": "rollout history",
          "tier": 2,
          "reasoning": "Domain concept for tracking the history of deployment changes."
        },
        {
          "term": "paused",
          "tier": 2,
          "reasoning": "Technical state in Kubernetes rollout lifecycle where updates are suspended."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Kubernetes domain term for API objects that can be managed."
        },
        {
          "term": "status",
          "tier": 3,
          "reasoning": "Technical term describing the current state of a Kubernetes resource or operation."
        },
        {
          "term": "undo",
          "tier": 2,
          "reasoning": "Technical operation concept for reverting to a previous rollout state."
        },
        {
          "term": "pause",
          "tier": 2,
          "reasoning": "Technical operation to halt a rollout in progress."
        },
        {
          "term": "resume",
          "tier": 2,
          "reasoning": "Technical operation to continue a paused rollout."
        },
        {
          "term": "restart",
          "tier": 2,
          "reasoning": "Technical operation to trigger a new rollout of a resource."
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T22:10:07.702845",
      "elapsed_time": 9.027247905731201
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec10",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`AnonymousAuthConfig`     {#apiserver-config-k8s-io-v1-AnonymousAuthConfig}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [AuthenticationConfiguration](#apiserver-config-k8s-io-v1-AuthenticationConfiguration)\n\n\n<p>AnonymousAuthConfig provides the configuration for the anonymous authenticator.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>enabled</code> <B>[Required]</B><br/>\n<code>bool</code>\n</td>\n<td>\n   <span class=\"text-muted\">No description provided.</span></td>\n</tr>\n<tr><td><code>conditions</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-config-k8s-io-v1-AnonymousAuthCondition\"><code>[]AnonymousAuthCondition</code></a>\n</td>\n<td>\n   <p>If set, anonymous auth is only allowed if the request meets one of the\nconditions.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for authentication settings."
        },
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Named configuration structure for the anonymous authenticator component."
        },
        {
          "term": "AnonymousAuthCondition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type defining conditions for anonymous authentication."
        },
        {
          "term": "anonymous authenticator",
          "tier": 2,
          "reasoning": "Domain concept referring to the authentication mechanism that handles anonymous requests."
        },
        {
          "term": "anonymous auth",
          "tier": 2,
          "reasoning": "Abbreviated form of anonymous authentication, a security concept in Kubernetes."
        },
        {
          "term": "enabled",
          "tier": 3,
          "reasoning": "Configuration field that controls whether a feature is active, technical term in config context."
        },
        {
          "term": "conditions",
          "tier": 2,
          "reasoning": "Technical term referring to criteria that must be met for authentication to proceed."
        },
        {
          "term": "request",
          "tier": 3,
          "reasoning": "Technical term referring to API requests in the authentication context."
        },
        {
          "term": "configuration",
          "tier": 3,
          "reasoning": "Technical term describing settings and parameters for system behavior."
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "API group and version identifier for Kubernetes API server configuration."
        },
        {
          "term": "bool",
          "tier": 3,
          "reasoning": "Data type specification indicating a boolean field in the configuration."
        },
        {
          "term": "Field",
          "tier": 3,
          "reasoning": "Technical term referring to a configuration parameter in the API object schema."
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:10:16.719404",
      "elapsed_time": 7.999697685241699
    },
    {
      "chunk_id": "reference_glossary_name_sec0",
      "doc_id": "reference_glossary_name",
      "heading": "Introduction",
      "source_file": "reference_glossary_name.md",
      "content": "---\ntitle: Name\nid: name\ndate: 2018-04-12\nfull_link: /docs/concepts/overview/working-with-objects/names\nshort_description: >\n  A client-provided string that refers to an object in a resource URL, such as `/api/v1/pods/some-name`.\n\naka: \ntags:\n- fundamental\n---\nA client-provided string that refers to an object in a {{< glossary_tooltip text=\"resource\" term_id=\"api-resource\" >}}\nURL, such as `/api/v1/pods/some-name`.\n\n<!--more--> \n\nOnly one object of a given kind can have a given name at a time. However, if you delete the object, you can make a new object with the same name.",
      "terms": [
        {
          "term": "Name",
          "tier": 1,
          "reasoning": "Core Kubernetes concept for identifying objects, the main subject of this glossary entry"
        },
        {
          "term": "object",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes concept referring to persistent entities in the system"
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Kubernetes domain concept referring to API endpoints and object types"
        },
        {
          "term": "resource URL",
          "tier": 2,
          "reasoning": "Technical concept describing the API path structure for accessing Kubernetes resources"
        },
        {
          "term": "URL",
          "tier": 3,
          "reasoning": "Standard web protocol concept used in context of Kubernetes API addressing"
        },
        {
          "term": "api",
          "tier": 2,
          "reasoning": "Core technical concept appearing in the resource URL path example"
        },
        {
          "term": "/api/v1/pods/some-name",
          "tier": 2,
          "reasoning": "Example API path demonstrating Kubernetes resource URL structure"
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Core Kubernetes resource type appearing in the example URL path"
        },
        {
          "term": "v1",
          "tier": 2,
          "reasoning": "API version identifier in Kubernetes API path structure"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to the type/category of an API object"
        },
        {
          "term": "client-provided string",
          "tier": 2,
          "reasoning": "Technical description of how names are specified by users/clients"
        },
        {
          "term": "client",
          "tier": 3,
          "reasoning": "Technical term referring to the entity making API requests"
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:10:26.494680",
      "elapsed_time": 8.75869345664978
    },
    {
      "chunk_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information_sec0",
      "doc_id": "tasks_inject-data-application_downward-api-volume-expose-pod-information",
      "heading": "Introduction",
      "source_file": "tasks_inject-data-application_downward-api-volume-expose-pod-information.md",
      "content": "---\ntitle: Expose Pod Information to Containers Through Files\ncontent_type: task\nweight: 40\n---\n\n<!-- overview -->\n\nThis page shows how a Pod can use a\n[`downwardAPI` volume](/docs/concepts/storage/volumes/#downwardapi),\nto expose information about itself to containers running in the Pod.\nA `downwardAPI` volume can expose Pod fields and container fields.\n\nIn Kubernetes, there are two ways to expose Pod and container fields to a running container:\n\n* [Environment variables](/docs/tasks/inject-data-application/environment-variable-expose-pod-information/)\n* Volume files, as explained in this task\n\nTogether, these two ways of exposing Pod and container fields are called the\n_downward API_.",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object and fundamental unit of deployment."
        },
        {
          "term": "downwardAPI",
          "tier": 1,
          "reasoning": "Specific Kubernetes volume type for exposing pod metadata."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core domain concept representing isolated runtime environments in Kubernetes."
        },
        {
          "term": "volume",
          "tier": 2,
          "reasoning": "Kubernetes storage abstraction concept for persistent or ephemeral data."
        },
        {
          "term": "Pod fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata attributes of a Pod object."
        },
        {
          "term": "container fields",
          "tier": 2,
          "reasoning": "Technical concept referring to metadata attributes of container specifications."
        },
        {
          "term": "Environment variables",
          "tier": 2,
          "reasoning": "Standard mechanism for passing configuration data to containers."
        },
        {
          "term": "Volume files",
          "tier": 2,
          "reasoning": "Method of exposing data to containers through the filesystem."
        },
        {
          "term": "downward API",
          "tier": 1,
          "reasoning": "Named Kubernetes feature for exposing pod and container metadata to running containers."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "running container",
          "tier": 2,
          "reasoning": "Technical concept describing an active container process within a pod."
        }
      ],
      "term_count": 11,
      "generated_at": "2026-02-08T22:10:35.316501",
      "elapsed_time": 7.803985834121704
    },
    {
      "chunk_id": "concepts_security_multi-tenancy_sec1",
      "doc_id": "concepts_security_multi-tenancy",
      "heading": "Use cases",
      "source_file": "concepts_security_multi-tenancy.md",
      "content": "The first step to determining how to share your cluster is understanding your use case, so you can\nevaluate the patterns and tools available. In general, multi-tenancy in Kubernetes clusters falls\ninto two broad categories, though many variations and hybrids are also possible.\n\n### Multiple teams\n\nA common form of multi-tenancy is to share a cluster between multiple teams within an\norganization, each of whom may operate one or more workloads. These workloads frequently need to\ncommunicate with each other, and with other workloads located on the same or different clusters.\n\nIn this scenario, members of the teams often have direct access to Kubernetes resources via tools\nsuch as `kubectl`, or indirect access through GitOps controllers or other types of release\nautomation tools. There is often some level of trust between members of different teams, but\nKubernetes policies such as RBAC, quotas, and network policies are essential to safely and fairly\nshare clusters.\n\n### Multiple customers\n\nThe other major form of multi-tenancy frequently involves a Software-as-a-Service (SaaS) vendor\nrunning multiple instances of a workload for customers. This business model is so strongly\nassociated with this deployment style that many people call it \"SaaS tenancy.\" However, a better\nterm might be \"multi-customer tenancy,\" since SaaS vendors may also use other deployment models,\nand this deployment model can also be used outside of SaaS.\n\nIn this scenario, the customers do not have access to the cluster; Kubernetes is invisible from\ntheir perspective and is only used by the vendor to manage the workloads. Cost optimization is\nfrequently a critical concern, and Kubernetes policies are used to ensure that the workloads are\nstrongly isolated from each other.",
      "terms": [
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept referring to a set of nodes running containerized applications"
        },
        {
          "term": "multi-tenancy",
          "tier": 2,
          "reasoning": "Key architectural pattern for sharing Kubernetes resources among multiple users or teams"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform that is the subject of this documentation"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Technical term for applications and services running on Kubernetes"
        },
        {
          "term": "clusters",
          "tier": 2,
          "reasoning": "Plural form of cluster, referring to multiple Kubernetes environments"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters"
        },
        {
          "term": "GitOps controllers",
          "tier": 2,
          "reasoning": "Automation tools that implement GitOps methodology for Kubernetes deployments"
        },
        {
          "term": "Kubernetes resources",
          "tier": 2,
          "reasoning": "API objects and entities managed within a Kubernetes cluster"
        },
        {
          "term": "RBAC",
          "tier": 1,
          "reasoning": "Role-Based Access Control - a core Kubernetes authorization mechanism"
        },
        {
          "term": "quotas",
          "tier": 2,
          "reasoning": "Kubernetes resource management mechanism for limiting resource consumption"
        },
        {
          "term": "network policies",
          "tier": 2,
          "reasoning": "Kubernetes resources that control network traffic between pods"
        },
        {
          "term": "Kubernetes policies",
          "tier": 2,
          "reasoning": "Configuration rules that govern behavior and access in Kubernetes"
        },
        {
          "term": "Software-as-a-Service",
          "tier": 2,
          "reasoning": "Cloud computing service model relevant to multi-tenancy deployment patterns"
        },
        {
          "term": "SaaS",
          "tier": 2,
          "reasoning": "Abbreviation for Software-as-a-Service, a common deployment model"
        },
        {
          "term": "SaaS tenancy",
          "tier": 2,
          "reasoning": "Specific multi-tenancy pattern associated with SaaS deployments"
        },
        {
          "term": "multi-customer tenancy",
          "tier": 2,
          "reasoning": "Alternative term for SaaS-style multi-tenancy deployment model"
        },
        {
          "term": "deployment model",
          "tier": 2,
          "reasoning": "Architectural pattern for how applications are deployed and managed"
        },
        {
          "term": "cost optimization",
          "tier": 3,
          "reasoning": "Operational concern relevant to multi-tenant Kubernetes deployments"
        },
        {
          "term": "isolated",
          "tier": 3,
          "reasoning": "Technical concept referring to workload separation and security boundaries"
        },
        {
          "term": "vendor",
          "tier": 3,
          "reasoning": "Role in SaaS context managing Kubernetes infrastructure for customers"
        },
        {
          "term": "customers",
          "tier": 3,
          "reasoning": "Tenants in a multi-customer deployment model"
        },
        {
          "term": "teams",
          "tier": 3,
          "reasoning": "Organizational units that share cluster resources in multi-tenancy"
        },
        {
          "term": "use case",
          "tier": 3,
          "reasoning": "Technical planning term for evaluating deployment patterns"
        },
        {
          "term": "deployment style",
          "tier": 2,
          "reasoning": "Pattern or approach for deploying applications in Kubernetes"
        }
      ],
      "term_count": 24,
      "generated_at": "2026-02-08T22:10:50.036469",
      "elapsed_time": 13.701468229293823
    },
    {
      "chunk_id": "tasks_debug_debug-application_get-shell-running-container_sec5",
      "doc_id": "tasks_debug_debug-application_get-shell-running-container",
      "heading": "Opening a shell when a Pod has more than one container",
      "source_file": "tasks_debug_debug-application_get-shell-running-container.md",
      "content": "If a Pod has more than one container, use `--container` or `-c` to\nspecify a container in the `kubectl exec` command. For example,\nsuppose you have a Pod named my-pod, and the Pod has two containers\nnamed _main-app_ and _helper-app_. The following command would open a\nshell to the _main-app_ container.\n\n```shell\nkubectl exec -i -t my-pod --container main-app -- /bin/bash\n```\n\n{{< note >}}\nThe short options `-i` and `-t` are the same as the long options `--stdin` and `--tty`\n{{< /note >}}",
      "terms": [
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing a group of containers"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Fundamental domain concept in Kubernetes representing an isolated runtime unit"
        },
        {
          "term": "kubectl exec",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand for executing commands in containers"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool"
        },
        {
          "term": "--container",
          "tier": 3,
          "reasoning": "CLI flag for specifying target container in kubectl commands"
        },
        {
          "term": "-c",
          "tier": 3,
          "reasoning": "Short form CLI flag for container specification"
        },
        {
          "term": "my-pod",
          "tier": 3,
          "reasoning": "Example Pod name used in documentation to illustrate command usage"
        },
        {
          "term": "main-app",
          "tier": 3,
          "reasoning": "Example container name demonstrating multi-container Pod usage"
        },
        {
          "term": "helper-app",
          "tier": 3,
          "reasoning": "Example container name illustrating sidecar/helper container pattern"
        },
        {
          "term": "shell",
          "tier": 3,
          "reasoning": "Technical term for command-line interface opened via exec"
        },
        {
          "term": "/bin/bash",
          "tier": 3,
          "reasoning": "Linux shell path used as exec target command"
        },
        {
          "term": "-i",
          "tier": 3,
          "reasoning": "Short CLI flag for stdin passthrough in kubectl exec"
        },
        {
          "term": "-t",
          "tier": 3,
          "reasoning": "Short CLI flag for TTY allocation in kubectl exec"
        },
        {
          "term": "--stdin",
          "tier": 3,
          "reasoning": "Long form CLI flag enabling stdin passthrough to container"
        },
        {
          "term": "--tty",
          "tier": 3,
          "reasoning": "Long form CLI flag for allocating a TTY for interactive sessions"
        },
        {
          "term": "exec",
          "tier": 2,
          "reasoning": "Kubernetes operation concept for running commands inside containers"
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T22:10:59.589001",
      "elapsed_time": 8.532642364501953
    },
    {
      "chunk_id": "tasks_manage-kubernetes-objects_declarative-config_sec0",
      "doc_id": "tasks_manage-kubernetes-objects_declarative-config",
      "heading": "Introduction",
      "source_file": "tasks_manage-kubernetes-objects_declarative-config.md",
      "content": "---\ntitle: Declarative Management of Kubernetes Objects Using Configuration Files\ncontent_type: task\nweight: 10\n---\n\n<!-- overview -->\nKubernetes objects can be created, updated, and deleted by storing multiple\nobject configuration files in a directory and using `kubectl apply` to\nrecursively create and update those objects as needed. This method\nretains writes made to live objects without merging the changes\nback into the object configuration files. `kubectl diff` also gives you a\npreview of what changes `apply` will make.",
      "terms": [
        {
          "term": "Kubernetes objects",
          "tier": 1,
          "reasoning": "Core concept referring to the fundamental API resources managed by Kubernetes."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "object configuration files",
          "tier": 2,
          "reasoning": "Domain-specific term for files that define the desired state of Kubernetes objects."
        },
        {
          "term": "configuration files",
          "tier": 2,
          "reasoning": "Technical term for files containing object specifications used with declarative management."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl CLI command for declarative object management."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "The official Kubernetes command-line interface tool."
        },
        {
          "term": "apply",
          "tier": 2,
          "reasoning": "Kubernetes-specific operation for declarative resource management."
        },
        {
          "term": "kubectl diff",
          "tier": 1,
          "reasoning": "Specific kubectl CLI command for previewing changes before applying."
        },
        {
          "term": "diff",
          "tier": 2,
          "reasoning": "Kubernetes operation to compare live objects with configuration files."
        },
        {
          "term": "live objects",
          "tier": 2,
          "reasoning": "Domain concept referring to the current state of objects running in the cluster."
        },
        {
          "term": "objects",
          "tier": 2,
          "reasoning": "Short form reference to Kubernetes API objects/resources."
        },
        {
          "term": "Declarative Management",
          "tier": 2,
          "reasoning": "Core Kubernetes operational paradigm where desired state is declared in configuration."
        },
        {
          "term": "created",
          "tier": 3,
          "reasoning": "Technical operation in the Kubernetes object lifecycle."
        },
        {
          "term": "updated",
          "tier": 3,
          "reasoning": "Technical operation in the Kubernetes object lifecycle."
        },
        {
          "term": "deleted",
          "tier": 3,
          "reasoning": "Technical operation in the Kubernetes object lifecycle."
        },
        {
          "term": "directory",
          "tier": 3,
          "reasoning": "File system concept relevant to storing multiple configuration files."
        },
        {
          "term": "recursively",
          "tier": 3,
          "reasoning": "Technical term describing how kubectl apply traverses directory structures."
        },
        {
          "term": "merging",
          "tier": 2,
          "reasoning": "Technical process concept related to how changes are combined in declarative management."
        },
        {
          "term": "writes",
          "tier": 3,
          "reasoning": "Technical term referring to modifications made to live objects."
        },
        {
          "term": "changes",
          "tier": 3,
          "reasoning": "Technical term in context of tracking modifications to objects."
        },
        {
          "term": "preview",
          "tier": 3,
          "reasoning": "Technical capability provided by kubectl diff to see pending changes."
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:11:12.897758",
      "elapsed_time": 12.291944026947021
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_HPAContainerMetrics_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_HPAContainerMetrics",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_HPAContainerMetrics.md",
      "content": "---\ntitle: HPAContainerMetrics\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha\n    defaultValue: false\n    fromVersion: \"1.20\"\n    toVersion: \"1.26\"\n  - stage: beta\n    defaultValue: true\n    fromVersion: \"1.27\"\n    toVersion: \"1.29\"\n  - stage: stable\n    defaultValue: true\n    fromVersion: \"1.30\"\n    toVersion: \"1.31\"\n\nremoved: true\n---\nAllow {{< glossary_tooltip text=\"HorizontalPodAutoscalers\" term_id=\"horizontal-pod-autoscaler\" >}}\nto scale based on metrics from individual containers within target pods.",
      "terms": [
        {
          "term": "HPAContainerMetrics",
          "tier": 1,
          "reasoning": "Feature gate name that is the primary subject of this documentation chunk."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "Kubernetes mechanism for enabling/disabling features, explicitly referenced as content_type."
        },
        {
          "term": "HorizontalPodAutoscalers",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for automatic horizontal scaling of pods."
        },
        {
          "term": "horizontal-pod-autoscaler",
          "tier": 1,
          "reasoning": "Glossary term ID referencing the HPA Kubernetes resource."
        },
        {
          "term": "pods",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes workload unit, referenced as 'target pods'."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core Kubernetes concept representing individual container units within pods."
        },
        {
          "term": "metrics",
          "tier": 2,
          "reasoning": "Technical concept for measurements used in autoscaling decisions."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Domain-specific action referring to adjusting replica counts in Kubernetes."
        },
        {
          "term": "alpha",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating experimental/early development status."
        },
        {
          "term": "beta",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating pre-stable testing phase."
        },
        {
          "term": "stable",
          "tier": 3,
          "reasoning": "Feature lifecycle stage indicating production-ready status."
        },
        {
          "term": "stage",
          "tier": 3,
          "reasoning": "Technical term describing feature gate lifecycle phases."
        },
        {
          "term": "defaultValue",
          "tier": 3,
          "reasoning": "Configuration property indicating whether feature is enabled by default."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Version boundary marker for feature gate availability."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Version boundary marker for feature gate availability end."
        },
        {
          "term": "target pods",
          "tier": 2,
          "reasoning": "Domain concept referring to pods being monitored/scaled by HPA."
        },
        {
          "term": "individual containers",
          "tier": 2,
          "reasoning": "Concept distinguishing per-container metrics from pod-level metrics."
        }
      ],
      "term_count": 17,
      "generated_at": "2026-02-08T22:11:25.972885",
      "elapsed_time": 12.057783603668213
    },
    {
      "chunk_id": "tasks_administer-cluster_kubelet-in-userns_sec3",
      "doc_id": "tasks_administer-cluster_kubelet-in-userns",
      "heading": "Running Kubernetes inside Unprivileged Containers",
      "source_file": "tasks_administer-cluster_kubelet-in-userns.md",
      "content": "{{% thirdparty-content %}}\n\n### sysbox\n\n[Sysbox](https://github.com/nestybox/sysbox) is an open-source container runtime\n(similar to \"runc\") that supports running system-level workloads such as Docker\nand Kubernetes inside unprivileged containers isolated with the Linux user\nnamespace.\n\nSee [Sysbox Quick Start Guide: Kubernetes-in-Docker](https://github.com/nestybox/sysbox/blob/master/docs/quickstart/kind.md) for more info.\n\nSysbox supports running Kubernetes inside unprivileged containers without\nrequiring Cgroup v2 and without the `KubeletInUserNamespace` feature gate. It\ndoes this by exposing specially crafted `/proc` and `/sys` filesystems inside\nthe container plus several other advanced OS virtualization techniques.",
      "terms": [
        {
          "term": "sysbox",
          "tier": 1,
          "reasoning": "Named open-source container runtime, proper noun and specific tool name"
        },
        {
          "term": "Sysbox",
          "tier": 1,
          "reasoning": "Capitalized variant of the container runtime name as it appears in text"
        },
        {
          "term": "container runtime",
          "tier": 2,
          "reasoning": "Core domain concept describing software that runs containers"
        },
        {
          "term": "runc",
          "tier": 1,
          "reasoning": "Named container runtime tool, proper noun reference"
        },
        {
          "term": "Docker",
          "tier": 1,
          "reasoning": "Named container platform and proper noun"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core domain proper noun, the container orchestration platform"
        },
        {
          "term": "unprivileged containers",
          "tier": 2,
          "reasoning": "Domain concept describing containers running without elevated privileges"
        },
        {
          "term": "Kubernetes-in-Docker",
          "tier": 2,
          "reasoning": "Specific architectural pattern for running Kubernetes inside Docker containers"
        },
        {
          "term": "Cgroup v2",
          "tier": 2,
          "reasoning": "Linux kernel feature for resource control, specific version reference"
        },
        {
          "term": "KubeletInUserNamespace",
          "tier": 1,
          "reasoning": "Named Kubernetes feature gate, proper noun"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes concept for enabling/disabling features"
        },
        {
          "term": "/proc",
          "tier": 2,
          "reasoning": "Linux virtual filesystem providing process information"
        },
        {
          "term": "/sys",
          "tier": 2,
          "reasoning": "Linux virtual filesystem providing kernel/device information"
        },
        {
          "term": "filesystems",
          "tier": 3,
          "reasoning": "General technical term for file system structures"
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core domain concept for isolated application environments"
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Plural form of core container concept as used in text"
        },
        {
          "term": "OS virtualization",
          "tier": 2,
          "reasoning": "Technical concept for operating system-level virtualization techniques"
        },
        {
          "term": "system-level workloads",
          "tier": 2,
          "reasoning": "Domain concept describing workloads requiring system access"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Core isolation concept in both Linux and Kubernetes contexts"
        },
        {
          "term": "Linux",
          "tier": 3,
          "reasoning": "Operating system platform referenced for kernel features"
        },
        {
          "term": "open-source",
          "tier": 3,
          "reasoning": "Technical term describing software licensing model"
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:11:38.196930",
      "elapsed_time": 11.204795837402344
    },
    {
      "chunk_id": "tutorials_kubernetes-basics_create-cluster_cluster-intro_sec0",
      "doc_id": "tutorials_kubernetes-basics_create-cluster_cluster-intro",
      "heading": "Kubernetes Clusters",
      "source_file": "tutorials_kubernetes-basics_create-cluster_cluster-intro.md",
      "content": "{{% alert %}}\n_Kubernetes is a production-grade, open-source platform that orchestrates\nthe placement (scheduling) and execution of application containers\nwithin and across computer clusters._\n{{% /alert %}}\n\n**Kubernetes coordinates a highly available cluster of computers that are connected\nto work as a single unit.** The abstractions in Kubernetes allow you to deploy\ncontainerized applications to a cluster without tying them specifically to individual\nmachines. To make use of this new model of deployment, applications need to be packaged\nin a way that decouples them from individual hosts: they need to be containerized.\nContainerized applications are more flexible and available than in past deployment models,\nwhere applications were installed directly onto specific machines as packages deeply\nintegrated into the host. **Kubernetes automates the distribution and scheduling of\napplication containers across a cluster in a more efficient way.** Kubernetes is an\nopen-source platform and is production-ready.\n\nA Kubernetes cluster consists of two types of resources:\n\n* The **Control Plane** coordinates the cluster\n* **Nodes** are the workers that run applications\n\n### Cluster Diagram\n\n{{< figure src=\"/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg\" style=\"width: 100%;\" >}}\n\n**The Control Plane is responsible for managing the cluster.** The Control Plane\ncoordinates all activities in your cluster, such as scheduling applications, maintaining\napplications' desired state, scaling applications, and rolling out new updates.\n\n{{% alert %}}\n_Control Planes manage the cluster and the nodes that are used to host the running\napplications._\n{{% /alert %}}\n\n**A node is a VM or a physical computer that serves as a worker machine in a Kubernetes\ncluster.** Each node has a Kubelet, which is an agent for managing the node and\ncommunicating with the Kubernetes control plane. The node should also have tools for\nhandling container operations, such as {{< glossary_tooltip text=\"containerd\" term_id=\"containerd\" >}}\nor {{< glossary_tooltip term_id=\"cri-o\" >}}. A Kubernetes cluster that handles production\ntraffic should have a minimum of three nodes because if one node goes down, both an\n[etcd](/docs/concepts/architecture/#etcd) member and a control plane instance are lost,\nand redundancy is compromised. You can mitigate this risk by adding more control plane nodes.\n\nWhen you deploy applications on Kubernetes, you tell the control plane to start\nthe application containers. The control plane schedules the containers to run on\nthe cluster's nodes. **Node-level components, such as the kubelet, communicate\nwith the control plane using the [Kubernetes API](/docs/concepts/overview/kubernetes-api/)**,\nwhich the control plane exposes. End users can also use the Kubernetes API directly\nto interact with the cluster.\n\nA Kubernetes cluster can be deployed on either physical or virtual machines. To\nget started with Kubernetes development, you can use Minikube. Minikube is a lightweight\nKubernetes implementation that creates a VM on your local machine and deploys a\nsimple cluster containing only one node. Minikube is available for Linux, macOS,\nand Windows systems. The Minikube CLI provides basic bootstrapping operations for\nworking with your cluster, including start, stop, status, and delete.",
      "terms": [
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core platform name and the primary subject of the documentation."
        },
        {
          "term": "Control Plane",
          "tier": 1,
          "reasoning": "Named Kubernetes component responsible for managing the cluster."
        },
        {
          "term": "Nodes",
          "tier": 1,
          "reasoning": "Named Kubernetes resource type representing worker machines."
        },
        {
          "term": "Kubelet",
          "tier": 1,
          "reasoning": "Named Kubernetes agent component running on each node."
        },
        {
          "term": "containerd",
          "tier": 1,
          "reasoning": "Named container runtime implementation used by Kubernetes."
        },
        {
          "term": "cri-o",
          "tier": 1,
          "reasoning": "Named container runtime implementation for Kubernetes."
        },
        {
          "term": "etcd",
          "tier": 1,
          "reasoning": "Named distributed key-value store component of Kubernetes architecture."
        },
        {
          "term": "Kubernetes API",
          "tier": 1,
          "reasoning": "Named API interface exposed by the control plane for cluster interaction."
        },
        {
          "term": "Minikube",
          "tier": 1,
          "reasoning": "Named lightweight Kubernetes implementation tool for local development."
        },
        {
          "term": "Minikube CLI",
          "tier": 1,
          "reasoning": "Named command-line interface for Minikube operations."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core architectural concept representing connected computers working as a unit."
        },
        {
          "term": "scheduling",
          "tier": 2,
          "reasoning": "Domain process for placing and executing application containers."
        },
        {
          "term": "containers",
          "tier": 2,
          "reasoning": "Core concept for packaged application units in Kubernetes."
        },
        {
          "term": "containerized applications",
          "tier": 2,
          "reasoning": "Domain concept describing applications packaged as containers."
        },
        {
          "term": "application containers",
          "tier": 2,
          "reasoning": "Domain concept for containers running applications."
        },
        {
          "term": "container operations",
          "tier": 2,
          "reasoning": "Domain concept for handling container lifecycle activities."
        },
        {
          "term": "computer clusters",
          "tier": 2,
          "reasoning": "Infrastructure concept for grouped computing resources."
        },
        {
          "term": "worker machine",
          "tier": 2,
          "reasoning": "Domain concept describing the role of nodes in a cluster."
        },
        {
          "term": "control plane instance",
          "tier": 2,
          "reasoning": "Domain concept for a running instance of the control plane."
        },
        {
          "term": "control plane nodes",
          "tier": 2,
          "reasoning": "Domain concept for nodes running control plane components."
        },
        {
          "term": "Node-level components",
          "tier": 2,
          "reasoning": "Architectural concept for components running on worker nodes."
        },
        {
          "term": "highly available",
          "tier": 2,
          "reasoning": "Architectural concept for fault-tolerant system design."
        },
        {
          "term": "redundancy",
          "tier": 2,
          "reasoning": "Architectural concept for system reliability through duplication."
        },
        {
          "term": "production-ready",
          "tier": 2,
          "reasoning": "Operational concept indicating readiness for production use."
        },
        {
          "term": "production-grade",
          "tier": 2,
          "reasoning": "Quality concept indicating enterprise-level reliability."
        },
        {
          "term": "deploy",
          "tier": 2,
          "reasoning": "Domain process for releasing applications to a cluster."
        },
        {
          "term": "deployment",
          "tier": 2,
          "reasoning": "Domain concept for the process of deploying applications."
        },
        {
          "term": "scaling applications",
          "tier": 2,
          "reasoning": "Domain process for adjusting application capacity."
        },
        {
          "term": "rolling out new updates",
          "tier": 2,
          "reasoning": "Domain process for incrementally deploying changes."
        },
        {
          "term": "desired state",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for declarative configuration management."
        },
        {
          "term": "scheduling applications",
          "tier": 2,
          "reasoning": "Domain process for assigning applications to nodes."
        },
        {
          "term": "bootstrapping operations",
          "tier": 2,
          "reasoning": "Domain concept for initial cluster setup procedures."
        },
        {
          "term": "open-source platform",
          "tier": 2,
          "reasoning": "Domain concept describing Kubernetes licensing and development model."
        },
        {
          "term": "VM",
          "tier": 3,
          "reasoning": "Abbreviation for virtual machine, infrastructure concept for node types."
        },
        {
          "term": "virtual machines",
          "tier": 3,
          "reasoning": "Infrastructure concept for virtualized computing resources."
        },
        {
          "term": "physical computer",
          "tier": 3,
          "reasoning": "Infrastructure concept for bare-metal node types."
        },
        {
          "term": "host",
          "tier": 3,
          "reasoning": "Infrastructure concept for the machine running containers."
        },
        {
          "term": "agent",
          "tier": 3,
          "reasoning": "Technical concept describing kubelet's role on nodes."
        },
        {
          "term": "Linux",
          "tier": 3,
          "reasoning": "Operating system platform supported by Minikube."
        },
        {
          "term": "macOS",
          "tier": 3,
          "reasoning": "Operating system platform supported by Minikube."
        },
        {
          "term": "Windows",
          "tier": 3,
          "reasoning": "Operating system platform supported by Minikube."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical concept for programmatic interfaces."
        },
        {
          "term": "packages",
          "tier": 3,
          "reasoning": "Technical concept for software distribution units."
        }
      ],
      "term_count": 43,
      "generated_at": "2026-02-08T22:11:59.889678",
      "elapsed_time": 20.674800634384155
    },
    {
      "chunk_id": "reference_command-line-tools-reference_feature-gates_DynamicResourceAllocation_sec0",
      "doc_id": "reference_command-line-tools-reference_feature-gates_DynamicResourceAllocation",
      "heading": "Introduction",
      "source_file": "reference_command-line-tools-reference_feature-gates_DynamicResourceAllocation.md",
      "content": "---\ntitle: DynamicResourceAllocation\ncontent_type: feature_gate\n_build:\n  list: never\n  render: false\n\nstages:\n  - stage: alpha\n    defaultValue: false\n    fromVersion: \"1.30\"\n    toVersion: \"1.31\"\n  - stage: beta\n    defaultValue: false\n    fromVersion: \"1.32\"\n    toVersion: \"1.33\"\n  - stage: stable\n    defaultValue: true\n    locked: false\n    fromVersion: \"1.34\"\n    toVersion: \"1.34\"\n  - stage: stable\n    defaultValue: true\n    locked: true\n    fromVersion: \"1.35\"\n\n---\nEnables support for resources with custom parameters and a lifecycle\nthat is independent of a Pod. Allocation of resources is handled\nby the Kubernetes scheduler based on \"structured parameters\".",
      "terms": [
        {
          "term": "DynamicResourceAllocation",
          "tier": 1,
          "reasoning": "Named Kubernetes feature gate that enables dynamic resource allocation functionality."
        },
        {
          "term": "feature_gate",
          "tier": 1,
          "reasoning": "Kubernetes mechanism for enabling/disabling optional features, explicitly referenced as content_type."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit, referenced in context of resource lifecycle."
        },
        {
          "term": "Kubernetes scheduler",
          "tier": 1,
          "reasoning": "Named Kubernetes component responsible for assigning pods to nodes and handling resource allocation."
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating early experimental status."
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating pre-stable testing phase."
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage in Kubernetes indicating production-ready status."
        },
        {
          "term": "resources",
          "tier": 2,
          "reasoning": "Domain concept referring to compute or custom resources that can be allocated to workloads."
        },
        {
          "term": "custom parameters",
          "tier": 2,
          "reasoning": "Technical concept describing user-defined configuration options for resources."
        },
        {
          "term": "lifecycle",
          "tier": 2,
          "reasoning": "Domain concept describing the stages and management of resource existence over time."
        },
        {
          "term": "Allocation",
          "tier": 2,
          "reasoning": "Technical process of assigning resources to workloads in Kubernetes."
        },
        {
          "term": "structured parameters",
          "tier": 2,
          "reasoning": "Specific technical concept for the parameter format used in dynamic resource allocation."
        },
        {
          "term": "scheduler",
          "tier": 2,
          "reasoning": "Core Kubernetes component concept responsible for resource placement decisions."
        },
        {
          "term": "defaultValue",
          "tier": 2,
          "reasoning": "Feature gate configuration property indicating whether feature is enabled by default."
        },
        {
          "term": "locked",
          "tier": 2,
          "reasoning": "Feature gate property indicating whether the feature state can be changed."
        },
        {
          "term": "stage",
          "tier": 2,
          "reasoning": "Technical term describing the maturity phase of a Kubernetes feature."
        },
        {
          "term": "fromVersion",
          "tier": 3,
          "reasoning": "Version metadata indicating when a feature stage begins."
        },
        {
          "term": "toVersion",
          "tier": 3,
          "reasoning": "Version metadata indicating when a feature stage ends."
        }
      ],
      "term_count": 18,
      "generated_at": "2026-02-08T22:12:11.421032",
      "elapsed_time": 10.50406527519226
    },
    {
      "chunk_id": "reference_using-api_server-side-apply_sec7",
      "doc_id": "reference_using-api_server-side-apply",
      "heading": "Transferring ownership",
      "source_file": "reference_using-api_server-side-apply.md",
      "content": "In addition to the concurrency controls provided by [conflict resolution](#conflicts),\nServer-Side Apply provides ways to perform coordinated\nfield ownership transfers from users to controllers.\n\nThis is best explained by example. Let's look at how to safely transfer\nownership of the `replicas` field from a user to a controller while enabling\nautomatic horizontal scaling for a Deployment, using the HorizontalPodAutoscaler\nresource and its accompanying controller.\n\nSay a user has defined Deployment with `replicas` set to the desired value:\n\n{{% code_sample file=\"application/ssa/nginx-deployment.yaml\" %}}\n\nAnd the user has created the Deployment using Server-Side Apply, like so:\n\n```shell\nkubectl apply -f https://k8s.io/examples/application/ssa/nginx-deployment.yaml --server-side\n```\n\nThen later, automatic scaling is enabled for the Deployment; for example:\n\n```shell\nkubectl autoscale deployment nginx-deployment --cpu-percent=50 --min=1 --max=10\n```\n\nNow, the user would like to remove `replicas` from their configuration, so they\ndon't accidentally fight with the HorizontalPodAutoscaler (HPA) and its controller.\nHowever, there is a race: it might take some time before the HPA feels the need\nto adjust `.spec.replicas`; if the user removes `.spec.replicas` before the HPA writes\nto the field and becomes its owner, then the API server would set `.spec.replicas` to\n1 (the default replica count for Deployment).\nThis is not what the user wants to happen, even temporarily - it might well degrade\na running workload.\n\nThere are two solutions:\n\n- (basic) Leave `replicas` in the configuration; when the HPA eventually writes to that\n  field, the system gives the user a conflict over it. At that point, it is safe\n  to remove from the configuration.\n\n- (more advanced) If, however, the user doesn't want to wait, for example\n  because they want to keep the cluster legible to their colleagues, then they\n  can take the following steps to make it safe to remove `replicas` from their\n  configuration:\n\nFirst, the user defines a new manifest containing only the `replicas` field:\n\n```yaml",
      "terms": [
        {
          "term": "Server-Side Apply",
          "tier": 1,
          "reasoning": "Core Kubernetes API mechanism for applying resource configurations with field ownership tracking."
        },
        {
          "term": "conflict resolution",
          "tier": 2,
          "reasoning": "Technical process for handling competing updates to resource fields in Kubernetes."
        },
        {
          "term": "concurrency controls",
          "tier": 2,
          "reasoning": "Technical mechanism for managing simultaneous access to shared resources."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Kubernetes concept where managers claim ownership of specific fields in a resource."
        },
        {
          "term": "controllers",
          "tier": 2,
          "reasoning": "Kubernetes control loop components that manage resource state."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes field specifying the desired number of pod instances for a workload."
        },
        {
          "term": "Deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for managing stateless application workloads."
        },
        {
          "term": "HorizontalPodAutoscaler",
          "tier": 1,
          "reasoning": "Kubernetes API resource that automatically scales workloads based on metrics."
        },
        {
          "term": "automatic horizontal scaling",
          "tier": 2,
          "reasoning": "Kubernetes capability to automatically adjust replica count based on load."
        },
        {
          "term": "HPA",
          "tier": 1,
          "reasoning": "Abbreviation for HorizontalPodAutoscaler, a core Kubernetes resource."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool for interacting with clusters."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for declaratively applying configurations."
        },
        {
          "term": "kubectl autoscale",
          "tier": 1,
          "reasoning": "Kubernetes CLI command for creating autoscaling configurations."
        },
        {
          "term": "--server-side",
          "tier": 1,
          "reasoning": "kubectl flag enabling Server-Side Apply mode."
        },
        {
          "term": "--cpu-percent",
          "tier": 1,
          "reasoning": "kubectl autoscale flag specifying CPU utilization target."
        },
        {
          "term": "--min",
          "tier": 1,
          "reasoning": "kubectl autoscale flag specifying minimum replica count."
        },
        {
          "term": "--max",
          "tier": 1,
          "reasoning": "kubectl autoscale flag specifying maximum replica count."
        },
        {
          "term": ".spec.replicas",
          "tier": 2,
          "reasoning": "Kubernetes resource field path specifying desired replica count."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component handling API requests."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical term for declarative resource definitions in Kubernetes."
        },
        {
          "term": "manifest",
          "tier": 2,
          "reasoning": "Kubernetes term for YAML/JSON resource definition files."
        },
        {
          "term": "default replica count",
          "tier": 2,
          "reasoning": "Kubernetes concept of fallback value when replicas field is unset."
        },
        {
          "term": "race",
          "tier": 2,
          "reasoning": "Technical term for timing-dependent condition between concurrent operations."
        },
        {
          "term": "conflict",
          "tier": 2,
          "reasoning": "Server-Side Apply concept when multiple managers claim the same field."
        },
        {
          "term": "owner",
          "tier": 2,
          "reasoning": "Server-Side Apply concept of the manager controlling a field."
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes term for applications running in the cluster."
        },
        {
          "term": "nginx-deployment",
          "tier": 1,
          "reasoning": "Specific example Deployment resource name used in documentation."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes architectural term for the complete container orchestration environment."
        },
        {
          "term": "user",
          "tier": 2,
          "reasoning": "Kubernetes concept of human operator managing resources, distinct from controllers."
        }
      ],
      "term_count": 29,
      "generated_at": "2026-02-08T22:12:27.205874",
      "elapsed_time": 14.764238595962524
    },
    {
      "chunk_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1_sec2",
      "doc_id": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1",
      "heading": "CustomResourceDefinitionSpec {#CustomResourceDefinitionSpec}",
      "source_file": "reference_kubernetes-api_extend-resources_custom-resource-definition-v1.md",
      "content": "CustomResourceDefinitionSpec describes how a user wants their resource to appear\n\n<hr>\n\n- **group** (string), required\n\n  group is the API group of the defined custom resource. The custom resources are served under `/apis/\\<group>/...`. Must match the name of the CustomResourceDefinition (in the form `\\<names.plural>.\\<group>`).\n\n- **names** (CustomResourceDefinitionNames), required\n\n  names specify the resource and kind names for the custom resource.\n\n  <a name=\"CustomResourceDefinitionNames\"></a>\n  *CustomResourceDefinitionNames indicates the names to serve this CustomResourceDefinition*\n\n  - **names.kind** (string), required\n\n    kind is the serialized kind of the resource. It is normally CamelCase and singular. Custom resource instances will use this value as the `kind` attribute in API calls.\n\n  - **names.plural** (string), required\n\n    plural is the plural name of the resource to serve. The custom resources are served under `/apis/\\<group>/\\<version>/.../\\<plural>`. Must match the name of the CustomResourceDefinition (in the form `\\<names.plural>.\\<group>`). Must be all lowercase.\n\n  - **names.categories** ([]string)\n\n    *Atomic: will be replaced during a merge*\n    \n    categories is a list of grouped resources this custom resource belongs to (e.g. 'all'). This is published in API discovery documents, and used by clients to support invocations like `kubectl get all`.\n\n  - **names.listKind** (string)\n\n    listKind is the serialized kind of the list for this resource. Defaults to \"`kind`List\".\n\n  - **names.shortNames** ([]string)\n\n    *Atomic: will be replaced during a merge*\n    \n    shortNames are short names for the resource, exposed in API discovery documents, and used by clients to support invocations like `kubectl get \\<shortname>`. It must be all lowercase.\n\n  - **names.singular** (string)\n\n    singular is the singular name of the resource. It must be all lowercase. Defaults to lowercased `kind`.\n\n- **scope** (string), required\n\n  scope indicates whether the defined custom resource is cluster- or namespace-scoped. Allowed values are `Cluster` and `Namespaced`.\n\n- **versions** ([]CustomResourceDefinitionVersion), required\n\n  *Atomic: will be replaced during a merge*\n  \n  versions is the list of all API versions of the defined custom resource. Version names are used to compute the order in which served versions are listed in API discovery. If the version string is \"kube-like\", it will sort above non \"kube-like\" version strings, which are ordered lexicographically. \"Kube-like\" versions start with a \"v\", then are followed by a number (the major version), then optionally the string \"alpha\" or \"beta\" and another number (the minor version). These are sorted first by GA > beta > alpha (where GA is a version with no suffix such as beta or alpha), and then by comparing major version, then minor version. An example sorted list of versions: v10, v2, v1, v11beta2, v10beta3, v3beta1, v12alpha1, v11alpha2, foo1, foo10.\n\n  <a name=\"CustomResourceDefinitionVersion\"></a>\n  *CustomResourceDefinitionVersion describes a version for CRD.*\n\n  - **versions.name** (string), required\n\n    name is the version name, e.g. \u201cv1\u201d, \u201cv2beta1\u201d, etc. The custom resources are served under this version at `/apis/\\<group>/\\<version>/...` if `served` is true.\n\n  - **versions.served** (boolean), required\n\n    served is a flag enabling/disabling this version from being served via REST APIs\n\n  - **versions.storage** (boolean), required\n\n    storage indicates this version should be used when persisting custom resources to storage. There must be exactly one version with storage=true.\n\n  - **versions.additionalPrinterColumns** ([]CustomResourceColumnDefinition)\n\n    *Atomic: will be replaced during a merge*\n    \n    additionalPrinterColumns specifies additional columns returned in Table output. See https://kubernetes.io/docs/reference/using-api/api-concepts/#receiving-resources-as-tables for details. If no columns are specified, a single column displaying the age of the custom resource is used.\n\n    <a name=\"CustomResourceColumnDefinition\"></a>\n    *CustomResourceColumnDefinition specifies a column for server side printing.*\n\n    - **versions.additionalPrinterColumns.jsonPath** (string), required\n\n      jsonPath is a simple JSON path (i.e. with array notation) which is evaluated against each custom resource to produce the value for this column.\n\n    - **versions.additionalPrinterColumns.name** (string), required\n\n      name is a human readable name for the column.\n\n    - **versions.additionalPrinterColumns.type** (string), required\n\n      type is an OpenAPI type definition for this column. See https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md#data-types for details.\n\n    - **versions.additionalPrinterColumns.description** (string)\n\n      description is a human readable description of this column.\n\n    - **versions.additionalPrinterColumns.format** (string)\n\n      format is an optional OpenAPI type definition for this column. The 'name' format is applied to the primary identifier column to assist in clients identifying column is the resource name. See https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md#data-types for details.\n\n    - **versions.additionalPrinterColumns.priority** (int32)\n\n      priority is an integer defining the relative importance of this column compared to others. Lower numbers are considered higher priority. Columns that may be omitted in limited space scenarios should be given a priority greater than 0.\n\n  - **versions.deprecated** (boolean)\n\n    deprecated indicates this version of the custom resource API is deprecated. When set to true, API requests to this version receive a warning header in the server response. Defaults to false.\n\n  - **versions.deprecationWarning** (string)\n\n    deprecationWarning overrides the default warning returned to API clients. May only be set when `deprecated` is true. The default warning indicates this version is deprecated and recommends use of the newest served version of equal or greater stability, if one exists.\n\n  - **versions.schema** (CustomResourceValidation)\n\n    schema describes the schema used for validation, pruning, and defaulting of this version of the custom resource.\n\n    <a name=\"CustomResourceValidation\"></a>\n    *CustomResourceValidation is a list of validation methods for CustomResources.*\n\n    - **versions.schema.openAPIV3Schema** (<a href=\"{{< ref \"../extend-resources/custom-resource-definition-v1#JSONSchemaProps\" >}}\">JSONSchemaProps</a>)\n\n      openAPIV3Schema is the OpenAPI v3 schema to use for validation and pruning.\n\n  - **versions.selectableFields** ([]SelectableField)\n\n    *Atomic: will be replaced during a merge*\n    \n    selectableFields specifies paths to fields that may be used as field selectors. A maximum of 8 selectable fields are allowed. See https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors\n\n    <a name=\"SelectableField\"></a>\n    *SelectableField specifies the JSON path of a field that may be used with field selectors.*\n\n    - **versions.selectableFields.jsonPath** (string), required\n\n      jsonPath is a simple JSON path which is evaluated against each custom resource to produce a field selector value. Only JSON paths without the array notation are allowed. Must point to a field of type string, boolean or integer. Types with enum values and strings with formats are allowed. If jsonPath refers to absent field in a resource, the jsonPath evaluates to an empty string. Must not point to metdata fields. Required.\n\n  - **versions.subresources** (CustomResourceSubresources)\n\n    subresources specify what subresources this version of the defined custom resource have.\n\n    <a name=\"CustomResourceSubresources\"></a>\n    *CustomResourceSubresources defines the status and scale subresources for CustomResources.*\n\n    - **versions.subresources.scale** (CustomResourceSubresourceScale)\n\n      scale indicates the custom resource should serve a `/scale` subresource that returns an `autoscaling/v1` Scale object.\n\n      <a name=\"CustomResourceSubresourceScale\"></a>\n      *CustomResourceSubresourceScale defines how to serve the scale subresource for CustomResources.*\n\n      - **versions.subresources.scale.specReplicasPath** (string), required\n\n        specReplicasPath defines the JSON path inside of a custom resource that corresponds to Scale `spec.replicas`. Only JSON paths without the array notation are allowed. Must be a JSON Path under `.spec`. If there is no value under the given path in the custom resource, the `/scale` subresource will return an error on GET.\n\n      - **versions.subresources.scale.statusReplicasPath** (string), required\n\n        statusReplicasPath defines the JSON path inside of a custom resource that corresponds to Scale `status.replicas`. Only JSON paths without the array notation are allowed. Must be a JSON Path under `.status`. If there is no value under the given path in the custom resource, the `status.replicas` value in the `/scale` subresource will default to 0.\n\n      - **versions.subresources.scale.labelSelectorPath** (string)\n\n        labelSelectorPath defines the JSON path inside of a custom resource that corresponds to Scale `status.selector`. Only JSON paths without the array notation are allowed. Must be a JSON Path under `.status` or `.spec`. Must be set to work with HorizontalPodAutoscaler. The field pointed by this JSON path must be a string field (not a complex selector struct) which contains a serialized label selector in string form. More info: https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions#scale-subresource If there is no value under the given path in the custom resource, the `status.selector` value in the `/scale` subresource will default to the empty string.\n\n    - **versions.subresources.status** (CustomResourceSubresourceStatus)\n\n      status indicates the custom resource should serve a `/status` subresource. When enabled: 1. requests to the custom resource primary endpoint ignore changes to the `status` stanza of the object. 2. requests to the custom resource `/status` subresource ignore changes to anything other than the `status` stanza of the object.\n\n      <a name=\"CustomResourceSubresourceStatus\"></a>\n      *CustomResourceSubresourceStatus defines how to serve the status subresource for CustomResources. Status is represented by the `.status` JSON path inside of a CustomResource. When set, * exposes a /status subresource for the custom resource * PUT requests to the /status subresource take a custom resource object, and ignore changes to anything except the status stanza * PUT/POST/PATCH requests to the custom resource ignore changes to the status stanza*\n\n- **conversion** (CustomResourceConversion)\n\n  conversion defines conversion settings for the CRD.\n\n  <a name=\"CustomResourceConversion\"></a>\n  *CustomResourceConversion describes how to convert different versions of a CR.*\n\n  - **conversion.strategy** (string), required\n\n    strategy specifies how custom resources are converted between versions. Allowed values are: - `\"None\"`: The converter only change the apiVersion and would not touch any other field in the custom resource. - `\"Webhook\"`: API Server will call to an external webhook to do the conversion. Additional information\n      is needed for this option. This requires spec.preserveUnknownFields to be false, and spec.conversion.webhook to be set.\n\n  - **conversion.webhook** (WebhookConversion)\n\n    webhook describes how to call the conversion webhook. Required when `strategy` is set to `\"Webhook\"`.\n\n    <a name=\"WebhookConversion\"></a>\n    *WebhookConversion describes how to call a conversion webhook*\n\n    - **conversion.webhook.conversionReviewVersions** ([]string), required\n\n      *Atomic: will be replaced during a merge*\n      \n      conversionReviewVersions is an ordered list of preferred `ConversionReview` versions the Webhook expects. The API server will use the first version in the list which it supports. If none of the versions specified in this list are supported by API server, conversion will fail for the custom resource. If a persisted Webhook configuration specifies allowed versions and does not include any versions known to the API Server, calls to the webhook will fail.\n\n    - **conversion.webhook.clientConfig** (WebhookClientConfig)\n\n      clientConfig is the instructions for how to call the webhook if strategy is `Webhook`.\n\n      <a name=\"WebhookClientConfig\"></a>\n      *WebhookClientConfig contains the information to make a TLS connection with the webhook.*\n\n      - **conversion.webhook.clientConfig.caBundle** ([]byte)\n\n        caBundle is a PEM encoded CA bundle which will be used to validate the webhook's server certificate. If unspecified, system trust roots on the apiserver are used.\n\n      - **conversion.webhook.clientConfig.service** (ServiceReference)\n\n        service is a reference to the service for this webhook. Either service or url must be specified.\n        \n        If the webhook is running within the cluster, then you should use `service`.\n\n        <a name=\"ServiceReference\"></a>\n        *ServiceReference holds a reference to Service.legacy.k8s.io*\n\n        - **conversion.webhook.clientConfig.service.name** (string), required\n\n          name is the name of the service. Required\n\n        - **conversion.webhook.clientConfig.service.namespace** (string), required\n\n          namespace is the namespace of the service. Required\n\n        - **conversion.webhook.clientConfig.service.path** (string)\n\n          path is an optional URL path at which the webhook will be contacted.\n\n        - **conversion.webhook.clientConfig.service.port** (int32)\n\n          port is an optional service port at which the webhook will be contacted. `port` should be a valid port number (1-65535, inclusive). Defaults to 443 for backward compatibility.\n\n      - **conversion.webhook.clientConfig.url** (string)\n\n        url gives the location of the webhook, in standard URL form (`scheme://host:port/path`). Exactly one of `url` or `service` must be specified.\n        \n        The `host` should not refer to a service running in the cluster; use the `service` field instead. The host might be resolved via external DNS in some apiservers (e.g., `kube-apiserver` cannot resolve in-cluster DNS as that would be a layering violation). `host` may also be an IP address.\n        \n        Please note that using `localhost` or `127.0.0.1` as a `host` is risky unless you take great care to run this webhook on all hosts which run an apiserver which might need to make calls to this webhook. Such installs are likely to be non-portable, i.e., not easy to turn up in a new cluster.\n        \n        The scheme must be \"https\"; the URL must begin with \"https://\".\n        \n        A path is optional, and if present may be any string permissible in a URL. You may use the path to pass an arbitrary string to the webhook, for example, a cluster identifier.\n        \n        Attempting to use a user or basic auth e.g. \"user:password@\" is not allowed. Fragments (\"#...\") and query parameters (\"?...\") are not allowed, either.\n\n- **preserveUnknownFields** (boolean)\n\n  preserveUnknownFields indicates that object fields which are not specified in the OpenAPI schema should be preserved when persisting to storage. apiVersion, kind, metadata and known fields inside metadata are always preserved. This field is deprecated in favor of setting `x-preserve-unknown-fields` to true in `spec.versions[*].schema.openAPIV3Schema`. See https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#field-pruning for details.",
      "terms": [
        {
          "term": "CustomResourceDefinitionSpec",
          "tier": 1,
          "reasoning": "Named Kubernetes API object specification type for custom resources"
        },
        {
          "term": "CustomResourceDefinitionNames",
          "tier": 1,
          "reasoning": "Named Kubernetes API type that specifies naming conventions for custom resources"
        },
        {
          "term": "CustomResourceDefinitionVersion",
          "tier": 1,
          "reasoning": "Named Kubernetes API type describing a version for CRD"
        },
        {
          "term": "CustomResourceDefinition",
          "tier": 1,
          "reasoning": "Core Kubernetes API object for extending the API with custom resources"
        },
        {
          "term": "CustomResourceColumnDefinition",
          "tier": 1,
          "reasoning": "Named Kubernetes API type for defining additional printer columns"
        },
        {
          "term": "custom resource",
          "tier": 1,
          "reasoning": "Core Kubernetes concept for user-defined API extensions"
        },
        {
          "term": "custom resources",
          "tier": 1,
          "reasoning": "Plural form of custom resource, frequently used in the documentation"
        },
        {
          "term": "CRD",
          "tier": 1,
          "reasoning": "Standard abbreviation for CustomResourceDefinition, a core Kubernetes resource"
        },
        {
          "term": "API group",
          "tier": 2,
          "reasoning": "Kubernetes concept for organizing API resources into logical groups"
        },
        {
          "term": "group",
          "tier": 2,
          "reasoning": "Field name representing the API group in CustomResourceDefinitionSpec"
        },
        {
          "term": "names",
          "tier": 2,
          "reasoning": "Configuration field specifying resource and kind names for custom resources"
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Kubernetes concept for the type of resource, used in API calls"
        },
        {
          "term": "plural",
          "tier": 2,
          "reasoning": "Naming convention field for the plural form of resource names in API paths"
        },
        {
          "term": "singular",
          "tier": 2,
          "reasoning": "Naming convention field for the singular form of resource names"
        },
        {
          "term": "categories",
          "tier": 2,
          "reasoning": "Field for grouping custom resources into logical categories like 'all'"
        },
        {
          "term": "listKind",
          "tier": 2,
          "reasoning": "Field specifying the serialized kind name for list operations"
        },
        {
          "term": "shortNames",
          "tier": 2,
          "reasoning": "Field for defining abbreviated names for resources in kubectl commands"
        },
        {
          "term": "scope",
          "tier": 2,
          "reasoning": "Field indicating whether a custom resource is cluster or namespace scoped"
        },
        {
          "term": "versions",
          "tier": 2,
          "reasoning": "Field containing all API versions of a custom resource definition"
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Concept representing a specific API version of a resource"
        },
        {
          "term": "served",
          "tier": 2,
          "reasoning": "Boolean flag controlling whether a version is available via REST APIs"
        },
        {
          "term": "storage",
          "tier": 2,
          "reasoning": "Boolean flag indicating which version is used for persisting resources"
        },
        {
          "term": "additionalPrinterColumns",
          "tier": 2,
          "reasoning": "Field for specifying extra columns in kubectl table output"
        },
        {
          "term": "API discovery",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for discovering available API resources"
        },
        {
          "term": "REST APIs",
          "tier": 2,
          "reasoning": "The interface through which Kubernetes resources are served"
        },
        {
          "term": "namespace-scoped",
          "tier": 2,
          "reasoning": "Scope type indicating resource exists within a namespace"
        },
        {
          "term": "Cluster",
          "tier": 2,
          "reasoning": "Allowed value for scope field indicating cluster-level resources"
        },
        {
          "term": "Namespaced",
          "tier": 2,
          "reasoning": "Allowed value for scope field indicating namespace-level resources"
        },
        {
          "term": "CamelCase",
          "tier": 3,
          "reasoning": "Naming convention specified for kind values"
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Kubernetes CLI tool referenced for resource operations"
        },
        {
          "term": "kubectl get",
          "tier": 1,
          "reasoning": "Specific kubectl command referenced for retrieving resources"
        },
        {
          "term": "Table output",
          "tier": 2,
          "reasoning": "Kubernetes API concept for returning resources in tabular format"
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface used throughout"
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Kubernetes version lifecycle stage indicating early experimental features"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Kubernetes version lifecycle stage indicating pre-stable features"
        },
        {
          "term": "GA",
          "tier": 2,
          "reasoning": "General Availability version stage with no suffix, indicating stable features"
        },
        {
          "term": "major version",
          "tier": 3,
          "reasoning": "Version numbering concept for primary version number"
        },
        {
          "term": "minor version",
          "tier": 3,
          "reasoning": "Version numbering concept for secondary version number"
        },
        {
          "term": "Atomic",
          "tier": 2,
          "reasoning": "Kubernetes merge strategy indicating field will be replaced during merge"
        },
        {
          "term": "merge",
          "tier": 3,
          "reasoning": "Operation concept for combining resource configurations"
        }
      ],
      "term_count": 40,
      "generated_at": "2026-02-08T22:12:46.631238",
      "elapsed_time": 18.40497326850891
    },
    {
      "chunk_id": "reference_glossary_pod-lifecycle_sec0",
      "doc_id": "reference_glossary_pod-lifecycle",
      "heading": "Introduction",
      "source_file": "reference_glossary_pod-lifecycle.md",
      "content": "---\ntitle: Pod Lifecycle\nid: pod-lifecycle\ndate: 2019-02-17\nfull-link: /docs/concepts/workloads/pods/pod-lifecycle/\nrelated:\n - pod\n - container\ntags:\n - fundamental\nshort_description: >\n  The sequence of states through which a Pod passes during its lifetime.\n \n---\n The sequence of states through which a Pod passes during its lifetime.\n\n<!--more--> \n\nThe [Pod Lifecycle](/docs/concepts/workloads/pods/pod-lifecycle/) is defined by the states or phases of a Pod. There are five possible Pod phases: Pending, Running, Succeeded, Failed, and Unknown. A high-level description of the Pod state is summarized in the [PodStatus](/docs/reference/generated/kubernetes-api/{{< param \"version\" >}}/#podstatus-v1-core) `phase` field.",
      "terms": [
        {
          "term": "Pod Lifecycle",
          "tier": 1,
          "reasoning": "Core Kubernetes concept describing the sequence of states a Pod passes through, appears as the document title and main subject."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Fundamental Kubernetes API object and resource, the primary subject of this documentation."
        },
        {
          "term": "pod-lifecycle",
          "tier": 1,
          "reasoning": "The identifier/slug for this concept, used in documentation URLs and references."
        },
        {
          "term": "container",
          "tier": 2,
          "reasoning": "Core Kubernetes concept listed as a related term, fundamental unit that Pods encapsulate."
        },
        {
          "term": "Pod phases",
          "tier": 2,
          "reasoning": "Technical concept describing the discrete states a Pod can be in during its lifecycle."
        },
        {
          "term": "Pending",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states in Kubernetes."
        },
        {
          "term": "Running",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating active execution."
        },
        {
          "term": "Succeeded",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating successful completion."
        },
        {
          "term": "Failed",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating unsuccessful termination."
        },
        {
          "term": "Unknown",
          "tier": 2,
          "reasoning": "One of the five defined Pod phase states indicating indeterminate status."
        },
        {
          "term": "PodStatus",
          "tier": 1,
          "reasoning": "Kubernetes API object/field that contains Pod state information including the phase field."
        },
        {
          "term": "phase",
          "tier": 2,
          "reasoning": "Technical field within PodStatus that summarizes the Pod's current state."
        },
        {
          "term": "states",
          "tier": 3,
          "reasoning": "Technical term describing the discrete conditions a Pod can be in during its lifecycle."
        },
        {
          "term": "phases",
          "tier": 2,
          "reasoning": "Synonym for states in Pod lifecycle context, specifically the five possible Pod conditions."
        },
        {
          "term": "lifetime",
          "tier": 3,
          "reasoning": "Technical term describing the duration from Pod creation to termination."
        },
        {
          "term": "Pod state",
          "tier": 2,
          "reasoning": "Compound term referring to the current condition of a Pod within its lifecycle."
        }
      ],
      "term_count": 16,
      "generated_at": "2026-02-08T22:12:56.723576",
      "elapsed_time": 9.065295934677124
    },
    {
      "chunk_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions_sec1",
      "doc_id": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions",
      "heading": "{{% heading \"prerequisites\" %}}",
      "source_file": "tasks_extend-kubernetes_custom-resources_custom-resource-definitions.md",
      "content": "{{< include \"task-tutorial-prereqs.md\" >}} {{< version-check >}}\nIf you are using an older version of Kubernetes that is still supported, switch to\nthe documentation for that version to see advice that is relevant for your cluster.\n\n<!-- steps -->",
      "terms": [
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "Core container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "version",
          "tier": 2,
          "reasoning": "Technical concept referring to specific releases of Kubernetes software."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept representing a set of nodes running containerized applications."
        },
        {
          "term": "documentation",
          "tier": 3,
          "reasoning": "Technical reference material for the Kubernetes platform, contextually relevant to versioning."
        }
      ],
      "term_count": 4,
      "generated_at": "2026-02-08T22:13:01.666399",
      "elapsed_time": 3.9238855838775635
    },
    {
      "chunk_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster_sec3",
      "doc_id": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster",
      "heading": "Optional: enable additional DRA API groups {#enable-dra}",
      "source_file": "tasks_configure-pod-container_assign-resources_set-up-dra-cluster.md",
      "content": "DRA overall is a stable feature in Kubernetes; however, aspects of it may still be alpha or beta.\nIf you want to use any aspect of DRA that is not yet stable,\nand the associated feature relies on a dedicated API kind,\nthen you must enable the associated alpha or beta API groups.\n\nSome older DRA drivers or workloads might still need the\nv1beta1 API from Kubernetes 1.30 or v1beta2 from Kubernetes 1.32.\nIf and only if support for those is desired, then enable the following\n{{< glossary_tooltip text=\"API groups\" term_id=\"api-group\" >}}:\n\n    * `resource.k8s.io/v1beta1`\n    * `resource.k8s.io/v1beta2`\n\nAlpha features with separate API types need:\n\n   * `resource.k8s.io/v1alpha3`\n\nFor more information, see\n[Enabling or disabling API groups](/docs/reference/using-api/#enabling-or-disabling).",
      "terms": [
        {
          "term": "DRA",
          "tier": 1,
          "reasoning": "Dynamic Resource Allocation - a specific Kubernetes feature/API for resource management"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core container orchestration platform being documented"
        },
        {
          "term": "API groups",
          "tier": 2,
          "reasoning": "Kubernetes concept for organizing and versioning API resources"
        },
        {
          "term": "API kind",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to a specific type of API resource"
        },
        {
          "term": "feature",
          "tier": 2,
          "reasoning": "Technical term describing a capability or functionality in Kubernetes"
        },
        {
          "term": "stable",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating production-ready status in Kubernetes"
        },
        {
          "term": "alpha",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating early experimental status in Kubernetes"
        },
        {
          "term": "beta",
          "tier": 2,
          "reasoning": "Feature lifecycle stage indicating pre-stable testing status in Kubernetes"
        },
        {
          "term": "DRA drivers",
          "tier": 1,
          "reasoning": "Specific driver components that implement DRA functionality"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Kubernetes concept referring to applications running on the cluster"
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "Specific API version identifier for beta stage APIs"
        },
        {
          "term": "v1beta2",
          "tier": 2,
          "reasoning": "Specific API version identifier for beta stage APIs"
        },
        {
          "term": "v1alpha3",
          "tier": 2,
          "reasoning": "Specific API version identifier for alpha stage APIs"
        },
        {
          "term": "resource.k8s.io/v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group path for DRA beta resources"
        },
        {
          "term": "resource.k8s.io/v1beta2",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group path for DRA beta resources"
        },
        {
          "term": "resource.k8s.io/v1alpha3",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group path for DRA alpha resources"
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "Application Programming Interface - fundamental technical concept for Kubernetes interaction"
        },
        {
          "term": "Alpha features",
          "tier": 2,
          "reasoning": "Compound term describing features in early experimental stage"
        },
        {
          "term": "API types",
          "tier": 2,
          "reasoning": "Technical term referring to different kinds of API resources"
        },
        {
          "term": "Kubernetes 1.30",
          "tier": 1,
          "reasoning": "Specific Kubernetes version release"
        },
        {
          "term": "Kubernetes 1.32",
          "tier": 1,
          "reasoning": "Specific Kubernetes version release"
        }
      ],
      "term_count": 21,
      "generated_at": "2026-02-08T22:13:13.241754",
      "elapsed_time": 10.55471920967102
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1_sec20",
      "doc_id": "reference_config-api_apiserver-config.v1",
      "heading": "`PrefixedClaimOrExpression`     {#apiserver-config-k8s-io-v1-PrefixedClaimOrExpression}",
      "source_file": "reference_config-api_apiserver-config.v1.md",
      "content": "**Appears in:**\n\n- [ClaimMappings](#apiserver-config-k8s-io-v1-ClaimMappings)\n\n\n<p>PrefixedClaimOrExpression provides the configuration for a single prefixed claim or expression.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n  \n<tr><td><code>claim</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>claim is the JWT claim to use.\nMutually exclusive with expression.</p>\n</td>\n</tr>\n<tr><td><code>prefix</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>prefix is prepended to claim's value to prevent clashes with existing names.\nprefix needs to be set if claim is set and can be the empty string.\nMutually exclusive with expression.</p>\n</td>\n</tr>\n<tr><td><code>expression</code><br/>\n<code>string</code>\n</td>\n<td>\n   <p>expression represents the expression which will be evaluated by CEL.</p>\n<p>CEL expressions have access to the contents of the token claims, organized into CEL variable:</p>\n<ul>\n<li>'claims' is a map of claim names to claim values.\nFor example, a variable named 'sub' can be accessed as 'claims.sub'.\nNested claims can be accessed using dot notation, e.g. 'claims.foo.bar'.</li>\n</ul>\n<p>Documentation on CEL: https://kubernetes.io/docs/reference/using-api/cel/</p>\n<p>Mutually exclusive with claim and prefix.</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "ClaimMappings",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration object for mapping claims"
        },
        {
          "term": "PrefixedClaimOrExpression",
          "tier": 1,
          "reasoning": "Named Kubernetes API configuration type for prefixed claims or expressions"
        },
        {
          "term": "claim",
          "tier": 2,
          "reasoning": "Technical field representing a JWT claim in authentication context"
        },
        {
          "term": "JWT claim",
          "tier": 2,
          "reasoning": "Domain concept referring to claims within JSON Web Tokens for authentication"
        },
        {
          "term": "prefix",
          "tier": 2,
          "reasoning": "Technical field for prepending values to prevent naming clashes"
        },
        {
          "term": "expression",
          "tier": 2,
          "reasoning": "Technical field representing a CEL expression for evaluation"
        },
        {
          "term": "CEL",
          "tier": 1,
          "reasoning": "Common Expression Language - specific technology used by Kubernetes for expressions"
        },
        {
          "term": "CEL variable",
          "tier": 2,
          "reasoning": "Domain concept for variables accessible within CEL expressions"
        },
        {
          "term": "CEL expressions",
          "tier": 2,
          "reasoning": "Domain concept for expressions evaluated by the CEL engine"
        },
        {
          "term": "claims",
          "tier": 2,
          "reasoning": "Technical term for the map of claim names to values in token context"
        },
        {
          "term": "token claims",
          "tier": 2,
          "reasoning": "Domain concept for claims contained within authentication tokens"
        },
        {
          "term": "claim names",
          "tier": 2,
          "reasoning": "Technical term for identifiers of claims within tokens"
        },
        {
          "term": "claim values",
          "tier": 2,
          "reasoning": "Technical term for the data associated with claim names"
        },
        {
          "term": "dot notation",
          "tier": 3,
          "reasoning": "Technical syntax pattern for accessing nested claims"
        },
        {
          "term": "Nested claims",
          "tier": 2,
          "reasoning": "Domain concept for hierarchically structured claims in tokens"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for the configuration fields"
        },
        {
          "term": "apiserver-config-k8s-io-v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version identifier for apiserver configuration"
        },
        {
          "term": "token",
          "tier": 2,
          "reasoning": "Authentication concept referring to JWT or similar authentication tokens"
        },
        {
          "term": "map",
          "tier": 3,
          "reasoning": "Data structure type used to describe claims organization"
        },
        {
          "term": "Mutually exclusive",
          "tier": 3,
          "reasoning": "Technical constraint term describing field relationships in API configuration"
        }
      ],
      "term_count": 20,
      "generated_at": "2026-02-08T22:13:26.579284",
      "elapsed_time": 12.318711757659912
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_create_kubectl_create_priorityclass_sec3",
      "doc_id": "reference_kubectl_generated_kubectl_create_kubectl_create_priorityclass",
      "heading": "{{% heading \"parentoptions\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_create_kubectl_create_priorityclass.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--as string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Username to impersonate for the operation. User could be a regular user or a service account in a namespace.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--as-group strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Group to impersonate for the operation, this flag can be repeated to specify multiple groups.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--as-uid string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>UID to impersonate for the operation.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--as-user-extra strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>User extras to impersonate for the operation, this flag can be repeated to specify multiple values for the same key.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cache-dir string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"$HOME/.kube/cache\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Default cache directory</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--certificate-authority string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to a cert file for the certificate authority</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--client-certificate string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to a client certificate file for TLS</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--client-key string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to a client key file for TLS</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--cluster string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The name of the kubeconfig cluster to use</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--context string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The name of the kubeconfig context to use</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--disable-compression</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, opt-out of response compression for all requests to the server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--insecure-skip-tls-verify</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--kubeconfig string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to the kubeconfig file to use for CLI requests.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--kuberc string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Path to the kuberc file to use for preferences. This can be disabled by exporting KUBECTL_KUBERC=false feature gate or turning off the feature KUBERC=off.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--match-server-version</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Require server version to match client version</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-n, --namespace string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If present, the namespace scope for this CLI request</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--password string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Password for basic authentication to the API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--profile string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of profile to capture. One of (none|cpu|heap|goroutine|threadcreate|block|mutex|trace)</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--profile-output string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"profile.pprof\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the file to write the profile to</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--request-timeout string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"0\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-s, --server string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The address and port of the Kubernetes API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-buffer-duration duration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1m0s</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Writes in the storage driver will be buffered for this duration, and committed to the non memory backends as a single transaction</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-db string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"cadvisor\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database name</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-host string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"localhost:8086\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database host:port</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-password string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"root\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database password</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-secure</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>use secure connection with database</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-table string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"stats\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>table name</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--storage-driver-user string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"root\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>database username</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--tls-server-name string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--token string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Bearer token for authentication to the API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--user string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The name of the kubeconfig user to use</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--username string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Username for basic authentication to the API server</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--version version[=true]</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>--version, --version=raw prints version information and quits; --version=vX.Y.Z... sets the reported version</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--warnings-as-errors</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Treat warnings received from the server as errors and exit with a non-zero exit code</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "--as",
          "tier": 1,
          "reasoning": "CLI flag for user impersonation in kubectl operations"
        },
        {
          "term": "--as-group",
          "tier": 1,
          "reasoning": "CLI flag for group impersonation in kubectl operations"
        },
        {
          "term": "--as-uid",
          "tier": 1,
          "reasoning": "CLI flag for UID impersonation in kubectl operations"
        },
        {
          "term": "--as-user-extra",
          "tier": 1,
          "reasoning": "CLI flag for user extras impersonation in kubectl operations"
        },
        {
          "term": "--cache-dir",
          "tier": 1,
          "reasoning": "CLI flag specifying the cache directory location"
        },
        {
          "term": "--certificate-authority",
          "tier": 1,
          "reasoning": "CLI flag for specifying certificate authority file path"
        },
        {
          "term": "--client-certificate",
          "tier": 1,
          "reasoning": "CLI flag for specifying client certificate file for TLS"
        },
        {
          "term": "--client-key",
          "tier": 1,
          "reasoning": "CLI flag for specifying client key file for TLS"
        },
        {
          "term": "--cluster",
          "tier": 1,
          "reasoning": "CLI flag for specifying kubeconfig cluster name"
        },
        {
          "term": "--context",
          "tier": 1,
          "reasoning": "CLI flag for specifying kubeconfig context name"
        },
        {
          "term": "--disable-compression",
          "tier": 1,
          "reasoning": "CLI flag to opt-out of response compression"
        },
        {
          "term": "--insecure-skip-tls-verify",
          "tier": 1,
          "reasoning": "CLI flag to skip TLS certificate verification"
        },
        {
          "term": "--kubeconfig",
          "tier": 1,
          "reasoning": "CLI flag for specifying kubeconfig file path"
        },
        {
          "term": "--kuberc",
          "tier": 1,
          "reasoning": "CLI flag for specifying kuberc preferences file path"
        },
        {
          "term": "--match-server-version",
          "tier": 1,
          "reasoning": "CLI flag requiring server version to match client version"
        },
        {
          "term": "--namespace",
          "tier": 1,
          "reasoning": "CLI flag for specifying namespace scope for requests"
        },
        {
          "term": "--password",
          "tier": 1,
          "reasoning": "CLI flag for basic authentication password"
        },
        {
          "term": "--profile",
          "tier": 1,
          "reasoning": "CLI flag for specifying profiling type to capture"
        },
        {
          "term": "service account",
          "tier": 1,
          "reasoning": "Kubernetes identity resource that can be impersonated"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for scoping resources and requests"
        },
        {
          "term": "kubeconfig",
          "tier": 1,
          "reasoning": "Configuration file for kubectl CLI requests"
        },
        {
          "term": "kuberc",
          "tier": 1,
          "reasoning": "Configuration file for kubectl preferences"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes cluster concept referenced in kubeconfig"
        },
        {
          "term": "context",
          "tier": 2,
          "reasoning": "Kubeconfig context for specifying cluster/user/namespace combination"
        },
        {
          "term": "TLS",
          "tier": 3,
          "reasoning": "Transport Layer Security protocol used for client certificates and keys"
        },
        {
          "term": "HTTPS",
          "tier": 3,
          "reasoning": "Secure HTTP protocol mentioned in TLS verification context"
        },
        {
          "term": "certificate authority",
          "tier": 2,
          "reasoning": "Security concept for certificate validation"
        },
        {
          "term": "client certificate",
          "tier": 2,
          "reasoning": "TLS authentication mechanism for client identity"
        },
        {
          "term": "client key",
          "tier": 2,
          "reasoning": "Private key file used with client certificate for TLS"
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Kubernetes component that receives authentication credentials"
        },
        {
          "term": "basic authentication",
          "tier": 2,
          "reasoning": "Authentication method using username/password for API server"
        },
        {
          "term": "impersonate",
          "tier": 2,
          "reasoning": "Kubernetes authorization concept for acting as another user/group"
        },
        {
          "term": "UID",
          "tier": 3,
          "reasoning": "User identifier that can be impersonated for operations"
        },
        {
          "term": "feature gate",
          "tier": 2,
          "reasoning": "Kubernetes mechanism for enabling/disabling features like KUBECTL_KUBERC"
        },
        {
          "term": "KUBERC",
          "tier": 1,
          "reasoning": "Feature gate name for kuberc functionality"
        },
        {
          "term": "KUBECTL_KUBERC",
          "tier": 1,
          "reasoning": "Environment variable feature gate for kuberc"
        },
        {
          "term": "cache directory",
          "tier": 2,
          "reasoning": "Local storage location for kubectl cached data"
        },
        {
          "term": "response compression",
          "tier": 2,
          "reasoning": "Server optimization feature that can be disabled"
        },
        {
          "term": "server version",
          "tier": 2,
          "reasoning": "Kubernetes server version for compatibility matching"
        },
        {
          "term": "client version",
          "tier": 2,
          "reasoning": "Kubectl client version for compatibility matching"
        },
        {
          "term": "profile",
          "tier": 2,
          "reasoning": "Profiling capability for performance analysis"
        },
        {
          "term": "cpu",
          "tier": 3,
          "reasoning": "Profile type for CPU profiling"
        },
        {
          "term": "heap",
          "tier": 3,
          "reasoning": "Profile type for memory heap profiling"
        },
        {
          "term": "goroutine",
          "tier": 3,
          "reasoning": "Profile type for Go goroutine profiling"
        },
        {
          "term": "threadcreate",
          "tier": 3,
          "reasoning": "Profile type for thread creation profiling"
        },
        {
          "term": "block",
          "tier": 3,
          "reasoning": "Profile type for blocking profiling"
        },
        {
          "term": "mutex",
          "tier": 3,
          "reasoning": "Profile type for mutex contention profiling"
        },
        {
          "term": "trace",
          "tier": 3,
          "reasoning": "Profile type for execution tracing"
        },
        {
          "term": "CLI",
          "tier": 3,
          "reasoning": "Command Line Interface referenced for kubectl requests"
        }
      ],
      "term_count": 49,
      "generated_at": "2026-02-08T22:13:45.521254",
      "elapsed_time": 17.91709041595459
    },
    {
      "chunk_id": "concepts_security__index_sec0",
      "doc_id": "concepts_security__index",
      "heading": "Introduction",
      "source_file": "concepts_security__index.md",
      "content": "---\ntitle: \"Security\"\nweight: 85\ndescription: >\n  Concepts for keeping your cloud-native workload secure.\nsimple_list: true\n---\n\nThis section of the Kubernetes documentation aims to help you learn to run\nworkloads more securely, and about the essential aspects of keeping a\nKubernetes cluster secure.\n\nKubernetes is based on a cloud-native architecture, and draws on advice from the\n{{< glossary_tooltip text=\"CNCF\" term_id=\"cncf\" >}} about good practice for\ncloud native information security.\n\nRead [Cloud Native Security and Kubernetes](/docs/concepts/security/cloud-native-security/)\nfor the broader context about how to secure your cluster and the applications that\nyou're running on it.",
      "terms": [
        {
          "term": "Security",
          "tier": 2,
          "reasoning": "Core domain concept and the main topic of this documentation section"
        },
        {
          "term": "cloud-native",
          "tier": 2,
          "reasoning": "Architectural paradigm describing modern distributed application design patterns"
        },
        {
          "term": "workload",
          "tier": 2,
          "reasoning": "Kubernetes domain term for applications and processes running on the cluster"
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The core platform and proper noun this documentation describes"
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Fundamental Kubernetes architectural concept representing a set of nodes"
        },
        {
          "term": "cloud native information security",
          "tier": 2,
          "reasoning": "Domain-specific security concept for cloud-native architectures"
        },
        {
          "term": "CNCF",
          "tier": 1,
          "reasoning": "Proper noun acronym for Cloud Native Computing Foundation, the governing body"
        },
        {
          "term": "Cloud Native Security",
          "tier": 2,
          "reasoning": "Specific security domain concept referenced as a documentation topic"
        },
        {
          "term": "applications",
          "tier": 3,
          "reasoning": "Technical term for software running on the cluster in this context"
        },
        {
          "term": "workloads",
          "tier": 2,
          "reasoning": "Plural form of workload, Kubernetes term for running applications"
        },
        {
          "term": "cloud-native architecture",
          "tier": 2,
          "reasoning": "Architectural pattern that Kubernetes is based upon"
        },
        {
          "term": "good practice",
          "tier": 3,
          "reasoning": "Technical term in security context referring to recommended security patterns"
        }
      ],
      "term_count": 12,
      "generated_at": "2026-02-08T22:13:54.482247",
      "elapsed_time": 7.940618991851807
    },
    {
      "chunk_id": "reference_config-api_apiserver-config.v1beta1_sec2",
      "doc_id": "reference_config-api_apiserver-config.v1beta1",
      "heading": "`AuthenticationConfiguration`     {#apiserver-k8s-io-v1beta1-AuthenticationConfiguration}",
      "source_file": "reference_config-api_apiserver-config.v1beta1.md",
      "content": "<p>AuthenticationConfiguration provides versioned configuration for authentication.</p>\n\n\n<table class=\"table\">\n<thead><tr><th width=\"30%\">Field</th><th>Description</th></tr></thead>\n<tbody>\n    \n<tr><td><code>apiVersion</code><br/>string</td><td><code>apiserver.k8s.io/v1beta1</code></td></tr>\n<tr><td><code>kind</code><br/>string</td><td><code>AuthenticationConfiguration</code></td></tr>\n    \n  \n<tr><td><code>jwt</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-JWTAuthenticator\"><code>[]JWTAuthenticator</code></a>\n</td>\n<td>\n   <p>jwt is a list of authenticator to authenticate Kubernetes users using\nJWT compliant tokens. The authenticator will attempt to parse a raw ID token,\nverify it's been signed by the configured issuer. The public key to verify the\nsignature is discovered from the issuer's public endpoint using OIDC discovery.\nFor an incoming token, each JWT authenticator will be attempted in\nthe order in which it is specified in this list.  Note however that\nother authenticators may run before or after the JWT authenticators.\nThe specific position of JWT authenticators in relation to other\nauthenticators is neither defined nor stable across releases.  Since\neach JWT authenticator must have a unique issuer URL, at most one\nJWT authenticator will attempt to cryptographically validate the token.</p>\n<p>The minimum valid JWT payload must contain the following claims:\n{\n&quot;iss&quot;: &quot;https://issuer.example.com&quot;,\n&quot;aud&quot;: [&quot;audience&quot;],\n&quot;exp&quot;: 1234567890,\n&quot;<!-- raw HTML omitted -->&quot;: &quot;username&quot;\n}</p>\n</td>\n</tr>\n<tr><td><code>anonymous</code> <B>[Required]</B><br/>\n<a href=\"#apiserver-k8s-io-v1beta1-AnonymousAuthConfig\"><code>AnonymousAuthConfig</code></a>\n</td>\n<td>\n   <p>If present --anonymous-auth must not be set</p>\n</td>\n</tr>\n</tbody>\n</table>",
      "terms": [
        {
          "term": "AuthenticationConfiguration",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for configuring authentication settings."
        },
        {
          "term": "apiVersion",
          "tier": 2,
          "reasoning": "Standard Kubernetes API field specifying the API version of a resource."
        },
        {
          "term": "apiserver.k8s.io/v1beta1",
          "tier": 1,
          "reasoning": "Specific Kubernetes API group and version identifier for the apiserver configuration."
        },
        {
          "term": "kind",
          "tier": 2,
          "reasoning": "Standard Kubernetes API field specifying the type of resource."
        },
        {
          "term": "jwt",
          "tier": 2,
          "reasoning": "Field name and reference to JWT-based authentication mechanism in Kubernetes."
        },
        {
          "term": "JWTAuthenticator",
          "tier": 1,
          "reasoning": "Kubernetes API type for configuring JWT-based authentication."
        },
        {
          "term": "JWT",
          "tier": 2,
          "reasoning": "JSON Web Token - standard protocol for secure token-based authentication."
        },
        {
          "term": "authenticator",
          "tier": 2,
          "reasoning": "Component responsible for verifying user identity in Kubernetes authentication."
        },
        {
          "term": "Kubernetes users",
          "tier": 2,
          "reasoning": "Domain concept referring to authenticated entities in a Kubernetes cluster."
        },
        {
          "term": "JWT compliant tokens",
          "tier": 2,
          "reasoning": "Tokens that conform to the JWT specification for authentication."
        },
        {
          "term": "ID token",
          "tier": 2,
          "reasoning": "Specific type of token containing identity claims used in OIDC authentication."
        },
        {
          "term": "issuer",
          "tier": 2,
          "reasoning": "Entity that creates and signs tokens in JWT/OIDC authentication flow."
        },
        {
          "term": "public key",
          "tier": 2,
          "reasoning": "Cryptographic key used to verify token signatures."
        },
        {
          "term": "signature",
          "tier": 2,
          "reasoning": "Cryptographic signature used to verify token authenticity."
        },
        {
          "term": "OIDC discovery",
          "tier": 2,
          "reasoning": "OpenID Connect protocol mechanism for discovering issuer configuration."
        },
        {
          "term": "OIDC",
          "tier": 2,
          "reasoning": "OpenID Connect - authentication protocol built on OAuth 2.0."
        },
        {
          "term": "issuer URL",
          "tier": 2,
          "reasoning": "Unique URL identifying the token issuer in OIDC/JWT authentication."
        },
        {
          "term": "JWT authenticator",
          "tier": 2,
          "reasoning": "Specific authenticator type that validates JWT tokens."
        },
        {
          "term": "cryptographically validate",
          "tier": 2,
          "reasoning": "Process of verifying token integrity using cryptographic methods."
        },
        {
          "term": "JWT payload",
          "tier": 2,
          "reasoning": "The claims section of a JWT token containing authentication data."
        },
        {
          "term": "claims",
          "tier": 2,
          "reasoning": "Assertions about the subject contained in a JWT token."
        },
        {
          "term": "iss",
          "tier": 2,
          "reasoning": "Standard JWT claim identifying the token issuer."
        },
        {
          "term": "aud",
          "tier": 2,
          "reasoning": "Standard JWT claim specifying the intended audience for the token."
        },
        {
          "term": "exp",
          "tier": 2,
          "reasoning": "Standard JWT claim specifying token expiration time."
        },
        {
          "term": "username",
          "tier": 2,
          "reasoning": "Identity claim representing the authenticated user's name."
        },
        {
          "term": "anonymous",
          "tier": 2,
          "reasoning": "Field for configuring anonymous authentication in Kubernetes."
        },
        {
          "term": "AnonymousAuthConfig",
          "tier": 1,
          "reasoning": "Kubernetes API type for configuring anonymous authentication settings."
        },
        {
          "term": "--anonymous-auth",
          "tier": 1,
          "reasoning": "CLI flag for the Kubernetes API server controlling anonymous authentication."
        },
        {
          "term": "authentication",
          "tier": 2,
          "reasoning": "Core security concept for verifying user identity in Kubernetes."
        },
        {
          "term": "token",
          "tier": 2,
          "reasoning": "Credential used for authentication in Kubernetes."
        },
        {
          "term": "public endpoint",
          "tier": 2,
          "reasoning": "Network endpoint accessible for retrieving issuer configuration."
        },
        {
          "term": "v1beta1",
          "tier": 2,
          "reasoning": "Kubernetes API version indicating beta stability level."
        }
      ],
      "term_count": 32,
      "generated_at": "2026-02-08T22:14:11.371544",
      "elapsed_time": 15.86068320274353
    },
    {
      "chunk_id": "tasks_run-application_configure-pdb_sec4",
      "doc_id": "tasks_run-application_configure-pdb",
      "heading": "Think about how your application reacts to disruptions",
      "source_file": "tasks_run-application_configure-pdb.md",
      "content": "Decide how many instances can be down at the same time for a short period\ndue to a voluntary disruption.\n\n- Stateless frontends:\n  - Concern: don't reduce serving capacity by more than 10%.\n    - Solution: use PDB with minAvailable 90% for example.\n- Single-instance Stateful Application:\n  - Concern: do not terminate this application without talking to me.\n    - Possible Solution 1: Do not use a PDB and tolerate occasional downtime.\n    - Possible Solution 2: Set PDB with maxUnavailable=0. Have an understanding\n      (outside of Kubernetes) that the cluster operator needs to consult you before\n      termination. When the cluster operator contacts you, prepare for downtime,\n      and then delete the PDB to indicate readiness for disruption. Recreate afterwards.\n- Multiple-instance Stateful application such as Consul, ZooKeeper, or etcd:\n  - Concern: Do not reduce number of instances below quorum, otherwise writes fail.\n    - Possible Solution 1: set maxUnavailable to 1 (works with varying scale of application).\n    - Possible Solution 2: set minAvailable to quorum-size (e.g. 3 when scale is 5).\n      (Allows more disruptions at once).\n- Restartable Batch Job:\n  - Concern: Job needs to complete in case of voluntary disruption.\n    - Possible solution: Do not create a PDB. The Job controller will create a replacement pod.\n\n### Rounding logic when specifying percentages\n\nValues for `minAvailable` or `maxUnavailable` can be expressed as integers or as a percentage.\n\n- When you specify an integer, it represents a number of Pods. For instance, if you set\n  `minAvailable` to 10, then 10 Pods must always be available, even during a disruption.\n- When you specify a percentage by setting the value to a string representation of a\n  percentage (eg. `\"50%\"`), it represents a percentage of total Pods. For instance, if\n  you set `minAvailable` to `\"50%\"`, then at least 50% of the Pods remain available\n  during a disruption.\n\nWhen you specify the value as a percentage, it may not map to an exact number of Pods.\nFor example, if you have 7 Pods and you set `minAvailable` to `\"50%\"`, it's not\nimmediately obvious whether that means 3 Pods or 4 Pods must be available. Kubernetes\nrounds up to the nearest integer, so in this case, 4 Pods must be available. When you\nspecify the value `maxUnavailable` as a percentage, Kubernetes rounds up the number of\nPods that may be disrupted. Thereby a disruption can exceed your defined\n`maxUnavailable` percentage. You can examine the\n[code](https://github.com/kubernetes/kubernetes/blob/23be9587a0f8677eb8091464098881df939c44a9/pkg/controller/disruption/disruption.go#L539)\nthat controls this behavior.",
      "terms": [
        {
          "term": "PDB",
          "tier": 1,
          "reasoning": "Abbreviation for PodDisruptionBudget, a core Kubernetes API object for managing voluntary disruptions."
        },
        {
          "term": "Consul",
          "tier": 1,
          "reasoning": "Named distributed system/service mesh tool mentioned as example of stateful application."
        },
        {
          "term": "ZooKeeper",
          "tier": 1,
          "reasoning": "Named distributed coordination service mentioned as example of stateful application."
        },
        {
          "term": "etcd",
          "tier": 1,
          "reasoning": "Named distributed key-value store, core Kubernetes component mentioned as stateful application example."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the primary subject of this documentation."
        },
        {
          "term": "Job",
          "tier": 1,
          "reasoning": "Kubernetes API object for running batch workloads to completion."
        },
        {
          "term": "Job controller",
          "tier": 1,
          "reasoning": "Kubernetes controller component that manages Job resources and creates replacement pods."
        },
        {
          "term": "Pods",
          "tier": 1,
          "reasoning": "Core Kubernetes API object representing the smallest deployable unit."
        },
        {
          "term": "Pod",
          "tier": 1,
          "reasoning": "Singular form of the core Kubernetes resource unit."
        },
        {
          "term": "voluntary disruption",
          "tier": 2,
          "reasoning": "Domain concept describing intentional, planned disruptions to workloads."
        },
        {
          "term": "Stateless frontends",
          "tier": 2,
          "reasoning": "Architectural pattern describing frontend services without persistent state."
        },
        {
          "term": "serving capacity",
          "tier": 2,
          "reasoning": "Technical concept referring to the ability to handle incoming requests."
        },
        {
          "term": "minAvailable",
          "tier": 2,
          "reasoning": "PDB configuration parameter specifying minimum available pods during disruption."
        },
        {
          "term": "Single-instance Stateful Application",
          "tier": 2,
          "reasoning": "Application architecture pattern with single replica maintaining state."
        },
        {
          "term": "maxUnavailable",
          "tier": 2,
          "reasoning": "PDB configuration parameter specifying maximum pods that can be unavailable."
        },
        {
          "term": "cluster operator",
          "tier": 2,
          "reasoning": "Role/persona responsible for managing Kubernetes cluster operations."
        },
        {
          "term": "termination",
          "tier": 2,
          "reasoning": "Technical process of stopping/ending a pod or application instance."
        },
        {
          "term": "downtime",
          "tier": 2,
          "reasoning": "Operational concept describing period when service is unavailable."
        },
        {
          "term": "Multiple-instance Stateful application",
          "tier": 2,
          "reasoning": "Application architecture pattern with multiple replicas maintaining distributed state."
        },
        {
          "term": "quorum",
          "tier": 2,
          "reasoning": "Distributed systems concept for minimum nodes needed for consensus operations."
        },
        {
          "term": "writes",
          "tier": 2,
          "reasoning": "Database/storage operation concept in context of quorum requirements."
        },
        {
          "term": "scale",
          "tier": 2,
          "reasoning": "Technical concept referring to number of application instances/replicas."
        },
        {
          "term": "disruptions",
          "tier": 2,
          "reasoning": "Technical concept describing interruptions to normal pod operation."
        },
        {
          "term": "Restartable Batch Job",
          "tier": 2,
          "reasoning": "Workload pattern describing batch jobs that can be safely restarted."
        },
        {
          "term": "replacement pod",
          "tier": 2,
          "reasoning": "Technical concept of creating new pod to replace terminated one."
        },
        {
          "term": "Rounding logic",
          "tier": 2,
          "reasoning": "Technical behavior describing how percentage values are converted to integers."
        },
        {
          "term": "percentage",
          "tier": 2,
          "reasoning": "Configuration value type for PDB parameters as alternative to integers."
        },
        {
          "term": "integers",
          "tier": 3,
          "reasoning": "Data type used for specifying exact pod counts in PDB configuration."
        },
        {
          "term": "total Pods",
          "tier": 2,
          "reasoning": "Technical concept referring to complete count of pods in a workload."
        },
        {
          "term": "rounds up",
          "tier": 2,
          "reasoning": "Mathematical operation Kubernetes uses when converting percentages to pod counts."
        },
        {
          "term": "nearest integer",
          "tier": 3,
          "reasoning": "Mathematical concept describing rounding behavior in Kubernetes."
        },
        {
          "term": "disruption",
          "tier": 2,
          "reasoning": "Singular form of the core concept describing pod interruption events."
        },
        {
          "term": "instances",
          "tier": 2,
          "reasoning": "Technical term for individual running copies of an application."
        },
        {
          "term": "quorum-size",
          "tier": 2,
          "reasoning": "Configuration value representing minimum nodes for distributed consensus."
        },
        {
          "term": "controller",
          "tier": 2,
          "reasoning": "Kubernetes architectural component that manages resource state."
        },
        {
          "term": "string representation",
          "tier": 3,
          "reasoning": "Data format concept for expressing percentage values in configuration."
        }
      ],
      "term_count": 36,
      "generated_at": "2026-02-08T22:14:32.634428",
      "elapsed_time": 20.238314867019653
    },
    {
      "chunk_id": "reference_kubectl_generated_kubectl_create_kubectl_create_deployment_sec2",
      "doc_id": "reference_kubectl_generated_kubectl_create_kubectl_create_deployment",
      "heading": "{{% heading \"options\" %}}",
      "source_file": "reference_kubectl_generated_kubectl_create_kubectl_create_deployment.md",
      "content": "<table style=\"width: 100%; table-layout: fixed;\">\n<colgroup>\n<col span=\"1\" style=\"width: 10px;\" />\n<col span=\"1\" />\n</colgroup>\n<tbody>\n\n<tr>\n<td colspan=\"2\">--allow-missing-template-keys&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: true</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--dry-run string[=\"unchanged\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"none\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be &quot;none&quot;, &quot;server&quot;, or &quot;client&quot;. If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--field-manager string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"kubectl-create\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Name of the manager used to track field ownership.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-h, --help</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>help for deployment</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--image strings</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Image names to run. A deployment can have multiple images set for multi-container pod.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-o, --output string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Output format. One of: (json, yaml, kyaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file).</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--port int32&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: -1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>The containerPort that this deployment exposes.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">-r, --replicas int32&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: 1</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Number of replicas to create. Default is 1.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--save-config</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, the configuration of current object will be saved in its annotation. Otherwise, the annotation will be unchanged. This flag is useful when you want to perform kubectl apply on this object in the future.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--show-managed-fields</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>If true, keep the managedFields when printing objects in JSON or YAML format.</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--template string</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].</p></td>\n</tr>\n\n<tr>\n<td colspan=\"2\">--validate string[=\"strict\"]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default: \"strict\"</td>\n</tr>\n<tr>\n<td></td><td style=\"line-height: 130%; word-wrap: break-word;\"><p>Must be one of: strict (or true), warn, ignore (or false). &quot;true&quot; or &quot;strict&quot; will use a schema to validate the input and fail the request if invalid. It will perform server side validation if ServerSideFieldValidation is enabled on the api-server, but will fall back to less reliable client-side validation if not. &quot;warn&quot; will warn about unknown or duplicate fields without blocking the request if server-side field validation is enabled on the API server, and behave as &quot;ignore&quot; otherwise. &quot;false&quot; or &quot;ignore&quot; will not perform any schema validation, silently dropping any unknown or duplicate fields.</p></td>\n</tr>\n\n</tbody>\n</table>",
      "terms": [
        {
          "term": "deployment",
          "tier": 1,
          "reasoning": "Core Kubernetes API object/resource type for managing containerized applications."
        },
        {
          "term": "kubectl-create",
          "tier": 1,
          "reasoning": "Specific kubectl subcommand identifier used as default field-manager name."
        },
        {
          "term": "kubectl",
          "tier": 1,
          "reasoning": "Official Kubernetes CLI tool referenced in field-manager default value."
        },
        {
          "term": "kubectl apply",
          "tier": 1,
          "reasoning": "Specific kubectl command for declarative resource management mentioned in save-config context."
        },
        {
          "term": "pod",
          "tier": 1,
          "reasoning": "Core Kubernetes resource mentioned in context of multi-container pod deployments."
        },
        {
          "term": "multi-container pod",
          "tier": 1,
          "reasoning": "Kubernetes pattern where a pod contains multiple containers, explicitly mentioned."
        },
        {
          "term": "api-server",
          "tier": 1,
          "reasoning": "Core Kubernetes control plane component that handles API requests and validation."
        },
        {
          "term": "API server",
          "tier": 1,
          "reasoning": "Alternative form of api-server mentioned in validation context."
        },
        {
          "term": "template",
          "tier": 2,
          "reasoning": "Technical concept for output formatting using golang templates."
        },
        {
          "term": "golang templates",
          "tier": 2,
          "reasoning": "Specific templating system used for output formatting in kubectl."
        },
        {
          "term": "jsonpath",
          "tier": 2,
          "reasoning": "Query language/output format for extracting data from JSON structures."
        },
        {
          "term": "dry-run",
          "tier": 2,
          "reasoning": "Technical operation mode that simulates actions without persisting changes."
        },
        {
          "term": "server-side request",
          "tier": 2,
          "reasoning": "Technical concept describing requests processed by the API server."
        },
        {
          "term": "client strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where operations are simulated client-side only."
        },
        {
          "term": "server strategy",
          "tier": 2,
          "reasoning": "Dry-run mode where server processes request without persisting."
        },
        {
          "term": "field-manager",
          "tier": 2,
          "reasoning": "Kubernetes concept for tracking ownership of resource fields."
        },
        {
          "term": "field ownership",
          "tier": 2,
          "reasoning": "Server-side apply concept for managing which controller owns which fields."
        },
        {
          "term": "replicas",
          "tier": 2,
          "reasoning": "Kubernetes concept for number of pod instances in a deployment."
        },
        {
          "term": "containerPort",
          "tier": 2,
          "reasoning": "Kubernetes specification for ports exposed by containers."
        },
        {
          "term": "image",
          "tier": 2,
          "reasoning": "Container image concept used to specify what containers run."
        },
        {
          "term": "annotation",
          "tier": 2,
          "reasoning": "Kubernetes metadata mechanism for storing configuration data."
        },
        {
          "term": "managedFields",
          "tier": 2,
          "reasoning": "Kubernetes metadata tracking field ownership for server-side apply."
        },
        {
          "term": "schema validation",
          "tier": 2,
          "reasoning": "Process of validating resource definitions against API schemas."
        },
        {
          "term": "server-side field validation",
          "tier": 2,
          "reasoning": "API server feature for validating fields during request processing."
        },
        {
          "term": "ServerSideFieldValidation",
          "tier": 2,
          "reasoning": "Specific feature gate/capability name for server-side validation."
        },
        {
          "term": "client-side validation",
          "tier": 2,
          "reasoning": "Validation performed by kubectl before sending to server."
        },
        {
          "term": "resource",
          "tier": 2,
          "reasoning": "Core Kubernetes concept for API objects that can be created/managed."
        },
        {
          "term": "configuration",
          "tier": 2,
          "reasoning": "Technical concept for object settings saved in annotations."
        },
        {
          "term": "json",
          "tier": 3,
          "reasoning": "Data format used for output and API communication."
        },
        {
          "term": "yaml",
          "tier": 3,
          "reasoning": "Data format commonly used for Kubernetes resource definitions."
        },
        {
          "term": "kyaml",
          "tier": 3,
          "reasoning": "Kubernetes-specific YAML output format option."
        },
        {
          "term": "go-template",
          "tier": 3,
          "reasoning": "Output format using Go templating language."
        },
        {
          "term": "go-template-file",
          "tier": 3,
          "reasoning": "Output format using Go template from file."
        },
        {
          "term": "jsonpath-as-json",
          "tier": 3,
          "reasoning": "Output format combining jsonpath with JSON output."
        },
        {
          "term": "jsonpath-file",
          "tier": 3,
          "reasoning": "Output format using jsonpath expression from file."
        },
        {
          "term": "map key",
          "tier": 3,
          "reasoning": "Data structure concept relevant to template processing."
        },
        {
          "term": "object",
          "tier": 3,
          "reasoning": "Technical term for Kubernetes resource instances."
        },
        {
          "term": "strict",
          "tier": 3,
          "reasoning": "Validation mode that fails on invalid input."
        },
        {
          "term": "warn",
          "tier": 3,
          "reasoning": "Validation mode that warns but doesn't block requests."
        },
        {
          "term": "ignore",
          "tier": 3,
          "reasoning": "Validation mode that silently drops unknown fields."
        },
        {
          "term": "int32",
          "tier": 3,
          "reasoning": "Data type specification for numeric flag values."
        },
        {
          "term": "strings",
          "tier": 3,
          "reasoning": "Data type for flags accepting multiple string values."
        }
      ],
      "term_count": 42,
      "generated_at": "2026-02-08T22:14:59.539581",
      "elapsed_time": 25.885162591934204
    },
    {
      "chunk_id": "reference_kubernetes-api_workload-resources_controller-revision-v1_sec3",
      "doc_id": "reference_kubernetes-api_workload-resources_controller-revision-v1",
      "heading": "Operations {#Operations}",
      "source_file": "reference_kubernetes-api_workload-resources_controller-revision-v1.md",
      "content": "<hr>\n\n\n\n\n\n\n### `get` read the specified ControllerRevision\n\n#### HTTP Request\n\nGET /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n401: Unauthorized\n\n\n### `list` list or watch objects of kind ControllerRevision\n\n#### HTTP Request\n\nGET /apis/apps/v1/namespaces/{namespace}/controllerrevisions\n\n#### Parameters\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **allowWatchBookmarks** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#allowWatchBookmarks\" >}}\">allowWatchBookmarks</a>\n\n\n- **continue** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#continue\" >}}\">continue</a>\n\n\n- **fieldSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldSelector\" >}}\">fieldSelector</a>\n\n\n- **labelSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#labelSelector\" >}}\">labelSelector</a>\n\n\n- **limit** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#limit\" >}}\">limit</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **resourceVersion** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersion\" >}}\">resourceVersion</a>\n\n\n- **resourceVersionMatch** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersionMatch\" >}}\">resourceVersionMatch</a>\n\n\n- **sendInitialEvents** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#sendInitialEvents\" >}}\">sendInitialEvents</a>\n\n\n- **timeoutSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#timeoutSeconds\" >}}\">timeoutSeconds</a>\n\n\n- **watch** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#watch\" >}}\">watch</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevisionList\" >}}\">ControllerRevisionList</a>): OK\n\n401: Unauthorized\n\n\n### `list` list or watch objects of kind ControllerRevision\n\n#### HTTP Request\n\nGET /apis/apps/v1/controllerrevisions\n\n#### Parameters\n\n\n- **allowWatchBookmarks** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#allowWatchBookmarks\" >}}\">allowWatchBookmarks</a>\n\n\n- **continue** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#continue\" >}}\">continue</a>\n\n\n- **fieldSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldSelector\" >}}\">fieldSelector</a>\n\n\n- **labelSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#labelSelector\" >}}\">labelSelector</a>\n\n\n- **limit** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#limit\" >}}\">limit</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **resourceVersion** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersion\" >}}\">resourceVersion</a>\n\n\n- **resourceVersionMatch** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersionMatch\" >}}\">resourceVersionMatch</a>\n\n\n- **sendInitialEvents** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#sendInitialEvents\" >}}\">sendInitialEvents</a>\n\n\n- **timeoutSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#timeoutSeconds\" >}}\">timeoutSeconds</a>\n\n\n- **watch** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#watch\" >}}\">watch</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevisionList\" >}}\">ControllerRevisionList</a>): OK\n\n401: Unauthorized\n\n\n### `create` create a ControllerRevision\n\n#### HTTP Request\n\nPOST /apis/apps/v1/namespaces/{namespace}/controllerrevisions\n\n#### Parameters\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>, required\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldManager** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldManager\" >}}\">fieldManager</a>\n\n\n- **fieldValidation** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldValidation\" >}}\">fieldValidation</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n201 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Created\n\n202 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Accepted\n\n401: Unauthorized\n\n\n### `update` replace the specified ControllerRevision\n\n#### HTTP Request\n\nPUT /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>, required\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldManager** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldManager\" >}}\">fieldManager</a>\n\n\n- **fieldValidation** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldValidation\" >}}\">fieldValidation</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n201 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Created\n\n401: Unauthorized\n\n\n### `patch` partially update the specified ControllerRevision\n\n#### HTTP Request\n\nPATCH /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../common-definitions/patch#Patch\" >}}\">Patch</a>, required\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldManager** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldManager\" >}}\">fieldManager</a>\n\n\n- **fieldValidation** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldValidation\" >}}\">fieldValidation</a>\n\n\n- **force** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#force\" >}}\">force</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): OK\n\n201 (<a href=\"{{< ref \"../workload-resources/controller-revision-v1#ControllerRevision\" >}}\">ControllerRevision</a>): Created\n\n401: Unauthorized\n\n\n### `delete` delete a ControllerRevision\n\n#### HTTP Request\n\nDELETE /apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}\n\n#### Parameters\n\n\n- **name** (*in path*): string, required\n\n  name of the ControllerRevision\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../common-definitions/delete-options#DeleteOptions\" >}}\">DeleteOptions</a>\n\n  \n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **gracePeriodSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#gracePeriodSeconds\" >}}\">gracePeriodSeconds</a>\n\n\n- **ignoreStoreReadErrorWithClusterBreakingPotential** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#ignoreStoreReadErrorWithClusterBreakingPotential\" >}}\">ignoreStoreReadErrorWithClusterBreakingPotential</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **propagationPolicy** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#propagationPolicy\" >}}\">propagationPolicy</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../common-definitions/status#Status\" >}}\">Status</a>): OK\n\n202 (<a href=\"{{< ref \"../common-definitions/status#Status\" >}}\">Status</a>): Accepted\n\n401: Unauthorized\n\n\n### `deletecollection` delete collection of ControllerRevision\n\n#### HTTP Request\n\nDELETE /apis/apps/v1/namespaces/{namespace}/controllerrevisions\n\n#### Parameters\n\n\n- **namespace** (*in path*): string, required\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#namespace\" >}}\">namespace</a>\n\n\n- **body**: <a href=\"{{< ref \"../common-definitions/delete-options#DeleteOptions\" >}}\">DeleteOptions</a>\n\n  \n\n\n- **continue** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#continue\" >}}\">continue</a>\n\n\n- **dryRun** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#dryRun\" >}}\">dryRun</a>\n\n\n- **fieldSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#fieldSelector\" >}}\">fieldSelector</a>\n\n\n- **gracePeriodSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#gracePeriodSeconds\" >}}\">gracePeriodSeconds</a>\n\n\n- **ignoreStoreReadErrorWithClusterBreakingPotential** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#ignoreStoreReadErrorWithClusterBreakingPotential\" >}}\">ignoreStoreReadErrorWithClusterBreakingPotential</a>\n\n\n- **labelSelector** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#labelSelector\" >}}\">labelSelector</a>\n\n\n- **limit** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#limit\" >}}\">limit</a>\n\n\n- **pretty** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#pretty\" >}}\">pretty</a>\n\n\n- **propagationPolicy** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#propagationPolicy\" >}}\">propagationPolicy</a>\n\n\n- **resourceVersion** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersion\" >}}\">resourceVersion</a>\n\n\n- **resourceVersionMatch** (*in query*): string\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#resourceVersionMatch\" >}}\">resourceVersionMatch</a>\n\n\n- **sendInitialEvents** (*in query*): boolean\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#sendInitialEvents\" >}}\">sendInitialEvents</a>\n\n\n- **timeoutSeconds** (*in query*): integer\n\n  <a href=\"{{< ref \"../common-parameters/common-parameters#timeoutSeconds\" >}}\">timeoutSeconds</a>\n\n\n\n#### Response\n\n\n200 (<a href=\"{{< ref \"../common-definitions/status#Status\" >}}\">Status</a>): OK\n\n401: Unauthorized",
      "terms": [
        {
          "term": "ControllerRevision",
          "tier": 1,
          "reasoning": "Core Kubernetes API resource for storing revision history of controllers"
        },
        {
          "term": "ControllerRevisionList",
          "tier": 1,
          "reasoning": "Kubernetes API object representing a list of ControllerRevision resources"
        },
        {
          "term": "namespace",
          "tier": 2,
          "reasoning": "Kubernetes concept for logical isolation and scoping of resources"
        },
        {
          "term": "HTTP Request",
          "tier": 3,
          "reasoning": "Protocol method used for API communication"
        },
        {
          "term": "GET",
          "tier": 3,
          "reasoning": "HTTP method used for retrieving resources from the API"
        },
        {
          "term": "apps/v1",
          "tier": 1,
          "reasoning": "Kubernetes API group and version for application workload resources"
        },
        {
          "term": "controllerrevisions",
          "tier": 1,
          "reasoning": "API endpoint path for ControllerRevision resources"
        },
        {
          "term": "name",
          "tier": 3,
          "reasoning": "Path parameter identifying a specific resource instance"
        },
        {
          "term": "pretty",
          "tier": 2,
          "reasoning": "Common API query parameter for formatting output"
        },
        {
          "term": "allowWatchBookmarks",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for watch operation optimization"
        },
        {
          "term": "continue",
          "tier": 2,
          "reasoning": "Kubernetes API pagination parameter for list operations"
        },
        {
          "term": "fieldSelector",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for filtering resources by field values"
        },
        {
          "term": "labelSelector",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for filtering resources by labels"
        },
        {
          "term": "limit",
          "tier": 2,
          "reasoning": "Kubernetes API pagination parameter to restrict result count"
        },
        {
          "term": "resourceVersion",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for optimistic concurrency control"
        },
        {
          "term": "resourceVersionMatch",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for specifying resource version matching semantics"
        },
        {
          "term": "sendInitialEvents",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for watch operation behavior"
        },
        {
          "term": "timeoutSeconds",
          "tier": 2,
          "reasoning": "Kubernetes API parameter for request timeout configuration"
        },
        {
          "term": "watch",
          "tier": 2,
          "reasoning": "Kubernetes API parameter enabling real-time resource change notifications"
        },
        {
          "term": "in path",
          "tier": 3,
          "reasoning": "API parameter location specifier for URL path parameters"
        },
        {
          "term": "in query",
          "tier": 3,
          "reasoning": "API parameter location specifier for URL query string parameters"
        },
        {
          "term": "string",
          "tier": 3,
          "reasoning": "Data type specification for API parameters"
        },
        {
          "term": "boolean",
          "tier": 3,
          "reasoning": "Data type specification for API parameters"
        },
        {
          "term": "integer",
          "tier": 3,
          "reasoning": "Data type specification for API parameters"
        },
        {
          "term": "required",
          "tier": 3,
          "reasoning": "Parameter constraint indicating mandatory fields"
        },
        {
          "term": "Response",
          "tier": 3,
          "reasoning": "API response section describing return values"
        },
        {
          "term": "200",
          "tier": 3,
          "reasoning": "HTTP status code indicating successful response"
        },
        {
          "term": "401",
          "tier": 3,
          "reasoning": "HTTP status code indicating unauthorized access"
        },
        {
          "term": "Unauthorized",
          "tier": 2,
          "reasoning": "Authentication/authorization error response status"
        },
        {
          "term": "OK",
          "tier": 3,
          "reasoning": "HTTP response status indicating successful operation"
        },
        {
          "term": "list",
          "tier": 2,
          "reasoning": "Kubernetes API operation for retrieving multiple resources"
        },
        {
          "term": "workload-resources",
          "tier": 2,
          "reasoning": "Category of Kubernetes resources for running applications"
        },
        {
          "term": "common-parameters",
          "tier": 2,
          "reasoning": "Shared API parameters used across multiple endpoints"
        },
        {
          "term": "apis",
          "tier": 2,
          "reasoning": "Kubernetes API path prefix for API group endpoints"
        }
      ],
      "term_count": 34,
      "generated_at": "2026-02-08T22:15:15.593408",
      "elapsed_time": 15.020176887512207
    },
    {
      "chunk_id": "reference_glossary_operator-pattern_sec0",
      "doc_id": "reference_glossary_operator-pattern",
      "heading": "Introduction",
      "source_file": "reference_glossary_operator-pattern.md",
      "content": "---\ntitle: Operator pattern\nid: operator-pattern\ndate: 2019-05-21\nfull_link: /docs/concepts/extend-kubernetes/operator/\nshort_description: >\n  A specialized controller used to manage a custom resource\n\naka:\ntags:\n- architecture\n---\nThe [operator pattern](/docs/concepts/extend-kubernetes/operator/) is a system\ndesign that links a {{< glossary_tooltip term_id=\"controller\" >}} to one or more custom\nresources.\n\n<!--more-->\n\nYou can extend Kubernetes by adding controllers to your cluster, beyond the built-in\ncontrollers that come as part of Kubernetes itself.\n\nIf a running application acts as a controller and has API access to carry out tasks\nagainst a custom resource that's defined in the control plane, that's an example of\nthe Operator pattern.",
      "terms": [
        {
          "term": "operator pattern",
          "tier": 1,
          "reasoning": "Core Kubernetes architectural pattern that is the main subject of this documentation chunk."
        },
        {
          "term": "controller",
          "tier": 1,
          "reasoning": "Named Kubernetes component that is central to the operator pattern definition."
        },
        {
          "term": "custom resource",
          "tier": 1,
          "reasoning": "Named Kubernetes API object type that operators manage."
        },
        {
          "term": "custom resources",
          "tier": 1,
          "reasoning": "Plural form of the core API object type referenced multiple times in the chunk."
        },
        {
          "term": "Kubernetes",
          "tier": 1,
          "reasoning": "The container orchestration platform that is the domain context for this documentation."
        },
        {
          "term": "cluster",
          "tier": 2,
          "reasoning": "Kubernetes architectural concept referring to the set of nodes running containerized applications."
        },
        {
          "term": "control plane",
          "tier": 2,
          "reasoning": "Core Kubernetes architectural concept where custom resources are defined."
        },
        {
          "term": "controllers",
          "tier": 1,
          "reasoning": "Plural form of the named Kubernetes component that can be added to extend functionality."
        },
        {
          "term": "Operator",
          "tier": 1,
          "reasoning": "Proper noun referring to the pattern implementation, capitalized in the text."
        },
        {
          "term": "API access",
          "tier": 2,
          "reasoning": "Technical concept describing the capability needed for operators to function."
        },
        {
          "term": "API",
          "tier": 3,
          "reasoning": "General technical term for application programming interface, contextually relevant to Kubernetes."
        },
        {
          "term": "application",
          "tier": 3,
          "reasoning": "Technical term describing the running software that acts as a controller in the operator pattern."
        },
        {
          "term": "extend Kubernetes",
          "tier": 2,
          "reasoning": "Domain concept describing the extensibility mechanism that operators provide."
        },
        {
          "term": "tasks",
          "tier": 3,
          "reasoning": "Technical term describing the operations carried out against custom resources."
        }
      ],
      "term_count": 14,
      "generated_at": "2026-02-08T22:15:26.757109",
      "elapsed_time": 10.142327308654785
    }
  ]
}